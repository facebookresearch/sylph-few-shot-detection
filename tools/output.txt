coco split: base
coco split: novel
coco split: all
coco split: novel
coco split: base
coco split: novel
coco split: all
coco split: all
coco split: base
coco split: all
coco split: novel
coco split: base
coco split: all
lvis split: all
lvis split: all
lvis split: all
lvis split: basemix
lvis split: basemix
lvis split: basemix
lvis split: novelmix
lvis split: novelmix
lvis split: novelmix
lvis split: basev1
lvis split: basev1
lvis split: basev1
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: novelv1
lvis split: novelv1
lvis split: novelv1
lvis split: basev2
lvis split: basev2
lvis split: basev2
lvis split: basefc
lvis split: basefc
lvis split: basefc
lvis split: novelr
lvis split: novelr
lvis split: novelr
lvis split: cnno
lvis split: cnno
lvis split: cnno
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: novel50
lvis split: novel50
lvis split: novel50
lvis split: base50
lvis split: base50
lvis split: base50
lvis split: base100
lvis split: base100
lvis split: base100
lvis split: base150
lvis split: base150
lvis split: base150
lvis split: base200
lvis split: base200
lvis split: base200
lvis split: base250
lvis split: base250
lvis split: base250
lvis split: base300
lvis split: base300
lvis split: base300
lvis split: base350
lvis split: base350
lvis split: base350
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
lvis split: all
lvis split: all
lvis split: basemix
lvis split: basemix
lvis split: novelmix
lvis split: novelmix
lvis split: basev1
lvis split: basev1
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: novelv1
lvis split: novelv1
lvis split: basev2
lvis split: basev2
lvis split: basefc
lvis split: basefc
lvis split: novelr
lvis split: novelr
lvis split: cnno
lvis split: cnno
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: novel50
lvis split: novel50
lvis split: base50
lvis split: base50
lvis split: base100
lvis split: base100
lvis split: base150
lvis split: base150
lvis split: base200
lvis split: base200
lvis split: base250
lvis split: base250
lvis split: base300
lvis split: base300
lvis split: base350
lvis split: base350
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
tao split: base
tao split: novelpartial
tao split: novel
coco split: base
coco split: novel
coco split: all
coco split: novel
coco split: base
coco split: novel
coco split: all
coco split: all
coco split: base
coco split: all
coco split: novel
coco split: base
coco split: all
lvis split: all
lvis split: all
lvis split: all
lvis split: basemix
lvis split: basemix
lvis split: basemix
lvis split: novelmix
lvis split: novelmix
lvis split: novelmix
lvis split: basev1
lvis split: basev1
lvis split: basev1
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: novelv1
lvis split: novelv1
lvis split: novelv1
lvis split: basev2
lvis split: basev2
lvis split: basev2
lvis split: basefc
lvis split: basefc
lvis split: basefc
lvis split: novelr
lvis split: novelr
lvis split: novelr
lvis split: cnno
lvis split: cnno
lvis split: cnno
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: novel50
lvis split: novel50
lvis split: novel50
lvis split: base50
lvis split: base50
lvis split: base50
lvis split: base100
lvis split: base100
lvis split: base100
lvis split: base150
lvis split: base150
lvis split: base150
lvis split: base200
lvis split: base200
lvis split: base200
lvis split: base250
lvis split: base250
lvis split: base250
lvis split: base300
lvis split: base300
lvis split: base300
lvis split: base350
lvis split: base350
lvis split: base350
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
lvis split: all
lvis split: all
lvis split: basemix
lvis split: basemix
lvis split: novelmix
lvis split: novelmix
lvis split: basev1
lvis split: basev1
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: novelv1
lvis split: novelv1
lvis split: basev2
lvis split: basev2
lvis split: basefc
lvis split: basefc
lvis split: novelr
lvis split: novelr
lvis split: cnno
lvis split: cnno
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: novel50
lvis split: novel50
lvis split: base50
lvis split: base50
lvis split: base100
lvis split: base100
lvis split: base150
lvis split: base150
lvis split: base200
lvis split: base200
lvis split: base250
lvis split: base250
lvis split: base300
lvis split: base300
lvis split: base350
lvis split: base350
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
tao split: base
tao split: novelpartial
tao split: novel
[5m[31mWARNING[0m [32m[11/14 23:04:33 d2go.setup]: [0mOverride cfg.OUTPUT_DIR (./output) to be the same as output_dir manifold://fai4ar/tree/liyin/few-shot/meta-fcos/test/20211114230156/e2e_train
[32m[11/14 23:04:34 d2go.setup]: [0mFull config saved to manifold://fai4ar/tree/liyin/few-shot/meta-fcos/test/20211114230156/e2e_train/config.yaml
[32m[11/14 23:04:34 d2go.setup]: [0mInitializing runner ...
[32m[11/14 23:04:34 d2go.setup]: [0mUsing 4 processes per machine. Rank of current process: 0
[32m[11/14 23:04:35 d2go.setup]: [0mEnvironment info:
---------------------  -------------------------------------------------------------------------
sys.platform           linux
Python                 3.8.6 (default, Jun  4 2021, 05:16:01) [GCC 9.x 20210412 (Facebook) 10.x]
numpy                  1.19.5
detectron2             1.0.fb_internal_placeholder @/tmp/jetter.sgfu703e/detectron2
Compiler               clang 9.0.20190721
CUDA compiler          CUDA 11.0
DETECTRON2_ENV_MODULE  <not set>
PyTorch                1.11.0a0+fb @/tmp/jetter.sgfu703e/torch
PyTorch debug build    False
GPU available          No: torch.cuda.is_available() == False
Pillow                 6.2.1
torchvision            0.12.0a0+fb @/tmp/jetter.sgfu703e/torchvision
fvcore                 0.1.5
iopath                 0.1.9
cv2                    3.4.11
---------------------  -------------------------------------------------------------------------
PyTorch built with:
  - GCC 4.2
  - C++ Version: 201703
  - clang 9.0.20190721
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.8.0 (Git Hash N/A)
  - OpenMP 201107 (a.k.a. OpenMP 3.1)
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - Build settings: 

[32m[11/14 23:04:36 d2go.setup]: [0mRunning with full config:
ABNORMAL_CHECKER:
  ENABLED: False
CUDNN_BENCHMARK: False
D2GO_DATA:
  AUG_OPS:
    TEST: ['ResizeShortestEdgeOp']
    TRAIN: ['ResizeScaleOp::{"min_scale": 0.5, "max_scale": 2.0, "target_height": 1024, "target_width": 1024}', 'RandomFlipOp', 'FixedSizeCropOp::{"crop_size": [1024, 1024]}', 'RandAugmentOp::{"magnitude":9.0, "magnitude_std":0.5, "increasing":1}']
  DATASETS:
    COCO_INJECTION:
      IM_DIRS: []
      JSON_FILES: []
      KEYPOINT_METADATA: []
      NAMES: []
    DYNAMIC_DATASETS: []
    TEST_CATEGORIES: ()
    TRAIN_CATEGORIES: ()
  MAPPER:
    BACKFILL_SIZE: False
    CATCH_EXCEPTION: True
    NAME: MetalearnDatasetMapper
    RETRY: 3
  STREAM_READER:
    AUTO_ENABLED: False
    SYNCHRONIZED: True
    USE_SAMPLER: False
  TEST:
    MAX_IMAGES: 0
    SUBSET_SAMPLING: frontmost
DATALOADER:
  ASPECT_RATIO_GROUPING: False
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 8
  RANDOM_SUBSET_RATIO: 1.0
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  BASE_CLASSES_SPLIT: 
  ID_TEST: [0]
  ID_TRAIN: [0]
  NOVEL_CLASSES_SPLIT: 
  NUMS_CLASSES: [0]
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('lvis_meta_val_all', 'lvis_meta_val_basefc', 'lvis_meta_val_novelr')
  TRAIN: ('lvis_meta_train_basefc',)
  TRAIN_REPEAT_FACTOR: []
EXPORT_CAFFE2:
  USE_HEATMAP_MAX_KEYPOINT: False
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    CROP_INSTANCE: True
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  HFLIP_TRAIN: True
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    ANTI_ALIAS: False
    FREEZE: True
    FREEZE_AT: 2
    FREEZE_EXCLUDE: []
    NAME: build_fcos_resnet_fpn_backbone
  BASIS_MODULE:
    ANN_SET: coco
    COMMON_STRIDE: 8
    CONVS_DIM: 128
    IN_FEATURES: ['p3', 'p4', 'p5']
    LOSS_ON: False
    LOSS_WEIGHT: 0.3
    NAME: ProtoNet
    NORM: SyncBN
    NUM_BASES: 4
    NUM_CLASSES: 80
    NUM_CONVS: 3
  BATEXT:
    CANONICAL_SIZE: 96
    CONV_DIM: 256
    IN_FEATURES: ['p2', 'p3', 'p4']
    NUM_CHARS: 25
    NUM_CONV: 2
    POOLER_RESOLUTION: (8, 32)
    POOLER_SCALES: (0.25, 0.125, 0.0625)
    RECOGNITION_LOSS: ctc
    RECOGNIZER: attn
    SAMPLING_RATIO: 1
    VOC_SIZE: 96
  BIFPN:
    DEPTH_MULTIPLIER: 1
    NORM: bn
    NORM_ARGS: []
    SCALE_FACTOR: 1
    TOP_BLOCK_BEFORE_FPN: False
    WIDTH_DIVISOR: 8
  BLENDMASK:
    ATTN_SIZE: 14
    BOTTOM_RESOLUTION: 56
    INSTANCE_LOSS_WEIGHT: 1.0
    POOLER_SAMPLING_RATIO: 1
    POOLER_SCALES: (0.25,)
    POOLER_TYPE: ROIAlignV2
    TOP_INTERP: bilinear
    VISUALIZE: False
  BOXINST:
    BOTTOM_PIXELS_REMOVED: 10
    ENABLED: False
    PAIRWISE:
      COLOR_THRESH: 0.3
      DILATION: 2
      SIZE: 3
      WARMUP_ITERS: 10000
  BiFPN:
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    NUM_REPEATS: 6
    OUT_CHANNELS: 160
  CONDINST:
    BOTTOM_PIXELS_REMOVED: -1
    MASK_BRANCH:
      CHANNELS: 128
      IN_FEATURES: ['p3', 'p4', 'p5']
      NORM: BN
      NUM_CONVS: 4
      OUT_CHANNELS: 8
      SEMANTIC_LOSS_ON: False
    MASK_HEAD:
      CHANNELS: 8
      DISABLE_REL_COORDS: False
      NUM_LAYERS: 3
      USE_FP16: False
    MASK_OUT_STRIDE: 4
    MAX_PROPOSALS: -1
    TOPK_PROPOSALS_PER_IM: -1
  DDP_FIND_UNUSED_PARAMETERS: True
  DDP_FP16_GRAD_COMPRESS: False
  DEVICE: cpu
  DLA:
    CONV_BODY: DLA34
    NORM: FrozenBN
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    NUM_GROUPS: 32
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    STEM_IN_CHANNELS: 3
    WIDTH_DIVISOR: 1
  FBNET_V2:
    ARCH: default
    ARCH_DEF: []
    NORM: bn
    NORM_ARGS: []
    SCALE_FACTOR: 1.0
    STEM_IN_CHANNELS: 3
    WIDTH_DIVISOR: 1
  FCOS:
    BOX_QUALITY: ['ctrness']
    CENTER_SAMPLE: True
    CLS_LOGITS_KERNEL_SIZE: 1
    FPN_STRIDES: [8, 16, 32, 64, 128]
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_MASK: False
    L2_NORM_CLS_WEIGHT: False
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 866
    NUM_CLS_CONVS: 4
    NUM_SHARE_CONVS: 0
    POST_NMS_TOPK_TEST: 300
    POST_NMS_TOPK_TRAIN: 300
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    USE_DEFORMABLE: False
    USE_RELU: True
    USE_SCALE: True
    YIELD_PROPOSAL: False
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  FROZEN_LAYER_REG_EXP: []
  KEYPOINT_ON: False
  KMEANS_ANCHORS:
    DATASETS: ()
    KMEANS_ANCHORS_ON: False
    NUM_CLUSTERS: 0
    NUM_TRAINING_IMG: 0
    RNG_SEED: 3
  LOAD_PROPOSALS: False
  MASK_ON: False
  MEInst:
    AGNOSTIC: True
    CENTER_SAMPLE: True
    DIM_MASK: 60
    FLAG_PARAMETERS: False
    FPN_STRIDES: [8, 16, 32, 64, 128]
    GCN_KERNEL_SIZE: 9
    INFERENCE_TH_TEST: 0.05
    INFERENCE_TH_TRAIN: 0.05
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    LAST_DEFORMABLE: False
    LOC_LOSS_TYPE: giou
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    LOSS_ON_MASK: False
    MASK_LOSS_TYPE: mse
    MASK_ON: True
    MASK_SIZE: 28
    NMS_TH: 0.6
    NORM: GN
    NUM_BOX_CONVS: 4
    NUM_CLASSES: 80
    NUM_CLS_CONVS: 4
    NUM_MASK_CONVS: 4
    NUM_SHARE_CONVS: 0
    PATH_COMPONENTS: datasets/coco/components/coco_2017_train_class_agnosticTrue_whitenTrue_sigmoidTrue_60.npz
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 100
    POS_RADIUS: 1.5
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 1000
    PRIOR_PROB: 0.01
    SIGMOID: True
    SIZES_OF_INTEREST: [64, 128, 256, 512]
    THRESH_WITH_CTR: False
    TOP_LEVELS: 2
    TYPE_DEFORMABLE: DCNv1
    USE_DEFORMABLE: False
    USE_GCN_IN_MASK: False
    USE_RELU: True
    USE_SCALE: True
    WHITEN: True
  META_ARCHITECTURE: MetaOneStageDetector
  META_LEARN:
    BASE_EVAL_SHOT: 10
    CLASS: 3
    CODE_GENERATOR:
      ALL_MASK: False
      BIAS_LAYER: ['', '', 1]
      BOX_BIAS_LAYER: []
      BOX_CLS_LAYER: ['', '', 2]
      BOX_ON: False
      BOX_TOWER_LAYERS: []
      CLS_LAYER: ['', '', 1]
      CLS_REWEIGHT: False
      COMPRESS_CODE_W_MAX: False
      CONTRASTIVE_LOSS: 
      CONV_L2_NORM: True
      DISTILLATION_LOSS_WEIGHT: 0.0
      FREEZE: False
      HEAD:
        FC_DIM: 512
        NUM_FC: 1
        OUTPUT_DIM: 256
      INIT_NORM_LAYER: False
      IN_CHANNEL: 256
      MASK_NORM: GN
      META_BIAS: False
      META_WEIGHT: False
      NAME: CodeGenerator
      OUT_CHANNEL: 256
      POST_NORM: GN
      ROI_BOX:
        FPN_MULTILEVEL_FEATURE: False
        POOLER_RESOLUTION: 7
        POOLER_TYPE: ROIAlignV2
      SCALE_LAYER: []
      TOKENIZER:
        CONV_DIM: 256
        FC_DIM: 256
        NORM: 
        NUM_CONV: 0
        NUM_FC: 1
      TOWER_LAYERS: [['GN', 'ReLU'], ['GN', 'ReLU']]
      TRANSFORMER_ENCODER:
        DROPOUT: 0.1
        HEADS: 8
        LAYERS: 1
      USE_BIAS: True
      USE_BKG: True
      USE_DEFORMABLE: False
      USE_MASK: True
      USE_PER_CLS_SCALE: False
      WEIGHT_LAYER: []
    EPISODIC_LEARNING: True
    EVAL_SHOT: 10
    EVAL_WITH_PRETRAINED_CODE: False
    QUERY_SHOT: 1
    SHOT: 5
    USE_ALL_GTS_IN_BASE_CLASSES: False
  MOBILENET: False
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    FREEZE: False
    FREEZE_BBOX_BRANCH: True
    FREEZE_BBOX_TOWER: False
    FREEZE_CLS_LOGITS: False
    FREEZE_CLS_TOWER: False
    MIN_SIZE: 0
    NAME: MetaFCOS
    OWD: False
  RESNETS:
    DEFORM_INTERVAL: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    FREEZE: False
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    CONV_DIMS: [-1]
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  SOLOV2:
    FPN_INSTANCE_STRIDES: [8, 8, 16, 32, 32]
    FPN_SCALE_RANGES: ((1, 96), (48, 192), (96, 384), (192, 768), (384, 2048))
    INSTANCE_CHANNELS: 512
    INSTANCE_IN_CHANNELS: 256
    INSTANCE_IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    LOSS:
      DICE_WEIGHT: 3.0
      FOCAL_ALPHA: 0.25
      FOCAL_GAMMA: 2.0
      FOCAL_USE_SIGMOID: True
      FOCAL_WEIGHT: 1.0
    MASK_CHANNELS: 128
    MASK_IN_CHANNELS: 256
    MASK_IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    MASK_THR: 0.5
    MAX_PER_IMG: 100
    NMS_KERNEL: gaussian
    NMS_PRE: 500
    NMS_SIGMA: 2
    NMS_TYPE: matrix
    NORM: GN
    NUM_CLASSES: 80
    NUM_GRIDS: [40, 36, 24, 16, 12]
    NUM_INSTANCE_CONVS: 4
    NUM_KERNELS: 256
    NUM_MASKS: 256
    PRIOR_PROB: 0.01
    SCORE_THR: 0.1
    SIGMA: 0.2
    TYPE_DCN: DCN
    UPDATE_THR: 0.05
    USE_COORD_CONV: True
    USE_DCN_IN_INSTANCE: False
  SUBCLASS:
    NUM_LAYERS: 1
    NUM_SUBCLASSES: 0
    SUBCLASS_ID_FETCHER: SubclassFetcher
    SUBCLASS_MAPPING: []
    SUBCLASS_ON: False
  TFA:
    EVAL_WITH_PRETRAINED_BASE_CLS_LOGITS: False
    FINETINE: False
    TRAIN_SHOT: 10
    USE_PRETRAINED_BASE_CLS_LOGITS: False
  TOP_MODULE:
    DIM: 16
    NAME: conv
  VOVNET:
    BACKBONE_OUT_CHANNELS: 256
    CONV_BODY: V-39-eSE
    NORM: FrozenBN
    OUT_CHANNELS: 256
    OUT_FEATURES: ['stage2', 'stage3', 'stage4', 'stage5']
  VT_FPN:
    HEADS: 16
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    LAYERS: 3
    MIN_GROUP_PLANES: 64
    NORM: BN
    OUT_CHANNELS: 256
    POS_HWS: []
    POS_N_DOWNSAMPLE: []
    TOKEN_C: 1024
    TOKEN_LS: [16, 16, 8, 8]
  WEIGHTS: manifold://fai4ar/tree/liyin/few-shot/meta-fcos/test/20210827111559/e2e_train/model_final.pth
  WEIGHTS_FILTER_BY_MODULE: []
  XRAYMOBILE_V1:
    SCALE_CHANNELS: 1
MODEL_EMA:
  DECAY: 0.999
  DEVICE: 
  ENABLED: False
  USE_EMA_WEIGHTS_FOR_EVAL_ONLY: False
OUTPUT_DIR: manifold://fai4ar/tree/liyin/few-shot/meta-fcos/test/20211114230156/e2e_train
QUANTIZATION:
  BACKEND: fbgemm
  CUSTOM_QSCHEME: 
  EAGER_MODE: True
  MODULES: []
  NAME: 
  PTQ:
    CALIBRATION_FORCE_ON_GPU: False
    CALIBRATION_NUM_IMAGES: 1
  QAT:
    BATCH_SIZE_FACTOR: 1.0
    DISABLE_OBSERVER_ITER: 38000
    ENABLED: False
    ENABLE_LEARNABLE_OBSERVER_ITER: 36000
    ENABLE_OBSERVER_ITER: 35000
    FAKE_QUANT_METHOD: default
    FREEZE_BN_ITER: 37000
    START_ITER: 35000
    UPDATE_OBSERVER_STATS_PERIOD: 1
    UPDATE_OBSERVER_STATS_PERIODICALLY: False
RCNN_PREPARE_FOR_EXPORT: default_rcnn_prepare_for_export
RCNN_PREPARE_FOR_QUANT: default_rcnn_prepare_for_quant
RCNN_PREPARE_FOR_QUANT_CONVERT: default_rcnn_prepare_for_quant_convert
SEED: -1
SOLVER:
  AMP:
    ENABLED: False
  AUTO_SCALING_METHODS: ['default_scale_d2_configs', 'default_scale_quantization_configs']
  BASE_LR: 0.0005
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: norm
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 48
  LR_MULTIPLIER_OVERWRITE: []
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 30000
  MOMENTUM: 0.9
  NESTEROV: False
  OPTIMIZER: sgd
  REFERENCE_WORLD_SIZE: 16
  STEPS: (20000, 26000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: None
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TENSORBOARD:
  TEST_VIS_MAX_IMAGES: 16
  TRAIN_LOADER_VIS_MAX_IMAGES: 16
  TRAIN_LOADER_VIS_WRITE_PERIOD: 20
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
  REPEAT_TEST: 5
TURING:
  TRAIN:
    ENABLED: False
VERSION: 2
VIS_PERIOD: 0
[32m[11/14 23:04:37 d2go.setup]: [0mRunning with runner: <sylph.runner.meta_fcos_runner.MetaFCOSRunner object at 0x7f6457c75610>
[32m[11/14 23:04:37 d2go.config.config]: [0mApplying auto scaling method: default_scale_d2_configs
[32m[11/14 23:04:37 d2go.config.config]: [0mApplying auto scaling method: default_scale_quantization_configs
[32m[11/14 23:04:37 d2go.config.config]: [0mAuto-scaled the config according to the actual world size: 
| config key                             | old value      | new value       |
|:---------------------------------------|:---------------|:----------------|
| QUANTIZATION.QAT.DISABLE_OBSERVER_ITER | 38000          | 152000          |
| QUANTIZATION.QAT.ENABLE_OBSERVER_ITER  | 35000          | 140000          |
| QUANTIZATION.QAT.FREEZE_BN_ITER        | 37000          | 148000          |
| QUANTIZATION.QAT.START_ITER            | 35000          | 140000          |
| SOLVER.BASE_LR                         | 0.0005         | 0.000125        |
| SOLVER.IMS_PER_BATCH                   | 48             | 12              |
| SOLVER.MAX_ITER                        | 30000          | 120000          |
| SOLVER.REFERENCE_WORLD_SIZE            | 16             | 4               |
| SOLVER.STEPS                           | (20000, 26000) | (80000, 104000) |
| SOLVER.WARMUP_ITERS                    | 1000           | 4000            |
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f6438bbb040>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f6438bbb0b0>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f6438bbb040>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f6438bbb0b0>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f6438bbb040>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f6438bbb0b0>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f6438bbb040>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f6438bbb0b0>
init Conv2d(256, 866, kernel_size=(1, 1), stride=(1, 1)) in <generator object Module.modules at 0x7f6438bbb040>
init Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f6439882f20>
init Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f6439882f20>
init Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f6439882f20>
weight path: manifold://fai4ar/tree/liyin/few-shot/meta-fcos/test/20210827111559/e2e_train/model_final.pth
eval with clss codes path: False
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GroupNorm(32, 256, eps=1e-05, affine=True)
  (2): ReLU()
  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (4): GroupNorm(32, 256, eps=1e-05, affine=True)
  (5): ReLU()
)
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GroupNorm(32, 256, eps=1e-05, affine=True)
  (2): ReLU()
  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (4): GroupNorm(32, 256, eps=1e-05, affine=True)
  (5): ReLU()
)
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GlobalAdaptiveAvgPool2d()
)
init Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GlobalAdaptiveAvgPool2d()
)
[32m[11/14 23:04:39 d2go.tools.train_net]: [0mModel:
MetaOneStageDetector(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): MetaFCOS(
    (fcos_head): MetaFCOSHead(
      (cls_tower): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        (2): ReLU()
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        (5): ReLU()
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): GroupNorm(32, 256, eps=1e-05, affine=True)
        (8): ReLU()
        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (10): GroupNorm(32, 256, eps=1e-05, affine=True)
        (11): ReLU()
      )
      (bbox_tower): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        (2): ReLU()
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        (5): ReLU()
        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): GroupNorm(32, 256, eps=1e-05, affine=True)
        (8): ReLU()
        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (10): GroupNorm(32, 256, eps=1e-05, affine=True)
        (11): ReLU()
      )
      (share_tower): Sequential()
      (cls_logits): Conv2d(256, 866, kernel_size=(1, 1), stride=(1, 1))
      (bbox_pred): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (ctrness): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (iou_overlap): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (scales): ModuleList(
        (0): Scale()
        (1): Scale()
        (2): Scale()
        (3): Scale()
        (4): Scale()
      )
      (cond_cls_logits): CondConvBasic()
    )
    (fcos_outputs): FCOSOutputs(
      (loc_loss_func): IOULoss()
      (distill_loss_type): L1Loss()
    )
  )
  (code_generator): CodeGenerator(
    (code_generator_head): CodeGeneratorHead(
      (init_norm): ModuleList(
        (0): GroupNorm(32, 256, eps=1e-05, affine=True)
        (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        (2): GroupNorm(32, 256, eps=1e-05, affine=True)
        (3): GroupNorm(32, 256, eps=1e-05, affine=True)
        (4): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (support_set_shared_tower): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GroupNorm(32, 256, eps=1e-05, affine=True)
        (2): ReLU()
        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        (5): ReLU()
      )
      (box_pooler): ROIPooler(
        (level_poolers): ModuleList(
          (0): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
          (1): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
          (2): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
          (3): ROIAlign(output_size=(7, 7), spatial_scale=0.015625, sampling_ratio=0, aligned=True)
          (4): ROIAlign(output_size=(7, 7), spatial_scale=0.0078125, sampling_ratio=0, aligned=True)
        )
      )
      (post_norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      (support_set_cls_conv): Sequential(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GlobalAdaptiveAvgPool2d()
      )
      (support_set_cls_bias): Sequential(
        (0): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): GlobalAdaptiveAvgPool2d()
      )
      (bias_scale): Scale()
      (conv_scale): Scale()
      (contrastive_loss_criterion): CosineEmbeddingLoss()
    )
  )
)
[32m[11/14 23:04:41 d2go.utils.flop_calculator]: [0mAdded callback to log flops info after the first inference
[32m[11/14 23:04:41 d2go.optimizer.build]: [0moptimizer parameter groups:
Param group 0: {dampening: 0, lr: 0.000125, momentum: 0.9, nesterov: False, params: 23, weight_decay: 0.0001}
Param group 1: {dampening: 0, lr: 0.000125, momentum: 0.9, nesterov: False, params: 24, weight_decay: 0.0}

[32m[11/14 23:04:41 fvcore.common.checkpoint]: [0m[Checkpointer] Loading from manifold://fai4ar/tree/liyin/few-shot/meta-fcos/test/20210827111559/e2e_train/model_final.pth ...
[5m[31mWARNING[0m [32m[11/14 23:04:42 fvcore.common.checkpoint]: [0mSome model parameters or buffers are not found in the checkpoint:
[34mcode_generator.code_generator_head.bias_scale.scale[0m
[34mcode_generator.code_generator_head.conv_scale.scale[0m
[34mcode_generator.code_generator_head.init_norm.0.{bias, weight}[0m
[34mcode_generator.code_generator_head.init_norm.1.{bias, weight}[0m
[34mcode_generator.code_generator_head.init_norm.2.{bias, weight}[0m
[34mcode_generator.code_generator_head.init_norm.3.{bias, weight}[0m
[34mcode_generator.code_generator_head.init_norm.4.{bias, weight}[0m
[34mcode_generator.code_generator_head.post_norm.{bias, weight}[0m
[34mcode_generator.code_generator_head.support_set_cls_bias.0.{bias, weight}[0m
[34mcode_generator.code_generator_head.support_set_cls_conv.0.{bias, weight}[0m
[34mcode_generator.code_generator_head.support_set_shared_tower.0.{bias, weight}[0m
[34mcode_generator.code_generator_head.support_set_shared_tower.1.{bias, weight}[0m
[34mcode_generator.code_generator_head.support_set_shared_tower.3.{bias, weight}[0m
[34mcode_generator.code_generator_head.support_set_shared_tower.4.{bias, weight}[0m
[34mproposal_generator.fcos_head.iou_overlap.{bias, weight}[0m
[32m[11/14 23:06:52 d2.data.build]: [0mRemoved 828 images with no usable annotations. 99342 images left.
[32m[11/14 23:06:52 d2.data.build]: [0mRemoved 0 images with no usable annotations. 109 images left.
[32m[11/14 23:06:52 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1081 images left.
[32m[11/14 23:06:52 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3720 images left.
[32m[11/14 23:06:52 d2.data.build]: [0mRemoved 0 images with no usable annotations. 158 images left.
[32m[11/14 23:06:52 d2.data.build]: [0mRemoved 0 images with no usable annotations. 207 images left.
[32m[11/14 23:06:52 d2.data.build]: [0mRemoved 0 images with no usable annotations. 39 images left.
[32m[11/14 23:06:52 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1700 images left.
[32m[11/14 23:06:52 d2.data.build]: [0mRemoved 0 images with no usable annotations. 25 images left.
[32m[11/14 23:06:52 d2.data.build]: [0mRemoved 0 images with no usable annotations. 16 images left.
[32m[11/14 23:06:52 d2.data.build]: [0mRemoved 0 images with no usable annotations. 39 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1018 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 17451 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 881 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 36 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 85 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1112 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 293 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2722 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 136 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 969 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 67 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1048 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 163 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4270 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 447 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 42 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3907 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3947 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 8537 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 372 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 755 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1556 images left.
[32m[11/14 23:06:53 d2.data.build]: [0mRemoved 0 images with no usable annotations. 243 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 50552 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 19 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 92 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 219 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5907 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 707 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 119 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 30 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 404 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1013 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2698 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 9028 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2536 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3984 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 56 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 47 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 336 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1210 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 53 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 868 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 155 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1371 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 231 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[11/14 23:06:54 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1907 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1069 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2137 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 188 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 8085 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1242 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1227 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 203 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 590 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4369 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3683 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 589 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4374 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 57 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 96 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4566 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 777 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1025 images left.
[32m[11/14 23:06:55 d2.data.build]: [0mRemoved 0 images with no usable annotations. 311 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 22 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 11557 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 16 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 12 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 180 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 60 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 311 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 214 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 406 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 154 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3075 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 124 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 316 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1269 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 623 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2114 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 9981 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 190 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 43 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 125 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 46 images left.
[32m[11/14 23:06:56 d2.data.build]: [0mRemoved 0 images with no usable annotations. 11261 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 33353 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 113 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 439 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4194 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7969 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 15 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 53 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1144 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 359 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5308 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 89 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7855 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 88 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3219 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 118 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 17 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 6550 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 118 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 84 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 12166 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 144 images left.
[32m[11/14 23:06:57 d2.data.build]: [0mRemoved 0 images with no usable annotations. 217 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 590 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1346 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 230 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 21 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 80 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 76 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 15 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1780 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 44 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1404 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3281 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 84 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 308 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 296 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7884 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 414 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 14 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7371 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2297 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 60 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 251 images left.
[32m[11/14 23:06:58 d2.data.build]: [0mRemoved 0 images with no usable annotations. 301 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 45 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 34 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2471 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 167 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 102 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1424 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 22 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4288 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 530 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 107 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 106 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 218 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 96 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 193 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 636 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5293 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 27 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 87 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 10528 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 928 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 16 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 122 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 22 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 49 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 18049 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 231 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 51 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 206 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 33 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 15 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2387 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1035 images left.
[32m[11/14 23:06:59 d2.data.build]: [0mRemoved 0 images with no usable annotations. 49 images left.
[32m[11/14 23:07:00 d2.data.build]: [0mRemoved 0 images with no usable annotations. 37 images left.
[32m[11/14 23:07:00 d2.data.build]: [0mRemoved 0 images with no usable annotations. 911 images left.
[32m[11/14 23:07:00 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2902 images left.
[32m[11/14 23:07:00 d2.data.build]: [0mRemoved 0 images with no usable annotations. 11549 images left.
[32m[11/14 23:07:00 d2.data.build]: [0mRemoved 0 images with no usable annotations. 392 images left.
[32m[11/14 23:07:00 d2.data.build]: [0mRemoved 0 images with no usable annotations. 903 images left.
[32m[11/14 23:07:00 d2.data.build]: [0mRemoved 0 images with no usable annotations. 417 images left.
[32m[11/14 23:07:00 d2.data.build]: [0mRemoved 0 images with no usable annotations. 265 images left.
[32m[11/14 23:07:00 d2.data.build]: [0mRemoved 0 images with no usable annotations. 354 images left.
[32m[11/14 23:07:00 d2.data.build]: [0mRemoved 0 images with no usable annotations. 541 images left.
[32m[11/14 23:07:00 d2.data.build]: [0mRemoved 0 images with no usable annotations. 179 images left.
[32m[11/14 23:07:00 d2.data.build]: [0mRemoved 0 images with no usable annotations. 80 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1380 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 840 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 557 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 303 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 106 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 269 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 35 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 901 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 197 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 63 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 301 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 36 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2677 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 932 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 47 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 111 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 390 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4145 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 282 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 16 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 132 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 273 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 271 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 709 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 32 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 305 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 16 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 72 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 40 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2745 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2985 images left.
[32m[11/14 23:07:01 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4081 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1775 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1920 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 499 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 326 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 15 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1883 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 65 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 149 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 12 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 124 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 29 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 535 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 50 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 510 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1832 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 59 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 152 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 40 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 128 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 6991 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 24 images left.
[32m[11/14 23:07:02 d2.data.build]: [0mRemoved 0 images with no usable annotations. 126 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 99 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 35 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 86 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3021 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 55 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 189 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1533 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 17 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4637 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 80 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1623 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1628 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4506 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7174 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 11 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1787 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 130 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1662 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 89 images left.
[32m[11/14 23:07:03 d2.data.build]: [0mRemoved 0 images with no usable annotations. 312 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 532 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 153 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 32 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 223 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 317 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 610 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 352 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2684 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 733 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 398 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 38 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 49 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4072 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 78 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 11911 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7927 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 23 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2842 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 76 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 306 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 152 images left.
[32m[11/14 23:07:04 d2.data.build]: [0mRemoved 0 images with no usable annotations. 24 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 59 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1090 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 36 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 77 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 666 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 95 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 48 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 767 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3070 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 43 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 813 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 90 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 52 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 337 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1702 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5325 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 29 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 210 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 41 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 737 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3185 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 32 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 17 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 115 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1056 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 53 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 151 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 179 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 165 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 67 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 530 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1458 images left.
[32m[11/14 23:07:05 d2.data.build]: [0mRemoved 0 images with no usable annotations. 525 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 96 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 84 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7007 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1082 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 309 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 18 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 218 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 48 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1103 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 49 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3960 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 86 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 30 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 303 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 22 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 35 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 41 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3137 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 14 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 121 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 41 images left.
[32m[11/14 23:07:06 d2.data.build]: [0mRemoved 0 images with no usable annotations. 39 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2332 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 84 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 37 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 310 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 18 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 50 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 38 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 487 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 82 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 248 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 112 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 247 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 93 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3923 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 56 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 6420 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 59 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5951 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 842 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3202 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 14 images left.
[32m[11/14 23:07:07 d2.data.build]: [0mRemoved 0 images with no usable annotations. 25 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 413 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 6377 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 64 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 778 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2571 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1618 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 747 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 44 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 46 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 315 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1398 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 68 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 165 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 53 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1765 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 126 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 41 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 15 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 12 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 144 images left.
[32m[11/14 23:07:08 d2.data.build]: [0mRemoved 0 images with no usable annotations. 619 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 204 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 86 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 8314 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7213 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 57 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1114 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 850 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7326 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 235 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 133 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 347 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 64 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 68 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4845 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 98 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5283 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 73 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 551 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 90 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 208 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1157 images left.
[32m[11/14 23:07:09 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4744 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 610 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 70 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 18 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 196 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 180 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 26 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 77 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 172 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 38 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 24 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 8013 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 29 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2002 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5421 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 55 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 8117 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 87 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 51 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 21 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 124 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 130 images left.
[32m[11/14 23:07:10 d2.data.build]: [0mRemoved 0 images with no usable annotations. 447 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 19 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 38 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 519 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 11174 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 60 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 702 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1765 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3515 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 8432 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 975 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 226 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 68 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 618 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4139 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2234 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2475 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 364 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1065 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2852 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 702 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 154 images left.
[32m[11/14 23:07:11 d2.data.build]: [0mRemoved 0 images with no usable annotations. 331 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2168 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5500 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4392 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 524 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 689 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7075 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1134 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 69 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 29 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 22 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7363 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 59 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2029 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 41 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1379 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5638 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 16 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 240 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 401 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 126 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 445 images left.
[32m[11/14 23:07:12 d2.data.build]: [0mRemoved 0 images with no usable annotations. 186 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 501 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 58 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1595 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2985 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 114 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 354 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 139 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 57 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 174 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 243 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 167 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 435 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1105 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 227 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1046 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3490 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 156 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 108 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 122 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2955 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 166 images left.
[32m[11/14 23:07:13 d2.data.build]: [0mRemoved 0 images with no usable annotations. 985 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 720 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5247 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 269 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1832 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 333 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 352 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1785 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 6257 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 33 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3979 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2709 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4069 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 61 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1179 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 39 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 35 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 120 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 290 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 187 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 790 images left.
[32m[11/14 23:07:14 d2.data.build]: [0mRemoved 0 images with no usable annotations. 488 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 28 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 36 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 9779 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 13034 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 223 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 71 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 157 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 929 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 76 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 73 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 109 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 264 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 306 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 184 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 91 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2645 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 163 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 68 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 643 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 295 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 957 images left.
[32m[11/14 23:07:15 d2.data.build]: [0mRemoved 0 images with no usable annotations. 600 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 61 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 46 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 385 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 45 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 89 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1075 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 76 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 465 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 12 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4972 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1869 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1041 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 50 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1069 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 18 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 76 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 987 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 543 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 229 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 697 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 91 images left.
[32m[11/14 23:07:16 d2.data.build]: [0mRemoved 0 images with no usable annotations. 28 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 13439 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 103 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 194 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 138 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 126 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 632 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 838 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 228 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1850 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 6115 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1636 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 141 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4762 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 28 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 488 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4103 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1123 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5214 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 148 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 49 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 21 images left.
[32m[11/14 23:07:17 d2.data.build]: [0mRemoved 0 images with no usable annotations. 34 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 14276 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1695 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 57 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 951 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 57 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 276 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3378 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1719 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3902 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4393 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 112 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 272 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 131 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 16 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 779 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 179 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 217 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 64 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 54 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1458 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1192 images left.
[32m[11/14 23:07:18 d2.data.build]: [0mRemoved 0 images with no usable annotations. 57 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 513 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 139 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 64 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 195 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 123 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 519 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 66 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 303 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 132 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 778 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 35 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 26 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3650 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 89 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 28 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 22 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3426 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2467 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 50 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 37 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2314 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 77 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 70 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 52 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 41 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 574 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 32 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3631 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 955 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 648 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 56 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 863 images left.
[32m[11/14 23:07:19 d2.data.build]: [0mRemoved 0 images with no usable annotations. 171 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 290 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 27 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 22 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 543 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3145 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2315 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 555 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2704 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 178 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1310 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 142 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1376 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 161 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 88 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 141 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 202 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 126 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 23 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 451 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 11 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 24 images left.
[32m[11/14 23:07:20 d2.data.build]: [0mRemoved 0 images with no usable annotations. 254 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 33 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 13304 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 41 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 10177 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 9374 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 377 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 90 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5305 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 331 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 110 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 450 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 479 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 8091 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 95 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2182 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3597 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 81 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 8496 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 8124 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1727 images left.
[32m[11/14 23:07:21 d2.data.build]: [0mRemoved 0 images with no usable annotations. 8263 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1784 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 102 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 33 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 121 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2119 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 61 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 23 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 895 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 670 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 6866 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2408 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 52 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 193 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 44 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 49 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 508 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3040 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 54 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 19 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 116 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2111 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 85 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 403 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 19 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 68 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 28 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1934 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 139 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 901 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 43 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 77 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 625 images left.
[32m[11/14 23:07:22 d2.data.build]: [0mRemoved 0 images with no usable annotations. 583 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1349 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1334 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1133 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 99 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7435 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1154 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4386 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 8350 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7381 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 461 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 618 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5603 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 170 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3835 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 337 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 22 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 56 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 145 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1894 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1482 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 137 images left.
[32m[11/14 23:07:23 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3141 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 72 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2804 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 81 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2496 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7550 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 9222 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 304 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1799 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 560 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 35 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 29 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1315 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 68 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 276 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 42 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 152 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 40 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 209 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4886 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 945 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 62 images left.
[32m[11/14 23:07:24 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3725 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 117 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2205 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2835 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3035 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 33 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 49 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 153 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 320 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 224 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 31 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 67 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 45 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 62 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 421 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 70 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 587 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 125 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 240 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 114 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2295 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1683 images left.
[32m[11/14 23:07:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 12338 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 294 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 39 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1683 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 326 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 423 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 306 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 135 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 45 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2212 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 987 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 6756 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 80 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7298 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 47 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 297 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2192 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2397 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 15 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 132 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 7806 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1797 images left.
[32m[11/14 23:07:26 d2.data.build]: [0mRemoved 0 images with no usable annotations. 334 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 124 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 120 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 31 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 13 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 14 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 9161 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 164 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 381 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 81 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 38 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4971 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 65 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3370 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1313 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 228 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 33 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 61 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 121 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 209 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 21 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 100 images left.
[32m[11/14 23:07:27 d2.data.build]: [0mRemoved 0 images with no usable annotations. 3069 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 123 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 68 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2703 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1449 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 39 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 109 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 23 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 54 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 98 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 60 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 44 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 814 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 237 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 27 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 140 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 49 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2907 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 11272 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 107 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 201 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 13 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 69 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 28 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 202 images left.
[32m[11/14 23:07:28 d2.data.build]: [0mRemoved 0 images with no usable annotations. 253 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4793 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 26 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4449 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 21 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 4259 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 271 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 60 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 123 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 119 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 80 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 268 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 1330 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 50 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 116 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 20 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 5443 images left.
[32m[11/14 23:07:29 d2.data.build]: [0mRemoved 0 images with no usable annotations. 798 images left.
coco split: base
coco split: novel
coco split: all
coco split: novel
coco split: base
coco split: novel
coco split: all
coco split: all
coco split: base
coco split: all
coco split: novel
coco split: base
coco split: all
lvis split: all
lvis split: all
lvis split: all
lvis split: basemix
lvis split: basemix
lvis split: basemix
lvis split: novelmix
lvis split: novelmix
lvis split: novelmix
lvis split: basev1
lvis split: basev1
lvis split: basev1
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: novelv1
lvis split: novelv1
lvis split: novelv1
lvis split: basev2
lvis split: basev2
lvis split: basev2
lvis split: basefc
lvis split: basefc
lvis split: basefc
lvis split: novelr
lvis split: novelr
lvis split: novelr
lvis split: cnno
lvis split: cnno
lvis split: cnno
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: novel50
lvis split: novel50
lvis split: novel50
lvis split: base50
lvis split: base50
lvis split: base50
lvis split: base100
lvis split: base100
lvis split: base100
lvis split: base150
lvis split: base150
lvis split: base150
lvis split: base200
lvis split: base200
lvis split: base200
lvis split: base250
lvis split: base250
lvis split: base250
lvis split: base300
lvis split: base300
lvis split: base300
lvis split: base350
lvis split: base350
lvis split: base350
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
lvis split: all
lvis split: all
lvis split: basemix
lvis split: basemix
lvis split: novelmix
lvis split: novelmix
lvis split: basev1
lvis split: basev1
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: novelv1
lvis split: novelv1
lvis split: basev2
lvis split: basev2
lvis split: basefc
lvis split: basefc
lvis split: novelr
lvis split: novelr
lvis split: cnno
lvis split: cnno
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: novel50
lvis split: novel50
lvis split: base50
lvis split: base50
lvis split: base100
lvis split: base100
lvis split: base150
lvis split: base150
lvis split: base200
lvis split: base200
lvis split: base250
lvis split: base250
lvis split: base300
lvis split: base300
lvis split: base350
lvis split: base350
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
tao split: base
tao split: novelpartial
tao split: novel
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fe750172f90>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fe750172eb0>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fe750172f90>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fe750172eb0>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fe750172f90>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fe750172eb0>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fe750172f90>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fe750172eb0>
init Conv2d(256, 866, kernel_size=(1, 1), stride=(1, 1)) in <generator object Module.modules at 0x7fe750172f90>
init Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fe750172e40>
init Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fe750172eb0>
init Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fe750172e40>
weight path: manifold://fai4ar/tree/liyin/few-shot/meta-fcos/test/20210827111559/e2e_train/model_final.pth
eval with clss codes path: False
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GroupNorm(32, 256, eps=1e-05, affine=True)
  (2): ReLU()
  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (4): GroupNorm(32, 256, eps=1e-05, affine=True)
  (5): ReLU()
)
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GroupNorm(32, 256, eps=1e-05, affine=True)
  (2): ReLU()
  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (4): GroupNorm(32, 256, eps=1e-05, affine=True)
  (5): ReLU()
)
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GlobalAdaptiveAvgPool2d()
)
init Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GlobalAdaptiveAvgPool2d()
)
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000388217.jpg', 'height': 640, 'width': 423, 'not_exhaustive_category_ids': [854], 'neg_category_ids': [924, 259, 1189, 1192, 909, 187, 1203], 'image_id': 388217, 'annotations': [{'bbox': [110.59, 470.08, 21.65, 14.33], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 602}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000388217.jpg', 'height': 640, 'width': 423, 'not_exhaustive_category_ids': [854], 'neg_category_ids': [924, 259, 1189, 1192, 909, 187, 1203], 'image_id': 388217, 'image': tensor([[[219., 228., 235.,  ..., 248., 248., 249.],
         [218., 229., 237.,  ..., 247., 247., 248.],
         [215., 222., 228.,  ..., 247., 248., 248.],
         ...,
         [242., 242., 242.,  ...,  37.,  34.,  31.],
         [241., 241., 241.,  ...,  40.,  40.,  40.],
         [241., 240., 239.,  ...,  50.,  58.,  62.]],

        [[234., 240., 245.,  ..., 252., 252., 253.],
         [234., 241., 245.,  ..., 252., 252., 253.],
         [231., 235., 239.,  ..., 252., 252., 252.],
         ...,
         [237., 237., 236.,  ...,  12.,  10.,  10.],
         [237., 236., 236.,  ...,  13.,  13.,  14.],
         [236., 236., 235.,  ...,  16.,  19.,  23.]],

        [[188., 214., 231.,  ..., 249., 249., 248.],
         [193., 218., 235.,  ..., 248., 248., 247.],
         [176., 190., 205.,  ..., 249., 248., 247.],
         ...,
         [163., 163., 163.,  ...,   3.,   3.,   3.],
         [163., 163., 161.,  ...,   4.,   4.,   4.],
         [163., 161., 159.,  ...,   5.,   7.,   9.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[642.5286, 575.4609, 708.0927, 618.8539]])), gt_classes: tensor([602])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000353221.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [217, 25, 309], 'neg_category_ids': [712, 610, 57, 1056, 159, 209, 470], 'image_id': 353221, 'annotations': [{'bbox': [512.7, 47.13, 56.6, 76.36], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 602}]}coco split: base
coco split: novel
coco split: all
coco split: novel
coco split: base
coco split: novel
coco split: all
coco split: all
coco split: base
coco split: all
coco split: novel
coco split: base
coco split: all
lvis split: all
lvis split: all
lvis split: all
lvis split: basemix
lvis split: basemix
lvis split: basemix
lvis split: novelmix
lvis split: novelmix
lvis split: novelmix
lvis split: basev1
lvis split: basev1
lvis split: basev1
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: novelv1
lvis split: novelv1
lvis split: novelv1
lvis split: basev2
lvis split: basev2
lvis split: basev2
lvis split: basefc
lvis split: basefc
lvis split: basefc
lvis split: novelr
lvis split: novelr
lvis split: novelr
lvis split: cnno
lvis split: cnno
lvis split: cnno
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: novel50
lvis split: novel50
lvis split: novel50
lvis split: base50
lvis split: base50
lvis split: base50
lvis split: base100
lvis split: base100
lvis split: base100
lvis split: base150
lvis split: base150
lvis split: base150
lvis split: base200
lvis split: base200
lvis split: base200
lvis split: base250
lvis split: base250
lvis split: base250
lvis split: base300
lvis split: base300
lvis split: base300
lvis split: base350
lvis split: base350
lvis split: base350
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
lvis split: all
lvis split: all
lvis split: basemix
lvis split: basemix
lvis split: novelmix
lvis split: novelmix
lvis split: basev1
lvis split: basev1
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: novelv1
lvis split: novelv1
lvis split: basev2
lvis split: basev2
lvis split: basefc
lvis split: basefc
lvis split: novelr
lvis split: novelr
lvis split: cnno
lvis split: cnno
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: novel50
lvis split: novel50
lvis split: base50
lvis split: base50
lvis split: base100
lvis split: base100
lvis split: base150
lvis split: base150
lvis split: base200
lvis split: base200
lvis split: base250
lvis split: base250
lvis split: base300
lvis split: base300
lvis split: base350
lvis split: base350
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
tao split: base
tao split: novelpartial
tao split: novel
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f01c3736f90>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f01c3736eb0>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f01c3736f90>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f01c3736eb0>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f01c3736f90>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f01c3736eb0>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f01c3736f90>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f01c3736eb0>
init Conv2d(256, 866, kernel_size=(1, 1), stride=(1, 1)) in <generator object Module.modules at 0x7f01c3736f90>
init Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f01c3736e40>
init Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f01c3736eb0>
init Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7f01c3736e40>
weight path: manifold://fai4ar/tree/liyin/few-shot/meta-fcos/test/20210827111559/e2e_train/model_final.pth
eval with clss codes path: False
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GroupNorm(32, 256, eps=1e-05, affine=True)
  (2): ReLU()
  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (4): GroupNorm(32, 256, eps=1e-05, affine=True)
  (5): ReLU()
)
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GroupNorm(32, 256, eps=1e-05, affine=True)
  (2): ReLU()
  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (4): GroupNorm(32, 256, eps=1e-05, affine=True)
  (5): ReLU()
)
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GlobalAdaptiveAvgPool2d()
)
init Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GlobalAdaptiveAvgPool2d()
)
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000083254.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [948], 'neg_category_ids': [304, 508, 1035, 572, 271, 1115, 627], 'image_id': 83254, 'annotations': [{'bbox': [244.91, 266.69, 74.72, 38.64], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 761}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000083254.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [948], 'neg_category_ids': [304, 508, 1035, 572, 271, 1115, 627], 'image_id': 83254, 'image': tensor([[[ 29.,  29.,  29.,  ...,  85.,  68.,  85.],
         [ 19.,  22.,  22.,  ...,  85.,  85.,  93.],
         [ 13.,  19.,  19.,  ...,  85.,  93., 110.],
         ...,
         [110., 110., 101.,  ..., 223., 224., 224.],
         [118., 110., 101.,  ..., 221., 221., 221.],
         [127., 110., 101.,  ..., 219., 217., 214.]],

        [[ 42.,  39.,  42.,  ..., 117., 101., 109.],
         [ 34.,  37.,  39.,  ..., 117., 109., 124.],
         [ 28.,  32.,  34.,  ..., 117., 124., 132.],
         ...,
         [124., 124., 124.,  ..., 228., 229., 228.],
         [132., 124., 124.,  ..., 228., 228., 228.],
         [140., 124., 124.,  ..., 229., 228., 226.]],

        [[ 94.,  94.,  87.,  ..., 134., 117., 126.],
         [ 87.,  87.,  87.,  ..., 134., 126., 142.],
         [ 76.,  87.,  87.,  ..., 134., 142., 157.],
         ...,
         [126., 126., 109.,  ..., 232., 232., 229.],
         [134., 126., 109.,  ..., 232., 232., 226.],
         [134., 117., 101.,  ..., 235., 229., 223.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 94.8239, 507.6295, 331.8264, 630.1506]])), gt_classes: tensor([761])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000125036.jpg', 'height': 500, 'width': 333, 'not_exhaustive_category_ids': [], 'neg_category_ids': [68, 570, 191], 'image_id': 125036, 'annotations': [{'bbox': [172.63, 135.6, 55.74, 78.6], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 761}]}coco split: base
coco split: novel
coco split: all
coco split: novel
coco split: base
coco split: novel
coco split: all
coco split: all
coco split: base
coco split: all
coco split: novel
coco split: base
coco split: all
lvis split: all
lvis split: all
lvis split: all
lvis split: basemix
lvis split: basemix
lvis split: basemix
lvis split: novelmix
lvis split: novelmix
lvis split: novelmix
lvis split: basev1
lvis split: basev1
lvis split: basev1
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: novelv1
lvis split: novelv1
lvis split: novelv1
lvis split: basev2
lvis split: basev2
lvis split: basev2
lvis split: basefc
lvis split: basefc
lvis split: basefc
lvis split: novelr
lvis split: novelr
lvis split: novelr
lvis split: cnno
lvis split: cnno
lvis split: cnno
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: novel50
lvis split: novel50
lvis split: novel50
lvis split: base50
lvis split: base50
lvis split: base50
lvis split: base100
lvis split: base100
lvis split: base100
lvis split: base150
lvis split: base150
lvis split: base150
lvis split: base200
lvis split: base200
lvis split: base200
lvis split: base250
lvis split: base250
lvis split: base250
lvis split: base300
lvis split: base300
lvis split: base300
lvis split: base350
lvis split: base350
lvis split: base350
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
lvis split: all
lvis split: all
lvis split: basemix
lvis split: basemix
lvis split: novelmix
lvis split: novelmix
lvis split: basev1
lvis split: basev1
lvis split: basev1unknown
lvis split: basev1unknown
lvis split: novelv1
lvis split: novelv1
lvis split: basev2
lvis split: basev2
lvis split: basefc
lvis split: basefc
lvis split: novelr
lvis split: novelr
lvis split: cnno
lvis split: cnno
lvis split: base350wcommon
lvis split: base350wcommon
lvis split: novel50
lvis split: novel50
lvis split: base50
lvis split: base50
lvis split: base100
lvis split: base100
lvis split: base150
lvis split: base150
lvis split: base200
lvis split: base200
lvis split: base250
lvis split: base250
lvis split: base300
lvis split: base300
lvis split: base350
lvis split: base350
lvis split: base350wcommon100
lvis split: base350wcommon100
lvis split: base350wcommon200
lvis split: base350wcommon200
lvis split: base350wcommon300
lvis split: base350wcommon300
lvis split: base350wcommon400
lvis split: base350wcommon400
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare100
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare200
lvis split: base350wcommonwrare300
lvis split: base350wcommonwrare300
tao split: base
tao split: novelpartial
tao split: novel
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fd9f8df6f90>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fd9f8df6eb0>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fd9f8df6f90>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fd9f8df6eb0>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fd9f8df6f90>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fd9f8df6eb0>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fd9f8df6f90>
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fd9f8df6eb0>
init Conv2d(256, 866, kernel_size=(1, 1), stride=(1, 1)) in <generator object Module.modules at 0x7fd9f8df6f90>
init Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fd9f8df6e40>
init Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fd9f8df6eb0>
init Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in <generator object Module.modules at 0x7fd9f8df6e40>
weight path: manifold://fai4ar/tree/liyin/few-shot/meta-fcos/test/20210827111559/e2e_train/model_final.pth
eval with clss codes path: False
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GroupNorm(32, 256, eps=1e-05, affine=True)
  (2): ReLU()
  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (4): GroupNorm(32, 256, eps=1e-05, affine=True)
  (5): ReLU()
)
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GroupNorm(32, 256, eps=1e-05, affine=True)
  (2): ReLU()
  (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (4): GroupNorm(32, 256, eps=1e-05, affine=True)
  (5): ReLU()
)
init Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GlobalAdaptiveAvgPool2d()
)
init Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) in module Sequential(
  (0): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): GlobalAdaptiveAvgPool2d()
)
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000401828.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [932], 'neg_category_ids': [1095, 124, 1098, 80, 836, 1113, 620, 686], 'image_id': 401828, 'annotations': [{'bbox': [284.18, 156.24, 50.06, 56.59], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 504}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000401828.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [932], 'neg_category_ids': [1095, 124, 1098, 80, 836, 1113, 620, 686], 'image_id': 401828, 'image': tensor([[[ 81.,  82.,  83.,  ..., 128., 128., 128.],
         [ 85.,  86.,  87.,  ..., 128., 128., 128.],
         [ 88.,  88.,  89.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 83.,  84.,  85.,  ..., 128., 128., 128.],
         [ 84.,  85.,  86.,  ..., 128., 128., 128.],
         [ 85.,  85.,  86.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 88.,  89.,  89.,  ..., 128., 128., 128.],
         [ 89.,  90.,  90.,  ..., 128., 128., 128.],
         [ 91.,  90.,  91.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[436.9267, 240.2190, 513.8940, 327.2261]])), gt_classes: tensor([504])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000035642.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [942, 963, 908, 772, 138, 868, 359, 846], 'image_id': 35642, 'annotations': [{'bbox': [403.48, 194.8, 98.9, 86.36], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 504}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000125036.jpg', 'height': 500, 'width': 333, 'not_exhaustive_category_ids': [], 'neg_category_ids': [68, 570, 191], 'image_id': 125036, 'image': tensor([[[174., 180., 184.,  ..., 128., 128., 128.],
         [181., 179., 172.,  ..., 128., 128., 128.],
         [183., 172., 156.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[199., 204., 208.,  ..., 128., 128., 128.],
         [206., 203., 197.,  ..., 128., 128., 128.],
         [207., 197., 182.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[219., 224., 227.,  ..., 128., 128., 128.],
         [225., 221., 213.,  ..., 128., 128., 128.],
         [224., 212., 194.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[256.0938, 201.2304, 338.7831, 317.8728]])), gt_classes: tensor([761])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000347877.jpg', 'height': 640, 'width': 498, 'not_exhaustive_category_ids': [], 'neg_category_ids': [963, 1047, 6, 720, 248, 752, 321], 'image_id': 347877, 'annotations': [{'bbox': [126.91, 49.0, 133.14, 236.07], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 761}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000347877.jpg', 'height': 640, 'width': 498, 'not_exhaustive_category_ids': [], 'neg_category_ids': [963, 1047, 6, 720, 248, 752, 321], 'image_id': 347877, 'image': tensor([[[ 63.,  63.,  61.,  ..., 233., 233., 233.],
         [ 61.,  60.,  60.,  ..., 233., 233., 233.],
         [ 61.,  60.,  60.,  ..., 233., 233., 233.],
         ...,
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.]],

        [[ 63.,  63.,  61.,  ..., 233., 233., 233.],
         [ 61.,  60.,  60.,  ..., 233., 233., 233.],
         [ 61.,  60.,  60.,  ..., 233., 233., 233.],
         ...,
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.]],

        [[180., 180., 178.,  ..., 233., 233., 233.],
         [178., 176., 176.,  ..., 233., 233., 233.],
         [178., 176., 176.,  ..., 233., 233., 233.],
         ...,
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[341.1573,  70.2078, 532.0447, 408.4519]])), gt_classes: tensor([761])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000520799.jpg', 'height': 500, 'width': 375, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 688, 499, 1, 944, 1048, 984, 283, 1192, 241, 178, 678, 209, 1138, 996, 891], 'image_id': 520799, 'annotations': [{'bbox': [88.36, 234.02, 101.34, 226.92], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 761}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000520799.jpg', 'height': 500, 'width': 375, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 688, 499, 1, 944, 1048, 984, 283, 1192, 241, 178, 678, 209, 1138, 996, 891], 'image_id': 520799, 'image': tensor([[[114., 115., 115.,  ..., 128., 128., 128.],
         [115., 115., 114.,  ..., 128., 128., 128.],
         [115., 113., 112.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[114., 115., 115.,  ..., 128., 128., 128.],
         [115., 115., 114.,  ..., 128., 128., 128.],
         [115., 113., 112.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[114., 115., 115.,  ..., 128., 128., 128.],
         [115., 115., 114.,  ..., 128., 128., 128.],
         [115., 113., 112.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[244.5960, 308.9064, 378.3648, 608.4408]])), gt_classes: tensor([761])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000062480.jpg', 'height': 281, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [765, 130, 837, 1129, 289], 'image_id': 62480, 'annotations': [{'bbox': [242.71, 132.79, 88.28, 32.04], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 761}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000062480.jpg', 'height': 281, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [765, 130, 837, 1129, 289], 'image_id': 62480, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[513.9329, 292.5160, 708.5020, 363.0952]])), gt_classes: tensor([761])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000083254.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [948], 'neg_category_ids': [304, 508, 1035, 572, 271, 1115, 627], 'image_id': 83254, 'image': tensor([[[ 29.,  29.,  29.,  ...,  85.,  68.,  85.],
         [ 19.,  22.,  22.,  ...,  85.,  85.,  93.],
         [ 13.,  19.,  19.,  ...,  85.,  93., 110.],
         ...,
         [110., 110., 101.,  ..., 223., 224., 224.],
         [118., 110., 101.,  ..., 221., 221., 221.],
         [127., 110., 101.,  ..., 219., 217., 214.]],

        [[ 42.,  39.,  42.,  ..., 117., 101., 109.],
         [ 34.,  37.,  39.,  ..., 117., 109., 124.],
         [ 28.,  32.,  34.,  ..., 117., 124., 132.],
         ...,
         [124., 124., 124.,  ..., 228., 229., 228.],
         [132., 124., 124.,  ..., 228., 228., 228.],
         [140., 124., 124.,  ..., 229., 228., 226.]],

        [[ 94.,  94.,  87.,  ..., 134., 117., 126.],
         [ 87.,  87.,  87.,  ..., 134., 126., 142.],
         [ 76.,  87.,  87.,  ..., 134., 142., 157.],
         ...,
         [126., 126., 109.,  ..., 232., 232., 229.],
         [134., 126., 109.,  ..., 232., 232., 226.],
         [134., 117., 101.,  ..., 235., 229., 223.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 94.8239, 507.6295, 331.8264, 630.1506]])), gt_classes: tensor([761])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000125036.jpg', 'height': 500, 'width': 333, 'not_exhaustive_category_ids': [], 'neg_category_ids': [68, 570, 191], 'image_id': 125036, 'image': tensor([[[174., 180., 184.,  ..., 128., 128., 128.],
         [181., 179., 172.,  ..., 128., 128., 128.],
         [183., 172., 156.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[199., 204., 208.,  ..., 128., 128., 128.],
         [206., 203., 197.,  ..., 128., 128., 128.],
         [207., 197., 182.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[219., 224., 227.,  ..., 128., 128., 128.],
         [225., 221., 213.,  ..., 128., 128., 128.],
         [224., 212., 194.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[256.0938, 201.2304, 338.7831, 317.8728]])), gt_classes: tensor([761])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000347877.jpg', 'height': 640, 'width': 498, 'not_exhaustive_category_ids': [], 'neg_category_ids': [963, 1047, 6, 720, 248, 752, 321], 'image_id': 347877, 'image': tensor([[[ 63.,  63.,  61.,  ..., 233., 233., 233.],
         [ 61.,  60.,  60.,  ..., 233., 233., 233.],
         [ 61.,  60.,  60.,  ..., 233., 233., 233.],
         ...,
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.]],

        [[ 63.,  63.,  61.,  ..., 233., 233., 233.],
         [ 61.,  60.,  60.,  ..., 233., 233., 233.],
         [ 61.,  60.,  60.,  ..., 233., 233., 233.],
         ...,
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.]],

        [[180., 180., 178.,  ..., 233., 233., 233.],
         [178., 176., 176.,  ..., 233., 233., 233.],
         [178., 176., 176.,  ..., 233., 233., 233.],
         ...,
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[341.1573,  70.2078, 532.0447, 408.4519]])), gt_classes: tensor([761])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000520799.jpg', 'height': 500, 'width': 375, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 688, 499, 1, 944, 1048, 984, 283, 1192, 241, 178, 678, 209, 1138, 996, 891], 'image_id': 520799, 'image': tensor([[[114., 115., 115.,  ..., 128., 128., 128.],
         [115., 115., 114.,  ..., 128., 128., 128.],
         [115., 113., 112.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[114., 115., 115.,  ..., 128., 128., 128.],
         [115., 115., 114.,  ..., 128., 128., 128.],
         [115., 113., 112.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[114., 115., 115.,  ..., 128., 128., 128.],
         [115., 115., 114.,  ..., 128., 128., 128.],
         [115., 113., 112.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[244.5960, 308.9064, 378.3648, 608.4408]])), gt_classes: tensor([761])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000062480.jpg', 'height': 281, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [765, 130, 837, 1129, 289], 'image_id': 62480, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[513.9329, 292.5160, 708.5020, 363.0952]])), gt_classes: tensor([761])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000129041.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1095, 1070, 412, 363, 157, 701, 578, 17, 497], 'image_id': 129041, 'annotations_cat_set': {1060, 968, 1198, 50, 1079, 411}, 'image': tensor([[[ 92.,  92.,  91.,  ...,  83.,  83.,  82.],
         [ 92.,  92.,  91.,  ...,  83.,  83.,  82.],
         [ 91.,  91.,  91.,  ...,  84.,  83.,  83.],
         ...,
         [138., 139., 141.,  ..., 149., 149., 149.],
         [139., 140., 141.,  ..., 149., 149., 149.],
         [140., 141., 141.,  ..., 150., 150., 149.]],

        [[ 58.,  58.,  58.,  ...,  50.,  50.,  50.],
         [ 58.,  58.,  58.,  ...,  50.,  50.,  50.],
         [ 57.,  57.,  58.,  ...,  51.,  51.,  51.],
         ...,
         [101., 102., 103.,  ..., 119., 119., 118.],
         [102., 103., 103.,  ..., 119., 119., 118.],
         [103., 104., 104.,  ..., 120., 120., 119.]],

        [[ 34.,  34.,  35.,  ...,  31.,  31.,  31.],
         [ 34.,  34.,  35.,  ...,  31.,  31.,  31.],
         [ 33.,  34.,  35.,  ...,  31.,  31.,  30.],
         ...,
         [ 75.,  75.,  76.,  ...,  94.,  94.,  93.],
         [ 76.,  76.,  76.,  ...,  93.,  93.,  92.],
         [ 77.,  77.,  77.,  ...,  92.,  92.,  91.]]]), 'instances': Instances(num_instances=5, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 423.8379,   68.7440,  502.8628,  154.5275],
        [ 154.0323,    0.0000,  551.3769,  322.6285],
        [  91.3593,  275.3771,  611.2886,  530.6968],
        [   0.0000,  415.7772, 1024.0000,  948.3227],
        [ 570.3006,    0.0000,  842.5427,   86.1553]])), gt_classes: tensor([860, 743, 681,  37, 761])])}], 'support_set_target': tensor(761)}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000035642.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [942, 963, 908, 772, 138, 868, 359, 846], 'image_id': 35642, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[452.0237, 218.0665, 562.8226, 314.7412]])), gt_classes: tensor([504])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000232254.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [544], 'neg_category_ids': [1072, 605, 83, 197], 'image_id': 232254, 'annotations': [{'bbox': [314.38, 245.8, 52.37, 32.82], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 504}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000232254.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [544], 'neg_category_ids': [1072, 605, 83, 197], 'image_id': 232254, 'image': tensor([[[46., 40., 43.,  ..., 63., 63., 63.],
         [24., 22., 33.,  ..., 63., 63., 63.],
         [31., 30., 36.,  ..., 63., 63., 63.],
         ...,
         [63., 63., 63.,  ..., 63., 63., 63.],
         [63., 63., 63.,  ..., 63., 63., 63.],
         [63., 63., 63.,  ..., 63., 63., 63.]],

        [[38., 40., 41.,  ..., 51., 51., 51.],
         [19., 21., 27.,  ..., 51., 51., 51.],
         [27., 24., 24.,  ..., 51., 51., 51.],
         ...,
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.]],

        [[45., 43., 42.,  ..., 46., 46., 46.],
         [25., 24., 28.,  ..., 46., 46., 46.],
         [31., 27., 25.,  ..., 46., 46., 46.],
         ...,
         [46., 46., 46.,  ..., 46., 46., 46.],
         [46., 46., 46.,  ..., 46., 46., 46.],
         [46., 46., 46.,  ..., 46., 46., 46.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[409.9515, 320.5232, 478.2420, 363.3205]])), gt_classes: tensor([504])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000246390.jpg', 'height': 452, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [53, 1103, 770, 471, 822, 1181, 1090, 166, 1021], 'image_id': 246390, 'annotations': [{'bbox': [168.41, 133.31, 62.45, 27.93], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 504}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000246390.jpg', 'height': 452, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [53, 1103, 770, 471, 822, 1181, 1090, 166, 1021], 'image_id': 246390, 'image': tensor([[[157., 158., 158.,  ..., 214., 216., 217.],
         [157., 158., 158.,  ..., 213., 215., 218.],
         [157., 158., 158.,  ..., 212., 215., 218.],
         ...,
         [137., 135., 135.,  ..., 179., 178., 178.],
         [137., 135., 133.,  ..., 178., 178., 178.],
         [137., 134., 132.,  ..., 178., 178., 178.]],

        [[158., 159., 159.,  ...,  98., 102., 104.],
         [158., 159., 159.,  ...,  97.,  99.,  99.],
         [158., 159., 159.,  ...,  96.,  96.,  94.],
         ...,
         [127., 125., 124.,  ..., 135., 134., 133.],
         [126., 123., 122.,  ..., 134., 133., 133.],
         [125., 122., 120.,  ..., 134., 133., 133.]],

        [[202., 203., 203.,  ...,  48.,  53.,  59.],
         [202., 203., 203.,  ...,  42.,  45.,  49.],
         [202., 203., 203.,  ...,  36.,  37.,  38.],
         ...,
         [178., 175., 174.,  ...,  94.,  95.,  95.],
         [177., 175., 173.,  ...,  93.,  94.,  95.],
         [177., 174., 172.,  ...,  93.,  94.,  95.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[684.3134, 228.7961, 858.9783, 306.9012]])), gt_classes: tensor([504])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000392506.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [647, 146], 'neg_category_ids': [926, 1139, 314, 562, 163], 'image_id': 392506, 'annotations': [{'bbox': [222.39, 169.05, 43.39, 110.7], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 504}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000392506.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [647, 146], 'neg_category_ids': [926, 1139, 314, 562, 163], 'image_id': 392506, 'image': tensor([[[ 38.,  44.,  55.,  ..., 128., 128., 128.],
         [ 42.,  44.,  48.,  ..., 128., 128., 128.],
         [ 53.,  49.,  43.,  ..., 128., 128., 128.],
         ...,
         [123., 122., 119.,  ..., 128., 128., 128.],
         [128., 128., 126.,  ..., 128., 128., 128.],
         [130., 131., 131.,  ..., 128., 128., 128.]],

        [[ 51.,  57.,  71.,  ..., 128., 128., 128.],
         [ 53.,  56.,  63.,  ..., 128., 128., 128.],
         [ 62.,  61.,  57.,  ..., 128., 128., 128.],
         ...,
         [133., 138., 147.,  ..., 128., 128., 128.],
         [135., 141., 151.,  ..., 128., 128., 128.],
         [134., 140., 150.,  ..., 128., 128., 128.]],

        [[ 49.,  54.,  63.,  ..., 128., 128., 128.],
         [ 54.,  55.,  56.,  ..., 128., 128., 128.],
         [ 65.,  60.,  51.,  ..., 128., 128., 128.],
         ...,
         [131., 140., 155.,  ..., 128., 128., 128.],
         [135., 145., 162.,  ..., 128., 128., 128.],
         [137., 146., 163.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[427.5474, 201.5717, 514.1466, 422.6258]])), gt_classes: tensor([504])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000401828.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [932], 'neg_category_ids': [1095, 124, 1098, 80, 836, 1113, 620, 686], 'image_id': 401828, 'image': tensor([[[ 81.,  82.,  83.,  ..., 128., 128., 128.],
         [ 85.,  86.,  87.,  ..., 128., 128., 128.],
         [ 88.,  88.,  89.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 83.,  84.,  85.,  ..., 128., 128., 128.],
         [ 84.,  85.,  86.,  ..., 128., 128., 128.],
         [ 85.,  85.,  86.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 88.,  89.,  89.,  ..., 128., 128., 128.],
         [ 89.,  90.,  90.,  ..., 128., 128., 128.],
         [ 91.,  90.,  91.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[436.9267, 240.2190, 513.8940, 327.2261]])), gt_classes: tensor([504])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000035642.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [942, 963, 908, 772, 138, 868, 359, 846], 'image_id': 35642, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[452.0237, 218.0665, 562.8226, 314.7412]])), gt_classes: tensor([504])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000232254.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [544], 'neg_category_ids': [1072, 605, 83, 197], 'image_id': 232254, 'image': tensor([[[46., 40., 43.,  ..., 63., 63., 63.],
         [24., 22., 33.,  ..., 63., 63., 63.],
         [31., 30., 36.,  ..., 63., 63., 63.],
         ...,
         [63., 63., 63.,  ..., 63., 63., 63.],
         [63., 63., 63.,  ..., 63., 63., 63.],
         [63., 63., 63.,  ..., 63., 63., 63.]],

        [[38., 40., 41.,  ..., 51., 51., 51.],
         [19., 21., 27.,  ..., 51., 51., 51.],
         [27., 24., 24.,  ..., 51., 51., 51.],
         ...,
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.]],

        [[45., 43., 42.,  ..., 46., 46., 46.],
         [25., 24., 28.,  ..., 46., 46., 46.],
         [31., 27., 25.,  ..., 46., 46., 46.],
         ...,
         [46., 46., 46.,  ..., 46., 46., 46.],
         [46., 46., 46.,  ..., 46., 46., 46.],
         [46., 46., 46.,  ..., 46., 46., 46.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[409.9515, 320.5232, 478.2420, 363.3205]])), gt_classes: tensor([504])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000246390.jpg', 'height': 452, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [53, 1103, 770, 471, 822, 1181, 1090, 166, 1021], 'image_id': 246390, 'image': tensor([[[157., 158., 158.,  ..., 214., 216., 217.],
         [157., 158., 158.,  ..., 213., 215., 218.],
         [157., 158., 158.,  ..., 212., 215., 218.],
         ...,
         [137., 135., 135.,  ..., 179., 178., 178.],
         [137., 135., 133.,  ..., 178., 178., 178.],
         [137., 134., 132.,  ..., 178., 178., 178.]],

        [[158., 159., 159.,  ...,  98., 102., 104.],
         [158., 159., 159.,  ...,  97.,  99.,  99.],
         [158., 159., 159.,  ...,  96.,  96.,  94.],
         ...,
         [127., 125., 124.,  ..., 135., 134., 133.],
         [126., 123., 122.,  ..., 134., 133., 133.],
         [125., 122., 120.,  ..., 134., 133., 133.]],

        [[202., 203., 203.,  ...,  48.,  53.,  59.],
         [202., 203., 203.,  ...,  42.,  45.,  49.],
         [202., 203., 203.,  ...,  36.,  37.,  38.],
         ...,
         [178., 175., 174.,  ...,  94.,  95.,  95.],
         [177., 175., 173.,  ...,  93.,  94.,  95.],
         [177., 174., 172.,  ...,  93.,  94.,  95.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[684.3134, 228.7961, 858.9783, 306.9012]])), gt_classes: tensor([504])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000392506.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [647, 146], 'neg_category_ids': [926, 1139, 314, 562, 163], 'image_id': 392506, 'image': tensor([[[ 38.,  44.,  55.,  ..., 128., 128., 128.],
         [ 42.,  44.,  48.,  ..., 128., 128., 128.],
         [ 53.,  49.,  43.,  ..., 128., 128., 128.],
         ...,
         [123., 122., 119.,  ..., 128., 128., 128.],
         [128., 128., 126.,  ..., 128., 128., 128.],
         [130., 131., 131.,  ..., 128., 128., 128.]],

        [[ 51.,  57.,  71.,  ..., 128., 128., 128.],
         [ 53.,  56.,  63.,  ..., 128., 128., 128.],
         [ 62.,  61.,  57.,  ..., 128., 128., 128.],
         ...,
         [133., 138., 147.,  ..., 128., 128., 128.],
         [135., 141., 151.,  ..., 128., 128., 128.],
         [134., 140., 150.,  ..., 128., 128., 128.]],

        [[ 49.,  54.,  63.,  ..., 128., 128., 128.],
         [ 54.,  55.,  56.,  ..., 128., 128., 128.],
         [ 65.,  60.,  51.,  ..., 128., 128., 128.],
         ...,
         [131., 140., 155.,  ..., 128., 128., 128.],
         [135., 145., 162.,  ..., 128., 128., 128.],
         [137., 146., 163.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[427.5474, 201.5717, 514.1466, 422.6258]])), gt_classes: tensor([504])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000189318.jpg', 'height': 236, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [828, 102, 608, 1079, 181, 955, 704, 1039, 360, 188], 'image_id': 189318, 'annotations_cat_set': {392, 1033, 715, 716}, 'image': tensor([[[162., 165., 165.,  ..., 128., 128., 128.],
         [162., 163., 163.,  ..., 128., 128., 128.],
         [163., 164., 164.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[159., 162., 162.,  ..., 128., 128., 128.],
         [160., 161., 161.,  ..., 128., 128., 128.],
         [161., 162., 162.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[151., 154., 154.,  ..., 128., 128., 128.],
         [152., 153., 153.,  ..., 128., 128., 128.],
         [153., 154., 154.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=33, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[179.4594,  72.9268, 233.9577, 200.7381],
        [458.1314,  68.5695, 507.7655, 191.2211],
        [603.3077,  82.5107, 656.3892, 230.8717],
        [556.8642,  94.3234, 596.7701, 214.2893],
        [313.2452,  70.2856, 358.2383, 186.5183],
        [502.5891, 144.6166, 557.8237, 226.7149],
        [332.2554,  59.2753, 425.4213, 250.8641],
        [ 64.9517,  53.9707, 117.6538, 184.3452],
        [626.7581,  84.0374, 644.1396,  98.8033],
        [507.3305,  51.5190, 520.6733,  72.9602],
        [529.1521,  73.3168, 545.9980,  86.4668],
        [210.7750,  53.4581, 219.8339,  59.4313],
        [476.2157,  64.4684, 494.9359,  77.6853],
        [569.3146,  78.9669, 586.7630, 112.1205],
        [551.8550,  71.1214, 565.5773,  81.2180],
        [330.9613,  66.1178, 342.8651,  77.0724],
        [594.9851,  54.0042, 604.8250,  86.3108],
        [666.5524,  64.4016, 674.6072,  88.8739],
        [257.3859,  55.1743, 265.4965,  65.9617],
        [125.7309,  81.4074, 136.0505, 139.4680],
        [285.9347,  62.1950, 297.3029, 103.7736],
        [419.0622,  50.9953, 437.0461,  75.3339],
        [161.8437,  61.5487, 172.9777, 119.8879],
        [ 45.3725,  59.4090,  59.1727,  79.9810],
        [643.4925,  53.7590, 707.1500, 233.3791],
        [  8.7800,  50.6609,  71.4893, 252.0008],
        [221.5185,  45.8578, 276.2845, 222.2016],
        [585.3238,  45.6350, 626.0329, 220.0619],
        [ 95.8880,  71.2552, 162.5689, 232.4764],
        [434.5917,  49.9031, 475.6356, 218.8249],
        [250.5471,  55.7983, 312.3415, 229.4452],
        [135.2137,  52.0205, 189.0092, 229.1109],
        [404.5591,  51.2961, 468.1944, 175.1067]])), gt_classes: tensor([280, 280, 280, 280, 280, 280, 280, 280, 504, 504, 504, 504, 504, 504,
        504, 504, 505, 505, 505, 505, 505, 505, 505, 505, 723, 723, 723, 723,
        723, 723, 723, 723, 723])])}], 'support_set_target': tensor(504)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000401182.jpg', 'height': 640, 'width': 490, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [322, 248, 717, 613, 886, 68, 1020], 'image_id': 401182, 'annotations': [{'bbox': [143.6, 201.42, 15.89, 95.51], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 137}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000401182.jpg', 'height': 640, 'width': 490, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [322, 248, 717, 613, 886, 68, 1020], 'image_id': 401182, 'image': tensor([[[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[592.8945, 306.9824, 621.3992, 478.1542]])), gt_classes: tensor([137])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000328255.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1026, 220, 174, 900, 109, 1080, 84, 1055, 991, 1035, 889, 909, 822, 403, 359, 317, 408], 'image_id': 328255, 'annotations': [{'bbox': [104.57, 0.0, 328.55, 102.73], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 137}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000328255.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1026, 220, 174, 900, 109, 1080, 84, 1055, 991, 1035, 889, 909, 822, 403, 359, 317, 408], 'image_id': 328255, 'image': tensor([[[  7.,   5.,   4.,  ..., 128., 128., 128.],
         [  6.,   7.,   6.,  ..., 128., 128., 128.],
         [  5.,   6.,   6.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  5.,   6.,   6.,  ..., 128., 128., 128.],
         [  7.,   8.,   9.,  ..., 128., 128., 128.],
         [  9.,   9.,   9.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  4.,   4.,   4.,  ..., 128., 128., 128.],
         [  6.,   7.,   8.,  ..., 128., 128., 128.],
         [  9.,  10.,  10.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 87.7408,   0.0000, 363.4147,  86.2504]])), gt_classes: tensor([137])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000545101.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [875, 454, 830, 1098, 652, 981, 929, 768, 7, 1183, 818, 641, 273, 96, 962], 'image_id': 545101, 'annotations': [{'bbox': [135.36, 308.12, 29.11, 118.88], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 137}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000545101.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [875, 454, 830, 1098, 652, 981, 929, 768, 7, 1183, 818, 641, 273, 96, 962], 'image_id': 545101, 'image': tensor([[[104., 105., 104.,  ...,  93.,  93.,  92.],
         [104., 105., 104.,  ...,  93.,  93.,  92.],
         [104., 104., 104.,  ...,  93.,  93.,  92.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[137., 138., 137.,  ..., 134., 134., 133.],
         [137., 138., 137.,  ..., 134., 134., 133.],
         [137., 137., 137.,  ..., 134., 134., 133.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[153., 154., 153.,  ..., 157., 156., 155.],
         [153., 154., 153.,  ..., 157., 156., 155.],
         [153., 153., 153.,  ..., 157., 156., 155.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[165.9765, 534.7000, 216.5096, 741.0000]])), gt_classes: tensor([137])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000420412.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [181, 139], 'neg_category_ids': [47, 288, 698, 1178, 1038, 469, 142, 1093], 'image_id': 420412, 'annotations': [{'bbox': [68.13, 243.73, 46.84, 148.74], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 137}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000420412.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [181, 139], 'neg_category_ids': [47, 288, 698, 1178, 1038, 469, 142, 1093], 'image_id': 420412, 'image': tensor([[[  2.,   2.,   2.,  ..., 234., 233., 233.],
         [  2.,   2.,   2.,  ..., 234., 233., 233.],
         [  2.,   1.,   2.,  ..., 234., 233., 233.],
         ...,
         [219., 221., 222.,  ..., 218., 218., 218.],
         [219., 221., 223.,  ..., 219., 219., 219.],
         [219., 221., 223.,  ..., 220., 219., 219.]],

        [[  3.,   2.,   2.,  ..., 213., 213., 213.],
         [  3.,   2.,   2.,  ..., 213., 213., 213.],
         [  3.,   1.,   2.,  ..., 212., 213., 213.],
         ...,
         [197., 199., 201.,  ..., 195., 195., 195.],
         [197., 199., 201.,  ..., 196., 196., 196.],
         [197., 199., 201.,  ..., 197., 196., 196.]],

        [[  2.,   2.,   2.,  ..., 178., 178., 178.],
         [  2.,   2.,   2.,  ..., 178., 178., 178.],
         [  2.,   1.,   2.,  ..., 177., 177., 177.],
         ...,
         [172., 174., 176.,  ..., 169., 169., 169.],
         [172., 174., 176.,  ..., 170., 170., 170.],
         [172., 174., 176.,  ..., 171., 170., 170.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000134815.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [181, 139, 836], 'neg_category_ids': [254, 368, 174, 479, 856, 308, 679, 618, 528, 1180, 625, 580], 'image_id': 134815, 'annotations': [{'bbox': [206.42, 114.18, 49.73, 155.34], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 137}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000134815.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [181, 139, 836], 'neg_category_ids': [254, 368, 174, 479, 856, 308, 679, 618, 528, 1180, 625, 580], 'image_id': 134815, 'image': tensor([[[209., 205., 203.,  ..., 157., 157., 151.],
         [212., 207., 205.,  ..., 139., 136., 125.],
         [212., 209., 207.,  ..., 122., 114., 101.],
         ...,
         [ 21.,   8.,   6.,  ...,  28.,  21.,  16.],
         [ 21.,   8.,   6.,  ...,  34.,  28.,  21.],
         [ 28.,   8.,   6.,  ...,  28.,  21.,  21.]],

        [[193., 189., 185.,  ..., 160., 160., 160.],
         [195., 189., 187.,  ..., 149., 146., 141.],
         [195., 191., 189.,  ..., 139., 132., 125.],
         ...,
         [ 15.,   4.,   1.,  ...,  29.,  25.,  25.],
         [ 13.,   4.,   1.,  ...,  32.,  29.,  29.],
         [ 13.,   4.,   1.,  ...,  29.,  25.,  29.]],

        [[142., 140., 139.,  ..., 151., 150., 150.],
         [143., 140., 140.,  ..., 146., 144., 143.],
         [143., 141., 140.,  ..., 141., 139., 137.],
         ...,
         [ 22.,  10.,   3.,  ...,  53.,  51.,  49.],
         [ 21.,   9.,   3.,  ...,  55.,  53.,  51.],
         [ 21.,   9.,   3.,  ...,  53.,  51.,  51.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[811.7589, 192.6416, 957.9962, 649.2765]])), gt_classes: tensor([137])])}, len instances: 1[32m[11/14 23:07:35 d2.engine.train_loop]: [0mStarting training from iteration 0

{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000302893.jpg', 'height': 500, 'width': 375, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1144, 652, 594, 1115, 661, 320], 'image_id': 302893, 'annotations': [{'bbox': [99.9, 97.66, 63.78, 30.05], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 179}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000302893.jpg', 'height': 500, 'width': 375, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1144, 652, 594, 1115, 661, 320], 'image_id': 302893, 'image': tensor([[[128., 129., 130.,  ..., 128., 128., 128.],
         [129., 129., 130.,  ..., 128., 128., 128.],
         [130., 130., 131.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[123., 124., 125.,  ..., 128., 128., 128.],
         [124., 124., 125.,  ..., 128., 128., 128.],
         [125., 125., 126.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 98.,  99., 100.,  ..., 128., 128., 128.],
         [ 99.,  99., 100.,  ..., 128., 128., 128.],
         [100., 100., 101.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[241.1866, 111.3324, 313.9808, 145.5894]])), gt_classes: tensor([179])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116326.jpg', 'height': 465, 'width': 640, 'not_exhaustive_category_ids': [1050, 832], 'neg_category_ids': [255, 877, 882, 130, 419, 1128, 745, 1083, 619], 'image_id': 116326, 'annotations': [{'bbox': [217.35, 12.4, 92.73, 78.45], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 179}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116326.jpg', 'height': 465, 'width': 640, 'not_exhaustive_category_ids': [1050, 832], 'neg_category_ids': [255, 877, 882, 130, 419, 1128, 745, 1083, 619], 'image_id': 116326, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[243.4999,  13.8933, 347.3865, 101.7911]])), gt_classes: tensor([179])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000400048.jpg', 'height': 453, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [689, 854, 51, 899, 816, 202, 701, 312, 992, 912, 841, 12, 776, 213], 'image_id': 400048, 'annotations': [{'bbox': [295.51, 0.0, 89.56, 85.29], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 179}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000400048.jpg', 'height': 453, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [689, 854, 51, 899, 816, 202, 701, 312, 992, 912, 841, 12, 776, 213], 'image_id': 400048, 'image': tensor([[[211., 211., 210.,  ..., 105., 108., 115.],
         [211., 210., 210.,  ..., 104., 107., 114.],
         [211., 211., 211.,  ..., 103., 106., 112.],
         ...,
         [  7.,   8.,   7.,  ...,   9.,  12.,  12.],
         [  5.,   6.,   6.,  ...,  15.,  15.,  12.],
         [  4.,   4.,   6.,  ...,  20.,  17.,  12.]],

        [[168., 168., 167.,  ...,  65.,  68.,  74.],
         [168., 167., 167.,  ...,  65.,  67.,  73.],
         [168., 168., 168.,  ...,  64.,  66.,  71.],
         ...,
         [ 11.,  10.,   9.,  ...,  22.,  22.,  18.],
         [  8.,   8.,   7.,  ...,  23.,  21.,  17.],
         [  6.,   5.,   6.,  ...,  24.,  21.,  16.]],

        [[119., 119., 118.,  ...,  37.,  39.,  45.],
         [119., 118., 118.,  ...,  37.,  38.,  44.],
         [119., 119., 119.,  ...,  36.,  37.,  42.],
         ...,
         [ 13.,  14.,  13.,  ..., 204., 207., 214.],
         [ 10.,  10.,  11.,  ..., 201., 205., 213.],
         [  7.,   7.,   9.,  ..., 199., 204., 212.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[215.0688,   0.0000, 426.9341, 163.8342]])), gt_classes: tensor([179])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000455735.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1190, 814, 177], 'neg_category_ids': [688, 345, 668, 341, 196, 1189, 478, 470, 1051, 6, 133, 525, 1087, 643, 726, 471, 297, 1020, 1120], 'image_id': 455735, 'annotations': [{'bbox': [288.41, 60.79, 36.46, 67.05], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 179}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000455735.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1190, 814, 177], 'neg_category_ids': [688, 345, 668, 341, 196, 1189, 478, 470, 1051, 6, 133, 525, 1087, 643, 726, 471, 297, 1020, 1120], 'image_id': 455735, 'image': tensor([[[ 44.,  46.,  49.,  ..., 128., 128., 128.],
         [ 51.,  53.,  53.,  ..., 128., 128., 128.],
         [ 54.,  56.,  56.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 82.,  82.,  83.,  ..., 128., 128., 128.],
         [ 89.,  88.,  88.,  ..., 128., 128., 128.],
         [ 91.,  91.,  91.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[123., 125., 128.,  ..., 127., 127., 127.],
         [127., 129., 131.,  ..., 127., 127., 127.],
         [128., 130., 132.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[407.8298,  85.9925, 459.3865, 180.8403]])), gt_classes: tensor([179])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000284884.jpg', 'height': 478, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [459, 904, 227, 1086, 775, 161, 1183], 'image_id': 284884, 'annotations': [{'bbox': [420.32, 51.99, 43.68, 32.96], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 179}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000284884.jpg', 'height': 478, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [459, 904, 227, 1086, 775, 161, 1183], 'image_id': 284884, 'image': tensor([[[144., 142., 140.,  ..., 152., 154., 156.],
         [144., 142., 140.,  ..., 155., 156., 157.],
         [143., 143., 141.,  ..., 159., 159., 158.],
         ...,
         [  0.,   0.,   2.,  ...,  29.,  30.,  32.],
         [  1.,   2.,   3.,  ...,  28.,  29.,  28.],
         [  1.,   2.,   3.,  ...,  29.,  29.,  28.]],

        [[151., 149., 147.,  ..., 154., 156., 158.],
         [151., 149., 147.,  ..., 157., 158., 159.],
         [150., 148., 148.,  ..., 161., 161., 160.],
         ...,
         [ 56.,  55.,  55.,  ...,  73.,  74.,  74.],
         [ 54.,  55.,  56.,  ...,  72.,  73.,  72.],
         [ 56.,  55.,  56.,  ...,  73.,  73.,  72.]],

        [[140., 138., 136.,  ..., 179., 181., 183.],
         [140., 138., 136.,  ..., 182., 183., 184.],
         [139., 137., 137.,  ..., 186., 186., 185.],
         ...,
         [134., 135., 135.,  ..., 157., 158., 158.],
         [134., 135., 136.,  ..., 156., 157., 156.],
         [134., 135., 136.,  ..., 157., 157., 156.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000353221.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [217, 25, 309], 'neg_category_ids': [712, 610, 57, 1056, 159, 209, 470], 'image_id': 353221, 'image': tensor([[[250., 252., 245.,  ..., 128., 128., 128.],
         [251., 252., 252.,  ..., 128., 128., 128.],
         [251., 252., 182.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[252., 255., 247.,  ..., 128., 128., 128.],
         [251., 253., 252.,  ..., 128., 128., 128.],
         [248., 252., 184.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[253., 253., 247.,  ..., 128., 128., 128.],
         [251., 251., 252.,  ..., 128., 128., 128.],
         [250., 252., 181.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[503.8880,  46.3200, 559.5151, 121.3675]])), gt_classes: tensor([602])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000388217.jpg', 'height': 640, 'width': 423, 'not_exhaustive_category_ids': [854], 'neg_category_ids': [924, 259, 1189, 1192, 909, 187, 1203], 'image_id': 388217, 'annotations': [{'bbox': [210.35, 466.62, 16.62, 14.4], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 602}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000388217.jpg', 'height': 640, 'width': 423, 'not_exhaustive_category_ids': [854], 'neg_category_ids': [924, 259, 1189, 1192, 909, 187, 1203], 'image_id': 388217, 'image': tensor([[[185., 185., 185.,  ..., 176., 176., 176.],
         [185., 185., 185.,  ..., 176., 176., 176.],
         [185., 185., 185.,  ..., 176., 176., 176.],
         ...,
         [ 68.,  71.,  74.,  ...,  11.,  10.,   8.],
         [ 56.,  64.,  70.,  ...,  12.,  12.,  13.],
         [ 47.,  56.,  62.,  ...,  12.,  14.,  16.]],

        [[185., 185., 185.,  ..., 188., 188., 188.],
         [185., 185., 185.,  ..., 188., 188., 188.],
         [185., 185., 185.,  ..., 188., 188., 188.],
         ...,
         [ 84.,  89.,  94.,  ...,  22.,  22.,  21.],
         [ 71.,  80.,  90.,  ...,  21.,  22.,  22.],
         [ 60.,  70.,  79.,  ...,  22.,  23.,  23.]],

        [[185., 185., 185.,  ..., 194., 194., 194.],
         [185., 185., 185.,  ..., 194., 194., 194.],
         [185., 185., 185.,  ..., 194., 194., 194.],
         ...,
         [181., 184., 186.,  ..., 121., 118., 114.],
         [174., 181., 186.,  ..., 119., 119., 120.],
         [167., 175., 179.,  ..., 109., 115., 119.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[473.7942, 818.3862, 514.3029, 853.4862]])), gt_classes: tensor([602])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000353221.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [217, 25, 309], 'neg_category_ids': [712, 610, 57, 1056, 159, 209, 470], 'image_id': 353221, 'annotations': [{'bbox': [564.37, 2.58, 24.76, 6.14], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 602}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000353221.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [217, 25, 309], 'neg_category_ids': [712, 610, 57, 1056, 159, 209, 470], 'image_id': 353221, 'image': tensor([[[255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255.,  86.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]],

        [[255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255.,  84.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]],

        [[255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 189.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[46.1804,  2.3422, 68.6579,  7.9161]])), gt_classes: tensor([602])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000355360.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [771, 387], 'neg_category_ids': [603, 669, 172, 502, 156, 700, 953, 207, 355, 526, 276], 'image_id': 355360, 'annotations': [{'bbox': [376.08, 35.0, 23.96, 28.14], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 602}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000355360.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [771, 387], 'neg_category_ids': [603, 669, 172, 502, 156, 700, 953, 207, 355, 526, 276], 'image_id': 355360, 'image': tensor([[[ 98.,  97.,  97.,  ..., 128., 128., 128.],
         [ 97.,  97.,  97.,  ..., 128., 128., 128.],
         [ 97.,  97.,  98.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[114., 113., 113.,  ..., 128., 128., 128.],
         [112., 111., 112.,  ..., 128., 128., 128.],
         [113., 113., 113.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[127., 126., 126.,  ..., 128., 128., 128.],
         [127., 127., 126.,  ..., 128., 128., 128.],
         [130., 130., 129.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[438.9559,  40.9016, 466.9217,  73.7866]])), gt_classes: tensor([602])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000388217.jpg', 'height': 640, 'width': 423, 'not_exhaustive_category_ids': [854], 'neg_category_ids': [924, 259, 1189, 1192, 909, 187, 1203], 'image_id': 388217, 'image': tensor([[[219., 228., 235.,  ..., 248., 248., 249.],
         [218., 229., 237.,  ..., 247., 247., 248.],
         [215., 222., 228.,  ..., 247., 248., 248.],
         ...,
         [242., 242., 242.,  ...,  37.,  34.,  31.],
         [241., 241., 241.,  ...,  40.,  40.,  40.],
         [241., 240., 239.,  ...,  50.,  58.,  62.]],

        [[234., 240., 245.,  ..., 252., 252., 253.],
         [234., 241., 245.,  ..., 252., 252., 253.],
         [231., 235., 239.,  ..., 252., 252., 252.],
         ...,
         [237., 237., 236.,  ...,  12.,  10.,  10.],
         [237., 236., 236.,  ...,  13.,  13.,  14.],
         [236., 236., 235.,  ...,  16.,  19.,  23.]],

        [[188., 214., 231.,  ..., 249., 249., 248.],
         [193., 218., 235.,  ..., 248., 248., 247.],
         [176., 190., 205.,  ..., 249., 248., 247.],
         ...,
         [163., 163., 163.,  ...,   3.,   3.,   3.],
         [163., 163., 161.,  ...,   4.,   4.,   4.],
         [163., 161., 159.,  ...,   5.,   7.,   9.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[642.5286, 575.4609, 708.0927, 618.8539]])), gt_classes: tensor([602])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000353221.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [217, 25, 309], 'neg_category_ids': [712, 610, 57, 1056, 159, 209, 470], 'image_id': 353221, 'image': tensor([[[250., 252., 245.,  ..., 128., 128., 128.],
         [251., 252., 252.,  ..., 128., 128., 128.],
         [251., 252., 182.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[252., 255., 247.,  ..., 128., 128., 128.],
         [251., 253., 252.,  ..., 128., 128., 128.],
         [248., 252., 184.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[253., 253., 247.,  ..., 128., 128., 128.],
         [251., 251., 252.,  ..., 128., 128., 128.],
         [250., 252., 181.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[503.8880,  46.3200, 559.5151, 121.3675]])), gt_classes: tensor([602])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000388217.jpg', 'height': 640, 'width': 423, 'not_exhaustive_category_ids': [854], 'neg_category_ids': [924, 259, 1189, 1192, 909, 187, 1203], 'image_id': 388217, 'image': tensor([[[185., 185., 185.,  ..., 176., 176., 176.],
         [185., 185., 185.,  ..., 176., 176., 176.],
         [185., 185., 185.,  ..., 176., 176., 176.],
         ...,
         [ 68.,  71.,  74.,  ...,  11.,  10.,   8.],
         [ 56.,  64.,  70.,  ...,  12.,  12.,  13.],
         [ 47.,  56.,  62.,  ...,  12.,  14.,  16.]],

        [[185., 185., 185.,  ..., 188., 188., 188.],
         [185., 185., 185.,  ..., 188., 188., 188.],
         [185., 185., 185.,  ..., 188., 188., 188.],
         ...,
         [ 84.,  89.,  94.,  ...,  22.,  22.,  21.],
         [ 71.,  80.,  90.,  ...,  21.,  22.,  22.],
         [ 60.,  70.,  79.,  ...,  22.,  23.,  23.]],

        [[185., 185., 185.,  ..., 194., 194., 194.],
         [185., 185., 185.,  ..., 194., 194., 194.],
         [185., 185., 185.,  ..., 194., 194., 194.],
         ...,
         [181., 184., 186.,  ..., 121., 118., 114.],
         [174., 181., 186.,  ..., 119., 119., 120.],
         [167., 175., 179.,  ..., 109., 115., 119.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[473.7942, 818.3862, 514.3029, 853.4862]])), gt_classes: tensor([602])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000353221.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [217, 25, 309], 'neg_category_ids': [712, 610, 57, 1056, 159, 209, 470], 'image_id': 353221, 'image': tensor([[[255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255.,  86.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]],

        [[255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255.,  84.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]],

        [[255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 189.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[46.1804,  2.3422, 68.6579,  7.9161]])), gt_classes: tensor([602])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000355360.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [771, 387], 'neg_category_ids': [603, 669, 172, 502, 156, 700, 953, 207, 355, 526, 276], 'image_id': 355360, 'image': tensor([[[ 98.,  97.,  97.,  ..., 128., 128., 128.],
         [ 97.,  97.,  97.,  ..., 128., 128., 128.],
         [ 97.,  97.,  98.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[114., 113., 113.,  ..., 128., 128., 128.],
         [112., 111., 112.,  ..., 128., 128., 128.],
         [113., 113., 113.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[127., 126., 126.,  ..., 128., 128., 128.],
         [127., 127., 126.,  ..., 128., 128., 128.],
         [130., 130., 129.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[438.9559,  40.9016, 466.9217,  73.7866]])), gt_classes: tensor([602])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000388217.jpg', 'height': 640, 'width': 423, 'not_exhaustive_category_ids': [854], 'neg_category_ids': [924, 259, 1189, 1192, 909, 187, 1203], 'image_id': 388217, 'annotations_cat_set': {1008, 854, 959}, 'image': tensor([[[189., 189., 189.,  ..., 105., 105., 105.],
         [189., 189., 189.,  ..., 105., 105., 105.],
         [189., 189., 189.,  ..., 105., 105., 105.],
         ...,
         [ 38.,  51.,  65.,  ..., 105., 105., 105.],
         [ 55.,  64.,  75.,  ..., 105., 105., 105.],
         [ 79.,  74.,  67.,  ..., 105., 105., 105.]],

        [[180., 180., 180.,  ...,  99.,  99.,  99.],
         [180., 180., 180.,  ...,  99.,  99.,  99.],
         [180., 180., 180.,  ...,  99.,  99.,  99.],
         ...,
         [ 20.,  29.,  44.,  ...,  99.,  99.,  99.],
         [ 38.,  47.,  58.,  ...,  99.,  99.,  99.],
         [ 63.,  58.,  47.,  ...,  99.,  99.,  99.]],

        [[135., 135., 135.,  ...,  55.,  55.,  55.],
         [135., 135., 135.,  ...,  55.,  55.,  55.],
         [135., 135., 135.,  ...,  55.,  55.,  55.],
         ...,
         [  9.,  14.,  21.,  ...,  55.,  55.,  55.],
         [ 18.,  22.,  27.,  ...,  55.,  55.,  55.],
         [ 31.,  28.,  22.,  ...,  55.,  55.,  55.]]]), 'instances': Instances(num_instances=732, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[250.5092, 262.9834, 447.7529, 785.8769],
        [ 16.7381, 550.1644,  53.4528, 687.7087],
        [ 81.9691, 507.8758,  88.9745, 516.5276],
        ...,
        [413.3392, 283.4380, 424.5378, 292.6689],
        [199.0165, 280.9174, 209.3798, 288.7517],
        [609.1342, 743.9289, 629.7245, 754.7437]])), gt_classes: tensor([707, 672, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602, 602,
        602, 602, 602, 602])])}], 'support_set_target': tensor(602)}
0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000302893.jpg', 'height': 500, 'width': 375, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1144, 652, 594, 1115, 661, 320], 'image_id': 302893, 'image': tensor([[[128., 129., 130.,  ..., 128., 128., 128.],
         [129., 129., 130.,  ..., 128., 128., 128.],
         [130., 130., 131.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[123., 124., 125.,  ..., 128., 128., 128.],
         [124., 124., 125.,  ..., 128., 128., 128.],
         [125., 125., 126.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 98.,  99., 100.,  ..., 128., 128., 128.],
         [ 99.,  99., 100.,  ..., 128., 128., 128.],
         [100., 100., 101.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[241.1866, 111.3324, 313.9808, 145.5894]])), gt_classes: tensor([179])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116326.jpg', 'height': 465, 'width': 640, 'not_exhaustive_category_ids': [1050, 832], 'neg_category_ids': [255, 877, 882, 130, 419, 1128, 745, 1083, 619], 'image_id': 116326, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[243.4999,  13.8933, 347.3865, 101.7911]])), gt_classes: tensor([179])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000400048.jpg', 'height': 453, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [689, 854, 51, 899, 816, 202, 701, 312, 992, 912, 841, 12, 776, 213], 'image_id': 400048, 'image': tensor([[[211., 211., 210.,  ..., 105., 108., 115.],
         [211., 210., 210.,  ..., 104., 107., 114.],
         [211., 211., 211.,  ..., 103., 106., 112.],
         ...,
         [  7.,   8.,   7.,  ...,   9.,  12.,  12.],
         [  5.,   6.,   6.,  ...,  15.,  15.,  12.],
         [  4.,   4.,   6.,  ...,  20.,  17.,  12.]],

        [[168., 168., 167.,  ...,  65.,  68.,  74.],
         [168., 167., 167.,  ...,  65.,  67.,  73.],
         [168., 168., 168.,  ...,  64.,  66.,  71.],
         ...,
         [ 11.,  10.,   9.,  ...,  22.,  22.,  18.],
         [  8.,   8.,   7.,  ...,  23.,  21.,  17.],
         [  6.,   5.,   6.,  ...,  24.,  21.,  16.]],

        [[119., 119., 118.,  ...,  37.,  39.,  45.],
         [119., 118., 118.,  ...,  37.,  38.,  44.],
         [119., 119., 119.,  ...,  36.,  37.,  42.],
         ...,
         [ 13.,  14.,  13.,  ..., 204., 207., 214.],
         [ 10.,  10.,  11.,  ..., 201., 205., 213.],
         [  7.,   7.,   9.,  ..., 199., 204., 212.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[215.0688,   0.0000, 426.9341, 163.8342]])), gt_classes: tensor([179])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000455735.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1190, 814, 177], 'neg_category_ids': [688, 345, 668, 341, 196, 1189, 478, 470, 1051, 6, 133, 525, 1087, 643, 726, 471, 297, 1020, 1120], 'image_id': 455735, 'image': tensor([[[ 44.,  46.,  49.,  ..., 128., 128., 128.],
         [ 51.,  53.,  53.,  ..., 128., 128., 128.],
         [ 54.,  56.,  56.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 82.,  82.,  83.,  ..., 128., 128., 128.],
         [ 89.,  88.,  88.,  ..., 128., 128., 128.],
         [ 91.,  91.,  91.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[123., 125., 128.,  ..., 127., 127., 127.],
         [127., 129., 131.,  ..., 127., 127., 127.],
         [128., 130., 132.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[407.8298,  85.9925, 459.3865, 180.8403]])), gt_classes: tensor([179])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000400048.jpg', 'height': 453, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [689, 854, 51, 899, 816, 202, 701, 312, 992, 912, 841, 12, 776, 213], 'image_id': 400048, 'image': tensor([[[211., 211., 210.,  ..., 105., 108., 115.],
         [211., 210., 210.,  ..., 104., 107., 114.],
         [211., 211., 211.,  ..., 103., 106., 112.],
         ...,
         [  7.,   8.,   7.,  ...,   9.,  12.,  12.],
         [  5.,   6.,   6.,  ...,  15.,  15.,  12.],
         [  4.,   4.,   6.,  ...,  20.,  17.,  12.]],

        [[168., 168., 167.,  ...,  65.,  68.,  74.],
         [168., 167., 167.,  ...,  65.,  67.,  73.],
         [168., 168., 168.,  ...,  64.,  66.,  71.],
         ...,
         [ 11.,  10.,   9.,  ...,  22.,  22.,  18.],
         [  8.,   8.,   7.,  ...,  23.,  21.,  17.],
         [  6.,   5.,   6.,  ...,  24.,  21.,  16.]],

        [[119., 119., 118.,  ...,  37.,  39.,  45.],
         [119., 118., 118.,  ...,  37.,  38.,  44.],
         [119., 119., 119.,  ...,  36.,  37.,  42.],
         ...,
         [ 13.,  14.,  13.,  ..., 204., 207., 214.],
         [ 10.,  10.,  11.,  ..., 201., 205., 213.],
         [  7.,   7.,   9.,  ..., 199., 204., 212.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[215.0688,   0.0000, 426.9341, 163.8342]])), gt_classes: tensor([179])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000541587.jpg', 'height': 640, 'width': 425, 'not_exhaustive_category_ids': [], 'neg_category_ids': [47, 628, 981, 77, 174, 1172, 858, 1192, 639, 799, 844, 707, 781], 'image_id': 541587, 'annotations_cat_set': {1139, 748, 461, 235}, 'image': tensor([[[ 52.,  51.,  51.,  ...,  90.,  90.,  90.],
         [ 50.,  51.,  51.,  ...,  90.,  90.,  90.],
         [ 49.,  51.,  52.,  ...,  90.,  90.,  90.],
         ...,
         [ 90.,  90.,  90.,  ...,  90.,  90.,  90.],
         [ 90.,  90.,  90.,  ...,  90.,  90.,  90.],
         [ 90.,  90.,  90.,  ...,  90.,  90.,  90.]],

        [[ 57.,  57.,  57.,  ...,  63.,  63.,  63.],
         [ 56.,  58.,  58.,  ...,  63.,  63.,  63.],
         [ 58.,  59.,  60.,  ...,  63.,  63.,  63.],
         ...,
         [ 63.,  63.,  63.,  ...,  63.,  63.,  63.],
         [ 63.,  63.,  63.,  ...,  63.,  63.,  63.],
         [ 63.,  63.,  63.,  ...,  63.,  63.,  63.]],

        [[195., 192., 190.,  ...,  42.,  42.,  42.],
         [193., 193., 193.,  ...,  42.,  42.,  42.],
         [195., 198., 199.,  ...,  42.,  42.,  42.],
         ...,
         [ 42.,  42.,  42.,  ...,  42.,  42.,  42.],
         [ 42.,  42.,  42.,  ...,  42.,  42.,  42.],
         [ 42.,  42.,  42.,  ...,  42.,  42.,  42.]]]), 'instances': Instances(num_instances=11, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1.5668e+02, 4.4341e+01, 4.6159e+02, 3.1974e+02],
        [3.3481e+02, 6.9340e+02, 3.7499e+02, 7.9673e+02],
        [4.8705e+02, 5.1182e+02, 5.5117e+02, 5.5721e+02],
        [3.3277e+02, 2.8566e+02, 6.1285e+02, 4.1712e+02],
        [1.3342e+02, 0.0000e+00, 5.0950e+02, 1.7332e+02],
        [2.1190e+01, 2.9349e+02, 1.6367e+02, 4.1928e+02],
        [1.3110e+02, 5.1587e+02, 1.7423e+02, 5.5886e+02],
        [5.3628e-01, 4.0122e+01, 8.4501e+01, 1.4381e+02],
        [5.6214e+02, 2.1156e+01, 6.1581e+02, 1.3121e+02],
        [2.3134e+02, 5.8190e+02, 3.4397e+02, 9.2629e+02],
        [5.3005e+01, 2.5535e+02, 4.8668e+02, 9.1395e+02]])), gt_classes: tensor([179, 179, 531, 531, 531, 531, 531, 531, 531, 812, 328])])}], 'support_set_target': tensor(179)}
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000401182.jpg', 'height': 640, 'width': 490, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [322, 248, 717, 613, 886, 68, 1020], 'image_id': 401182, 'image': tensor([[[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[592.8945, 306.9824, 621.3992, 478.1542]])), gt_classes: tensor([137])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000328255.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1026, 220, 174, 900, 109, 1080, 84, 1055, 991, 1035, 889, 909, 822, 403, 359, 317, 408], 'image_id': 328255, 'image': tensor([[[  7.,   5.,   4.,  ..., 128., 128., 128.],
         [  6.,   7.,   6.,  ..., 128., 128., 128.],
         [  5.,   6.,   6.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  5.,   6.,   6.,  ..., 128., 128., 128.],
         [  7.,   8.,   9.,  ..., 128., 128., 128.],
         [  9.,   9.,   9.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  4.,   4.,   4.,  ..., 128., 128., 128.],
         [  6.,   7.,   8.,  ..., 128., 128., 128.],
         [  9.,  10.,  10.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 87.7408,   0.0000, 363.4147,  86.2504]])), gt_classes: tensor([137])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000545101.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [875, 454, 830, 1098, 652, 981, 929, 768, 7, 1183, 818, 641, 273, 96, 962], 'image_id': 545101, 'image': tensor([[[104., 105., 104.,  ...,  93.,  93.,  92.],
         [104., 105., 104.,  ...,  93.,  93.,  92.],
         [104., 104., 104.,  ...,  93.,  93.,  92.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[137., 138., 137.,  ..., 134., 134., 133.],
         [137., 138., 137.,  ..., 134., 134., 133.],
         [137., 137., 137.,  ..., 134., 134., 133.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[153., 154., 153.,  ..., 157., 156., 155.],
         [153., 154., 153.,  ..., 157., 156., 155.],
         [153., 153., 153.,  ..., 157., 156., 155.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[165.9765, 534.7000, 216.5096, 741.0000]])), gt_classes: tensor([137])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000134815.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [181, 139, 836], 'neg_category_ids': [254, 368, 174, 479, 856, 308, 679, 618, 528, 1180, 625, 580], 'image_id': 134815, 'image': tensor([[[209., 205., 203.,  ..., 157., 157., 151.],
         [212., 207., 205.,  ..., 139., 136., 125.],
         [212., 209., 207.,  ..., 122., 114., 101.],
         ...,
         [ 21.,   8.,   6.,  ...,  28.,  21.,  16.],
         [ 21.,   8.,   6.,  ...,  34.,  28.,  21.],
         [ 28.,   8.,   6.,  ...,  28.,  21.,  21.]],

        [[193., 189., 185.,  ..., 160., 160., 160.],
         [195., 189., 187.,  ..., 149., 146., 141.],
         [195., 191., 189.,  ..., 139., 132., 125.],
         ...,
         [ 15.,   4.,   1.,  ...,  29.,  25.,  25.],
         [ 13.,   4.,   1.,  ...,  32.,  29.,  29.],
         [ 13.,   4.,   1.,  ...,  29.,  25.,  29.]],

        [[142., 140., 139.,  ..., 151., 150., 150.],
         [143., 140., 140.,  ..., 146., 144., 143.],
         [143., 141., 140.,  ..., 141., 139., 137.],
         ...,
         [ 22.,  10.,   3.,  ...,  53.,  51.,  49.],
         [ 21.,   9.,   3.,  ...,  55.,  53.,  51.],
         [ 21.,   9.,   3.,  ...,  53.,  51.,  51.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[811.7589, 192.6416, 957.9962, 649.2765]])), gt_classes: tensor([137])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000134815.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [181, 139, 836], 'neg_category_ids': [254, 368, 174, 479, 856, 308, 679, 618, 528, 1180, 625, 580], 'image_id': 134815, 'image': tensor([[[209., 205., 203.,  ..., 157., 157., 151.],
         [212., 207., 205.,  ..., 139., 136., 125.],
         [212., 209., 207.,  ..., 122., 114., 101.],
         ...,
         [ 21.,   8.,   6.,  ...,  28.,  21.,  16.],
         [ 21.,   8.,   6.,  ...,  34.,  28.,  21.],
         [ 28.,   8.,   6.,  ...,  28.,  21.,  21.]],

        [[193., 189., 185.,  ..., 160., 160., 160.],
         [195., 189., 187.,  ..., 149., 146., 141.],
         [195., 191., 189.,  ..., 139., 132., 125.],
         ...,
         [ 15.,   4.,   1.,  ...,  29.,  25.,  25.],
         [ 13.,   4.,   1.,  ...,  32.,  29.,  29.],
         [ 13.,   4.,   1.,  ...,  29.,  25.,  29.]],

        [[142., 140., 139.,  ..., 151., 150., 150.],
         [143., 140., 140.,  ..., 146., 144., 143.],
         [143., 141., 140.,  ..., 141., 139., 137.],
         ...,
         [ 22.,  10.,   3.,  ...,  53.,  51.,  49.],
         [ 21.,   9.,   3.,  ...,  55.,  53.,  51.],
         [ 21.,   9.,   3.,  ...,  53.,  51.,  51.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[811.7589, 192.6416, 957.9962, 649.2765]])), gt_classes: tensor([137])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000268067.jpg', 'height': 457, 'width': 640, 'not_exhaustive_category_ids': [181, 617], 'neg_category_ids': [279, 476, 196, 200, 131, 132, 1173, 1056, 158, 704, 619, 1181, 622], 'image_id': 268067, 'annotations_cat_set': {708, 1095, 1160, 617, 372, 181, 1021}, 'image': tensor([[[255., 255., 255.,  ...,  39.,  39.,  40.],
         [255., 255., 255.,  ...,  38.,  39.,  40.],
         [255., 255., 255.,  ...,  39.,  41.,  43.],
         ...,
         [ 46.,  46.,  46.,  ...,  92.,  92.,  93.],
         [ 45.,  46.,  46.,  ...,  92.,  93.,  95.],
         [ 44.,  45.,  46.,  ...,  92.,  95.,  97.]],

        [[255., 255., 255.,  ...,  85.,  86.,  86.],
         [255., 255., 255.,  ...,  85.,  86.,  86.],
         [255., 255., 255.,  ...,  86.,  87.,  87.],
         ...,
         [ 95.,  96.,  97.,  ..., 131., 134., 135.],
         [ 94.,  95.,  96.,  ..., 131., 133., 135.],
         [ 93.,  94.,  95.,  ..., 130., 133., 134.]],

        [[255., 255., 255.,  ..., 132., 133., 133.],
         [255., 255., 255.,  ..., 133., 134., 134.],
         [255., 255., 255.,  ..., 134., 136., 137.],
         ...,
         [145., 146., 147.,  ..., 172., 173., 174.],
         [144., 145., 146.,  ..., 171., 172., 173.],
         [143., 144., 145.,  ..., 169., 171., 172.]]]), 'instances': Instances(num_instances=30, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 480.5651,  395.4236,  514.4206,  445.7266],
        [ 476.5468,  294.4022,  514.6746,  342.1888],
        [ 363.2027,  308.6689,  405.0948,  360.8649],
        [ 524.1661,  443.1641,  557.3287,  481.8090],
        [ 423.7776,  301.3740,  463.3141,  349.2760],
        [ 393.9405,  304.0980,  434.2852,  354.4010],
        [ 479.2026,  438.2008,  528.0458,  491.7818],
        [ 451.0744,  297.5880,  490.3107,  348.1910],
        [ 123.1893,  600.6061,  199.6989,  702.3894],
        [ 316.8073,  311.8316,  372.2093,  366.0129],
        [  58.7809,  616.6967,  116.1457,  695.1868],
        [ 511.7417,  396.5548,  556.3819,  453.6448],
        [ 521.8568,  542.2925,  656.0084,  996.1042],
        [ 827.6411,  477.4920, 1024.0000,  618.0587],
        [ 990.3597,  576.5050, 1012.5527,  597.6050],
        [ 842.7906,  561.4996,  861.5659,  582.2764],
        [ 870.4338,  565.4010,  888.3083,  584.6080],
        [ 932.0941,  571.3570,  953.4789,  592.4570],
        [ 960.6380,  573.7117,  982.2999,  593.9807],
        [1020.8665,  580.2449, 1024.0000,  600.8370],
        [ 638.5726,  580.5450,  651.8515,  604.0920],
        [ 578.3441,  392.3302,  733.1183,  485.2718],
        [ 364.9578,  615.7501,  531.1404, 1024.0000],
        [ 853.2059,    0.0000, 1024.0000,  217.4818],
        [ 686.7923,    6.3895,  877.3850,  329.2841],
        [   0.0000,  849.5815,  146.7219, 1024.0000],
        [ 679.8411,  529.9188,  809.9513,  839.2855],
        [ 534.9279,   19.8252,  684.3444,  323.8822],
        [ 120.2102,  707.0526,  390.1069, 1024.0000],
        [ 878.3318,  611.2253,  991.9762,  792.0529]])), gt_classes: tensor([500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 825, 716,
        436, 436, 436, 436, 436, 436, 436, 775, 137, 137, 137, 137, 137, 137,
        137, 266])])}], 'support_set_target': tensor(137)}{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000171328.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [666], 'neg_category_ids': [941, 281, 175, 865, 799, 1180, 533], 'image_id': 171328, 'annotations': [{'bbox': [409.18, 196.51, 11.05, 9.53], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 468}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000171328.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [666], 'neg_category_ids': [941, 281, 175, 865, 799, 1180, 533], 'image_id': 171328, 'image': tensor([[[ 4., 10., 11.,  ..., 33., 33., 33.],
         [ 3.,  7.,  8.,  ..., 33., 33., 33.],
         [ 2.,  6.,  5.,  ..., 33., 33., 33.],
         ...,
         [33., 33., 33.,  ..., 33., 33., 33.],
         [33., 33., 33.,  ..., 33., 33., 33.],
         [33., 33., 33.,  ..., 33., 33., 33.]],

        [[13., 15., 16.,  ..., 33., 33., 33.],
         [13., 12., 12.,  ..., 33., 33., 33.],
         [10., 11., 12.,  ..., 33., 33., 33.],
         ...,
         [33., 33., 33.,  ..., 33., 33., 33.],
         [33., 33., 33.,  ..., 33., 33., 33.],
         [33., 33., 33.,  ..., 33., 33., 33.]],

        [[ 8., 13., 11.,  ..., 33., 33., 33.],
         [ 9., 10.,  8.,  ..., 33., 33., 33.],
         [ 8., 10.,  8.,  ..., 33., 33., 33.],
         ...,
         [33., 33., 33.,  ..., 33., 33., 33.],
         [33., 33., 33.,  ..., 33., 33., 33.],
         [33., 33., 33.,  ..., 33., 33., 33.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[483.3439, 232.1130, 496.3967, 243.3696]])), gt_classes: tensor([468])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000171328.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [666], 'neg_category_ids': [941, 281, 175, 865, 799, 1180, 533], 'image_id': 171328, 'annotations': [{'bbox': [545.75, 191.58, 5.45, 5.55], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 468}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000171328.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [666], 'neg_category_ids': [941, 281, 175, 865, 799, 1180, 533], 'image_id': 171328, 'image': tensor([[[ 16.,  46.,  44.,  ..., 128., 128., 128.],
         [ 13.,  30.,  27.,  ..., 128., 128., 128.],
         [ 11.,  24.,  21.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 51.,  63.,  62.,  ..., 128., 128., 128.],
         [ 51.,  49.,  49.,  ..., 128., 128., 128.],
         [ 36.,  48.,  48.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 31.,  57.,  37.,  ..., 128., 128., 128.],
         [ 38.,  37.,  28.,  ..., 128., 128., 128.],
         [ 30.,  42.,  34.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[589.2394, 206.9064, 595.1238, 212.9004]])), gt_classes: tensor([468])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000013893.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [666, 735, 461], 'neg_category_ids': [150, 1028, 633, 902, 483, 549, 577, 779], 'image_id': 13893, 'annotations': [{'bbox': [169.52, 522.9, 44.83, 25.64], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 468}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000013893.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [666, 735, 461], 'neg_category_ids': [150, 1028, 633, 902, 483, 549, 577, 779], 'image_id': 13893, 'image': tensor([[[  9.,   8.,   5.,  ..., 127., 127., 127.],
         [ 11.,  10.,   7.,  ..., 127., 127., 127.],
         [ 12.,  11.,   8.,  ..., 127., 127., 127.],
         ...,
         [187., 187., 188.,  ..., 127., 127., 127.],
         [185., 186., 187.,  ..., 127., 127., 127.],
         [176., 178., 180.,  ..., 127., 127., 127.]],

        [[239., 241.,  11.,  ..., 127., 127., 127.],
         [236., 238., 242.,  ..., 127., 127., 127.],
         [233., 235., 240.,  ..., 127., 127., 127.],
         ...,
         [182., 183., 183.,  ..., 127., 127., 127.],
         [180., 181., 182.,  ..., 127., 127., 127.],
         [171., 173., 175.,  ..., 127., 127., 127.]],

        [[242.,  11.,   7.,  ..., 127., 127., 127.],
         [239., 241.,   9.,  ..., 127., 127., 127.],
         [236., 239.,  11.,  ..., 127., 127., 127.],
         ...,
         [183., 184., 184.,  ..., 127., 127., 127.],
         [181., 183., 184.,  ..., 127., 127., 127.],
         [172., 174., 177.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 415.8378,  971.9232,  503.5030, 1022.0814]])), gt_classes: tensor([468])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000023400.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [666], 'neg_category_ids': [481, 1193, 955, 469, 1062, 1067], 'image_id': 23400, 'annotations': [{'bbox': [103.96, 101.03, 360.64, 420.14], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 468}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000023400.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [666], 'neg_category_ids': [481, 1193, 955, 469, 1062, 1067], 'image_id': 23400, 'image': tensor([[[ 41.,  42.,  42.,  ...,   7.,   5.,   4.],
         [ 40.,  41.,  41.,  ...,   8.,   5.,   3.],
         [ 40.,  41.,  41.,  ...,   9.,   6.,   4.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[155., 154., 154.,  ...,  46.,  41.,  37.],
         [154., 153., 153.,  ...,  48.,  43.,  39.],
         [154., 153., 153.,  ...,  49.,  44.,  40.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[252., 252., 252.,  ..., 156., 150., 143.],
         [252., 253., 253.,  ..., 162., 156., 149.],
         [252., 253., 253.,  ..., 166., 160., 153.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 29.3427,  22.8508, 828.4078, 953.7493]])), gt_classes: tensor([468])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000048428.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1142, 1026, 634, 1052, 1032, 660], 'image_id': 48428, 'annotations': [{'bbox': [114.52, 348.83, 56.18, 51.7], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 468}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000048428.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1142, 1026, 634, 1052, 1032, 660], 'image_id': 48428, 'image': tensor([[[234., 232., 231.,  ...,   4.,   5.,   5.],
         [240., 236., 233.,  ...,   7.,   6.,   5.],
         [  8., 240., 234.,  ...,   9.,   8.,   5.],
         ...,
         [  4.,   6.,   8.,  ...,   7.,   8.,   8.],
         [  2.,   5.,   8.,  ...,   9.,   9.,   9.],
         [  0.,   4.,   7.,  ..., 244.,  10.,   9.]],

        [[174., 174., 176.,  ..., 181., 180., 180.],
         [177., 177., 176.,  ..., 180., 181., 181.],
         [181., 179., 177.,  ..., 180., 181., 182.],
         ...,
         [203., 203., 204.,  ..., 244., 244., 243.],
         [207., 205., 204.,  ..., 242., 242., 242.],
         [211., 207., 205.,  ..., 240., 240., 241.]],

        [[ 51.,  51.,  51.,  ..., 100., 100.,  99.],
         [ 59.,  58.,  57.,  ..., 100.,  99.,  99.],
         [ 68.,  66.,  63.,  ...,  99.,  99., 100.],
         ...,
         [125., 125., 125.,  ..., 153., 154., 160.],
         [126., 125., 124.,  ..., 157., 158., 162.],
         [128., 126., 124.,  ..., 161., 161., 164.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 75.9200, 214.0892, 252.4857, 376.5403]])), gt_classes: tensor([468])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000173422.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [500, 58], 'neg_category_ids': [782, 1007, 792, 328, 1079, 676, 334, 940], 'image_id': 173422, 'annotations': [{'bbox': [414.98, 195.69, 19.07, 19.5], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 357}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000173422.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [500, 58], 'neg_category_ids': [782, 1007, 792, 328, 1079, 676, 334, 940], 'image_id': 173422, 'image': tensor([[[ 64.,  66.,  65.,  ...,  96.,  93.,  91.],
         [ 74.,  76.,  76.,  ...,  68.,  66.,  65.],
         [ 90.,  91.,  92.,  ...,  24.,  23.,  23.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 72.,  74.,  74.,  ...,  97.,  96.,  94.],
         [ 82.,  83.,  83.,  ...,  73.,  72.,  71.],
         [ 97.,  98.,  97.,  ...,  35.,  34.,  34.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 62.,  64.,  66.,  ...,  88.,  87.,  85.],
         [ 74.,  76.,  77.,  ...,  61.,  60.,  59.],
         [ 94.,  95.,  94.,  ...,  19.,  18.,  18.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[652.7310, 339.4716, 685.8055, 373.2991]])), gt_classes: tensor([357])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000088635.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [967], 'neg_category_ids': [470, 306, 6, 523, 140, 143, 71, 342], 'image_id': 88635, 'annotations': [{'bbox': [446.76, 214.03, 18.83, 23.51], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 357}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000088635.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [967], 'neg_category_ids': [470, 306, 6, 523, 140, 143, 71, 342], 'image_id': 88635, 'image': tensor([[[255., 255., 255.,  ..., 176., 172., 169.],
         [255., 255., 255.,  ..., 176., 172., 169.],
         [255., 255., 255.,  ..., 179., 176., 172.],
         ...,
         [198., 195., 198.,  ..., 127., 126., 126.],
         [202., 198., 198.,  ..., 131., 129., 129.],
         [211., 211., 206.,  ..., 142., 140., 138.]],

        [[247., 247., 250.,  ..., 162., 162., 165.],
         [247., 247., 250.,  ..., 162., 162., 165.],
         [250., 250., 250.,  ..., 165., 165., 168.],
         ...,
         [223., 228., 223.,  ..., 150., 147., 145.],
         [228., 228., 223.,  ..., 151., 148., 145.],
         [233., 233., 228.,  ..., 156., 153., 147.]],

        [[251., 251., 251.,  ..., 163., 163., 163.],
         [251., 251., 251.,  ..., 163., 163., 163.],
         [251., 251., 251.,  ..., 166., 166., 166.],
         ...,
         [229., 229., 224.,  ..., 166., 163., 160.],
         [233., 229., 224.,  ..., 166., 163., 158.],
         [229., 229., 224.,  ..., 175., 169., 156.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[792.1718, 403.0937, 845.7490, 469.9992]])), gt_classes: tensor([357])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000411061.jpg', 'height': 332, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [783, 949, 522, 1132, 1083, 1137, 1039, 120], 'image_id': 411061, 'annotations': [{'bbox': [270.65, 203.52, 8.92, 9.45], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 357}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000411061.jpg', 'height': 332, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [783, 949, 522, 1132, 1083, 1137, 1039, 120], 'image_id': 411061, 'image': tensor([[[30., 17., 11.,  ..., 11., 17., 25.],
         [30., 17., 11.,  ..., 11., 17., 25.],
         [43., 19., 20.,  ..., 12., 19., 24.],
         ...,
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.]],

        [[76., 52., 40.,  ..., 17., 28., 43.],
         [76., 52., 40.,  ..., 17., 28., 43.],
         [75., 35., 41.,  ..., 19., 28., 40.],
         ...,
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.]],

        [[57., 44., 38.,  ..., 11., 19., 28.],
         [57., 44., 38.,  ..., 11., 19., 28.],
         [65., 35., 43.,  ..., 12., 20., 27.],
         ...,
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[542.4513, 592.1697, 568.4085, 619.6657]])), gt_classes: tensor([357])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000232241.jpg', 'height': 330, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [168, 782, 668, 786, 24, 605, 635, 15, 80, 420, 309, 745, 330, 841, 143], 'image_id': 232241, 'annotations': [{'bbox': [94.03, 239.55, 19.72, 22.18], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 357}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000232241.jpg', 'height': 330, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [168, 782, 668, 786, 24, 605, 635, 15, 80, 420, 309, 745, 330, 841, 143], 'image_id': 232241, 'image': tensor([[[219., 220., 218.,  ..., 128., 128., 128.],
         [217., 218., 217.,  ..., 128., 128., 128.],
         [215., 216., 216.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[142., 143., 143.,  ..., 128., 128., 128.],
         [140., 142., 142.,  ..., 128., 128., 128.],
         [138., 140., 141.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 93.,  94.,  94.,  ..., 128., 128., 128.],
         [ 91.,  93.,  93.,  ..., 128., 128., 128.],
         [ 90.,  91.,  92.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[487.4475, 302.7041, 512.3342, 330.7316]])), gt_classes: tensor([357])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000508299.jpg', 'height': 448, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [631, 501, 197, 220, 591, 594, 595, 400, 1156, 11], 'image_id': 508299, 'annotations': [{'bbox': [364.46, 66.74, 11.02, 9.65], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 357}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000508299.jpg', 'height': 448, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [631, 501, 197, 220, 591, 594, 595, 400, 1156, 11], 'image_id': 508299, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [141., 148., 153.,  ..., 100., 103., 107.],
         [ 58.,  65.,  70.,  ..., 102., 103., 107.],
         [ 42.,  45.,  51.,  ..., 102., 103., 107.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [137., 144., 149.,  ...,  54.,  58.,  58.],
         [ 54.,  61.,  68.,  ...,  56.,  58.,  58.],
         [ 33.,  38.,  44.,  ...,  54.,  56.,  58.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [125., 130., 135.,  ...,  42.,  42.,  44.],
         [ 44.,  49.,  52.,  ...,  47.,  45.,  44.],
         [ 24.,  28.,  31.,  ...,  47.,  45.,  44.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[563.8650, 106.8604, 598.3541, 137.0598]])), gt_classes: tensor([357])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000171328.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [666], 'neg_category_ids': [941, 281, 175, 865, 799, 1180, 533], 'image_id': 171328, 'image': tensor([[[ 4., 10., 11.,  ..., 33., 33., 33.],
         [ 3.,  7.,  8.,  ..., 33., 33., 33.],
         [ 2.,  6.,  5.,  ..., 33., 33., 33.],
         ...,
         [33., 33., 33.,  ..., 33., 33., 33.],
         [33., 33., 33.,  ..., 33., 33., 33.],
         [33., 33., 33.,  ..., 33., 33., 33.]],

        [[13., 15., 16.,  ..., 33., 33., 33.],
         [13., 12., 12.,  ..., 33., 33., 33.],
         [10., 11., 12.,  ..., 33., 33., 33.],
         ...,
         [33., 33., 33.,  ..., 33., 33., 33.],
         [33., 33., 33.,  ..., 33., 33., 33.],
         [33., 33., 33.,  ..., 33., 33., 33.]],

        [[ 8., 13., 11.,  ..., 33., 33., 33.],
         [ 9., 10.,  8.,  ..., 33., 33., 33.],
         [ 8., 10.,  8.,  ..., 33., 33., 33.],
         ...,
         [33., 33., 33.,  ..., 33., 33., 33.],
         [33., 33., 33.,  ..., 33., 33., 33.],
         [33., 33., 33.,  ..., 33., 33., 33.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[483.3439, 232.1130, 496.3967, 243.3696]])), gt_classes: tensor([468])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000171328.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [666], 'neg_category_ids': [941, 281, 175, 865, 799, 1180, 533], 'image_id': 171328, 'image': tensor([[[ 16.,  46.,  44.,  ..., 128., 128., 128.],
         [ 13.,  30.,  27.,  ..., 128., 128., 128.],
         [ 11.,  24.,  21.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 51.,  63.,  62.,  ..., 128., 128., 128.],
         [ 51.,  49.,  49.,  ..., 128., 128., 128.],
         [ 36.,  48.,  48.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 31.,  57.,  37.,  ..., 128., 128., 128.],
         [ 38.,  37.,  28.,  ..., 128., 128., 128.],
         [ 30.,  42.,  34.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[589.2394, 206.9064, 595.1238, 212.9004]])), gt_classes: tensor([468])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000013893.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [666, 735, 461], 'neg_category_ids': [150, 1028, 633, 902, 483, 549, 577, 779], 'image_id': 13893, 'image': tensor([[[  9.,   8.,   5.,  ..., 127., 127., 127.],
         [ 11.,  10.,   7.,  ..., 127., 127., 127.],
         [ 12.,  11.,   8.,  ..., 127., 127., 127.],
         ...,
         [187., 187., 188.,  ..., 127., 127., 127.],
         [185., 186., 187.,  ..., 127., 127., 127.],
         [176., 178., 180.,  ..., 127., 127., 127.]],

        [[239., 241.,  11.,  ..., 127., 127., 127.],
         [236., 238., 242.,  ..., 127., 127., 127.],
         [233., 235., 240.,  ..., 127., 127., 127.],
         ...,
         [182., 183., 183.,  ..., 127., 127., 127.],
         [180., 181., 182.,  ..., 127., 127., 127.],
         [171., 173., 175.,  ..., 127., 127., 127.]],

        [[242.,  11.,   7.,  ..., 127., 127., 127.],
         [239., 241.,   9.,  ..., 127., 127., 127.],
         [236., 239.,  11.,  ..., 127., 127., 127.],
         ...,
         [183., 184., 184.,  ..., 127., 127., 127.],
         [181., 183., 184.,  ..., 127., 127., 127.],
         [172., 174., 177.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 415.8378,  971.9232,  503.5030, 1022.0814]])), gt_classes: tensor([468])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000023400.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [666], 'neg_category_ids': [481, 1193, 955, 469, 1062, 1067], 'image_id': 23400, 'image': tensor([[[ 41.,  42.,  42.,  ...,   7.,   5.,   4.],
         [ 40.,  41.,  41.,  ...,   8.,   5.,   3.],
         [ 40.,  41.,  41.,  ...,   9.,   6.,   4.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[155., 154., 154.,  ...,  46.,  41.,  37.],
         [154., 153., 153.,  ...,  48.,  43.,  39.],
         [154., 153., 153.,  ...,  49.,  44.,  40.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[252., 252., 252.,  ..., 156., 150., 143.],
         [252., 253., 253.,  ..., 162., 156., 149.],
         [252., 253., 253.,  ..., 166., 160., 153.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 29.3427,  22.8508, 828.4078, 953.7493]])), gt_classes: tensor([468])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000048428.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1142, 1026, 634, 1052, 1032, 660], 'image_id': 48428, 'image': tensor([[[234., 232., 231.,  ...,   4.,   5.,   5.],
         [240., 236., 233.,  ...,   7.,   6.,   5.],
         [  8., 240., 234.,  ...,   9.,   8.,   5.],
         ...,
         [  4.,   6.,   8.,  ...,   7.,   8.,   8.],
         [  2.,   5.,   8.,  ...,   9.,   9.,   9.],
         [  0.,   4.,   7.,  ..., 244.,  10.,   9.]],

        [[174., 174., 176.,  ..., 181., 180., 180.],
         [177., 177., 176.,  ..., 180., 181., 181.],
         [181., 179., 177.,  ..., 180., 181., 182.],
         ...,
         [203., 203., 204.,  ..., 244., 244., 243.],
         [207., 205., 204.,  ..., 242., 242., 242.],
         [211., 207., 205.,  ..., 240., 240., 241.]],

        [[ 51.,  51.,  51.,  ..., 100., 100.,  99.],
         [ 59.,  58.,  57.,  ..., 100.,  99.,  99.],
         [ 68.,  66.,  63.,  ...,  99.,  99., 100.],
         ...,
         [125., 125., 125.,  ..., 153., 154., 160.],
         [126., 125., 124.,  ..., 157., 158., 162.],
         [128., 126., 124.,  ..., 161., 161., 164.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 75.9200, 214.0892, 252.4857, 376.5403]])), gt_classes: tensor([468])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000271057.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [851, 1070, 502, 670, 718, 340, 999], 'image_id': 271057, 'annotations_cat_set': {666, 45}, 'image': tensor([[[149., 149., 149.,  ..., 128., 128., 128.],
         [147., 147., 147.,  ..., 128., 128., 128.],
         [149., 149., 148.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[152., 152., 152.,  ..., 128., 128., 128.],
         [150., 150., 150.,  ..., 128., 128., 128.],
         [152., 152., 151.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[154., 154., 154.,  ..., 128., 128., 128.],
         [152., 152., 152.,  ..., 128., 128., 128.],
         [154., 154., 153.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=3, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 98.7710, 111.7699, 558.6974, 395.4755],
        [327.6667,  75.7247, 480.9669, 231.4420],
        [157.0528,  85.8385, 327.0197, 253.3381]])), gt_classes: tensor([ 33, 468, 468])])}], 'support_set_target': tensor(468)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000118866.jpg', 'height': 479, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [876, 605, 1047, 1187, 418, 834, 975, 188, 365], 'image_id': 118866, 'annotations': [{'bbox': [130.4, 21.2, 63.57, 103.6], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 657}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000118866.jpg', 'height': 479, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [876, 605, 1047, 1187, 418, 834, 975, 188, 365], 'image_id': 118866, 'image': tensor([[[27., 30., 31.,  ...,  2.,  2.,  3.],
         [27., 28., 31.,  ...,  2.,  2.,  3.],
         [26., 27., 29.,  ...,  3.,  3.,  3.],
         ...,
         [10., 10., 10.,  ..., 10., 11., 11.],
         [12., 11., 10.,  ..., 10., 10.,  9.],
         [14., 12., 10.,  ...,  9.,  9.,  8.]],

        [[33., 34., 35.,  ...,  4.,  5.,  6.],
         [34., 34., 35.,  ...,  4.,  4.,  6.],
         [33., 34., 35.,  ...,  4.,  4.,  6.],
         ...,
         [15., 13., 13.,  ..., 19., 20., 18.],
         [15., 14., 13.,  ..., 17., 17., 16.],
         [17., 15., 13.,  ..., 16., 16., 15.]],

        [[50., 51., 54.,  ...,  9., 11., 10.],
         [50., 51., 54.,  ...,  9.,  9., 10.],
         [51., 52., 52.,  ...,  8.,  8., 10.],
         ...,
         [22., 20., 19.,  ..., 26., 27., 27.],
         [22., 21., 19.,  ..., 26., 26., 25.],
         [24., 22., 20.,  ..., 27., 27., 26.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000,   0.0000, 180.7948, 180.8910]])), gt_classes: tensor([657])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000383173.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [461], 'neg_category_ids': [562, 219, 607, 653, 222, 1113, 577], 'image_id': 383173, 'annotations': [{'bbox': [307.46, 166.72, 76.22, 212.55], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 657}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000383173.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [461], 'neg_category_ids': [562, 219, 607, 653, 222, 1113, 577], 'image_id': 383173, 'image': tensor([[[180., 180., 180.,  ..., 128., 128., 128.],
         [180., 180., 180.,  ..., 128., 128., 128.],
         [180., 180., 180.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[181., 181., 181.,  ..., 128., 128., 128.],
         [181., 181., 181.,  ..., 128., 128., 128.],
         [181., 181., 181.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[183., 183., 183.,  ..., 128., 128., 128.],
         [183., 183., 183.,  ..., 128., 128., 128.],
         [183., 183., 183.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[245.1082, 178.9788, 326.9326, 407.1575]])), gt_classes: tensor([657])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000039671.jpg', 'height': 406, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 759, 711, 1167, 1028, 198, 1190, 176, 595, 37, 890, 599, 41, 252, 497], 'image_id': 39671, 'annotations': [{'bbox': [290.91, 53.71, 29.15, 23.36], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 657}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000039671.jpg', 'height': 406, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 759, 711, 1167, 1028, 198, 1190, 176, 595, 37, 890, 599, 41, 252, 497], 'image_id': 39671, 'image': tensor([[[  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[  0.,   0.,   0.,  ..., 201., 201., 201.],
         [  0.,   0.,   0.,  ..., 201., 201., 201.],
         [  0.,   0.,   0.,  ..., 201., 201., 201.],
         ...,
         [201., 201., 201.,  ..., 201., 201., 201.],
         [201., 201., 201.,  ..., 201., 201., 201.],
         [201., 201., 201.,  ..., 201., 201., 201.]],

        [[  0.,   0.,   0.,  ..., 172., 172., 172.],
         [  0.,   0.,   0.,  ..., 172., 172., 172.],
         [  0.,   0.,   0.,  ..., 172., 172., 172.],
         ...,
         [172., 172., 172.,  ..., 172., 172., 172.],
         [172., 172., 172.,  ..., 172., 172., 172.],
         [172., 172., 172.,  ..., 172., 172., 172.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[453.6378,  83.7400, 499.0936, 120.1609]])), gt_classes: tensor([657])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000486306.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1099, 54, 744, 205, 912, 726, 915, 45], 'image_id': 486306, 'annotations': [{'bbox': [80.49, 53.43, 113.17, 168.48], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 657}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000486306.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1099, 54, 744, 205, 912, 726, 915, 45], 'image_id': 486306, 'image': tensor([[[192., 192., 192.,  ..., 177., 177., 176.],
         [193., 193., 193.,  ..., 176., 175., 175.],
         [194., 194., 195.,  ..., 174., 174., 174.],
         ...,
         [166., 166., 165.,  ..., 177., 176., 176.],
         [165., 165., 165.,  ..., 175., 174., 174.],
         [165., 165., 165.,  ..., 171., 170., 170.]],

        [[208., 208., 208.,  ..., 189., 189., 188.],
         [208., 209., 210.,  ..., 188., 187., 187.],
         [209., 210., 212.,  ..., 186., 186., 186.],
         ...,
         [208., 208., 208.,  ..., 196., 195., 195.],
         [208., 208., 207.,  ..., 193., 193., 193.],
         [208., 208., 207.,  ..., 189., 190., 190.]],

        [[198., 198., 197.,  ..., 171., 171., 170.],
         [199., 199., 199.,  ..., 170., 169., 169.],
         [201., 201., 201.,  ..., 168., 168., 168.],
         ...,
         [233., 233., 233.,  ..., 193., 192., 192.],
         [233., 233., 232.,  ..., 191., 190., 190.],
         [233., 233., 232.,  ..., 189., 188., 187.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[526.2159,   0.0000, 859.1833, 297.7852]])), gt_classes: tensor([657])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000340943.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [204, 154, 217, 510, 1099], 'neg_category_ids': [981, 560, 983, 788, 1107, 576, 847, 276, 146], 'image_id': 340943, 'annotations': [{'bbox': [380.21, 148.63, 32.69, 54.08], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 657}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000340943.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [204, 154, 217, 510, 1099], 'neg_category_ids': [981, 560, 983, 788, 1107, 576, 847, 276, 146], 'image_id': 340943, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[462.1928, 180.7285, 501.9315, 246.4877]])), gt_classes: tensor([657])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000118866.jpg', 'height': 479, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [876, 605, 1047, 1187, 418, 834, 975, 188, 365], 'image_id': 118866, 'image': tensor([[[27., 30., 31.,  ...,  2.,  2.,  3.],
         [27., 28., 31.,  ...,  2.,  2.,  3.],
         [26., 27., 29.,  ...,  3.,  3.,  3.],
         ...,
         [10., 10., 10.,  ..., 10., 11., 11.],
         [12., 11., 10.,  ..., 10., 10.,  9.],
         [14., 12., 10.,  ...,  9.,  9.,  8.]],

        [[33., 34., 35.,  ...,  4.,  5.,  6.],
         [34., 34., 35.,  ...,  4.,  4.,  6.],
         [33., 34., 35.,  ...,  4.,  4.,  6.],
         ...,
         [15., 13., 13.,  ..., 19., 20., 18.],
         [15., 14., 13.,  ..., 17., 17., 16.],
         [17., 15., 13.,  ..., 16., 16., 15.]],

        [[50., 51., 54.,  ...,  9., 11., 10.],
         [50., 51., 54.,  ...,  9.,  9., 10.],
         [51., 52., 52.,  ...,  8.,  8., 10.],
         ...,
         [22., 20., 19.,  ..., 26., 27., 27.],
         [22., 21., 19.,  ..., 26., 26., 25.],
         [24., 22., 20.,  ..., 27., 27., 26.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000,   0.0000, 180.7948, 180.8910]])), gt_classes: tensor([657])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000383173.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [461], 'neg_category_ids': [562, 219, 607, 653, 222, 1113, 577], 'image_id': 383173, 'image': tensor([[[180., 180., 180.,  ..., 128., 128., 128.],
         [180., 180., 180.,  ..., 128., 128., 128.],
         [180., 180., 180.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[181., 181., 181.,  ..., 128., 128., 128.],
         [181., 181., 181.,  ..., 128., 128., 128.],
         [181., 181., 181.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[183., 183., 183.,  ..., 128., 128., 128.],
         [183., 183., 183.,  ..., 128., 128., 128.],
         [183., 183., 183.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[245.1082, 178.9788, 326.9326, 407.1575]])), gt_classes: tensor([657])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000039671.jpg', 'height': 406, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 759, 711, 1167, 1028, 198, 1190, 176, 595, 37, 890, 599, 41, 252, 497], 'image_id': 39671, 'image': tensor([[[  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[  0.,   0.,   0.,  ..., 201., 201., 201.],
         [  0.,   0.,   0.,  ..., 201., 201., 201.],
         [  0.,   0.,   0.,  ..., 201., 201., 201.],
         ...,
         [201., 201., 201.,  ..., 201., 201., 201.],
         [201., 201., 201.,  ..., 201., 201., 201.],
         [201., 201., 201.,  ..., 201., 201., 201.]],

        [[  0.,   0.,   0.,  ..., 172., 172., 172.],
         [  0.,   0.,   0.,  ..., 172., 172., 172.],
         [  0.,   0.,   0.,  ..., 172., 172., 172.],
         ...,
         [172., 172., 172.,  ..., 172., 172., 172.],
         [172., 172., 172.,  ..., 172., 172., 172.],
         [172., 172., 172.,  ..., 172., 172., 172.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[453.6378,  83.7400, 499.0936, 120.1609]])), gt_classes: tensor([657])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000486306.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1099, 54, 744, 205, 912, 726, 915, 45], 'image_id': 486306, 'image': tensor([[[192., 192., 192.,  ..., 177., 177., 176.],
         [193., 193., 193.,  ..., 176., 175., 175.],
         [194., 194., 195.,  ..., 174., 174., 174.],
         ...,
         [166., 166., 165.,  ..., 177., 176., 176.],
         [165., 165., 165.,  ..., 175., 174., 174.],
         [165., 165., 165.,  ..., 171., 170., 170.]],

        [[208., 208., 208.,  ..., 189., 189., 188.],
         [208., 209., 210.,  ..., 188., 187., 187.],
         [209., 210., 212.,  ..., 186., 186., 186.],
         ...,
         [208., 208., 208.,  ..., 196., 195., 195.],
         [208., 208., 207.,  ..., 193., 193., 193.],
         [208., 208., 207.,  ..., 189., 190., 190.]],

        [[198., 198., 197.,  ..., 171., 171., 170.],
         [199., 199., 199.,  ..., 170., 169., 169.],
         [201., 201., 201.,  ..., 168., 168., 168.],
         ...,
         [233., 233., 233.,  ..., 193., 192., 192.],
         [233., 233., 232.,  ..., 191., 190., 190.],
         [233., 233., 232.,  ..., 189., 188., 187.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[526.2159,   0.0000, 859.1833, 297.7852]])), gt_classes: tensor([657])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000340943.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [204, 154, 217, 510, 1099], 'neg_category_ids': [981, 560, 983, 788, 1107, 576, 847, 276, 146], 'image_id': 340943, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[462.1928, 180.7285, 501.9315, 246.4877]])), gt_classes: tensor([657])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000340943.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [204, 154, 217, 510, 1099], 'neg_category_ids': [981, 560, 983, 788, 1107, 576, 847, 276, 146], 'image_id': 340943, 'annotations_cat_set': {934, 390, 1099, 204, 139, 217, 154, 510}, 'image': tensor([[[178., 177., 176.,  ..., 117., 117., 116.],
         [179., 177., 176.,  ..., 116., 116., 116.],
         [178., 177., 176.,  ..., 116., 116., 116.],
         ...,
         [129., 131., 128.,  ..., 118., 118., 119.],
         [130., 132., 129.,  ..., 118., 118., 119.],
         [129., 131., 128.,  ..., 119., 119., 119.]],

        [[192., 192., 191.,  ..., 126., 126., 125.],
         [192., 192., 191.,  ..., 125., 125., 125.],
         [192., 192., 191.,  ..., 125., 125., 125.],
         ...,
         [187., 189., 186.,  ..., 126., 126., 125.],
         [188., 190., 186.,  ..., 126., 126., 125.],
         [187., 189., 185.,  ..., 127., 127., 126.]],

        [[203., 201., 200.,  ..., 129., 129., 128.],
         [203., 201., 200.,  ..., 128., 128., 128.],
         [202., 201., 200.,  ..., 128., 128., 128.],
         ...,
         [129., 131., 128.,  ..., 150., 150., 149.],
         [130., 132., 129.,  ..., 148., 148., 147.],
         [129., 131., 128.,  ..., 146., 146., 145.]]]), 'instances': Instances(num_instances=75, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 995.4131,  768.6805, 1024.0000,  815.9275],
        [ 652.7738,  653.3217,  694.0170,  678.2040],
        [ 551.1926,  639.9296,  627.5192,  749.3424],
        [ 942.7880,  743.5303, 1024.0000,  777.0639],
        [ 832.8510,  745.7266,  919.3008,  814.8026],
        [ 796.1071,  718.2462,  896.3493,  814.7491],
        [ 912.4448,  656.3483,  945.1447,  683.1591],
        [ 656.4160,  680.0521,  746.9635,  748.1907],
        [ 921.5772,  796.0002,  981.7279,  836.3906],
        [ 600.7646,  710.4252,  683.4919,  792.3307],
        [ 924.9249,  721.2460,  993.3510,  749.0479],
        [ 598.4615,  649.9201,  652.5060,  717.6301],
        [ 683.4651,  725.7725,  804.4628,  793.7236],
        [ 577.5721,  781.1351,  679.0999,  841.1046],
        [1010.5446,  679.9986, 1024.0000,  717.4694],
        [1003.1797,  784.4027, 1024.0000,  845.8721],
        [ 617.9583,  674.1061,  666.2984,  719.4782],
        [ 279.2022,  342.0912,  366.7501,  486.9392],
        [ 134.3960,  160.6561,  194.8680,  318.7622],
        [   0.0000,  248.4809,   10.6666,  326.9850],
        [  13.1037,  228.1251,   76.7627,  312.9501],
        [  76.8966,  231.2588,  135.5743,  314.1554],
        [1018.0433,  522.2138, 1024.0000,  565.2290],
        [ 983.1473,  562.1220, 1006.8220,  587.0044],
        [1003.6885,  562.8988, 1024.0000,  606.3157],
        [1002.6709,  514.5000, 1024.0000,  537.6146],
        [ 868.4432,  651.4200,  895.0638,  672.7668],
        [ 781.6988,  880.5575,  837.1092,  950.0085],
        [ 880.4948,  826.9894,  917.9618,  861.8622],
        [ 844.8221,  871.1027,  871.7909,  926.0368],
        [ 915.8461,  836.1763,  978.3802,  916.4749],
        [ 800.0975,  858.1392,  840.3229,  920.0103],
        [ 924.7910,  910.5555,  965.4449,  932.6524],
        [1003.3404,  861.2194, 1024.0000,  915.8321],
        [ 740.3218,  842.8187,  769.8882,  894.1638],
        [ 841.6620, 1000.7642,  885.4226, 1019.0576],
        [ 729.1271,  618.8506,  752.2394,  657.7142],
        [ 747.0974,  654.3394,  771.3880,  674.2668],
        [ 691.0443,  615.7169,  733.4390,  658.7321],
        [ 728.6719,  840.7028,  743.0802,  867.1655],
        [ 667.9052,  635.4032,  691.3388,  655.7054],
        [ 980.1746,  848.1219, 1006.2060,  885.4321],
        [ 829.5837,  615.6365,  911.4807,  650.5897],
        [ 893.4570,  945.7766,  994.7972,  981.2654],
        [ 936.4677,  650.6432, 1024.0000,  681.3645],
        [ 750.7932,  819.6238,  804.3021,  895.1548],
        [ 914.8016,  636.2870,  996.9665,  660.5801],
        [ 755.6138,  634.3051,  853.5797,  686.9893],
        [ 847.8217,  808.6959,  895.5191,  856.8803],
        [ 655.5859,  907.6629,  701.5425,  936.2950],
        [ 943.0826,  904.0471, 1024.0000,  930.4561],
        [ 763.5411,  701.1580,  817.6124,  739.1913],
        [ 822.8883,  683.2930,  851.4907,  703.8899],
        [ 840.8050,  661.5176,  872.8622,  682.0878],
        [ 766.9423,  921.2156,  818.4695,  969.2126],
        [ 870.9072,  884.7090,  921.0684,  926.0903],
        [ 690.1873,  934.0988,  730.5466,  972.8552],
        [ 826.7984,  639.4743,  896.6439,  667.5707],
        [ 716.8346,  841.2921,  751.0342,  890.4408],
        [ 896.2422,  688.7838,  958.3211,  727.5671],
        [ 746.6957,  613.0920,  813.5149,  648.7951],
        [ 968.0695,  877.2362, 1014.2672,  910.0198],
        [ 942.0917,  968.8644, 1024.0000, 1014.7723],
        [ 693.2671,  895.6636,  725.2975,  935.2772],
        [ 802.4810,  987.8810,  851.7585, 1008.7994],
        [ 814.7469,  851.2289,  983.7365,  896.4404],
        [  13.3180, 1021.2272,  142.7785, 1024.0000],
        [ 280.0056,  342.8679,  366.3216,  392.2041],
        [   0.0000,  246.7400,   10.2649,  280.0861],
        [  17.9779,  232.5177,   67.2554,  272.5062],
        [ 755.2121,  364.1612, 1024.0000,  609.2620],
        [   5.4443,  462.0836,  178.6386,  575.8622],
        [ 292.1108,  671.3741,  529.7141,  793.3486],
        [ 628.1083,  510.7502,  884.8334,  611.2975],
        [ 303.3321,  429.3536,  672.0564,  648.9023]])), gt_classes: tensor([117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117,
        117, 117, 117, 657, 657, 657, 657, 657, 363, 363, 363, 363, 166, 166,
        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,
        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 166,
        166, 166, 166, 166, 166, 166, 166, 166, 166, 166, 278, 157, 157, 157,
        107, 107, 107, 107, 107])])}], 'support_set_target': tensor(657)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000100202.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [81, 217], 'neg_category_ids': [584, 811, 82, 419, 746, 232, 1161, 513], 'image_id': 100202, 'annotations': [{'bbox': [54.23, 75.34, 176.36, 92.96], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 636}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000100202.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [81, 217], 'neg_category_ids': [584, 811, 82, 419, 746, 232, 1161, 513], 'image_id': 100202, 'image': tensor([[[  0.,   0.,   3.,  ...,  17.,  55.,  78.],
         [ 10.,   0.,   0.,  ...,  25.,  62.,  84.],
         [ 19.,   1.,   0.,  ...,  32.,  69.,  89.],
         ...,
         [116., 116., 118.,  ..., 103., 107., 111.],
         [116., 118., 120.,  ..., 103., 107., 111.],
         [114., 116., 120.,  ..., 107., 111., 112.]],

        [[ 60.,  68.,  80.,  ...,  23.,  75., 102.],
         [ 75.,  71.,  71.,  ...,  30.,  80., 103.],
         [ 91.,  73.,  60.,  ...,  37.,  86., 105.],
         ...,
         [146., 148., 150.,  ..., 130., 132., 134.],
         [148., 150., 154.,  ..., 130., 132., 134.],
         [148., 150., 154.,  ..., 132., 134., 136.]],

        [[143., 148., 161.,  ...,  33.,  96., 130.],
         [161., 154., 152.,  ...,  41., 102., 132.],
         [181., 159., 141.,  ...,  48., 107., 134.],
         ...,
         [123., 125., 125.,  ..., 100., 102., 102.],
         [125., 127., 127.,  ..., 100., 102., 102.],
         [125., 127., 129.,  ..., 102., 103., 105.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 722.4940,  206.5366, 1024.0000,  462.6104]])), gt_classes: tensor([636])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000328214.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [641], 'neg_category_ids': [1169, 854, 76, 1141, 463, 838, 66, 824, 450], 'image_id': 328214, 'annotations': [{'bbox': [69.55, 500.28, 32.82, 28.06], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 636}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000328214.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [641], 'neg_category_ids': [1169, 854, 76, 1141, 463, 838, 66, 824, 450], 'image_id': 328214, 'image': tensor([[[197., 199., 201.,  ...,  35.,  33.,  31.],
         [198., 200., 203.,  ...,  33.,  31.,  30.],
         [194., 198., 201.,  ...,  34.,  33.,  32.],
         ...,
         [106., 110., 113.,  ...,  73.,  72.,  70.],
         [134., 136., 138.,  ...,  74.,  73.,  71.],
         [111., 114., 114.,  ...,  74.,  74.,  72.]],

        [[169., 170., 171.,  ...,  42.,  42.,  44.],
         [171., 171., 173.,  ...,  44.,  44.,  46.],
         [172., 172., 172.,  ...,  45.,  44.,  46.],
         ...,
         [104., 110., 117.,  ...,  35.,  36.,  36.],
         [134., 138., 144.,  ...,  36.,  37.,  37.],
         [113., 116., 119.,  ...,  36.,  36.,  36.]],

        [[179., 187., 194.,  ...,  55.,  57.,  59.],
         [179., 190., 198.,  ...,  53.,  55.,  57.],
         [176., 185., 193.,  ...,  56.,  57.,  59.],
         ...,
         [138., 139., 136.,  ..., 123., 122., 122.],
         [161., 161., 160.,  ..., 124., 123., 123.],
         [134., 134., 132.,  ..., 124., 124., 124.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000370383.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [], 'neg_category_ids': [646, 862, 838, 229, 314, 799, 917, 730], 'image_id': 370383, 'annotations': [{'bbox': [114.9, 456.39, 70.14, 43.57], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 636}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000370383.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [], 'neg_category_ids': [646, 862, 838, 229, 314, 799, 917, 730], 'image_id': 370383, 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 738.4852,  87.1565, 843.0674]])), gt_classes: tensor([636])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000400453.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [], 'neg_category_ids': [983, 1191, 7, 82, 37, 724, 995, 93], 'image_id': 400453, 'annotations': [{'bbox': [0.0, 412.07, 300.52, 199.93], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 636}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000400453.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [], 'neg_category_ids': [983, 1191, 7, 82, 37, 724, 995, 93], 'image_id': 400453, 'image': tensor([[[ 18.,  17.,  15.,  ...,  38.,  38.,  38.],
         [ 18.,  18.,  15.,  ...,  38.,  38.,  38.],
         [ 20.,  19.,  18.,  ...,  38.,  38.,  38.],
         ...,
         [ 38.,  38.,  38.,  ...,  38.,  38.,  38.],
         [ 38.,  38.,  38.,  ...,  38.,  38.,  38.],
         [ 38.,  38.,  38.,  ...,  38.,  38.,  38.]],

        [[ 28.,  28.,  27.,  ...,  38.,  38.,  38.],
         [ 29.,  28.,  27.,  ...,  38.,  38.,  38.],
         [ 29.,  29.,  28.,  ...,  38.,  38.,  38.],
         ...,
         [ 38.,  38.,  38.,  ...,  38.,  38.,  38.],
         [ 38.,  38.,  38.,  ...,  38.,  38.,  38.],
         [ 38.,  38.,  38.,  ...,  38.,  38.,  38.]],

        [[ 29.,  29.,  28.,  ...,  29.,  29.,  29.],
         [211.,  29.,  28.,  ...,  29.,  29.,  29.],
         [211., 211.,  29.,  ...,  29.,  29.,  29.],
         ...,
         [ 29.,  29.,  29.,  ...,  29.,  29.,  29.],
         [ 29.,  29.,  29.,  ...,  29.,  29.,  29.],
         [ 29.,  29.,  29.,  ...,  29.,  29.,  29.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[279.9248, 370.3243, 550.0000, 550.0000]])), gt_classes: tensor([636])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000509577.jpg', 'height': 440, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [192, 517, 965, 1, 105, 1150, 1105, 1010, 1031, 596, 37, 1113, 1199, 90, 1115, 65, 935], 'image_id': 509577, 'annotations': [{'bbox': [217.89, 118.32, 213.1, 113.46], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 636}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000509577.jpg', 'height': 440, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [192, 517, 965, 1, 105, 1150, 1105, 1010, 1031, 596, 37, 1113, 1199, 90, 1115, 65, 935], 'image_id': 509577, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[178.3117, 100.8409, 360.1126, 197.5398]])), gt_classes: tensor([636])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000203618.jpg', 'height': 450, 'width': 630, 'not_exhaustive_category_ids': [666, 806], 'neg_category_ids': [1003, 104, 881, 126, 790, 264, 1013, 189, 940], 'image_id': 203618, 'annotations': [{'bbox': [591.97, 226.59, 38.03, 50.31], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 433}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000203618.jpg', 'height': 450, 'width': 630, 'not_exhaustive_category_ids': [666, 806], 'neg_category_ids': [1003, 104, 881, 126, 790, 264, 1013, 189, 940], 'image_id': 203618, 'image': tensor([[[ 87.,  88.,  88.,  ..., 145., 145., 145.],
         [ 87.,  87.,  87.,  ..., 146., 145., 145.],
         [ 87.,  86.,  86.,  ..., 147., 145., 145.],
         ...,
         [147., 151., 148.,  ...,  63.,  62.,  61.],
         [149., 151., 148.,  ...,  63.,  62.,  61.],
         [150., 150., 147.,  ...,  63.,  61.,  60.]],

        [[ 44.,  45.,  47.,  ..., 148., 147., 148.],
         [ 42.,  43.,  45.,  ..., 149., 148., 149.],
         [ 40.,  41.,  42.,  ..., 150., 149., 150.],
         ...,
         [152., 153., 152.,  ..., 123., 123., 123.],
         [151., 151., 151.,  ..., 124., 124., 124.],
         [149., 150., 151.,  ..., 125., 124., 124.]],

        [[126., 126., 127.,  ..., 147., 147., 147.],
         [124., 125., 125.,  ..., 148., 148., 148.],
         [122., 123., 123.,  ..., 149., 149., 149.],
         ...,
         [ 94., 101., 111.,  ...,   3.,   4.,   4.],
         [101., 108., 118.,  ...,   3.,   4.,   4.],
         [108., 115., 125.,  ...,   2.,   3.,   3.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000291347.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1187, 982, 1110, 1133, 1059, 70, 214, 191], 'image_id': 291347, 'annotations': [{'bbox': [544.72, 115.26, 76.38, 83.21], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 433}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000291347.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1187, 982, 1110, 1133, 1059, 70, 214, 191], 'image_id': 291347, 'image': tensor([[[ 50.,  49.,  50.,  ...,  39.,  33.,  27.],
         [ 51.,  49.,  50.,  ...,  41.,  35.,  29.],
         [ 53.,  51.,  52.,  ...,  41.,  35.,  30.],
         ...,
         [ 57.,  56.,  57.,  ...,   2.,   2.,   1.],
         [ 56.,  55.,  56.,  ...,   1.,   1.,   1.],
         [ 55.,  54.,  55.,  ...,   0.,   0.,   1.]],

        [[153., 152., 152.,  ..., 126., 119., 113.],
         [153., 151., 152.,  ..., 128., 121., 115.],
         [154., 152., 153.,  ..., 130., 123., 117.],
         ...,
         [156., 155., 155.,  ...,  39.,  39.,  38.],
         [155., 154., 154.,  ...,  38.,  38.,  38.],
         [155., 153., 153.,  ...,  37.,  37.,  38.]],

        [[246., 246., 246.,  ..., 221., 215., 209.],
         [245., 244., 245.,  ..., 224., 217., 211.],
         [245., 244., 244.,  ..., 227., 220., 214.],
         ...,
         [231., 230., 231.,  ...,  97.,  96.,  96.],
         [230., 229., 230.,  ...,  94.,  94.,  95.],
         [229., 228., 229.,  ...,  92.,  93.,  94.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000076254.jpg', 'height': 450, 'width': 630, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1185, 272, 1055, 1154, 1015, 493, 873], 'image_id': 76254, 'annotations': [{'bbox': [356.75, 0.29, 94.24, 65.2], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 433}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000076254.jpg', 'height': 450, 'width': 630, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1185, 272, 1055, 1154, 1015, 493, 873], 'image_id': 76254, 'image': tensor([[[ 43.,  44.,  45.,  ...,  41.,  41.,  42.],
         [ 42.,  43.,  44.,  ...,  41.,  42.,  42.],
         [ 41.,  42.,  43.,  ...,  42.,  43.,  43.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 37.,  38.,  38.,  ...,  38.,  38.,  38.],
         [ 36.,  37.,  37.,  ...,  38.,  38.,  38.],
         [ 34.,  35.,  35.,  ...,  38.,  38.,  38.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 78.,  81.,  84.,  ...,  47.,  47.,  47.],
         [ 77.,  80.,  83.,  ...,  47.,  47.,  47.],
         [ 76.,  79.,  82.,  ...,  47.,  47.,  47.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[255.5507,   0.5504, 434.3075, 124.2855]])), gt_classes: tensor([433])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000143017.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [774, 735, 510, 613, 12], 'neg_category_ids': [585, 521, 309, 640, 746, 618, 1088, 1066], 'image_id': 143017, 'annotations': [{'bbox': [240.98, 271.9, 21.51, 21.34], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 433}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000143017.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [774, 735, 510, 613, 12], 'neg_category_ids': [585, 521, 309, 640, 746, 618, 1088, 1066], 'image_id': 143017, 'image': tensor([[[51., 51., 52.,  ..., 61., 60., 60.],
         [53., 55., 58.,  ..., 57., 57., 56.],
         [56., 58., 62.,  ..., 56., 54., 54.],
         ...,
         [23., 23., 23.,  ..., 31., 31., 29.],
         [27., 28., 29.,  ..., 36., 35., 34.],
         [31., 31., 33.,  ..., 38., 38., 37.]],

        [[47., 62., 81.,  ..., 65., 65., 65.],
         [49., 58., 72.,  ..., 62., 62., 63.],
         [50., 55., 63.,  ..., 61., 61., 61.],
         ...,
         [30., 30., 29.,  ..., 27., 27., 27.],
         [35., 35., 36.,  ..., 32., 33., 31.],
         [37., 38., 40.,  ..., 35., 36., 35.]],

        [[48., 66., 88.,  ..., 67., 66., 66.],
         [50., 64., 80.,  ..., 65., 64., 64.],
         [52., 61., 73.,  ..., 65., 63., 62.],
         ...,
         [ 1.,  1.,  1.,  ..., 28., 27., 26.],
         [ 3.,  3.,  4.,  ..., 33., 33., 31.],
         [ 5.,  5.,  6.,  ..., 36., 36., 34.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[791.4161, 584.7179, 837.7634, 630.6878]])), gt_classes: tensor([433])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000088324.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1025, 613], 'neg_category_ids': [556, 226, 290, 488, 490, 726, 1161, 625], 'image_id': 88324, 'annotations': [{'bbox': [193.29, 191.06, 20.96, 11.28], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 433}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000088324.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1025, 613], 'neg_category_ids': [556, 226, 290, 488, 490, 726, 1161, 625], 'image_id': 88324, 'image': tensor([[[ 14.,   9.,   5.,  ...,  38.,  40.,  42.],
         [ 13.,   9.,   5.,  ...,  38.,  40.,  41.],
         [ 12.,   9.,   5.,  ...,  37.,  39.,  40.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 14.,  10.,   5.,  ...,  25.,  27.,  28.],
         [ 14.,  11.,   6.,  ...,  23.,  25.,  25.],
         [ 14.,  12.,   8.,  ...,  19.,  20.,  20.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 50.,  45.,  40.,  ..., 102., 103., 104.],
         [ 51.,  47.,  42.,  ..., 102., 103., 103.],
         [ 53.,  49.,  44.,  ..., 101., 102., 102.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[228.4925, 354.2571, 267.3668, 375.1721]])), gt_classes: tensor([433])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000173422.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [500, 58], 'neg_category_ids': [782, 1007, 792, 328, 1079, 676, 334, 940], 'image_id': 173422, 'image': tensor([[[ 64.,  66.,  65.,  ...,  96.,  93.,  91.],
         [ 74.,  76.,  76.,  ...,  68.,  66.,  65.],
         [ 90.,  91.,  92.,  ...,  24.,  23.,  23.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 72.,  74.,  74.,  ...,  97.,  96.,  94.],
         [ 82.,  83.,  83.,  ...,  73.,  72.,  71.],
         [ 97.,  98.,  97.,  ...,  35.,  34.,  34.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 62.,  64.,  66.,  ...,  88.,  87.,  85.],
         [ 74.,  76.,  77.,  ...,  61.,  60.,  59.],
         [ 94.,  95.,  94.,  ...,  19.,  18.,  18.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[652.7310, 339.4716, 685.8055, 373.2991]])), gt_classes: tensor([357])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000088635.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [967], 'neg_category_ids': [470, 306, 6, 523, 140, 143, 71, 342], 'image_id': 88635, 'image': tensor([[[255., 255., 255.,  ..., 176., 172., 169.],
         [255., 255., 255.,  ..., 176., 172., 169.],
         [255., 255., 255.,  ..., 179., 176., 172.],
         ...,
         [198., 195., 198.,  ..., 127., 126., 126.],
         [202., 198., 198.,  ..., 131., 129., 129.],
         [211., 211., 206.,  ..., 142., 140., 138.]],

        [[247., 247., 250.,  ..., 162., 162., 165.],
         [247., 247., 250.,  ..., 162., 162., 165.],
         [250., 250., 250.,  ..., 165., 165., 168.],
         ...,
         [223., 228., 223.,  ..., 150., 147., 145.],
         [228., 228., 223.,  ..., 151., 148., 145.],
         [233., 233., 228.,  ..., 156., 153., 147.]],

        [[251., 251., 251.,  ..., 163., 163., 163.],
         [251., 251., 251.,  ..., 163., 163., 163.],
         [251., 251., 251.,  ..., 166., 166., 166.],
         ...,
         [229., 229., 224.,  ..., 166., 163., 160.],
         [233., 229., 224.,  ..., 166., 163., 158.],
         [229., 229., 224.,  ..., 175., 169., 156.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[792.1718, 403.0937, 845.7490, 469.9992]])), gt_classes: tensor([357])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000411061.jpg', 'height': 332, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [783, 949, 522, 1132, 1083, 1137, 1039, 120], 'image_id': 411061, 'image': tensor([[[30., 17., 11.,  ..., 11., 17., 25.],
         [30., 17., 11.,  ..., 11., 17., 25.],
         [43., 19., 20.,  ..., 12., 19., 24.],
         ...,
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.]],

        [[76., 52., 40.,  ..., 17., 28., 43.],
         [76., 52., 40.,  ..., 17., 28., 43.],
         [75., 35., 41.,  ..., 19., 28., 40.],
         ...,
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.]],

        [[57., 44., 38.,  ..., 11., 19., 28.],
         [57., 44., 38.,  ..., 11., 19., 28.],
         [65., 35., 43.,  ..., 12., 20., 27.],
         ...,
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.],
         [51., 51., 51.,  ..., 51., 51., 51.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[542.4513, 592.1697, 568.4085, 619.6657]])), gt_classes: tensor([357])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000232241.jpg', 'height': 330, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [168, 782, 668, 786, 24, 605, 635, 15, 80, 420, 309, 745, 330, 841, 143], 'image_id': 232241, 'image': tensor([[[219., 220., 218.,  ..., 128., 128., 128.],
         [217., 218., 217.,  ..., 128., 128., 128.],
         [215., 216., 216.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[142., 143., 143.,  ..., 128., 128., 128.],
         [140., 142., 142.,  ..., 128., 128., 128.],
         [138., 140., 141.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 93.,  94.,  94.,  ..., 128., 128., 128.],
         [ 91.,  93.,  93.,  ..., 128., 128., 128.],
         [ 90.,  91.,  92.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[487.4475, 302.7041, 512.3342, 330.7316]])), gt_classes: tensor([357])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000508299.jpg', 'height': 448, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [631, 501, 197, 220, 591, 594, 595, 400, 1156, 11], 'image_id': 508299, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [141., 148., 153.,  ..., 100., 103., 107.],
         [ 58.,  65.,  70.,  ..., 102., 103., 107.],
         [ 42.,  45.,  51.,  ..., 102., 103., 107.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [137., 144., 149.,  ...,  54.,  58.,  58.],
         [ 54.,  61.,  68.,  ...,  56.,  58.,  58.],
         [ 33.,  38.,  44.,  ...,  54.,  56.,  58.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [125., 130., 135.,  ...,  42.,  42.,  44.],
         [ 44.,  49.,  52.,  ...,  47.,  45.,  44.],
         [ 24.,  28.,  31.,  ...,  47.,  45.,  44.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[563.8650, 106.8604, 598.3541, 137.0598]])), gt_classes: tensor([357])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000049891.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [500, 146], 'neg_category_ids': [218, 762, 832, 55, 482, 375, 611, 640, 463, 612, 548, 110, 641, 68, 534], 'image_id': 49891, 'annotations_cat_set': {132, 143, 816, 146, 500, 502}, 'image': tensor([[[ 0.,  0.,  0.,  ..., 29., 29., 29.],
         [ 0.,  0.,  0.,  ..., 29., 29., 29.],
         [ 0.,  0.,  0.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]],

        [[ 0.,  0.,  0.,  ..., 29., 29., 29.],
         [ 0.,  0.,  0.,  ..., 29., 29., 29.],
         [ 0.,  0.,  0.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]],

        [[ 0.,  0.,  0.,  ..., 29., 29., 29.],
         [ 0.,  0.,  0.,  ..., 29., 29., 29.],
         [ 0.,  0.,  0.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]]]), 'instances': Instances(num_instances=16, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 92.7192, 108.5073, 247.6248, 186.2261],
        [152.3451, 528.1114, 516.6752, 708.7169],
        [ 22.0898, 474.1346,  99.7780, 505.5184],
        [ 43.8613, 574.4326, 104.2070, 646.4616],
        [ 51.2938, 582.9049, 125.0097, 657.4536],
        [ 39.5568, 566.6662, 115.0028, 621.0583],
        [ 20.0137, 489.7365,  97.7987, 518.8084],
        [ 17.5086, 504.5770,  95.2520, 536.8329],
        [310.6141, 265.9246, 374.4753, 335.4894],
        [235.9433, 607.0069, 315.8459, 656.5399],
        [178.9609, 186.7660, 247.8601, 232.2151],
        [ 68.2764, 600.1127, 194.4902, 730.4792],
        [215.7357, 184.9248, 343.9149, 304.4102],
        [236.5661, 823.4954, 352.1086, 886.0000],
        [ 88.0272, 637.1032, 457.9627, 841.8107],
        [151.4454, 648.7735, 473.7273, 761.3232]])), gt_classes: tensor([359, 109, 111, 111, 111, 111, 111, 111, 111, 575, 575, 357, 357, 357,
        101, 101])])}], 'support_set_target': tensor(357)}
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000100202.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [81, 217], 'neg_category_ids': [584, 811, 82, 419, 746, 232, 1161, 513], 'image_id': 100202, 'image': tensor([[[  0.,   0.,   3.,  ...,  17.,  55.,  78.],
         [ 10.,   0.,   0.,  ...,  25.,  62.,  84.],
         [ 19.,   1.,   0.,  ...,  32.,  69.,  89.],
         ...,
         [116., 116., 118.,  ..., 103., 107., 111.],
         [116., 118., 120.,  ..., 103., 107., 111.],
         [114., 116., 120.,  ..., 107., 111., 112.]],

        [[ 60.,  68.,  80.,  ...,  23.,  75., 102.],
         [ 75.,  71.,  71.,  ...,  30.,  80., 103.],
         [ 91.,  73.,  60.,  ...,  37.,  86., 105.],
         ...,
         [146., 148., 150.,  ..., 130., 132., 134.],
         [148., 150., 154.,  ..., 130., 132., 134.],
         [148., 150., 154.,  ..., 132., 134., 136.]],

        [[143., 148., 161.,  ...,  33.,  96., 130.],
         [161., 154., 152.,  ...,  41., 102., 132.],
         [181., 159., 141.,  ...,  48., 107., 134.],
         ...,
         [123., 125., 125.,  ..., 100., 102., 102.],
         [125., 127., 127.,  ..., 100., 102., 102.],
         [125., 127., 129.,  ..., 102., 103., 105.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 722.4940,  206.5366, 1024.0000,  462.6104]])), gt_classes: tensor([636])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000370383.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [], 'neg_category_ids': [646, 862, 838, 229, 314, 799, 917, 730], 'image_id': 370383, 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 738.4852,  87.1565, 843.0674]])), gt_classes: tensor([636])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000400453.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [], 'neg_category_ids': [983, 1191, 7, 82, 37, 724, 995, 93], 'image_id': 400453, 'image': tensor([[[ 18.,  17.,  15.,  ...,  38.,  38.,  38.],
         [ 18.,  18.,  15.,  ...,  38.,  38.,  38.],
         [ 20.,  19.,  18.,  ...,  38.,  38.,  38.],
         ...,
         [ 38.,  38.,  38.,  ...,  38.,  38.,  38.],
         [ 38.,  38.,  38.,  ...,  38.,  38.,  38.],
         [ 38.,  38.,  38.,  ...,  38.,  38.,  38.]],

        [[ 28.,  28.,  27.,  ...,  38.,  38.,  38.],
         [ 29.,  28.,  27.,  ...,  38.,  38.,  38.],
         [ 29.,  29.,  28.,  ...,  38.,  38.,  38.],
         ...,
         [ 38.,  38.,  38.,  ...,  38.,  38.,  38.],
         [ 38.,  38.,  38.,  ...,  38.,  38.,  38.],
         [ 38.,  38.,  38.,  ...,  38.,  38.,  38.]],

        [[ 29.,  29.,  28.,  ...,  29.,  29.,  29.],
         [211.,  29.,  28.,  ...,  29.,  29.,  29.],
         [211., 211.,  29.,  ...,  29.,  29.,  29.],
         ...,
         [ 29.,  29.,  29.,  ...,  29.,  29.,  29.],
         [ 29.,  29.,  29.,  ...,  29.,  29.,  29.],
         [ 29.,  29.,  29.,  ...,  29.,  29.,  29.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[279.9248, 370.3243, 550.0000, 550.0000]])), gt_classes: tensor([636])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000509577.jpg', 'height': 440, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [192, 517, 965, 1, 105, 1150, 1105, 1010, 1031, 596, 37, 1113, 1199, 90, 1115, 65, 935], 'image_id': 509577, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[178.3117, 100.8409, 360.1126, 197.5398]])), gt_classes: tensor([636])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000100202.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [81, 217], 'neg_category_ids': [584, 811, 82, 419, 746, 232, 1161, 513], 'image_id': 100202, 'image': tensor([[[  0.,   0.,   3.,  ...,  17.,  55.,  78.],
         [ 10.,   0.,   0.,  ...,  25.,  62.,  84.],
         [ 19.,   1.,   0.,  ...,  32.,  69.,  89.],
         ...,
         [116., 116., 118.,  ..., 103., 107., 111.],
         [116., 118., 120.,  ..., 103., 107., 111.],
         [114., 116., 120.,  ..., 107., 111., 112.]],

        [[ 60.,  68.,  80.,  ...,  23.,  75., 102.],
         [ 75.,  71.,  71.,  ...,  30.,  80., 103.],
         [ 91.,  73.,  60.,  ...,  37.,  86., 105.],
         ...,
         [146., 148., 150.,  ..., 130., 132., 134.],
         [148., 150., 154.,  ..., 130., 132., 134.],
         [148., 150., 154.,  ..., 132., 134., 136.]],

        [[143., 148., 161.,  ...,  33.,  96., 130.],
         [161., 154., 152.,  ...,  41., 102., 132.],
         [181., 159., 141.,  ...,  48., 107., 134.],
         ...,
         [123., 125., 125.,  ..., 100., 102., 102.],
         [125., 127., 127.,  ..., 100., 102., 102.],
         [125., 127., 129.,  ..., 102., 103., 105.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 722.4940,  206.5366, 1024.0000,  462.6104]])), gt_classes: tensor([636])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000374028.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [904], 'neg_category_ids': [1028, 813, 883, 815, 508, 530, 531], 'image_id': 374028, 'annotations_cat_set': {904, 81, 818, 150, 87, 217, 734}, 'image': tensor([[[ 28.,  27.,  26.,  ..., 128., 128., 128.],
         [ 31.,  29.,  27.,  ..., 128., 128., 128.],
         [ 34.,  31.,  28.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 34.,  33.,  32.,  ..., 128., 128., 128.],
         [ 36.,  34.,  32.,  ..., 128., 128., 128.],
         [ 37.,  35.,  32.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 39.,  38.,  37.,  ..., 128., 128., 128.],
         [ 41.,  39.,  37.,  ..., 128., 128., 128.],
         [ 42.,  40.,  37.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=38, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[170.4209, 379.5428, 274.5637, 499.6712],
        [ 92.7228, 481.8475, 296.7978, 576.3922],
        [235.8963, 393.3199, 316.2147, 453.1719],
        [ 63.9154, 451.4592, 127.6339, 728.3488],
        [ 99.5536, 571.9666, 140.4776, 716.4814],
        [ 90.2692, 445.4119, 279.4709, 565.4645],
        [111.8823, 317.1142, 193.1700, 530.5142],
        [590.8995, 611.8427, 638.6241, 656.8568],
        [ 66.3993, 456.6427, 166.8162, 730.4858],
        [517.0333, 393.9867, 664.8566, 537.5013],
        [638.7149, 371.1614, 707.5830, 536.5312],
        [429.1269, 355.9748, 628.8095, 524.3759],
        [332.1784, 521.1780, 604.4096, 875.5463],
        [261.8866, 715.5569, 311.8527, 763.8144],
        [515.4885, 708.4789, 564.6215, 796.7187],
        [620.1916, 554.7188, 645.1823, 580.1055],
        [624.8262, 547.7924, 667.2952, 613.0855],
        [494.7992, 534.3790, 727.0000, 594.8979],
        [156.9714, 696.2630, 244.1054, 790.3075],
        [436.7907, 819.3772, 523.0463, 929.0781],
        [635.0345, 592.0031, 664.8566, 622.3459],
        [457.5707, 548.0651, 521.1681, 571.8453],
        [ 65.5512, 451.3986, 128.5578, 723.9231],
        [188.4142, 296.9564, 649.8471, 384.8172],
        [593.4440, 546.6860, 696.7841, 709.1003],
        [493.7390, 532.4542, 522.5615, 555.3401],
        [619.1162, 522.7997, 710.7031, 603.8856],
        [422.6142, 532.3481, 474.8976, 566.8438],
        [599.4720, 640.7002, 726.6062, 690.6400],
        [475.6246, 684.2441, 539.0856, 730.0008],
        [591.2327, 611.9336, 653.0428, 656.6900],
        [470.2024, 694.0502, 540.0550, 851.9176],
        [540.1913, 711.3131, 592.0658, 778.9555],
        [502.3419, 776.0000, 562.1679, 852.5391],
        [437.5328, 789.6406, 633.9743, 852.9483],
        [470.7022, 476.9975, 522.7736, 554.8552],
        [665.7654, 612.8884, 693.8004, 644.0345],
        [  0.0000, 354.2470, 727.0000, 920.3027]])), gt_classes: tensor([166, 166, 166, 166, 166, 166, 166, 166, 166,  62,  62,  62, 636, 518,
        518, 518, 518, 518, 518, 518, 518, 518, 114, 114,  66,  66,  66,  66,
         66,  66,  66,  66,  66,  66,  66,  66,  66, 577])])}], 'support_set_target': tensor(636)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000556999.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [76, 220, 900, 80, 82, 774, 750, 1200, 976], 'image_id': 556999, 'annotations': [{'bbox': [201.16, 327.74, 128.92, 97.26], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 781}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000556999.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [76, 220, 900, 80, 82, 774, 750, 1200, 976], 'image_id': 556999, 'image': tensor([[[129., 130., 130.,  ..., 119., 119., 118.],
         [128., 129., 130.,  ..., 119., 119., 118.],
         [127., 128., 129.,  ..., 119., 119., 118.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[133., 134., 134.,  ..., 127., 126., 124.],
         [132., 133., 134.,  ..., 127., 126., 124.],
         [131., 132., 133.,  ..., 127., 127., 125.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[162., 163., 163.,  ..., 156., 155., 153.],
         [161., 162., 163.,  ..., 156., 155., 153.],
         [160., 161., 162.,  ..., 156., 156., 154.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[232.6904, 636.2012, 483.0773, 825.0000]])), gt_classes: tensor([781])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000449517.jpg', 'height': 515, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [48, 456, 812, 442, 445, 1139, 472, 1020], 'image_id': 449517, 'annotations': [{'bbox': [307.64, 364.81, 74.36, 77.43], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 781}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000449517.jpg', 'height': 515, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [48, 456, 812, 442, 445, 1139, 472, 1020], 'image_id': 449517, 'image': tensor([[[188., 188., 189.,  ..., 138., 138., 137.],
         [188., 188., 189.,  ..., 138., 138., 137.],
         [188., 188., 188.,  ..., 138., 138., 137.],
         ...,
         [141., 142., 142.,  ..., 127., 128., 128.],
         [147., 145., 144.,  ..., 131., 132., 130.],
         [151., 148., 146.,  ..., 134., 134., 131.]],

        [[188., 188., 189.,  ..., 138., 138., 137.],
         [188., 188., 189.,  ..., 138., 138., 137.],
         [188., 188., 188.,  ..., 138., 138., 137.],
         ...,
         [141., 142., 142.,  ..., 127., 128., 128.],
         [147., 145., 144.,  ..., 131., 132., 130.],
         [151., 148., 146.,  ..., 134., 134., 131.]],

        [[188., 188., 189.,  ..., 138., 138., 137.],
         [188., 188., 189.,  ..., 138., 138., 137.],
         [188., 188., 188.,  ..., 138., 138., 137.],
         ...,
         [141., 142., 142.,  ..., 127., 128., 128.],
         [147., 145., 144.,  ..., 131., 132., 130.],
         [151., 148., 146.,  ..., 134., 134., 131.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 535.2933,  850.1772,  747.1031, 1024.0000]])), gt_classes: tensor([781])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000389168.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1190, 500, 626], 'neg_category_ids': [48, 758, 964, 857, 740, 30, 31, 58, 178, 677, 722, 87, 798, 574, 142, 936], 'image_id': 389168, 'annotations': [{'bbox': [110.2, 280.04, 102.7, 32.09], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 781}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000389168.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1190, 500, 626], 'neg_category_ids': [48, 758, 964, 857, 740, 30, 31, 58, 178, 677, 722, 87, 798, 574, 142, 936], 'image_id': 389168, 'image': tensor([[[ 59.,  63.,  59.,  ..., 128., 128., 128.],
         [ 59.,  61.,  60.,  ..., 128., 128., 128.],
         [ 59.,  59.,  60.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 75.,  80.,  76.,  ..., 128., 128., 128.],
         [ 75.,  77.,  77.,  ..., 128., 128., 128.],
         [ 76.,  75.,  76.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[104., 107., 103.,  ..., 128., 128., 128.],
         [104., 105., 103.,  ..., 128., 128., 128.],
         [105., 104., 105.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[382.3880, 250.2858, 474.3366, 278.9662]])), gt_classes: tensor([781])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038663.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1028, 104, 418, 908, 311, 839, 441, 1111, 1087], 'image_id': 38663, 'annotations': [{'bbox': [610.73, 226.92, 29.27, 21.52], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 781}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038663.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1028, 104, 418, 908, 311, 839, 441, 1111, 1087], 'image_id': 38663, 'image': tensor([[[ 55.,  56.,  52.,  ..., 128., 128., 128.],
         [ 47.,  53.,  51.,  ..., 128., 128., 128.],
         [ 40.,  42.,  54.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 60.,  62.,  58.,  ..., 128., 128., 128.],
         [ 58.,  62.,  61.,  ..., 128., 128., 128.],
         [ 50.,  51.,  63.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 69.,  69.,  65.,  ..., 128., 128., 128.],
         [ 66.,  71.,  68.,  ..., 128., 128., 128.],
         [ 60.,  61.,  73.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[620.2726, 230.6487, 650.0000, 252.5224]])), gt_classes: tensor([781])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000124210.jpg', 'height': 429, 'width': 640, 'not_exhaustive_category_ids': [811], 'neg_category_ids': [255, 348, 1190, 480, 131, 1056, 88, 382, 553, 163, 555, 252, 387], 'image_id': 124210, 'annotations': [{'bbox': [294.02, 235.65, 99.53, 69.86], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 781}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000124210.jpg', 'height': 429, 'width': 640, 'not_exhaustive_category_ids': [811], 'neg_category_ids': [255, 348, 1190, 480, 131, 1056, 88, 382, 553, 163, 555, 252, 387], 'image_id': 124210, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 255.,  ..., 127., 127., 127.],
         [127., 255., 255.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[519.2896, 578.1182, 778.6896, 760.1776]])), gt_classes: tensor([781])])}, len instances: 1
not 0
entering support set: 2
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000076254.jpg', 'height': 450, 'width': 630, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1185, 272, 1055, 1154, 1015, 493, 873], 'image_id': 76254, 'image': tensor([[[ 43.,  44.,  45.,  ...,  41.,  41.,  42.],
         [ 42.,  43.,  44.,  ...,  41.,  42.,  42.],
         [ 41.,  42.,  43.,  ...,  42.,  43.,  43.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 37.,  38.,  38.,  ...,  38.,  38.,  38.],
         [ 36.,  37.,  37.,  ...,  38.,  38.,  38.],
         [ 34.,  35.,  35.,  ...,  38.,  38.,  38.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 78.,  81.,  84.,  ...,  47.,  47.,  47.],
         [ 77.,  80.,  83.,  ...,  47.,  47.,  47.],
         [ 76.,  79.,  82.,  ...,  47.,  47.,  47.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[255.5507,   0.5504, 434.3075, 124.2855]])), gt_classes: tensor([433])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000143017.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [774, 735, 510, 613, 12], 'neg_category_ids': [585, 521, 309, 640, 746, 618, 1088, 1066], 'image_id': 143017, 'image': tensor([[[51., 51., 52.,  ..., 61., 60., 60.],
         [53., 55., 58.,  ..., 57., 57., 56.],
         [56., 58., 62.,  ..., 56., 54., 54.],
         ...,
         [23., 23., 23.,  ..., 31., 31., 29.],
         [27., 28., 29.,  ..., 36., 35., 34.],
         [31., 31., 33.,  ..., 38., 38., 37.]],

        [[47., 62., 81.,  ..., 65., 65., 65.],
         [49., 58., 72.,  ..., 62., 62., 63.],
         [50., 55., 63.,  ..., 61., 61., 61.],
         ...,
         [30., 30., 29.,  ..., 27., 27., 27.],
         [35., 35., 36.,  ..., 32., 33., 31.],
         [37., 38., 40.,  ..., 35., 36., 35.]],

        [[48., 66., 88.,  ..., 67., 66., 66.],
         [50., 64., 80.,  ..., 65., 64., 64.],
         [52., 61., 73.,  ..., 65., 63., 62.],
         ...,
         [ 1.,  1.,  1.,  ..., 28., 27., 26.],
         [ 3.,  3.,  4.,  ..., 33., 33., 31.],
         [ 5.,  5.,  6.,  ..., 36., 36., 34.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[791.4161, 584.7179, 837.7634, 630.6878]])), gt_classes: tensor([433])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000088324.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1025, 613], 'neg_category_ids': [556, 226, 290, 488, 490, 726, 1161, 625], 'image_id': 88324, 'image': tensor([[[ 14.,   9.,   5.,  ...,  38.,  40.,  42.],
         [ 13.,   9.,   5.,  ...,  38.,  40.,  41.],
         [ 12.,   9.,   5.,  ...,  37.,  39.,  40.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 14.,  10.,   5.,  ...,  25.,  27.,  28.],
         [ 14.,  11.,   6.,  ...,  23.,  25.,  25.],
         [ 14.,  12.,   8.,  ...,  19.,  20.,  20.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 50.,  45.,  40.,  ..., 102., 103., 104.],
         [ 51.,  47.,  42.,  ..., 102., 103., 103.],
         [ 53.,  49.,  44.,  ..., 101., 102., 102.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[228.4925, 354.2571, 267.3668, 375.1721]])), gt_classes: tensor([433])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000143017.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [774, 735, 510, 613, 12], 'neg_category_ids': [585, 521, 309, 640, 746, 618, 1088, 1066], 'image_id': 143017, 'image': tensor([[[51., 51., 52.,  ..., 61., 60., 60.],
         [53., 55., 58.,  ..., 57., 57., 56.],
         [56., 58., 62.,  ..., 56., 54., 54.],
         ...,
         [23., 23., 23.,  ..., 31., 31., 29.],
         [27., 28., 29.,  ..., 36., 35., 34.],
         [31., 31., 33.,  ..., 38., 38., 37.]],

        [[47., 62., 81.,  ..., 65., 65., 65.],
         [49., 58., 72.,  ..., 62., 62., 63.],
         [50., 55., 63.,  ..., 61., 61., 61.],
         ...,
         [30., 30., 29.,  ..., 27., 27., 27.],
         [35., 35., 36.,  ..., 32., 33., 31.],
         [37., 38., 40.,  ..., 35., 36., 35.]],

        [[48., 66., 88.,  ..., 67., 66., 66.],
         [50., 64., 80.,  ..., 65., 64., 64.],
         [52., 61., 73.,  ..., 65., 63., 62.],
         ...,
         [ 1.,  1.,  1.,  ..., 28., 27., 26.],
         [ 3.,  3.,  4.,  ..., 33., 33., 31.],
         [ 5.,  5.,  6.,  ..., 36., 36., 34.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[791.4161, 584.7179, 837.7634, 630.6878]])), gt_classes: tensor([433])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000143017.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [774, 735, 510, 613, 12], 'neg_category_ids': [585, 521, 309, 640, 746, 618, 1088, 1066], 'image_id': 143017, 'image': tensor([[[51., 51., 52.,  ..., 61., 60., 60.],
         [53., 55., 58.,  ..., 57., 57., 56.],
         [56., 58., 62.,  ..., 56., 54., 54.],
         ...,
         [23., 23., 23.,  ..., 31., 31., 29.],
         [27., 28., 29.,  ..., 36., 35., 34.],
         [31., 31., 33.,  ..., 38., 38., 37.]],

        [[47., 62., 81.,  ..., 65., 65., 65.],
         [49., 58., 72.,  ..., 62., 62., 63.],
         [50., 55., 63.,  ..., 61., 61., 61.],
         ...,
         [30., 30., 29.,  ..., 27., 27., 27.],
         [35., 35., 36.,  ..., 32., 33., 31.],
         [37., 38., 40.,  ..., 35., 36., 35.]],

        [[48., 66., 88.,  ..., 67., 66., 66.],
         [50., 64., 80.,  ..., 65., 64., 64.],
         [52., 61., 73.,  ..., 65., 63., 62.],
         ...,
         [ 1.,  1.,  1.,  ..., 28., 27., 26.],
         [ 3.,  3.,  4.,  ..., 33., 33., 31.],
         [ 5.,  5.,  6.,  ..., 36., 36., 34.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[791.4161, 584.7179, 837.7634, 630.6878]])), gt_classes: tensor([433])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000402922.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [735, 639, 613], 'neg_category_ids': [807, 808, 1187, 926, 504, 439, 6, 906, 329, 268, 1085, 229, 292, 916, 729, 191], 'image_id': 402922, 'annotations_cat_set': {160, 835, 324, 613, 735, 277, 921, 29, 639}, 'image': tensor([[[164., 156., 142.,  ..., 128., 128., 128.],
         [112.,  97.,  77.,  ..., 128., 128., 128.],
         [ 48.,  29.,   8.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[190., 182., 166.,  ..., 128., 128., 128.],
         [133., 116.,  93.,  ..., 128., 128., 128.],
         [ 60.,  39.,  13.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[204., 191., 170.,  ..., 128., 128., 128.],
         [134., 118.,  98.,  ..., 128., 128., 128.],
         [ 54.,  39.,  24.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=230, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[438.5926, 448.3251, 472.4323, 477.6030],
        [707.6436, 487.0871, 754.7731, 531.0507],
        [478.1502, 463.0419, 511.9432, 491.6346],
        [504.0909, 351.5213, 540.4390, 387.5580],
        [458.1455, 367.0323, 490.5363, 401.4182],
        [459.5633, 281.2856, 495.0078, 314.3322],
        [208.0553, 483.5364, 242.2846, 521.8157],
        [587.2102, 407.5541, 625.3968, 442.6097],
        [572.7676, 306.8258, 609.9882, 341.2740],
        [351.8899, 325.6540, 373.8889, 350.6180],
        [545.8765, 242.0407, 561.6122, 248.5815],
        [459.0179, 340.5576, 491.6425, 369.5863],
        [610.6270, 488.9404, 657.0397, 528.8548],
        [621.5641, 321.2779, 657.6474, 357.6727],
        [319.8886, 313.3822, 344.9100, 336.8512],
        [126.3382, 376.2829, 152.3256, 405.5296],
        [455.8240, 456.2831, 489.5236, 482.6020],
        [397.8197, 345.3075, 422.0622, 371.6109],
        [594.4238, 346.2731, 626.6120, 379.9115],
        [439.0444, 333.3784, 457.8806, 360.3669],
        [562.4847, 258.5329, 596.1998, 288.8386],
        [490.2870, 257.5985, 522.8804, 287.3903],
        [344.6763, 377.7312, 365.1328, 402.2281],
        [150.2224, 376.5476, 182.5353, 408.8467],
        [640.0420, 501.7728, 683.0272, 546.8265],
        [500.6321, 476.2948, 532.7269, 501.8974],
        [439.6832, 281.9864, 465.8264, 311.2798],
        [514.5919, 445.2728, 549.9584, 482.8668],
        [380.6350, 337.6922, 404.5347, 362.2357],
        [557.4524, 466.6238, 594.8444, 506.2268],
        [482.6528, 345.4165, 512.5976, 378.2296],
        [359.8201, 355.0876, 384.0938, 384.1941],
        [291.7043, 352.5959, 310.5561, 377.0927],
        [735.7811, 384.0851, 779.0000, 423.5323],
        [742.0287, 504.5916, 778.1431, 544.8798],
        [314.1240, 391.7005, 338.2262, 413.4253],
        [567.5638, 365.8176, 600.2507, 401.6830],
        [496.4567, 404.3460, 527.5076, 439.1057],
        [522.1637, 272.2530, 564.7438, 304.2251],
        [446.1645, 418.7358, 476.9661, 451.1906],
        [540.7818, 390.8907, 573.3284, 426.6003],
        [564.9931, 506.9743, 603.8497, 542.2323],
        [387.1474, 396.4815, 413.8204, 427.8929],
        [403.2883, 434.4804, 432.6566, 460.3322],
        [506.8018, 273.1718, 533.1943, 298.6031],
        [497.2980, 295.4417, 526.3859, 326.6507],
        [501.9720, 240.8260, 537.1672, 267.7990],
        [391.8058, 370.1003, 420.3640, 398.8798],
        [422.1089, 441.2704, 449.1091, 469.0688],
        [446.4137, 335.3561, 476.4520, 367.4995],
        [470.2979, 249.5471, 502.4083, 272.1129],
        [601.4348, 316.3878, 633.4672, 350.4623],
        [487.9656, 320.3435, 519.1879, 347.8615],
        [729.3309, 310.8593, 771.6774, 346.8493],
        [300.1331, 381.5934, 323.4875, 406.5574],
        [519.7332, 300.6276, 550.5505, 328.3326],
        [708.8277, 528.7458, 751.4702, 572.6782],
        [576.4756, 290.2091, 610.7983, 311.4044],
        [372.8917, 392.4324, 395.2646, 418.2530],
        [616.4850, 529.7269, 661.9319, 569.5791],
        [733.8959, 346.8960, 774.3727, 386.0006],
        [414.4747, 352.1909, 443.4691, 378.4320],
        [328.2862, 398.6929, 350.1917, 420.1219],
        [403.2104, 402.3059, 434.6353, 435.6017],
        [520.0292, 484.5643, 550.2388, 512.5184],
        [681.9210, 441.1302, 723.7689, 480.0636],
        [548.0732, 283.2322, 581.0873, 309.5511],
        [578.5945, 270.2596, 613.3378, 295.3015],
        [418.2139, 303.9292, 446.6319, 329.5317],
        [441.7086, 309.2397, 458.1611, 334.1726],
        [646.0403, 546.7953, 687.9661, 584.0000],
        [588.7994, 376.7034, 624.5243, 409.6098],
        [332.5863, 373.8690, 352.4196, 399.2380],
        [664.9077, 306.4053, 710.6817, 337.0692],
        [618.0274, 352.6893, 650.8857, 386.6859],
        [339.3635, 401.2936, 364.6966, 425.8995],
        [400.6553, 322.1344, 422.8101, 346.4755],
        [472.7128, 316.0919, 500.5387, 343.8904],
        [637.3311, 293.1213, 678.3376, 331.2137],
        [648.0189, 391.9652, 685.7537, 429.0298],
        [450.6204, 308.2741, 483.4474, 339.8101],
        [517.5520, 413.8302, 548.1979, 445.7711],
        [646.7881, 329.6252, 681.4069, 360.0866],
        [542.7293, 304.3185, 578.6412, 338.3774],
        [676.1408, 477.3850, 719.3130, 519.4485],
        [467.2130, 428.2355, 502.4394, 462.1231],
        [487.2178, 374.1805, 523.9866, 407.3673],
        [648.8135, 427.8150, 691.0042, 467.4336],
        [640.1043, 355.0720, 683.7439, 394.8619],
        [645.6508, 463.4468, 690.6614, 502.4113],
        [519.9669, 381.7024, 549.3975, 415.9793],
        [420.6912, 275.9283, 449.7790, 305.7045],
        [614.6310, 452.3430, 654.8897, 490.4510],
        [288.1209, 377.1550, 308.3282, 400.6707],
        [588.0671, 476.0923, 624.0569, 518.7633],
        [539.2394, 458.0585, 568.2493, 495.3566],
        [449.0935, 364.6340, 465.6706, 393.0709],
        [590.4820, 519.1682, 629.4320, 554.7533],
        [618.6662, 417.9727, 658.5355, 454.4455],
        [365.6158, 333.5497, 388.9547, 357.0342],
        [672.5730, 517.6888, 719.6246, 558.9737],
        [677.8858, 328.7064, 712.1618, 365.2258],
        [368.6696, 417.1006, 395.1244, 443.5441],
        [142.0273, 268.3752, 166.2854, 292.9500],
        [482.1698, 294.6007, 506.3033, 318.2567],
        [354.1334, 410.9958, 376.9893, 435.1189],
        [470.2356, 397.1044, 502.9224, 430.0888],
        [559.2441, 432.3936, 597.0723, 471.2491],
        [433.6849, 360.0088, 454.4998, 385.6113],
        [494.9766, 435.4927, 527.8192, 472.8064],
        [710.6349, 375.5821, 748.0270, 412.0859],
        [356.9846, 382.5589, 383.8756, 410.5753],
        [533.5839, 329.9989, 567.4548, 366.0668],
        [337.1824, 319.8451, 360.3498, 344.5912],
        [449.4830, 392.9308, 475.0498, 422.0373],
        [303.7321, 358.5293, 325.5285, 383.2130],
        [539.6445, 424.4824, 571.1005, 457.6380],
        [606.8566, 287.4681, 645.4482, 322.8819],
        [317.8943, 363.3414, 346.0318, 391.7783],
        [673.6636, 363.7619, 717.2097, 399.6896],
        [562.2355, 334.4062, 602.3851, 369.1814],
        [703.4993, 336.3373, 747.7621, 377.4353],
        [673.6324, 397.7118, 717.2097, 439.2926],
        [419.2266, 328.4105, 446.4293, 354.4802],
        [509.4972, 324.6573, 545.7363, 356.3646],
        [424.8199, 411.1360, 454.9827, 441.2859],
        [705.8986, 410.8868, 746.2976, 449.5087],
        [740.2681, 541.9209, 779.0000, 584.0000],
        [540.9532, 495.0295, 578.9372, 530.2720],
        [708.9679, 451.3931, 750.5977, 489.8904],
        [677.5898, 557.9147, 721.8525, 584.0000],
        [462.3988, 266.5376, 492.4371, 285.8952],
        [736.1550, 423.2832, 778.8130, 462.5280],
        [388.1290, 426.5381, 408.7725, 448.6366],
        [540.2833, 247.1799, 571.4900, 274.6513],
        [537.5879, 362.2669, 575.8212, 393.8652],
        [738.2895, 458.5568, 779.0000, 502.9097],
        [ 90.7535,  83.9403, 169.7597, 183.0334],
        [354.1490, 191.5676, 401.3096, 242.7260],
        [  5.4063, 103.8118,  15.7202, 122.5777],
        [ 68.0067,  97.4268, 102.9059, 172.3968],
        [ 16.4213,  91.0729,  49.5288, 153.1481],
        [209.9872,  85.3107, 348.7116, 253.2847],
        [238.6544, 340.3864, 262.3049, 353.7639],
        [206.8556, 301.1260, 230.9268, 322.9131],
        [299.3386, 291.6107, 318.5331, 311.7781],
        [304.1216, 313.4912, 326.1673, 335.8701],
        [271.7931, 329.1891, 295.0073, 339.1716],
        [284.5219, 262.5352, 308.0478, 281.3946],
        [354.6320, 268.4531, 381.1180, 285.7551],
        [206.6531, 325.7786, 226.5488, 336.2906],
        [264.5952, 301.0325, 296.4718, 325.6228],
        [287.4510, 310.1585, 313.5631, 335.8701],
        [249.6072, 321.2779, 266.3401, 343.7969],
        [258.6592, 233.8180, 281.0320, 257.2559],
        [223.7444, 287.3592, 238.9816, 307.2307],
        [232.7029, 242.3834, 261.8686, 267.1917],
        [269.2380, 255.7297, 298.3882, 279.9151],
        [212.8540, 258.4395, 234.9464, 282.2043],
        [246.3510, 271.5522, 272.7279, 294.4606],
        [289.9749, 282.9052, 320.3248, 308.9594],
        [311.2884, 291.9377, 341.9654, 314.3322],
        [272.5409, 246.8062, 307.2220, 264.1393],
        [237.3613, 316.9641, 261.1831, 339.0159],
        [310.0109, 250.2323, 333.4120, 268.6556],
        [193.8308, 317.3222, 209.6912, 327.6629],
        [276.3737, 280.1642, 299.2918, 301.1415],
        [196.2457, 320.7795, 217.7928, 331.5562],
        [242.9389, 294.3672, 265.0002, 317.3378],
        [208.5850, 281.1142, 232.5626, 303.0103],
        [232.2355, 290.0533, 253.3620, 311.9806],
        [320.7766, 274.1218, 359.5085, 303.7734],
        [226.8604, 263.0492, 247.0832, 284.7273],
        [216.0479, 329.5629, 241.4121, 342.9560],
        [314.9809, 267.0359, 334.7986, 291.4705],
        [282.2940, 331.8833, 308.2971, 362.1890],
        [257.8802, 346.4444, 263.8784, 354.0442],
        [230.2568, 266.4442, 254.7019, 290.7386],
        [255.3873, 297.5908, 278.6794, 321.8074],
        [217.4033, 307.8848, 237.9066, 328.3793],
        [326.9463, 251.6339, 364.3071, 277.0807],
        [257.8023, 324.5015, 280.2842, 345.0272],
        [195.4822, 298.6965, 214.0069, 316.8862],
        [224.2897, 311.6068, 248.5789, 330.5284],
        [259.1889, 276.9094, 284.9894, 298.9768],
        [532.2751, 108.5150, 559.5245, 129.3210],
        [557.0941, 140.7674, 582.3181, 166.3543],
        [582.7543, 113.9345, 612.4186, 142.2468],
        [557.0317, 112.0501, 581.9130, 142.3403],
        [566.4265,  86.1517, 626.1758, 113.9345],
        [697.5322, 149.5974, 740.0812, 178.7507],
        [698.5605, 118.8401, 753.3865, 151.2482],
        [530.7327,  82.6477, 560.7709, 109.7608],
        [531.1066, 141.4214, 557.0473, 162.1651],
        [607.9472, 142.6829, 639.5278, 172.3034],
        [666.5903, 115.8344, 703.1877, 149.6130],
        [639.2630, 113.7165, 669.2078, 146.7942],
        [611.2813, 114.1214, 639.5590, 143.6640],
        [667.2291, 146.9344, 699.2615, 175.3713],
        [582.5829, 141.6239, 612.6056, 169.4223],
        [636.8481, 143.8509, 667.5563, 176.3213],
        [378.0643, 159.2373, 509.1077, 230.2517],
        [ 93.4021, 195.3986, 113.8275, 208.0597],
        [ 45.6806, 192.7356,  65.3114, 208.5425],
        [ 81.3120, 194.6667,  91.0028, 202.7025],
        [ 55.8231, 211.2367,  69.6582, 225.2371],
        [ 91.4390, 207.1876, 106.6139, 221.2503],
        [ 50.5571, 237.5245,  65.4983, 252.0388],
        [ 84.0385, 220.0201, 105.5701, 230.7656],
        [ 47.2230, 235.8114,  60.2479, 247.4758],
        [111.5372, 190.6487, 124.7958, 202.2509],
        [ 54.0782, 224.2404,  67.7886, 236.9639],
        [ 67.8821, 198.9805,  88.5723, 212.7629],
        [ 28.0284, 245.0153,  36.2079, 249.0955],
        [ 64.5324, 194.1839,  82.6831, 207.0319],
        [ 72.7586, 216.2825,  88.3698, 228.6321],
        [ 34.3539, 233.3975,  48.3136, 246.4947],
        [ 80.0500, 216.6874,  93.0282, 230.0181],
        [ 65.0620, 213.0588,  81.1406, 227.0280],
        [ 49.6846, 206.3622,  68.5520, 221.7175],
        [ 37.2206, 247.2111,  51.5698, 251.3069],
        [ 80.4863, 202.5779,  93.1061, 215.3636],
        [ 71.0292, 227.5575,  82.0910, 238.3499],
        [185.1994,   0.0000, 331.8540,  25.6181],
        [527.6790,  18.0962, 646.3986,  71.1390],
        [252.9101,  92.3654, 294.7424, 130.8783],
        [330.2025,   0.0000, 460.0774, 250.2012],
        [444.0144, 478.8177, 545.0196, 584.0000],
        [177.0667, 355.6794, 245.5876, 416.9604],
        [ 29.6799, 264.0459,  48.5317, 310.8438]])), gt_classes: tensor([519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 204, 204, 204,
        204, 204, 204, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450,
        450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450,
        450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450, 450,
        450, 450, 450, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233, 233,
        233, 233, 233, 233, 233, 121, 433, 433, 433, 433, 433, 433, 433, 433,
        433, 433, 433, 433, 433, 433, 433, 433, 433, 433, 433, 433, 433,  23,
         23, 646, 588, 588, 588, 588])])}], 'support_set_target': tensor(433)}
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000556999.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [76, 220, 900, 80, 82, 774, 750, 1200, 976], 'image_id': 556999, 'image': tensor([[[129., 130., 130.,  ..., 119., 119., 118.],
         [128., 129., 130.,  ..., 119., 119., 118.],
         [127., 128., 129.,  ..., 119., 119., 118.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[133., 134., 134.,  ..., 127., 126., 124.],
         [132., 133., 134.,  ..., 127., 126., 124.],
         [131., 132., 133.,  ..., 127., 127., 125.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[162., 163., 163.,  ..., 156., 155., 153.],
         [161., 162., 163.,  ..., 156., 155., 153.],
         [160., 161., 162.,  ..., 156., 156., 154.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[232.6904, 636.2012, 483.0773, 825.0000]])), gt_classes: tensor([781])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000449517.jpg', 'height': 515, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [48, 456, 812, 442, 445, 1139, 472, 1020], 'image_id': 449517, 'image': tensor([[[188., 188., 189.,  ..., 138., 138., 137.],
         [188., 188., 189.,  ..., 138., 138., 137.],
         [188., 188., 188.,  ..., 138., 138., 137.],
         ...,
         [141., 142., 142.,  ..., 127., 128., 128.],
         [147., 145., 144.,  ..., 131., 132., 130.],
         [151., 148., 146.,  ..., 134., 134., 131.]],

        [[188., 188., 189.,  ..., 138., 138., 137.],
         [188., 188., 189.,  ..., 138., 138., 137.],
         [188., 188., 188.,  ..., 138., 138., 137.],
         ...,
         [141., 142., 142.,  ..., 127., 128., 128.],
         [147., 145., 144.,  ..., 131., 132., 130.],
         [151., 148., 146.,  ..., 134., 134., 131.]],

        [[188., 188., 189.,  ..., 138., 138., 137.],
         [188., 188., 189.,  ..., 138., 138., 137.],
         [188., 188., 188.,  ..., 138., 138., 137.],
         ...,
         [141., 142., 142.,  ..., 127., 128., 128.],
         [147., 145., 144.,  ..., 131., 132., 130.],
         [151., 148., 146.,  ..., 134., 134., 131.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 535.2933,  850.1772,  747.1031, 1024.0000]])), gt_classes: tensor([781])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000389168.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1190, 500, 626], 'neg_category_ids': [48, 758, 964, 857, 740, 30, 31, 58, 178, 677, 722, 87, 798, 574, 142, 936], 'image_id': 389168, 'image': tensor([[[ 59.,  63.,  59.,  ..., 128., 128., 128.],
         [ 59.,  61.,  60.,  ..., 128., 128., 128.],
         [ 59.,  59.,  60.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 75.,  80.,  76.,  ..., 128., 128., 128.],
         [ 75.,  77.,  77.,  ..., 128., 128., 128.],
         [ 76.,  75.,  76.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[104., 107., 103.,  ..., 128., 128., 128.],
         [104., 105., 103.,  ..., 128., 128., 128.],
         [105., 104., 105.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[382.3880, 250.2858, 474.3366, 278.9662]])), gt_classes: tensor([781])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038663.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1028, 104, 418, 908, 311, 839, 441, 1111, 1087], 'image_id': 38663, 'image': tensor([[[ 55.,  56.,  52.,  ..., 128., 128., 128.],
         [ 47.,  53.,  51.,  ..., 128., 128., 128.],
         [ 40.,  42.,  54.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 60.,  62.,  58.,  ..., 128., 128., 128.],
         [ 58.,  62.,  61.,  ..., 128., 128., 128.],
         [ 50.,  51.,  63.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 69.,  69.,  65.,  ..., 128., 128., 128.],
         [ 66.,  71.,  68.,  ..., 128., 128., 128.],
         [ 60.,  61.,  73.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[620.2726, 230.6487, 650.0000, 252.5224]])), gt_classes: tensor([781])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000124210.jpg', 'height': 429, 'width': 640, 'not_exhaustive_category_ids': [811], 'neg_category_ids': [255, 348, 1190, 480, 131, 1056, 88, 382, 553, 163, 555, 252, 387], 'image_id': 124210, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 255.,  ..., 127., 127., 127.],
         [127., 255., 255.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[519.2896, 578.1182, 778.6896, 760.1776]])), gt_classes: tensor([781])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000004296.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [181, 346], 'neg_category_ids': [537, 412, 217, 324, 585, 393, 1097, 944, 496, 717, 309, 724, 1013, 89, 727, 1202, 960, 874], 'image_id': 4296, 'annotations_cat_set': {609, 1, 1155, 739, 421, 390, 133, 645, 429, 430, 1101, 181, 344, 346, 540, 1021}, 'image': tensor([[[ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 96.,  95.,  96.,  ...,  95.,  95.,  95.],
         [ 96.,  96.,  96.,  ...,  95.,  95.,  95.],
         ...,
         [ 91.,  92.,  92.,  ...,  86.,  86.,  86.],
         [ 91.,  92.,  92.,  ...,  86.,  86.,  86.],
         [ 91.,  92.,  92.,  ...,  86.,  86.,  86.]],

        [[ 98.,  98.,  98.,  ...,  99.,  99.,  99.],
         [ 98.,  98.,  98.,  ...,  99.,  99.,  99.],
         [ 99.,  98.,  98.,  ...,  99.,  99.,  99.],
         ...,
         [ 96.,  97.,  97.,  ...,  86.,  86.,  87.],
         [ 96.,  96.,  96.,  ...,  86.,  86.,  86.],
         [ 96.,  96.,  96.,  ...,  87.,  86.,  86.]],

        [[100., 100., 100.,  ..., 103., 103., 103.],
         [100., 100., 100.,  ..., 102., 102., 102.],
         [100., 100., 100.,  ..., 102., 102., 102.],
         ...,
         [101., 101., 101.,  ...,  86.,  86.,  87.],
         [101., 101., 101.,  ...,  86.,  86.,  86.],
         [101., 101., 101.,  ...,  87.,  86.,  86.]]]), 'instances': Instances(num_instances=44, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 229.2039,  537.3538,  308.1400,  585.6770],
        [ 450.5065,  531.1404,  731.5267,  900.5182],
        [ 560.5753,  812.9005,  661.0835,  830.2056],
        [ 833.2967,  506.5055, 1022.1802,  526.5532],
        [ 562.3467,  645.4803,  665.5485,  660.1157],
        [ 734.8026,  606.3315,  812.7680,  654.1451],
        [  64.9742,  645.6988,  158.1300,  697.7355],
        [ 171.3790,  637.6165,  273.4160,  694.5802],
        [ 732.9826,  718.5841,  809.1767,  783.7270],
        [ 734.0504,  655.4556,  811.4091,  715.8657],
        [ 488.2153,  800.0127,  719.6851,  888.9167],
        [ 272.5909,  633.9274,  369.8475,  685.6243],
        [ 383.0966,  626.8160,  472.2970,  679.7507],
        [ 156.6497,  109.7987,  260.7250,  453.4252],
        [  54.3459,  624.0248,  398.1898,  918.6728],
        [ 660.7438,  110.3327,  780.3248,  444.6149],
        [ 363.2715,  109.2648,  449.9240,  446.4352],
        [ 831.2341,  101.6680, 1024.0000,  305.3488],
        [ 451.1131,  102.9544,  692.5076,  304.3295],
        [  51.2399,  110.0900,  157.4262,  458.0367],
        [ 734.8026,  655.8925,  812.3798,  716.2783],
        [ 764.5037,  818.9682,  865.0847,  912.4109],
        [ 827.0361,  349.4247, 1024.0000,  867.2429],
        [ 158.0329,  500.8262,  171.6945,  522.9612],
        [ 744.7757,  469.7109,  775.1077,  540.7031],
        [ 714.2496,  473.4001,  750.5024,  567.1098],
        [ 451.9624,  531.2375,  730.5561,  889.0139],
        [ 461.4503,  109.8958,  575.7656,  293.7959],
        [  53.1569,  111.1337,  154.4659,  456.4833],
        [ 363.2473,  109.2891,  449.9969,  446.4109],
        [ 938.1000,  111.1822, 1024.0000,  289.1360],
        [ 833.3938,  104.4592,  939.2647,  287.8496],
        [ 734.8511,  656.0624,  810.5598,  716.8123],
        [ 154.9026,  110.5269,  259.8272,  454.2747],
        [  54.8555,  619.7532,  490.2293,  896.5864],
        [ 665.5485,  109.9444,  781.6837,  442.8916],
        [ 250.4849,  106.4008,  356.4286,  450.9253],
        [ 776.3938,  537.6207,  804.0809,  585.0459],
        [ 702.3837,  544.0768,  729.3427,  579.6821],
        [ 749.3619,  537.5722,  779.5241,  586.5993],
        [ 158.0329,  573.9542,  376.3507,  620.0688],
        [ 622.7924,   26.0886,  648.2470,   59.8736],
        [   1.9079,  637.7136,   39.5196,  732.5640],
        [   0.0000,  624.5588,    7.1250,  699.8955]])), gt_classes: tensor([305, 716, 386, 386, 386, 278, 278, 278, 278, 278, 278, 278, 278, 137,
        137, 137, 137, 137, 137, 137, 137, 304, 299, 823, 102, 102, 523, 252,
        252, 252, 252, 252, 252, 252, 252, 252, 252, 250, 250, 250, 430, 455,
          0,   0])])}], 'support_set_target': tensor(781)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000481702.jpg', 'height': 382, 'width': 400, 'not_exhaustive_category_ids': [127, 756], 'neg_category_ids': [854, 669, 1151, 911, 229, 662, 663, 450], 'image_id': 481702, 'annotations': [{'bbox': [99.61, 2.55, 26.79, 29.07], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 588}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000481702.jpg', 'height': 382, 'width': 400, 'not_exhaustive_category_ids': [127, 756], 'neg_category_ids': [854, 669, 1151, 911, 229, 662, 663, 450], 'image_id': 481702, 'image': tensor([[[237., 228., 218.,  ..., 215., 206., 197.],
         [233., 223., 211.,  ..., 212., 203., 193.],
         [230., 218., 205.,  ..., 210., 200., 190.],
         ...,
         [204., 205., 206.,  ..., 181., 180., 179.],
         [202., 202., 203.,  ..., 180., 179., 178.],
         [200., 200., 201.,  ..., 179., 178., 178.]],

        [[222., 212., 201.,  ..., 207., 198., 188.],
         [216., 205., 192.,  ..., 206., 196., 186.],
         [210., 198., 184.,  ..., 205., 195., 184.],
         ...,
         [186., 187., 188.,  ...,   2.,   1.,   1.],
         [183., 184., 185.,  ...,   1.,   1.,   0.],
         [179., 180., 181.,  ...,   0.,   0.,   0.]],

        [[210., 198., 186.,  ..., 166., 161., 155.],
         [205., 192., 178.,  ..., 164., 158., 152.],
         [200., 186., 171.,  ..., 163., 156., 149.],
         ...,
         [170., 171., 171.,  ...,  28.,  24.,  20.],
         [167., 167., 168.,  ...,  22.,  20.,  17.],
         [164., 164., 164.,  ...,  16.,  15.,  13.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000578344.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [343, 237, 832, 1171, 1076, 1054, 399, 136, 229, 724, 401, 145, 364, 342], 'image_id': 578344, 'annotations': [{'bbox': [341.61, 173.68, 117.51, 217.55], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 588}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000578344.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [343, 237, 832, 1171, 1076, 1054, 399, 136, 229, 724, 401, 145, 364, 342], 'image_id': 578344, 'image': tensor([[[ 43.,  43.,  43.,  ..., 128., 128., 128.],
         [ 43.,  43.,  43.,  ..., 128., 128., 128.],
         [ 43.,  43.,  43.,  ..., 128., 128., 128.],
         ...,
         [ 54.,  54.,  54.,  ..., 128., 128., 128.],
         [ 52.,  52.,  53.,  ..., 128., 128., 128.],
         [ 52.,  52.,  53.,  ..., 128., 128., 128.]],

        [[ 53.,  53.,  52.,  ..., 128., 128., 128.],
         [ 53.,  53.,  52.,  ..., 128., 128., 128.],
         [ 53.,  53.,  52.,  ..., 128., 128., 128.],
         ...,
         [ 80.,  80.,  79.,  ..., 128., 128., 128.],
         [ 79.,  79.,  78.,  ..., 128., 128., 128.],
         [ 79.,  79.,  78.,  ..., 128., 128., 128.]],

        [[ 70.,  70.,  69.,  ..., 128., 128., 128.],
         [ 70.,  70.,  69.,  ..., 128., 128., 128.],
         [ 70.,  70.,  69.,  ..., 128., 128., 128.],
         ...,
         [106., 106., 105.,  ..., 128., 128., 128.],
         [105., 105., 104.,  ..., 128., 128., 128.],
         [105., 105., 104.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 43.2825,  98.1146, 286.8710, 549.1909]])), gt_classes: tensor([588])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000237355.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [995], 'neg_category_ids': [785, 1046, 132, 595, 912, 892], 'image_id': 237355, 'annotations': [{'bbox': [0.54, 95.94, 96.81, 150.01], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 588}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000237355.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [995], 'neg_category_ids': [785, 1046, 132, 595, 912, 892], 'image_id': 237355, 'image': tensor([[[ 13.,  12.,  12.,  ..., 128., 128., 128.],
         [ 16.,  15.,  15.,  ..., 128., 128., 128.],
         [ 17.,  16.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 20.,  19.,  19.,  ..., 128., 128., 128.],
         [ 23.,  22.,  22.,  ..., 128., 128., 128.],
         [ 24.,  23.,  22.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 23.,  22.,  22.,  ..., 128., 128., 128.],
         [ 26.,  25.,  25.,  ..., 128., 128., 128.],
         [ 27.,  26.,  25.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[503.2862, 126.8207, 631.2860, 325.1151]])), gt_classes: tensor([588])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000313007.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [815, 419, 227, 86, 266, 1112, 913], 'image_id': 313007, 'annotations': [{'bbox': [289.91, 351.33, 76.66, 75.85], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 588}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000313007.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [815, 419, 227, 86, 266, 1112, 913], 'image_id': 313007, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[139.6824, 535.4506, 316.8802, 710.8538]])), gt_classes: tensor([588])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000571355.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [959], 'neg_category_ids': [476, 303, 1004, 1100, 152, 200, 565, 484], 'image_id': 571355, 'annotations': [{'bbox': [179.0, 200.47, 25.02, 26.1], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 588}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000571355.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [959], 'neg_category_ids': [476, 303, 1004, 1100, 152, 200, 565, 484], 'image_id': 571355, 'image': tensor([[[ 82., 118., 135.,  ..., 234., 234., 234.],
         [ 84., 117., 133.,  ..., 234., 234., 234.],
         [ 87., 117., 137.,  ..., 234., 234., 234.],
         ...,
         [234., 234., 234.,  ..., 234., 234., 234.],
         [234., 234., 234.,  ..., 234., 234., 234.],
         [234., 234., 234.,  ..., 234., 234., 234.]],

        [[ 67.,  82.,  91.,  ..., 234., 234., 234.],
         [ 60.,  76.,  87.,  ..., 234., 234., 234.],
         [ 62.,  78.,  89.,  ..., 234., 234., 234.],
         ...,
         [234., 234., 234.,  ..., 234., 234., 234.],
         [234., 234., 234.,  ..., 234., 234., 234.],
         [234., 234., 234.,  ..., 234., 234., 234.]],

        [[ 69., 140., 201.,  ..., 234., 234., 234.],
         [ 64., 126., 184.,  ..., 234., 234., 234.],
         [ 64., 113., 162.,  ..., 234., 234., 234.],
         ...,
         [234., 234., 234.,  ..., 234., 234., 234.],
         [234., 234., 234.,  ..., 234., 234., 234.],
         [234., 234., 234.,  ..., 234., 234., 234.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[354.2337, 162.8819, 374.5625, 184.0881]])), gt_classes: tensor([588])])}, len instances: 1
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000578344.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [343, 237, 832, 1171, 1076, 1054, 399, 136, 229, 724, 401, 145, 364, 342], 'image_id': 578344, 'image': tensor([[[ 43.,  43.,  43.,  ..., 128., 128., 128.],
         [ 43.,  43.,  43.,  ..., 128., 128., 128.],
         [ 43.,  43.,  43.,  ..., 128., 128., 128.],
         ...,
         [ 54.,  54.,  54.,  ..., 128., 128., 128.],
         [ 52.,  52.,  53.,  ..., 128., 128., 128.],
         [ 52.,  52.,  53.,  ..., 128., 128., 128.]],

        [[ 53.,  53.,  52.,  ..., 128., 128., 128.],
         [ 53.,  53.,  52.,  ..., 128., 128., 128.],
         [ 53.,  53.,  52.,  ..., 128., 128., 128.],
         ...,
         [ 80.,  80.,  79.,  ..., 128., 128., 128.],
         [ 79.,  79.,  78.,  ..., 128., 128., 128.],
         [ 79.,  79.,  78.,  ..., 128., 128., 128.]],

        [[ 70.,  70.,  69.,  ..., 128., 128., 128.],
         [ 70.,  70.,  69.,  ..., 128., 128., 128.],
         [ 70.,  70.,  69.,  ..., 128., 128., 128.],
         ...,
         [106., 106., 105.,  ..., 128., 128., 128.],
         [105., 105., 104.,  ..., 128., 128., 128.],
         [105., 105., 104.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 43.2825,  98.1146, 286.8710, 549.1909]])), gt_classes: tensor([588])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000237355.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [995], 'neg_category_ids': [785, 1046, 132, 595, 912, 892], 'image_id': 237355, 'image': tensor([[[ 13.,  12.,  12.,  ..., 128., 128., 128.],
         [ 16.,  15.,  15.,  ..., 128., 128., 128.],
         [ 17.,  16.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 20.,  19.,  19.,  ..., 128., 128., 128.],
         [ 23.,  22.,  22.,  ..., 128., 128., 128.],
         [ 24.,  23.,  22.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 23.,  22.,  22.,  ..., 128., 128., 128.],
         [ 26.,  25.,  25.,  ..., 128., 128., 128.],
         [ 27.,  26.,  25.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[503.2862, 126.8207, 631.2860, 325.1151]])), gt_classes: tensor([588])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000313007.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [815, 419, 227, 86, 266, 1112, 913], 'image_id': 313007, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[139.6824, 535.4506, 316.8802, 710.8538]])), gt_classes: tensor([588])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000571355.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [959], 'neg_category_ids': [476, 303, 1004, 1100, 152, 200, 565, 484], 'image_id': 571355, 'image': tensor([[[ 82., 118., 135.,  ..., 234., 234., 234.],
         [ 84., 117., 133.,  ..., 234., 234., 234.],
         [ 87., 117., 137.,  ..., 234., 234., 234.],
         ...,
         [234., 234., 234.,  ..., 234., 234., 234.],
         [234., 234., 234.,  ..., 234., 234., 234.],
         [234., 234., 234.,  ..., 234., 234., 234.]],

        [[ 67.,  82.,  91.,  ..., 234., 234., 234.],
         [ 60.,  76.,  87.,  ..., 234., 234., 234.],
         [ 62.,  78.,  89.,  ..., 234., 234., 234.],
         ...,
         [234., 234., 234.,  ..., 234., 234., 234.],
         [234., 234., 234.,  ..., 234., 234., 234.],
         [234., 234., 234.,  ..., 234., 234., 234.]],

        [[ 69., 140., 201.,  ..., 234., 234., 234.],
         [ 64., 126., 184.,  ..., 234., 234., 234.],
         [ 64., 113., 162.,  ..., 234., 234., 234.],
         ...,
         [234., 234., 234.,  ..., 234., 234., 234.],
         [234., 234., 234.,  ..., 234., 234., 234.],
         [234., 234., 234.,  ..., 234., 234., 234.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[354.2337, 162.8819, 374.5625, 184.0881]])), gt_classes: tensor([588])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000237355.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [995], 'neg_category_ids': [785, 1046, 132, 595, 912, 892], 'image_id': 237355, 'image': tensor([[[ 13.,  12.,  12.,  ..., 128., 128., 128.],
         [ 16.,  15.,  15.,  ..., 128., 128., 128.],
         [ 17.,  16.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 20.,  19.,  19.,  ..., 128., 128., 128.],
         [ 23.,  22.,  22.,  ..., 128., 128., 128.],
         [ 24.,  23.,  22.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 23.,  22.,  22.,  ..., 128., 128., 128.],
         [ 26.,  25.,  25.,  ..., 128., 128., 128.],
         [ 27.,  26.,  25.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[503.2862, 126.8207, 631.2860, 325.1151]])), gt_classes: tensor([588])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000136365.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [559, 1078], 'neg_category_ids': [368, 1004, 766, 611, 109, 90, 726, 621], 'image_id': 136365, 'annotations_cat_set': {835, 559, 1040, 1078, 1079, 61}, 'image': tensor([[[ 22.,  23.,  24.,  ...,  77.,  77.,  76.],
         [ 22.,  23.,  24.,  ...,  68.,  68.,  67.],
         [ 21.,  22.,  23.,  ...,  59.,  59.,  58.],
         ...,
         [100., 100., 100.,  ..., 112., 113., 114.],
         [100., 100., 100.,  ..., 109., 110., 111.],
         [ 99., 100., 100.,  ..., 107., 107., 107.]],

        [[ 39.,  40.,  41.,  ...,  82.,  82.,  81.],
         [ 39.,  40.,  41.,  ...,  72.,  72.,  71.],
         [ 38.,  39.,  40.,  ...,  63.,  63.,  62.],
         ...,
         [115., 115., 114.,  ..., 124., 125., 127.],
         [114., 114., 114.,  ..., 121., 122., 123.],
         [113., 114., 114.,  ..., 119., 119., 119.]],

        [[ 30.,  31.,  32.,  ...,  81.,  81.,  80.],
         [ 30.,  31.,  32.,  ...,  72.,  72.,  71.],
         [ 29.,  30.,  31.,  ...,  64.,  64.,  63.],
         ...,
         [163., 163., 163.,  ..., 177., 179., 180.],
         [162., 162., 162.,  ..., 175., 176., 177.],
         [161., 162., 162.,  ..., 175., 175., 175.]]]), 'instances': Instances(num_instances=39, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[803.0748, 578.1232, 811.7248, 597.4783],
        [645.7350, 577.4672, 655.0660, 597.1503],
        [799.7459, 169.0681, 808.0177, 187.8427],
        [644.1967, 181.6350, 648.8116, 200.1573],
        [645.1046, 378.7688, 649.9717, 399.3351],
        [ 13.5766, 572.1931,  21.7727, 595.0810],
        [ 15.2915, 194.3785,  19.7804, 215.1467],
        [801.9904, 373.8985, 808.7238, 394.5910],
        [136.5684, 466.7371, 184.6354, 514.3298],
        [  0.0000, 556.2195, 224.4306, 758.3750],
        [372.5150, 574.2875, 410.5953, 654.4331],
        [234.0389, 646.2823, 400.7349, 904.0804],
        [397.9860, 490.9625, 444.4389, 559.8029],
        [184.2319, 233.2905, 273.0775, 327.8450],
        [412.2850, 323.8075, 482.2418, 451.7981],
        [843.8787, 260.3169, 899.8139, 391.4114],
        [408.8048, 190.9466, 473.6674, 317.0446],
        [732.2101,  43.0205, 788.7758,  98.5622],
        [178.7846,  78.9548, 251.3390, 220.7993],
        [691.5574, 355.9818, 776.9229, 450.8897],
        [541.5311, 184.3603, 581.7551, 276.3914],
        [311.3848,  98.2342, 381.7199, 225.7201],
        [442.3962, 492.3503, 490.3875, 541.4067],
        [842.4413, 121.8034, 901.0748, 256.5065],
        [686.7911, 171.7682, 772.1062, 266.8527],
        [ 36.5761, 181.1808,  72.5633, 314.4959],
        [529.4766,  56.5211, 634.6135, 163.4912],
        [286.6200, 240.6843, 352.6931, 366.6561],
        [394.6067,  78.2987, 444.1111, 174.1150],
        [676.3001, 458.6620, 778.5117, 556.3204],
        [439.6474,  73.3779, 489.5805, 168.0587],
        [548.7185, 357.8744, 625.7366, 448.3157],
        [ 36.5509, 328.2488,  73.2189, 454.2963],
        [550.0551, 450.6373, 622.0546, 579.1326],
        [844.7614, 390.6544, 900.7470, 459.3938],
        [679.2507,  50.1367, 733.4458, 152.9178],
        [581.0237, 182.0640, 622.4581, 273.5399],
        [719.9285, 132.6291, 782.7737, 180.9536],
        [188.7965, 334.0276, 255.4244, 448.0886]])), gt_classes: tensor([399, 399, 399, 399, 399, 399, 399, 399, 760, 761, 730, 730, 588, 588,
        588, 588, 588, 588, 588, 588, 588, 588, 588, 588, 588, 588, 588, 588,
        588, 588, 588, 588, 588, 588, 588, 588, 588, 588, 588])])}], 'support_set_target': tensor(588)}
[32m[11/14 23:09:09 d2go.utils.flop_calculator]: [0mCallback: model flops info:
DistributedDataParallel(
  input_shapes=[[{'support_set': [{'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None, None, None], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}], 'query_set': [{'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None, None], 'image_id': None, 'annotations_cat_set': None, 'image': [3, 1024, 1024], 'instances': None}], 'support_set_target': []}, {'support_set': [{'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None, None], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None, None], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}], 'query_set': [{'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None, None], 'image_id': None, 'annotations_cat_set': None, 'image': [3, 1024, 1024], 'instances': None}], 'support_set_target': []}, {'support_set': [{'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}], 'query_set': [{'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None, None], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'annotations_cat_set': None, 'image': [3, 1024, 1024], 'instances': None}], 'support_set_target': []}]], output_shapes={'loss_fcos_cls': []}, nparams=33.825728, nflops=1460381.636352
  (module): MetaOneStageDetector(
    input_shapes=[[{'support_set': [{'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None, None, None], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}], 'query_set': [{'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None, None], 'image_id': None, 'annotations_cat_set': None, 'image': [3, 1024, 1024], 'instances': None}], 'support_set_target': []}, {'support_set': [{'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None, None], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None, None], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}], 'query_set': [{'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None, None], 'image_id': None, 'annotations_cat_set': None, 'image': [3, 1024, 1024], 'instances': None}], 'support_set_target': []}, {'support_set': [{'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [], 'neg_category_ids': [None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}, {'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None], 'neg_category_ids': [None, None, None, None, None, None], 'image_id': None, 'image': [3, 1024, 1024], 'instances': None}], 'query_set': [{'file_name': None, 'height': None, 'width': None, 'not_exhaustive_category_ids': [None, None], 'neg_category_ids': [None, None, None, None, None, None, None, None], 'image_id': None, 'annotations_cat_set': None, 'image': [3, 1024, 1024], 'instances': None}], 'support_set_target': []}]], output_shapes={'loss_fcos_cls': []}, nparams=33.825728, nflops=1460381.636352
    (backbone): FPN(
      input_shapes=[[15, 3, 1024, 1024]], output_shapes={'p3': [15, 256, 128, 128], 'p4': [15, 256, 64, 64], 'p5': [15, 256, 32, 32], 'p6': [15, 256, 16, 16], 'p7': [15, 256, 8, 8]}, nparams=27.321536, nflops=1458170.75712
      (fpn_lateral3): Conv2d(
        512, 256, kernel_size=(1, 1), stride=(1, 1),
        input_shapes=[[15, 512, 128, 128]], output_shapes=[15, 256, 128, 128], nparams=0.131072, nflops=32212.25472
      )
      (fpn_output3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
        input_shapes=[[15, 256, 128, 128]], output_shapes=[15, 256, 128, 128], nparams=0.589824, nflops=144955.14624
      )
      (fpn_lateral4): Conv2d(
        1024, 256, kernel_size=(1, 1), stride=(1, 1),
        input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.262144, nflops=16106.12736
      )
      (fpn_output4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
        input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.589824, nflops=36238.78656
      )
      (fpn_lateral5): Conv2d(
        2048, 256, kernel_size=(1, 1), stride=(1, 1),
        input_shapes=[[15, 2048, 32, 32]], output_shapes=[15, 256, 32, 32], nparams=0.524288, nflops=8053.06368
      )
      (fpn_output5): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
        input_shapes=[[15, 256, 32, 32]], output_shapes=[15, 256, 32, 32], nparams=0.589824, nflops=9059.69664
      )
      (top_block): LastLevelP6P7(
        input_shapes=[[15, 256, 32, 32]], output_shapes=[[15, 256, 16, 16], [15, 256, 8, 8]], nparams=1.179648, nflops=2831.1552
        (p6): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1),
          input_shapes=[[15, 256, 32, 32]], output_shapes=[15, 256, 16, 16], nparams=0.589824, nflops=2264.92416
        )
        (p7): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1),
          input_shapes=[[15, 256, 16, 16]], output_shapes=[15, 256, 8, 8], nparams=0.589824, nflops=566.23104
        )
      )
      (bottom_up): ResNet(
        input_shapes=[[15, 3, 1024, 1024]], output_shapes={'res3': [15, 512, 128, 128], 'res4': [15, 1024, 64, 64], 'res5': [15, 2048, 32, 32]}, nparams=23.454912, nflops=1208714.52672
        (stem): BasicStem(
          input_shapes=[[15, 3, 1024, 1024]], output_shapes=[15, 64, 256, 256], nparams=0.009408, nflops=36993.76128
          (conv1): Conv2d(
            3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False,
            input_shapes=[[15, 3, 1024, 1024]], output_shapes=[15, 64, 512, 512], nparams=0.009408, nflops=36993.76128
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
        )
        (res2): Sequential(
          input_shapes=[[15, 64, 256, 256]], output_shapes=[15, 256, 256, 256], nparams=0.212992, nflops=209379.65568
          (0): BottleneckBlock(
            input_shapes=[[15, 64, 256, 256]], output_shapes=[15, 256, 256, 256], nparams=0.073728, nflops=72477.57312
            (shortcut): Conv2d(
              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 64, 256, 256]], output_shapes=[15, 256, 256, 256], nparams=0.016384, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv1): Conv2d(
              64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 64, 256, 256]], output_shapes=[15, 64, 256, 256], nparams=0.004096, nflops=4026.53184
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
            (conv2): Conv2d(
              64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 64, 256, 256]], output_shapes=[15, 64, 256, 256], nparams=0.036864, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
            (conv3): Conv2d(
              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 64, 256, 256]], output_shapes=[15, 256, 256, 256], nparams=0.016384, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
          )
          (1): BottleneckBlock(
            input_shapes=[[15, 256, 256, 256]], output_shapes=[15, 256, 256, 256], nparams=0.069632, nflops=68451.04128
            (conv1): Conv2d(
              256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 256, 256, 256]], output_shapes=[15, 64, 256, 256], nparams=0.016384, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
            (conv2): Conv2d(
              64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 64, 256, 256]], output_shapes=[15, 64, 256, 256], nparams=0.036864, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
            (conv3): Conv2d(
              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 64, 256, 256]], output_shapes=[15, 256, 256, 256], nparams=0.016384, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
          )
          (2): BottleneckBlock(
            input_shapes=[[15, 256, 256, 256]], output_shapes=[15, 256, 256, 256], nparams=0.069632, nflops=68451.04128
            (conv1): Conv2d(
              256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 256, 256, 256]], output_shapes=[15, 64, 256, 256], nparams=0.016384, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
            (conv2): Conv2d(
              64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 64, 256, 256]], output_shapes=[15, 64, 256, 256], nparams=0.036864, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
            )
            (conv3): Conv2d(
              64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 64, 256, 256]], output_shapes=[15, 256, 256, 256], nparams=0.016384, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
          )
        )
        (res3): Sequential(
          input_shapes=[[15, 256, 256, 256]], output_shapes=[15, 512, 128, 128], nparams=1.212416, nflops=297963.35616
          (0): BottleneckBlock(
            input_shapes=[[15, 256, 256, 256]], output_shapes=[15, 512, 128, 128], nparams=0.376832, nflops=92610.23232
            (shortcut): Conv2d(
              256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False,
              input_shapes=[[15, 256, 256, 256]], output_shapes=[15, 512, 128, 128], nparams=0.131072, nflops=32212.25472
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv1): Conv2d(
              256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False,
              input_shapes=[[15, 256, 256, 256]], output_shapes=[15, 128, 128, 128], nparams=0.032768, nflops=8053.06368
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv2): Conv2d(
              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 128, 128, 128]], output_shapes=[15, 128, 128, 128], nparams=0.147456, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv3): Conv2d(
              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 128, 128, 128]], output_shapes=[15, 512, 128, 128], nparams=0.065536, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
          )
          (1): BottleneckBlock(
            input_shapes=[[15, 512, 128, 128]], output_shapes=[15, 512, 128, 128], nparams=0.278528, nflops=68451.04128
            (conv1): Conv2d(
              512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 512, 128, 128]], output_shapes=[15, 128, 128, 128], nparams=0.065536, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv2): Conv2d(
              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 128, 128, 128]], output_shapes=[15, 128, 128, 128], nparams=0.147456, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv3): Conv2d(
              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 128, 128, 128]], output_shapes=[15, 512, 128, 128], nparams=0.065536, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
          )
          (2): BottleneckBlock(
            input_shapes=[[15, 512, 128, 128]], output_shapes=[15, 512, 128, 128], nparams=0.278528, nflops=68451.04128
            (conv1): Conv2d(
              512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 512, 128, 128]], output_shapes=[15, 128, 128, 128], nparams=0.065536, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv2): Conv2d(
              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 128, 128, 128]], output_shapes=[15, 128, 128, 128], nparams=0.147456, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv3): Conv2d(
              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 128, 128, 128]], output_shapes=[15, 512, 128, 128], nparams=0.065536, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
          )
          (3): BottleneckBlock(
            input_shapes=[[15, 512, 128, 128]], output_shapes=[15, 512, 128, 128], nparams=0.278528, nflops=68451.04128
            (conv1): Conv2d(
              512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 512, 128, 128]], output_shapes=[15, 128, 128, 128], nparams=0.065536, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv2): Conv2d(
              128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 128, 128, 128]], output_shapes=[15, 128, 128, 128], nparams=0.147456, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
            )
            (conv3): Conv2d(
              128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 128, 128, 128]], output_shapes=[15, 512, 128, 128], nparams=0.065536, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
          )
        )
        (res4): Sequential(
          input_shapes=[[15, 512, 128, 128]], output_shapes=[15, 1024, 64, 64], nparams=7.077888, nflops=434865.43872
          (0): BottleneckBlock(
            input_shapes=[[15, 512, 128, 128]], output_shapes=[15, 1024, 64, 64], nparams=1.507328, nflops=92610.23232
            (shortcut): Conv2d(
              512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False,
              input_shapes=[[15, 512, 128, 128]], output_shapes=[15, 1024, 64, 64], nparams=0.524288, nflops=32212.25472
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
            (conv1): Conv2d(
              512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False,
              input_shapes=[[15, 512, 128, 128]], output_shapes=[15, 256, 64, 64], nparams=0.131072, nflops=8053.06368
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.589824, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 1024, 64, 64], nparams=0.262144, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (1): BottleneckBlock(
            input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 1024, 64, 64], nparams=1.114112, nflops=68451.04128
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.262144, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.589824, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 1024, 64, 64], nparams=0.262144, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (2): BottleneckBlock(
            input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 1024, 64, 64], nparams=1.114112, nflops=68451.04128
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.262144, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.589824, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 1024, 64, 64], nparams=0.262144, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (3): BottleneckBlock(
            input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 1024, 64, 64], nparams=1.114112, nflops=68451.04128
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.262144, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.589824, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 1024, 64, 64], nparams=0.262144, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (4): BottleneckBlock(
            input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 1024, 64, 64], nparams=1.114112, nflops=68451.04128
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.262144, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.589824, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 1024, 64, 64], nparams=0.262144, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
          (5): BottleneckBlock(
            input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 1024, 64, 64], nparams=1.114112, nflops=68451.04128
            (conv1): Conv2d(
              1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.262144, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv2): Conv2d(
              256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 256, 64, 64], nparams=0.589824, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
            )
            (conv3): Conv2d(
              256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 256, 64, 64]], output_shapes=[15, 1024, 64, 64], nparams=0.262144, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
            )
          )
        )
        (res5): Sequential(
          input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 2048, 32, 32], nparams=14.942208, nflops=229512.31488
          (0): BottleneckBlock(
            input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 2048, 32, 32], nparams=6.029312, nflops=92610.23232
            (shortcut): Conv2d(
              1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False,
              input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 2048, 32, 32], nparams=2.097152, nflops=32212.25472
              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
            )
            (conv1): Conv2d(
              1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False,
              input_shapes=[[15, 1024, 64, 64]], output_shapes=[15, 512, 32, 32], nparams=0.524288, nflops=8053.06368
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv2): Conv2d(
              512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 512, 32, 32]], output_shapes=[15, 512, 32, 32], nparams=2.359296, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv3): Conv2d(
              512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 512, 32, 32]], output_shapes=[15, 2048, 32, 32], nparams=1.048576, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
            )
          )
          (1): BottleneckBlock(
            input_shapes=[[15, 2048, 32, 32]], output_shapes=[15, 2048, 32, 32], nparams=4.456448, nflops=68451.04128
            (conv1): Conv2d(
              2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 2048, 32, 32]], output_shapes=[15, 512, 32, 32], nparams=1.048576, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv2): Conv2d(
              512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 512, 32, 32]], output_shapes=[15, 512, 32, 32], nparams=2.359296, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv3): Conv2d(
              512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 512, 32, 32]], output_shapes=[15, 2048, 32, 32], nparams=1.048576, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
            )
          )
          (2): BottleneckBlock(
            input_shapes=[[15, 2048, 32, 32]], output_shapes=[15, 2048, 32, 32], nparams=4.456448, nflops=68451.04128
            (conv1): Conv2d(
              2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 2048, 32, 32]], output_shapes=[15, 512, 32, 32], nparams=1.048576, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv2): Conv2d(
              512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False,
              input_shapes=[[15, 512, 32, 32]], output_shapes=[15, 512, 32, 32], nparams=2.359296, nflops=36238.78656
              (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
            )
            (conv3): Conv2d(
              512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False,
              input_shapes=[[15, 512, 32, 32]], output_shapes=[15, 2048, 32, 32], nparams=1.048576, nflops=16106.12736
              (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
            )
          )
        )
      )
    )
    (proposal_generator): MetaFCOS(
      input_shapes=[[3, 3, 1024, 1024], {'p3': [3, 256, 128, 128], 'p4': [3, 256, 64, 64], 'p5': [3, 256, 32, 32], 'p6': [3, 256, 16, 16], 'p7': [3, 256, 8, 8]}, [None, None, None], None, {'cls_conv': [3, 256, 1, 1], 'cls_bias': [3]}, [[], [], []]], output_shapes=[{'instances': None, 'loss_denorm': None}, {'loss_fcos_cls': []}], nparams=4.732416, nflops=908.623872
      (fcos_head): MetaFCOSHead(
        input_shapes=[[[3, 256, 128, 128], [3, 256, 64, 64], [3, 256, 32, 32], [3, 256, 16, 16], [3, 256, 8, 8]], None, None, {'cls_conv': [3, 256, 1, 1], 'cls_bias': [3]}], output_shapes=[[[3, 3, 128, 128], [3, 3, 64, 64], [3, 3, 32, 32], [3, 3, 16, 16], [3, 3, 8, 8]], [[3, 4, 128, 128], [3, 4, 64, 64], [3, 4, 32, 32], [3, 4, 16, 16], [3, 4, 8, 8]], [[3, 1, 128, 128], [3, 1, 64, 64], [3, 1, 32, 32], [3, 1, 16, 16], [3, 1, 8, 8]], [[3, 1, 128, 128], [3, 1, 64, 64], [3, 1, 32, 32], [3, 1, 16, 16], [3, 1, 8, 8]], [], []], nparams=4.732416, nflops=908.623872
        (cls_tower): Sequential(
          input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=2.359296, nflops=452.984832
          (0): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.589824, nflops=113.246208
          )
          (1): GroupNorm(
            32, 256, eps=1e-05, affine=True,
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0
          )
          (2): ReLU(input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0)
          (3): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.589824, nflops=113.246208
          )
          (4): GroupNorm(
            32, 256, eps=1e-05, affine=True,
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0
          )
          (5): ReLU(input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0)
          (6): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.589824, nflops=113.246208
          )
          (7): GroupNorm(
            32, 256, eps=1e-05, affine=True,
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0
          )
          (8): ReLU(input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0)
          (9): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.589824, nflops=113.246208
          )
          (10): GroupNorm(
            32, 256, eps=1e-05, affine=True,
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0
          )
          (11): ReLU(input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0)
        )
        (bbox_tower): Sequential(
          input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=2.359296, nflops=452.984832
          (0): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.589824, nflops=113.246208
          )
          (1): GroupNorm(
            32, 256, eps=1e-05, affine=True,
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0
          )
          (2): ReLU(input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0)
          (3): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.589824, nflops=113.246208
          )
          (4): GroupNorm(
            32, 256, eps=1e-05, affine=True,
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0
          )
          (5): ReLU(input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0)
          (6): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.589824, nflops=113.246208
          )
          (7): GroupNorm(
            32, 256, eps=1e-05, affine=True,
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0
          )
          (8): ReLU(input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0)
          (9): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.589824, nflops=113.246208
          )
          (10): GroupNorm(
            32, 256, eps=1e-05, affine=True,
            input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0
          )
          (11): ReLU(input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0)
        )
        (share_tower): Sequential(input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 256, 8, 8], nparams=0.0, nflops=0.0)
        (cls_logits): Conv2d(256, 866, kernel_size=(1, 1), stride=(1, 1))
        (bbox_pred): Conv2d(
          256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
          input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 4, 8, 8], nparams=0.009216, nflops=1.769472
        )
        (ctrness): Conv2d(
          256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
          input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 1, 8, 8], nparams=0.002304, nflops=0.442368
        )
        (iou_overlap): Conv2d(
          256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
          input_shapes=[[3, 256, 8, 8]], output_shapes=[3, 1, 8, 8], nparams=0.002304, nflops=0.442368
        )
        (scales): ModuleList(
          (0): Scale(input_shapes=[[3, 4, 128, 128]], output_shapes=[3, 4, 128, 128], nparams=0.0, nflops=0.0)
          (1): Scale(input_shapes=[[3, 4, 64, 64]], output_shapes=[3, 4, 64, 64], nparams=0.0, nflops=0.0)
          (2): Scale(input_shapes=[[3, 4, 32, 32]], output_shapes=[3, 4, 32, 32], nparams=0.0, nflops=0.0)
          (3): Scale(input_shapes=[[3, 4, 16, 16]], output_shapes=[3, 4, 16, 16], nparams=0.0, nflops=0.0)
          (4): Scale(input_shapes=[[3, 4, 8, 8]], output_shapes=[3, 4, 8, 8], nparams=0.0, nflops=0.0)
        )
        (cond_cls_logits): CondConvBasic(input_shapes=[[3, 256, 8, 8], [3, 256, 1, 1], [3]], output_shapes=[3, 3, 8, 8], nparams=0.0, nflops=0.0)
      )
      (fcos_outputs): FCOSOutputs(
        (loc_loss_func): IOULoss(input_shapes=[[313], [313], [313]], output_shapes=[], nparams=0.0, nflops=0.0)
        (distill_loss_type): L1Loss()
      )
    )
    (code_generator): CodeGenerator(
      input_shapes=[[[15, 256, 128, 128], [15, 256, 64, 64], [15, 256, 32, 32], [15, 256, 16, 16], [15, 256, 8, 8]], [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]], output_shapes={'cls_conv': [3, 256, 1, 1], 'cls_bias': [3]}, nparams=1.771776, nflops=1302.25536
      (code_generator_head): CodeGeneratorHead(
        input_shapes=[[[15, 256, 128, 128], [15, 256, 64, 64], [15, 256, 32, 32], [15, 256, 16, 16], [15, 256, 8, 8]], [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]], output_shapes={'cls_conv': [3, 256, 1, 1], 'cls_bias': [3]}, nparams=1.771776, nflops=1302.25536
        (init_norm): ModuleList(
          (0): GroupNorm(32, 256, eps=1e-05, affine=True)
          (1): GroupNorm(32, 256, eps=1e-05, affine=True)
          (2): GroupNorm(32, 256, eps=1e-05, affine=True)
          (3): GroupNorm(32, 256, eps=1e-05, affine=True)
          (4): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
        (support_set_shared_tower): Sequential(
          input_shapes=[[15, 256, 7, 7]], output_shapes=[15, 256, 7, 7], nparams=1.179648, nflops=867.04128
          (0): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
            input_shapes=[[15, 256, 7, 7]], output_shapes=[15, 256, 7, 7], nparams=0.589824, nflops=433.52064
          )
          (1): GroupNorm(
            32, 256, eps=1e-05, affine=True,
            input_shapes=[[15, 256, 7, 7]], output_shapes=[15, 256, 7, 7], nparams=0.0, nflops=0.0
          )
          (2): ReLU(input_shapes=[[15, 256, 7, 7]], output_shapes=[15, 256, 7, 7], nparams=0.0, nflops=0.0)
          (3): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
            input_shapes=[[15, 256, 7, 7]], output_shapes=[15, 256, 7, 7], nparams=0.589824, nflops=433.52064
          )
          (4): GroupNorm(
            32, 256, eps=1e-05, affine=True,
            input_shapes=[[15, 256, 7, 7]], output_shapes=[15, 256, 7, 7], nparams=0.0, nflops=0.0
          )
          (5): ReLU(input_shapes=[[15, 256, 7, 7]], output_shapes=[15, 256, 7, 7], nparams=0.0, nflops=0.0)
        )
        (box_pooler): ROIPooler(
          input_shapes=[[[15, 256, 128, 128], [15, 256, 64, 64], [15, 256, 32, 32], [15, 256, 16, 16], [15, 256, 8, 8]], [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]], output_shapes=[15, 256, 7, 7], nparams=0.0, nflops=0.0
          (level_poolers): ModuleList(
            (0): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
            (1): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
            (2): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
            (3): ROIAlign(output_size=(7, 7), spatial_scale=0.015625, sampling_ratio=0, aligned=True)
            (4): ROIAlign(output_size=(7, 7), spatial_scale=0.0078125, sampling_ratio=0, aligned=True)
          )
        )
        (post_norm): GroupNorm(
          32, 256, eps=1e-05, affine=True,
          input_shapes=[[3, 256, 1, 1]], output_shapes=[3, 256, 1, 1], nparams=0.0, nflops=0.0
        )
        (support_set_cls_conv): Sequential(
          input_shapes=[[15, 256, 7, 7]], output_shapes=[15, 256, 1, 1], nparams=0.589824, nflops=433.52064
          (0): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
            input_shapes=[[15, 256, 7, 7]], output_shapes=[15, 256, 7, 7], nparams=0.589824, nflops=433.52064
          )
          (1): GlobalAdaptiveAvgPool2d(input_shapes=[[15, 256, 7, 7]], output_shapes=[15, 256, 1, 1], nparams=0.0, nflops=0.0)
        )
        (support_set_cls_bias): Sequential(
          input_shapes=[[15, 256, 7, 7]], output_shapes=[15, 1, 1, 1], nparams=0.002304, nflops=1.69344
          (0): Conv2d(
            256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1),
            input_shapes=[[15, 256, 7, 7]], output_shapes=[15, 1, 7, 7], nparams=0.002304, nflops=1.69344
          )
          (1): GlobalAdaptiveAvgPool2d(input_shapes=[[15, 1, 7, 7]], output_shapes=[15, 1, 1, 1], nparams=0.0, nflops=0.0)
        )
        (bias_scale): Scale(input_shapes=[[3]], output_shapes=[3], nparams=0.0, nflops=0.0)
        (conv_scale): Scale(input_shapes=[[3, 256, 1, 1]], output_shapes=[3, 256, 1, 1], nparams=0.0, nflops=0.0)
        (contrastive_loss_criterion): CosineEmbeddingLoss()
      )
    )
  )
)
[32m[11/14 23:09:11 d2go.utils.flop_calculator]: [0mModel parameters (M): 33.825728, MFlops (batch_size=3): 1460381.636352, MFlops (batch_size=1): 486793.878784
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000436436.jpg', 'height': 481, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [280, 853, 390, 982, 151, 153, 715, 973, 296, 386], 'image_id': 436436, 'annotations': [{'bbox': [366.96, 198.92, 139.55, 142.69], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 369}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000436436.jpg', 'height': 481, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [280, 853, 390, 982, 151, 153, 715, 973, 296, 386], 'image_id': 436436, 'image': tensor([[[ 77.,  83.,  87.,  ..., 128., 128., 128.],
         [ 80.,  82.,  87.,  ..., 128., 128., 128.],
         [ 80.,  82.,  87.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 99., 104., 106.,  ..., 128., 128., 128.],
         [103., 106., 110.,  ..., 128., 128., 128.],
         [105., 107., 112.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[111., 115., 116.,  ..., 128., 128., 128.],
         [115., 117., 119.,  ..., 128., 128., 128.],
         [117., 119., 122.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[168.1140, 250.6144, 343.8598, 430.3860]])), gt_classes: tensor([369])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000041938.jpg', 'height': 448, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1068, 75, 1130, 755, 64, 41, 779], 'image_id': 41938, 'annotations': [{'bbox': [59.03, 18.15, 329.06, 292.0], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 369}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000041938.jpg', 'height': 448, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1068, 75, 1130, 755, 64, 41, 779], 'image_id': 41938, 'image': tensor([[[176., 189., 185.,  ..., 128., 128., 128.],
         [172., 179., 166.,  ..., 128., 128., 128.],
         [185., 171., 157.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[182., 203., 194.,  ..., 128., 128., 128.],
         [179., 198., 184.,  ..., 128., 128., 128.],
         [195., 196., 181.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[201., 132., 204.,  ..., 128., 128., 128.],
         [196., 218., 191.,  ..., 128., 128., 128.],
         [213., 212., 192.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[249.5483,  17.9879, 575.5234, 307.3808]])), gt_classes: tensor([369])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000346334.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1187, 814, 1008, 914, 187, 44, 496, 875], 'image_id': 346334, 'annotations': [{'bbox': [427.79, 241.06, 55.54, 28.69], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 369}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000346334.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1187, 814, 1008, 914, 187, 44, 496, 875], 'image_id': 346334, 'image': tensor([[[146., 155., 168.,  ..., 128., 128., 128.],
         [163., 161., 162.,  ..., 128., 128., 128.],
         [179., 166., 153.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[146., 156., 170.,  ..., 128., 128., 128.],
         [164., 163., 164.,  ..., 128., 128., 128.],
         [181., 168., 155.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[158., 167., 180.,  ..., 128., 128., 128.],
         [175., 173., 173.,  ..., 128., 128., 128.],
         [191., 178., 164.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[645.6956, 363.5988, 729.5262, 406.8729]])), gt_classes: tensor([369])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000172923.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [784, 1046, 969, 1130, 289, 703, 17, 98], 'image_id': 172923, 'annotations': [{'bbox': [463.89, 256.0, 78.19, 75.51], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 369}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000172923.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [784, 1046, 969, 1130, 289, 703, 17, 98], 'image_id': 172923, 'image': tensor([[[ 34.,  40.,  43.,  ..., 128., 128., 128.],
         [ 36.,  37.,  41.,  ..., 128., 128., 128.],
         [ 35.,  34.,  39.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 76.,  85.,  85.,  ..., 128., 128., 128.],
         [ 77.,  78.,  82.,  ..., 128., 128., 128.],
         [ 70.,  70.,  76.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 51.,  59.,  61.,  ..., 128., 128., 128.],
         [ 55.,  55.,  58.,  ..., 128., 128., 128.],
         [ 51.,  51.,  54.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 84.3030, 220.4000, 151.6197, 285.4094]])), gt_classes: tensor([369])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000480894.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [691, 948, 129, 767, 1179, 934, 17], 'image_id': 480894, 'annotations': [{'bbox': [42.76, 213.41, 288.32, 131.19], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 369}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000480894.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [691, 948, 129, 767, 1179, 934, 17], 'image_id': 480894, 'image': tensor([[[ 57.,  56.,  56.,  ..., 128., 128., 128.],
         [ 59.,  60.,  62.,  ..., 128., 128., 128.],
         [ 63.,  63.,  63.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 88.,  88.,  89.,  ..., 128., 128., 128.],
         [ 88.,  90.,  92.,  ..., 128., 128., 128.],
         [ 90.,  91.,  91.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[121., 121., 122.,  ..., 128., 128., 128.],
         [121., 123., 125.,  ..., 128., 128., 128.],
         [124., 125., 125.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[280.4414, 193.9182, 542.1819, 313.1260]])), gt_classes: tensor([369])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000157102.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [255, 2, 23, 151, 200, 859, 791, 1128, 1103, 591, 157, 113, 975, 774, 1015, 844, 726], 'image_id': 157102, 'annotations': [{'bbox': [254.65, 121.07, 224.98, 177.1], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 260}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000157102.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [255, 2, 23, 151, 200, 859, 791, 1128, 1103, 591, 157, 113, 975, 774, 1015, 844, 726], 'image_id': 157102, 'image': tensor([[[108., 104., 101.,  ..., 115., 115., 115.],
         [124., 121., 115.,  ..., 115., 115., 115.],
         [144., 141., 137.,  ..., 115., 115., 115.],
         ...,
         [124., 121., 113.,  ..., 115., 115., 115.],
         [123., 123., 117.,  ..., 115., 115., 115.],
         [123., 123., 121.,  ..., 115., 115., 115.]],

        [[121., 119., 115.,  ..., 115., 115., 115.],
         [139., 135., 130.,  ..., 115., 115., 115.],
         [159., 157., 153.,  ..., 115., 115., 115.],
         ...,
         [130., 126., 121.,  ..., 115., 115., 115.],
         [126., 124., 124.,  ..., 115., 115., 115.],
         [124., 124., 126.,  ..., 115., 115., 115.]],

        [[110., 108., 104.,  ..., 115., 115., 115.],
         [126., 123., 117.,  ..., 115., 115., 115.],
         [144., 141., 137.,  ..., 115., 115., 115.],
         ...,
         [113., 110., 104.,  ..., 115., 115., 115.],
         [110., 108., 108.,  ..., 115., 115., 115.],
         [108., 108., 110.,  ..., 115., 115., 115.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[477.9993,  51.3846, 900.3055, 384.0005]])), gt_classes: tensor([260])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000056206.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [42, 219, 259, 1148, 911, 797, 865, 69, 646, 1067], 'image_id': 56206, 'annotations': [{'bbox': [539.43, 375.33, 100.57, 51.67], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 260}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000056206.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [42, 219, 259, 1148, 911, 797, 865, 69, 646, 1067], 'image_id': 56206, 'image': tensor([[[188., 189., 189.,  ..., 128., 128., 128.],
         [188., 189., 189.,  ..., 128., 128., 128.],
         [188., 189., 189.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[184., 184., 184.,  ..., 128., 128., 128.],
         [184., 184., 184.,  ..., 128., 128., 128.],
         [184., 184., 184.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[156., 158., 159.,  ..., 128., 128., 128.],
         [156., 158., 159.,  ..., 128., 128., 128.],
         [156., 158., 159.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 505.4209, 135.4552, 575.0000]])), gt_classes: tensor([260])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000062175.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [193, 806, 217, 1046, 947, 9, 157, 841, 530], 'image_id': 62175, 'annotations': [{'bbox': [0.0, 2.14, 640.0, 414.23], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 260}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000062175.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [193, 806, 217, 1046, 947, 9, 157, 841, 530], 'image_id': 62175, 'image': tensor([[[153., 128., 102.,  ...,  51.,  39.,  30.],
         [132., 100.,  66.,  ...,  55.,  46.,  36.],
         [108.,  93.,  76.,  ...,  51.,  45.,  39.],
         ...,
         [254., 254., 254.,  ...,  37.,  37.,  36.],
         [254., 253., 252.,  ...,  33.,  32.,  32.],
         [253., 250., 248.,  ...,  28.,  27.,  28.]],

        [[156., 133., 109.,  ...,  44.,  33.,  24.],
         [138., 105.,  71.,  ...,  48.,  39.,  29.],
         [114.,  96.,  78.,  ...,  46.,  41.,  34.],
         ...,
         [254., 254., 254.,  ...,  69.,  71.,  71.],
         [254., 253., 252.,  ...,  70.,  72.,  71.],
         [253., 250., 248.,  ...,  68.,  69.,  68.]],

        [[130., 102.,  73.,  ...,  33.,  23.,  16.],
         [108.,  74.,  39.,  ...,  35.,  29.,  20.],
         [ 86.,  72.,  57.,  ...,  27.,  22.,  17.],
         ...,
         [254., 254., 254.,  ...,  14.,  12.,  15.],
         [250., 250., 249.,  ...,  13.,  11.,  15.],
         [244., 243., 241.,  ...,  18.,  18.,  21.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,    0.0000, 1024.0000,  964.7809]])), gt_classes: tensor([260])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000126814.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [361], 'neg_category_ids': [1095, 104, 1169, 283, 974, 1087, 163], 'image_id': 126814, 'annotations': [{'bbox': [54.24, 251.7, 41.82, 88.84], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 260}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000126814.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [361], 'neg_category_ids': [1095, 104, 1169, 283, 974, 1087, 163], 'image_id': 126814, 'image': tensor([[[ 88.,  87.,  86.,  ..., 123., 136., 142.],
         [ 91.,  90.,  89.,  ..., 123., 136., 142.],
         [ 97.,  97.,  96.,  ..., 124., 137., 143.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[107., 105., 103.,  ..., 134., 147., 152.],
         [110., 108., 107.,  ..., 135., 147., 153.],
         [117., 116., 115.,  ..., 136., 148., 154.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[113., 111., 109.,  ..., 164., 177., 182.],
         [115., 114., 112.,  ..., 164., 177., 182.],
         [121., 119., 118.,  ..., 165., 177., 182.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000549201.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [804], 'neg_category_ids': [176, 482, 949, 264, 858, 795, 704, 1013, 1088, 1117, 729, 514], 'image_id': 549201, 'annotations': [{'bbox': [259.06, 295.08, 93.05, 67.14], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 260}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000549201.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [804], 'neg_category_ids': [176, 482, 949, 264, 858, 795, 704, 1013, 1088, 1117, 729, 514], 'image_id': 549201, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[300.0354, 307.5775, 397.0109, 377.5611]])), gt_classes: tensor([260])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000436436.jpg', 'height': 481, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [280, 853, 390, 982, 151, 153, 715, 973, 296, 386], 'image_id': 436436, 'image': tensor([[[ 77.,  83.,  87.,  ..., 128., 128., 128.],
         [ 80.,  82.,  87.,  ..., 128., 128., 128.],
         [ 80.,  82.,  87.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 99., 104., 106.,  ..., 128., 128., 128.],
         [103., 106., 110.,  ..., 128., 128., 128.],
         [105., 107., 112.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[111., 115., 116.,  ..., 128., 128., 128.],
         [115., 117., 119.,  ..., 128., 128., 128.],
         [117., 119., 122.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[168.1140, 250.6144, 343.8598, 430.3860]])), gt_classes: tensor([369])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000041938.jpg', 'height': 448, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1068, 75, 1130, 755, 64, 41, 779], 'image_id': 41938, 'image': tensor([[[176., 189., 185.,  ..., 128., 128., 128.],
         [172., 179., 166.,  ..., 128., 128., 128.],
         [185., 171., 157.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[182., 203., 194.,  ..., 128., 128., 128.],
         [179., 198., 184.,  ..., 128., 128., 128.],
         [195., 196., 181.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[201., 132., 204.,  ..., 128., 128., 128.],
         [196., 218., 191.,  ..., 128., 128., 128.],
         [213., 212., 192.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[249.5483,  17.9879, 575.5234, 307.3808]])), gt_classes: tensor([369])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000346334.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1187, 814, 1008, 914, 187, 44, 496, 875], 'image_id': 346334, 'image': tensor([[[146., 155., 168.,  ..., 128., 128., 128.],
         [163., 161., 162.,  ..., 128., 128., 128.],
         [179., 166., 153.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[146., 156., 170.,  ..., 128., 128., 128.],
         [164., 163., 164.,  ..., 128., 128., 128.],
         [181., 168., 155.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[158., 167., 180.,  ..., 128., 128., 128.],
         [175., 173., 173.,  ..., 128., 128., 128.],
         [191., 178., 164.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[645.6956, 363.5988, 729.5262, 406.8729]])), gt_classes: tensor([369])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000172923.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [784, 1046, 969, 1130, 289, 703, 17, 98], 'image_id': 172923, 'image': tensor([[[ 34.,  40.,  43.,  ..., 128., 128., 128.],
         [ 36.,  37.,  41.,  ..., 128., 128., 128.],
         [ 35.,  34.,  39.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 76.,  85.,  85.,  ..., 128., 128., 128.],
         [ 77.,  78.,  82.,  ..., 128., 128., 128.],
         [ 70.,  70.,  76.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 51.,  59.,  61.,  ..., 128., 128., 128.],
         [ 55.,  55.,  58.,  ..., 128., 128., 128.],
         [ 51.,  51.,  54.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 84.3030, 220.4000, 151.6197, 285.4094]])), gt_classes: tensor([369])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000480894.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [691, 948, 129, 767, 1179, 934, 17], 'image_id': 480894, 'image': tensor([[[ 57.,  56.,  56.,  ..., 128., 128., 128.],
         [ 59.,  60.,  62.,  ..., 128., 128., 128.],
         [ 63.,  63.,  63.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 88.,  88.,  89.,  ..., 128., 128., 128.],
         [ 88.,  90.,  92.,  ..., 128., 128., 128.],
         [ 90.,  91.,  91.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[121., 121., 122.,  ..., 128., 128., 128.],
         [121., 123., 125.,  ..., 128., 128., 128.],
         [124., 125., 125.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[280.4414, 193.9182, 542.1819, 313.1260]])), gt_classes: tensor([369])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000041938.jpg', 'height': 448, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1068, 75, 1130, 755, 64, 41, 779], 'image_id': 41938, 'annotations_cat_set': {76, 519}, 'image': tensor([[[ 88.,  90.,  94.,  ..., 108., 100.,  92.],
         [ 87.,  89.,  92.,  ..., 110., 103.,  95.],
         [ 85.,  86.,  90.,  ..., 119., 112., 103.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 87.,  91.,  96.,  ..., 126., 117., 111.],
         [ 87.,  91.,  96.,  ..., 129., 120., 114.],
         [ 86.,  91.,  95.,  ..., 136., 130., 122.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[108., 116., 125.,  ..., 123., 114., 107.],
         [107., 115., 124.,  ..., 125., 117., 110.],
         [105., 113., 121.,  ..., 134., 127., 117.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=4, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 202.2175,  196.0802,  740.4987,  855.7482],
        [ 429.3937,   39.0954, 1024.0000,  668.0686],
        [ 443.3245,   37.7815, 1024.0000,  660.6804],
        [ 188.6743,  195.4341,  749.4342,  845.0859]])), gt_classes: tensor([369, 369,  58,  58])])}], 'support_set_target': tensor(369)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000199487.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1076, 59], 'neg_category_ids': [666, 433, 479, 953, 910, 87, 1063, 386, 779], 'image_id': 199487, 'annotations': [{'bbox': [0.0, 178.07, 7.52, 6.31], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 758}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000199487.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1076, 59], 'neg_category_ids': [666, 433, 479, 953, 910, 87, 1063, 386, 779], 'image_id': 199487, 'image': tensor([[[223., 204., 184.,  ..., 250., 250., 250.],
         [207., 183., 159.,  ..., 250., 250., 250.],
         [183., 164., 145.,  ..., 250., 250., 250.],
         ...,
         [230., 233., 235.,  ...,  71.,  71.,  71.],
         [231., 232., 234.,  ...,  70.,  70.,  71.],
         [231., 231., 232.,  ...,  70.,  70.,  71.]],

        [[229., 208., 187.,  ..., 240., 240., 240.],
         [221., 189., 157.,  ..., 240., 240., 240.],
         [189., 161., 133.,  ..., 240., 240., 240.],
         ...,
         [226., 229., 230.,  ...,  63.,  63.,  62.],
         [227., 228., 229.,  ...,  62.,  62.,  63.],
         [227., 227., 228.,  ...,  62.,  62.,  63.]],

        [[224., 203., 182.,  ..., 233., 233., 233.],
         [210., 179., 149.,  ..., 233., 233., 233.],
         [177., 150., 122.,  ..., 233., 233., 233.],
         ...,
         [221., 224., 226.,  ...,  94.,  94.,  94.],
         [222., 223., 225.,  ...,  93.,  93.,  94.],
         [222., 222., 223.,  ...,  93.,  93.,  94.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 482.8376,   8.6095, 500.1244]])), gt_classes: tensor([758])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000151927.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [51, 608, 53, 5, 4, 510, 845, 235], 'image_id': 151927, 'annotations': [{'bbox': [22.01, 115.65, 80.6, 53.7], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 758}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000151927.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [51, 608, 53, 5, 4, 510, 845, 235], 'image_id': 151927, 'image': tensor([[[ 81.,  94., 120.,  ..., 127., 127., 127.],
         [ 87.,  94., 113.,  ..., 127., 127., 127.],
         [ 95.,  98., 110.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 82., 100., 132.,  ..., 127., 127., 127.],
         [ 83.,  95., 117.,  ..., 127., 127., 127.],
         [ 86.,  92., 106.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 42.,  61.,  94.,  ..., 127., 127., 127.],
         [ 41.,  54.,  78.,  ..., 127., 127., 127.],
         [ 42.,  49.,  65.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[487.7245, 173.8364, 608.9077, 254.5542]])), gt_classes: tensor([758])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000234994.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [517, 689, 734, 768, 487, 686, 646, 804, 319], 'image_id': 234994, 'annotations': [{'bbox': [438.64, 2.06, 32.79, 62.19], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 758}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000234994.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [517, 689, 734, 768, 487, 686, 646, 804, 319], 'image_id': 234994, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [  0.,   0., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[522.9412,   2.4565, 562.0330,  76.6174]])), gt_classes: tensor([758])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000100519.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [757, 193, 811, 1081, 1157, 292, 297, 847], 'image_id': 100519, 'annotations': [{'bbox': [517.43, 60.55, 61.02, 92.55], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 758}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000100519.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [757, 193, 811, 1081, 1157, 292, 297, 847], 'image_id': 100519, 'image': tensor([[[212., 213., 216.,  ...,   1.,   0.,   0.],
         [213., 214., 216.,  ...,   4.,   1.,   1.],
         [215., 214., 216.,  ...,   8.,   2.,   2.],
         ...,
         [219., 219., 218.,  ..., 241., 241., 240.],
         [221., 221., 221.,  ..., 242., 243., 241.],
         [223., 223., 224.,  ..., 242., 243., 241.]],

        [[182., 188., 214.,  ...,   5.,   2.,   1.],
         [185., 188., 212.,  ...,  11.,   4.,   2.],
         [190., 188., 210.,  ...,  17.,   6.,   4.],
         ...,
         [223., 223., 222.,  ..., 247., 247., 246.],
         [235., 235., 235.,  ..., 247., 247., 246.],
         [240., 240., 240.,  ..., 247., 247., 247.]],

        [[209., 209., 211.,  ...,  32.,   7.,   7.],
         [211., 211., 213.,  ..., 140.,  21.,   8.],
         [213., 213., 215.,  ..., 148.,  80.,  10.],
         ...,
         [235., 235., 234.,  ..., 248., 248., 247.],
         [239., 239., 239.,  ..., 248., 249., 248.],
         [242., 243., 243.,  ..., 248., 249., 248.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000249362.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [322, 171, 586, 460, 505, 617, 804, 937, 1182], 'image_id': 249362, 'annotations': [{'bbox': [160.76, 4.25, 29.96, 20.67], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 758}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000249362.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [322, 171, 586, 460, 505, 617, 804, 937, 1182], 'image_id': 249362, 'image': tensor([[[ 45.,  45.,  47.,  ..., 117., 122., 155.],
         [ 49.,  49.,  49.,  ..., 119., 126., 160.],
         [ 56.,  55.,  51.,  ..., 122., 132., 166.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 43.,  43.,  45.,  ..., 114., 118., 153.],
         [ 47.,  47.,  47.,  ..., 116., 122., 158.],
         [ 53.,  53.,  49.,  ..., 119., 129., 165.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 42.,  42.,  44.,  ..., 114., 119., 154.],
         [ 47.,  47.,  47.,  ..., 116., 123., 159.],
         [ 53.,  53.,  49.,  ..., 119., 129., 166.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[253.5289,   7.1542, 303.9460,  41.9487]])), gt_classes: tensor([758])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349203.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1142, 368, 412, 102, 50, 558, 285, 233, 154, 226, 614, 156, 1012, 1137, 384, 531], 'image_id': 349203, 'annotations': [{'bbox': [244.13, 297.25, 5.95, 5.55], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 760}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349203.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1142, 368, 412, 102, 50, 558, 285, 233, 154, 226, 614, 156, 1012, 1137, 384, 531], 'image_id': 349203, 'image': tensor([[[  5.,   5.,   3.,  ...,  48.,  60.,  52.],
         [ 12.,   9.,   7.,  ...,  37.,  47.,  43.],
         [ 23.,  12.,   8.,  ...,  28.,  38.,  30.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 12.,  10.,   2.,  ...,  81.,  91.,  84.],
         [ 12.,   9.,   6.,  ...,  71.,  80.,  75.],
         [ 11.,   8.,   7.,  ...,  62.,  72.,  61.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,  73.,  82.,  74.],
         [  4.,   4.,   5.,  ...,  63.,  71.,  65.],
         [ 11.,   8.,   6.,  ...,  54.,  63.,  51.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[359.2170, 510.4644, 369.4343, 519.9953]])), gt_classes: tensor([760])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000026746.jpg', 'height': 454, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1045, 898, 1146, 812, 416, 154, 641], 'image_id': 26746, 'annotations': [{'bbox': [212.55, 213.42, 14.18, 10.67], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 760}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000026746.jpg', 'height': 454, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1045, 898, 1146, 812, 416, 154, 641], 'image_id': 26746, 'image': tensor([[[  4.,   4.,   2.,  ..., 128., 128., 128.],
         [  1.,   2.,   2.,  ..., 128., 128., 128.],
         [  0.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  4.,   1.,   1.,  ..., 128., 128., 128.],
         [  3.,   2.,   1.,  ..., 128., 128., 128.],
         [  2.,   2.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  4.,   2.,   1.,  ..., 128., 128., 128.],
         [  1.,   2.,   2.,  ..., 128., 128., 128.],
         [  1.,   2.,   2.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[546.9370, 282.5229, 565.7034, 296.6478]])), gt_classes: tensor([760])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000080865.jpg', 'height': 640, 'width': 472, 'not_exhaustive_category_ids': [1078], 'neg_category_ids': [300, 301, 256, 1003, 25, 542, 1115, 1130, 486, 1034, 746, 1180, 362, 45], 'image_id': 80865, 'annotations': [{'bbox': [135.84, 390.34, 6.62, 6.91], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 760}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000080865.jpg', 'height': 640, 'width': 472, 'not_exhaustive_category_ids': [1078], 'neg_category_ids': [300, 301, 256, 1003, 25, 542, 1115, 1130, 486, 1034, 746, 1180, 362, 45], 'image_id': 80865, 'image': tensor([[[225., 225., 226.,  ..., 253., 253., 253.],
         [226., 225., 225.,  ..., 253., 253., 253.],
         [226., 225., 225.,  ..., 253., 253., 253.],
         ...,
         [162., 163., 163.,  ..., 204., 205., 205.],
         [162., 162., 162.,  ..., 204., 204., 204.],
         [152., 152., 151.,  ..., 202., 202., 202.]],

        [[211., 211., 211.,  ..., 254., 254., 254.],
         [211., 210., 210.,  ..., 254., 254., 254.],
         [211., 210., 210.,  ..., 254., 254., 254.],
         ...,
         [183., 184., 184.,  ..., 130., 131., 131.],
         [181., 182., 182.,  ..., 130., 130., 130.],
         [170., 170., 169.,  ..., 129., 128., 128.]],

        [[195., 195., 195.,  ..., 250., 250., 250.],
         [195., 194., 194.,  ..., 250., 250., 250.],
         [195., 194., 194.,  ..., 250., 250., 250.],
         ...,
         [187., 188., 188.,  ..., 145., 145., 145.],
         [186., 187., 187.,  ..., 146., 146., 146.],
         [176., 175., 175.,  ..., 146., 146., 146.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[816.9844, 900.7354, 834.0393, 918.5394]])), gt_classes: tensor([760])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000554301.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1078], 'neg_category_ids': [72, 142, 968, 508, 700, 64, 996], 'image_id': 554301, 'annotations': [{'bbox': [224.79, 349.85, 8.97, 9.22], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 760}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000554301.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1078], 'neg_category_ids': [72, 142, 968, 508, 700, 64, 996], 'image_id': 554301, 'image': tensor([[[ 33.,  33.,  36.,  ...,   0.,   0.,   0.],
         [ 33.,  33.,  36.,  ...,   0.,   0.,   1.],
         [ 32.,  32.,  35.,  ...,   0.,   3.,   2.],
         ...,
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.]],

        [[ 15.,  15.,  16.,  ...,   0.,   0.,   0.],
         [ 15.,  15.,  16.,  ...,   0.,   0.,   1.],
         [ 15.,  15.,  16.,  ...,   0.,   3.,   2.],
         ...,
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.]],

        [[ 14.,  14.,  16.,  ...,   0.,   0.,   0.],
         [ 14.,  14.,  15.,  ...,   0.,   0.,   1.],
         [ 12.,  12.,  14.,  ...,   0.,   3.,   2.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[390.1387, 615.1530, 405.9062, 631.3647]])), gt_classes: tensor([760])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000351855.jpg', 'height': 429, 'width': 640, 'not_exhaustive_category_ids': [1064, 1078], 'neg_category_ids': [410, 171, 459, 590, 133, 1131, 510, 1178, 646, 450], 'image_id': 351855, 'annotations': [{'bbox': [417.92, 81.37, 3.08, 2.01], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 760}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000351855.jpg', 'height': 429, 'width': 640, 'not_exhaustive_category_ids': [1064, 1078], 'neg_category_ids': [410, 171, 459, 590, 133, 1131, 510, 1178, 646, 450], 'image_id': 351855, 'image': tensor([[[  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  0.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[202.5750,  75.3004, 205.4240,  77.1605]])), gt_classes: tensor([760])])}, len instances: 1
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000157102.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [255, 2, 23, 151, 200, 859, 791, 1128, 1103, 591, 157, 113, 975, 774, 1015, 844, 726], 'image_id': 157102, 'image': tensor([[[108., 104., 101.,  ..., 115., 115., 115.],
         [124., 121., 115.,  ..., 115., 115., 115.],
         [144., 141., 137.,  ..., 115., 115., 115.],
         ...,
         [124., 121., 113.,  ..., 115., 115., 115.],
         [123., 123., 117.,  ..., 115., 115., 115.],
         [123., 123., 121.,  ..., 115., 115., 115.]],

        [[121., 119., 115.,  ..., 115., 115., 115.],
         [139., 135., 130.,  ..., 115., 115., 115.],
         [159., 157., 153.,  ..., 115., 115., 115.],
         ...,
         [130., 126., 121.,  ..., 115., 115., 115.],
         [126., 124., 124.,  ..., 115., 115., 115.],
         [124., 124., 126.,  ..., 115., 115., 115.]],

        [[110., 108., 104.,  ..., 115., 115., 115.],
         [126., 123., 117.,  ..., 115., 115., 115.],
         [144., 141., 137.,  ..., 115., 115., 115.],
         ...,
         [113., 110., 104.,  ..., 115., 115., 115.],
         [110., 108., 108.,  ..., 115., 115., 115.],
         [108., 108., 110.,  ..., 115., 115., 115.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[477.9993,  51.3846, 900.3055, 384.0005]])), gt_classes: tensor([260])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000056206.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [42, 219, 259, 1148, 911, 797, 865, 69, 646, 1067], 'image_id': 56206, 'image': tensor([[[188., 189., 189.,  ..., 128., 128., 128.],
         [188., 189., 189.,  ..., 128., 128., 128.],
         [188., 189., 189.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[184., 184., 184.,  ..., 128., 128., 128.],
         [184., 184., 184.,  ..., 128., 128., 128.],
         [184., 184., 184.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[156., 158., 159.,  ..., 128., 128., 128.],
         [156., 158., 159.,  ..., 128., 128., 128.],
         [156., 158., 159.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 505.4209, 135.4552, 575.0000]])), gt_classes: tensor([260])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000062175.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [193, 806, 217, 1046, 947, 9, 157, 841, 530], 'image_id': 62175, 'image': tensor([[[153., 128., 102.,  ...,  51.,  39.,  30.],
         [132., 100.,  66.,  ...,  55.,  46.,  36.],
         [108.,  93.,  76.,  ...,  51.,  45.,  39.],
         ...,
         [254., 254., 254.,  ...,  37.,  37.,  36.],
         [254., 253., 252.,  ...,  33.,  32.,  32.],
         [253., 250., 248.,  ...,  28.,  27.,  28.]],

        [[156., 133., 109.,  ...,  44.,  33.,  24.],
         [138., 105.,  71.,  ...,  48.,  39.,  29.],
         [114.,  96.,  78.,  ...,  46.,  41.,  34.],
         ...,
         [254., 254., 254.,  ...,  69.,  71.,  71.],
         [254., 253., 252.,  ...,  70.,  72.,  71.],
         [253., 250., 248.,  ...,  68.,  69.,  68.]],

        [[130., 102.,  73.,  ...,  33.,  23.,  16.],
         [108.,  74.,  39.,  ...,  35.,  29.,  20.],
         [ 86.,  72.,  57.,  ...,  27.,  22.,  17.],
         ...,
         [254., 254., 254.,  ...,  14.,  12.,  15.],
         [250., 250., 249.,  ...,  13.,  11.,  15.],
         [244., 243., 241.,  ...,  18.,  18.,  21.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,    0.0000, 1024.0000,  964.7809]])), gt_classes: tensor([260])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000549201.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [804], 'neg_category_ids': [176, 482, 949, 264, 858, 795, 704, 1013, 1088, 1117, 729, 514], 'image_id': 549201, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[300.0354, 307.5775, 397.0109, 377.5611]])), gt_classes: tensor([260])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000062175.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [193, 806, 217, 1046, 947, 9, 157, 841, 530], 'image_id': 62175, 'image': tensor([[[153., 128., 102.,  ...,  51.,  39.,  30.],
         [132., 100.,  66.,  ...,  55.,  46.,  36.],
         [108.,  93.,  76.,  ...,  51.,  45.,  39.],
         ...,
         [254., 254., 254.,  ...,  37.,  37.,  36.],
         [254., 253., 252.,  ...,  33.,  32.,  32.],
         [253., 250., 248.,  ...,  28.,  27.,  28.]],

        [[156., 133., 109.,  ...,  44.,  33.,  24.],
         [138., 105.,  71.,  ...,  48.,  39.,  29.],
         [114.,  96.,  78.,  ...,  46.,  41.,  34.],
         ...,
         [254., 254., 254.,  ...,  69.,  71.,  71.],
         [254., 253., 252.,  ...,  70.,  72.,  71.],
         [253., 250., 248.,  ...,  68.,  69.,  68.]],

        [[130., 102.,  73.,  ...,  33.,  23.,  16.],
         [108.,  74.,  39.,  ...,  35.,  29.,  20.],
         [ 86.,  72.,  57.,  ...,  27.,  22.,  17.],
         ...,
         [254., 254., 254.,  ...,  14.,  12.,  15.],
         [250., 250., 249.,  ...,  13.,  11.,  15.],
         [244., 243., 241.,  ...,  18.,  18.,  21.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,    0.0000, 1024.0000,  964.7809]])), gt_classes: tensor([260])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000184705.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1027, 1028, 954, 1176, 772, 332, 337, 145], 'image_id': 184705, 'annotations_cat_set': {705, 225, 708, 361, 877, 626, 631, 185, 670}, 'image': tensor([[[ 4.,  4.,  4.,  ..., 18., 18., 18.],
         [ 4.,  4.,  4.,  ..., 18., 18., 18.],
         [ 4.,  4.,  4.,  ..., 18., 18., 18.],
         ...,
         [ 2.,  2.,  3.,  ...,  4.,  5.,  5.],
         [ 2.,  3.,  3.,  ...,  5.,  5.,  6.],
         [ 2.,  2.,  3.,  ...,  5.,  6.,  6.]],

        [[ 5.,  6.,  6.,  ..., 19., 19., 20.],
         [ 5.,  6.,  6.,  ..., 19., 20., 20.],
         [ 6.,  6.,  6.,  ..., 19., 20., 20.],
         ...,
         [ 2.,  2.,  2.,  ...,  6.,  7.,  7.],
         [ 2.,  2.,  2.,  ...,  7.,  8.,  8.],
         [ 2.,  2.,  2.,  ...,  8.,  8.,  9.]],

        [[ 5.,  5.,  5.,  ..., 20., 20., 20.],
         [ 5.,  5.,  5.,  ..., 20., 20., 20.],
         [ 5.,  6.,  6.,  ..., 20., 20., 20.],
         ...,
         [ 3.,  2.,  3.,  ...,  7.,  8.,  8.],
         [ 3.,  3.,  3.,  ...,  8.,  8.,  9.],
         [ 3.,  3.,  3.,  ...,  8.,  9.,  9.]]]), 'instances': Instances(num_instances=9, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 794.4059,  169.0316,  875.3517,  293.6145],
        [ 299.8195,  852.1816,  528.7300, 1024.0000],
        [ 345.3308,  235.5186, 1024.0000,  741.5996],
        [  12.0891,  661.2542,  280.5932,  755.4818],
        [ 839.7983,  261.5952,  925.6398,  286.2455],
        [   0.0000,  460.3194, 1024.0000, 1024.0000],
        [   0.0000,  317.5992,  358.0453,  596.5024],
        [   0.0000,    0.0000,   47.0960,  275.7389],
        [ 305.0955,   57.2373, 1024.0000,  828.6484]])), gt_classes: tensor([500, 497, 172, 617, 472, 260, 260, 441, 446])])}], 'support_set_target': tensor(260)}
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000199487.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1076, 59], 'neg_category_ids': [666, 433, 479, 953, 910, 87, 1063, 386, 779], 'image_id': 199487, 'image': tensor([[[223., 204., 184.,  ..., 250., 250., 250.],
         [207., 183., 159.,  ..., 250., 250., 250.],
         [183., 164., 145.,  ..., 250., 250., 250.],
         ...,
         [230., 233., 235.,  ...,  71.,  71.,  71.],
         [231., 232., 234.,  ...,  70.,  70.,  71.],
         [231., 231., 232.,  ...,  70.,  70.,  71.]],

        [[229., 208., 187.,  ..., 240., 240., 240.],
         [221., 189., 157.,  ..., 240., 240., 240.],
         [189., 161., 133.,  ..., 240., 240., 240.],
         ...,
         [226., 229., 230.,  ...,  63.,  63.,  62.],
         [227., 228., 229.,  ...,  62.,  62.,  63.],
         [227., 227., 228.,  ...,  62.,  62.,  63.]],

        [[224., 203., 182.,  ..., 233., 233., 233.],
         [210., 179., 149.,  ..., 233., 233., 233.],
         [177., 150., 122.,  ..., 233., 233., 233.],
         ...,
         [221., 224., 226.,  ...,  94.,  94.,  94.],
         [222., 223., 225.,  ...,  93.,  93.,  94.],
         [222., 222., 223.,  ...,  93.,  93.,  94.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 482.8376,   8.6095, 500.1244]])), gt_classes: tensor([758])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000151927.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [51, 608, 53, 5, 4, 510, 845, 235], 'image_id': 151927, 'image': tensor([[[ 81.,  94., 120.,  ..., 127., 127., 127.],
         [ 87.,  94., 113.,  ..., 127., 127., 127.],
         [ 95.,  98., 110.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 82., 100., 132.,  ..., 127., 127., 127.],
         [ 83.,  95., 117.,  ..., 127., 127., 127.],
         [ 86.,  92., 106.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 42.,  61.,  94.,  ..., 127., 127., 127.],
         [ 41.,  54.,  78.,  ..., 127., 127., 127.],
         [ 42.,  49.,  65.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[487.7245, 173.8364, 608.9077, 254.5542]])), gt_classes: tensor([758])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000234994.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [517, 689, 734, 768, 487, 686, 646, 804, 319], 'image_id': 234994, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [  0.,   0., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[522.9412,   2.4565, 562.0330,  76.6174]])), gt_classes: tensor([758])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000249362.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [322, 171, 586, 460, 505, 617, 804, 937, 1182], 'image_id': 249362, 'image': tensor([[[ 45.,  45.,  47.,  ..., 117., 122., 155.],
         [ 49.,  49.,  49.,  ..., 119., 126., 160.],
         [ 56.,  55.,  51.,  ..., 122., 132., 166.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 43.,  43.,  45.,  ..., 114., 118., 153.],
         [ 47.,  47.,  47.,  ..., 116., 122., 158.],
         [ 53.,  53.,  49.,  ..., 119., 129., 165.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 42.,  42.,  44.,  ..., 114., 119., 154.],
         [ 47.,  47.,  47.,  ..., 116., 123., 159.],
         [ 53.,  53.,  49.,  ..., 119., 129., 166.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[253.5289,   7.1542, 303.9460,  41.9487]])), gt_classes: tensor([758])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000151927.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [51, 608, 53, 5, 4, 510, 845, 235], 'image_id': 151927, 'image': tensor([[[ 81.,  94., 120.,  ..., 127., 127., 127.],
         [ 87.,  94., 113.,  ..., 127., 127., 127.],
         [ 95.,  98., 110.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 82., 100., 132.,  ..., 127., 127., 127.],
         [ 83.,  95., 117.,  ..., 127., 127., 127.],
         [ 86.,  92., 106.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 42.,  61.,  94.,  ..., 127., 127., 127.],
         [ 41.,  54.,  78.,  ..., 127., 127., 127.],
         [ 42.,  49.,  65.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[487.7245, 173.8364, 608.9077, 254.5542]])), gt_classes: tensor([758])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000213009.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [500], 'neg_category_ids': [610, 545, 951, 289, 267, 1135, 160, 334, 445, 1200, 554], 'image_id': 213009, 'annotations_cat_set': {675, 614, 1076, 500, 56}, 'image': tensor([[[135., 136., 134.,  ...,  23.,  23.,  23.],
         [134., 135., 134.,  ...,  18.,  19.,  21.],
         [133., 134., 133.,  ...,  26.,  29.,  31.],
         ...,
         [ 50.,  50.,  50.,  ...,  51.,  50.,  50.],
         [ 49.,  48.,  48.,  ...,  49.,  48.,  47.],
         [ 49.,  48.,  47.,  ...,  49.,  48.,  47.]],

        [[132., 136., 136.,  ...,   7.,   7.,   6.],
         [131., 135., 135.,  ...,   6.,   7.,   7.],
         [130., 133., 133.,  ...,  21.,  22.,  24.],
         ...,
         [ 95.,  95.,  96.,  ...,  85.,  84.,  84.],
         [ 93.,  93.,  93.,  ...,  82.,  81.,  80.],
         [ 93.,  92.,  92.,  ...,  82.,  81.,  79.]],

        [[132., 135., 134.,  ...,   7.,   7.,   7.],
         [130., 133., 133.,  ...,   5.,   6.,   7.],
         [129., 132., 132.,  ...,  17.,  19.,  21.],
         ...,
         [128., 129., 129.,  ..., 110., 109., 109.],
         [126., 126., 126.,  ..., 108., 107., 106.],
         [125., 125., 125.,  ..., 109., 108., 106.]]]), 'instances': Instances(num_instances=10, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[321.9992, 628.7462, 369.2098, 697.7000],
        [190.3460, 543.8775, 244.0391, 639.4355],
        [314.8040, 791.9006, 372.1286, 847.9934],
        [312.9373, 752.8087, 354.4120, 792.1042],
        [921.5494, 598.0360, 949.9232, 630.7822],
        [ 35.2741,  42.8769,  71.4882,  92.9973],
        [454.9423, 649.5817, 509.4499, 740.2870],
        [ 65.0735,  39.1781,  95.7892,  86.9910],
        [923.7554, 561.3874, 961.1234, 603.5333],
        [836.5975, 908.9727, 970.0496, 935.3733]])), gt_classes: tensor([474, 474, 434, 434, 357, 357, 357, 357, 357,  41])])}], 'support_set_target': tensor(758)}
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349203.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1142, 368, 412, 102, 50, 558, 285, 233, 154, 226, 614, 156, 1012, 1137, 384, 531], 'image_id': 349203, 'image': tensor([[[  5.,   5.,   3.,  ...,  48.,  60.,  52.],
         [ 12.,   9.,   7.,  ...,  37.,  47.,  43.],
         [ 23.,  12.,   8.,  ...,  28.,  38.,  30.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 12.,  10.,   2.,  ...,  81.,  91.,  84.],
         [ 12.,   9.,   6.,  ...,  71.,  80.,  75.],
         [ 11.,   8.,   7.,  ...,  62.,  72.,  61.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,  73.,  82.,  74.],
         [  4.,   4.,   5.,  ...,  63.,  71.,  65.],
         [ 11.,   8.,   6.,  ...,  54.,  63.,  51.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[359.2170, 510.4644, 369.4343, 519.9953]])), gt_classes: tensor([760])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000026746.jpg', 'height': 454, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1045, 898, 1146, 812, 416, 154, 641], 'image_id': 26746, 'image': tensor([[[  4.,   4.,   2.,  ..., 128., 128., 128.],
         [  1.,   2.,   2.,  ..., 128., 128., 128.],
         [  0.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  4.,   1.,   1.,  ..., 128., 128., 128.],
         [  3.,   2.,   1.,  ..., 128., 128., 128.],
         [  2.,   2.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  4.,   2.,   1.,  ..., 128., 128., 128.],
         [  1.,   2.,   2.,  ..., 128., 128., 128.],
         [  1.,   2.,   2.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[546.9370, 282.5229, 565.7034, 296.6478]])), gt_classes: tensor([760])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000080865.jpg', 'height': 640, 'width': 472, 'not_exhaustive_category_ids': [1078], 'neg_category_ids': [300, 301, 256, 1003, 25, 542, 1115, 1130, 486, 1034, 746, 1180, 362, 45], 'image_id': 80865, 'image': tensor([[[225., 225., 226.,  ..., 253., 253., 253.],
         [226., 225., 225.,  ..., 253., 253., 253.],
         [226., 225., 225.,  ..., 253., 253., 253.],
         ...,
         [162., 163., 163.,  ..., 204., 205., 205.],
         [162., 162., 162.,  ..., 204., 204., 204.],
         [152., 152., 151.,  ..., 202., 202., 202.]],

        [[211., 211., 211.,  ..., 254., 254., 254.],
         [211., 210., 210.,  ..., 254., 254., 254.],
         [211., 210., 210.,  ..., 254., 254., 254.],
         ...,
         [183., 184., 184.,  ..., 130., 131., 131.],
         [181., 182., 182.,  ..., 130., 130., 130.],
         [170., 170., 169.,  ..., 129., 128., 128.]],

        [[195., 195., 195.,  ..., 250., 250., 250.],
         [195., 194., 194.,  ..., 250., 250., 250.],
         [195., 194., 194.,  ..., 250., 250., 250.],
         ...,
         [187., 188., 188.,  ..., 145., 145., 145.],
         [186., 187., 187.,  ..., 146., 146., 146.],
         [176., 175., 175.,  ..., 146., 146., 146.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[816.9844, 900.7354, 834.0393, 918.5394]])), gt_classes: tensor([760])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000554301.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1078], 'neg_category_ids': [72, 142, 968, 508, 700, 64, 996], 'image_id': 554301, 'image': tensor([[[ 33.,  33.,  36.,  ...,   0.,   0.,   0.],
         [ 33.,  33.,  36.,  ...,   0.,   0.,   1.],
         [ 32.,  32.,  35.,  ...,   0.,   3.,   2.],
         ...,
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.]],

        [[ 15.,  15.,  16.,  ...,   0.,   0.,   0.],
         [ 15.,  15.,  16.,  ...,   0.,   0.,   1.],
         [ 15.,  15.,  16.,  ...,   0.,   3.,   2.],
         ...,
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.]],

        [[ 14.,  14.,  16.,  ...,   0.,   0.,   0.],
         [ 14.,  14.,  15.,  ...,   0.,   0.,   1.],
         [ 12.,  12.,  14.,  ...,   0.,   3.,   2.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[390.1387, 615.1530, 405.9062, 631.3647]])), gt_classes: tensor([760])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000351855.jpg', 'height': 429, 'width': 640, 'not_exhaustive_category_ids': [1064, 1078], 'neg_category_ids': [410, 171, 459, 590, 133, 1131, 510, 1178, 646, 450], 'image_id': 351855, 'image': tensor([[[  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  0.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[202.5750,  75.3004, 205.4240,  77.1605]])), gt_classes: tensor([760])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000205648.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [1078], 'neg_category_ids': [375, 263, 83, 465, 268, 1090, 679, 530, 997, 846], 'image_id': 205648, 'annotations_cat_set': {1155, 1134, 148, 1078, 1079}, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=22, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[756.1932, 778.9035, 773.2452, 830.0576],
        [239.8034, 274.2227, 314.5428, 603.4703],
        [293.8926, 106.8624, 431.6969, 208.2325],
        [317.5347, 875.7388, 357.5247, 915.4385],
        [601.5715, 560.0176, 721.9132, 678.9408],
        [536.7466, 921.1657, 579.4548, 952.8903],
        [694.9273, 208.2911, 727.7015, 239.9375],
        [255.8385, 902.8503, 297.3343, 945.3060],
        [653.8030,   0.0000, 685.4235,  16.4385],
        [415.8183, 154.8695, 455.3390, 194.5106],
        [211.7028, 900.3678, 251.4973, 940.4193],
        [475.4025,   0.0000, 506.0061,  15.7349],
        [545.4877, 852.4193, 581.8210, 889.7733],
        [687.7897, 336.3232, 720.8768, 368.8296],
        [681.8058, 849.0181, 717.0049, 886.0594],
        [797.3566, 900.2114, 835.0000, 942.4521],
        [157.2421, 344.2788, 184.8342, 377.3912],
        [171.1652, 332.1988, 213.0716, 374.9087],
        [169.1120,  53.1280, 201.3582,  79.0276],
        [713.8761, 582.8093, 754.6288, 624.0336],
        [422.4474, 792.7427, 461.7139, 828.2203],
        [302.3013, 299.5946, 460.4429, 414.5888]])), gt_classes: tensor([823, 761, 112, 760, 760, 760, 760, 760, 760, 760, 760, 760, 760, 760,
        760, 760, 760, 760, 760, 760, 760, 808])])}], 'support_set_target': tensor(760)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000181179.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [964, 1050, 522, 905, 7, 90, 337, 95, 1091], 'image_id': 181179, 'annotations': [{'bbox': [109.04, 223.77, 47.85, 59.9], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 418}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000181179.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [964, 1050, 522, 905, 7, 90, 337, 95, 1091], 'image_id': 181179, 'image': tensor([[[ 30.,  33.,  38.,  ...,  74.,  78.,  76.],
         [ 33.,  35.,  38.,  ...,  71.,  74.,  73.],
         [ 38.,  38.,  38.,  ...,  66.,  67.,  67.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[105., 108., 113.,  ..., 137., 138., 136.],
         [109., 111., 114.,  ..., 136., 137., 137.],
         [117., 116., 116.,  ..., 135., 136., 138.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[198., 200., 205.,  ..., 210., 216., 213.],
         [202., 203., 206.,  ..., 209., 214., 212.],
         [208., 208., 208.,  ..., 208., 211., 211.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[743.8118, 418.1702, 833.2315, 530.1083]])), gt_classes: tensor([418])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000331588.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [591, 832], 'neg_category_ids': [1184, 323, 368, 1156, 724, 1059, 445, 843, 408], 'image_id': 331588, 'annotations': [{'bbox': [413.29, 173.32, 13.91, 23.75], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 418}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000331588.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [591, 832], 'neg_category_ids': [1184, 323, 368, 1156, 724, 1059, 445, 843, 408], 'image_id': 331588, 'image': tensor([[[255., 255., 255.,  ..., 253., 253., 255.],
         [255., 255., 255.,  ..., 253., 251., 251.],
         [255., 255., 255.,  ..., 251., 249., 249.],
         ...,
         [238., 242., 246.,  ..., 140., 141., 141.],
         [228., 230., 231.,  ..., 147., 149., 150.],
         [215., 217., 219.,  ..., 154., 156., 158.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [224., 228., 231.,  ..., 215., 217., 217.],
         [215., 217., 219.,  ..., 228., 230., 231.],
         [208., 206., 208.,  ..., 242., 244., 246.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [249., 255., 255.,  ..., 204., 206., 206.],
         [246., 247., 249.,  ..., 217., 219., 221.],
         [240., 242., 240.,  ..., 231., 233., 235.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[616.3300, 518.7083, 659.8857, 593.0754]])), gt_classes: tensor([418])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000476934.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [1025], 'neg_category_ids': [366, 877, 1049, 637, 265, 35, 681, 1160, 214, 1093], 'image_id': 476934, 'annotations': [{'bbox': [88.11, 289.82, 110.71, 138.18], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 418}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000476934.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [1025], 'neg_category_ids': [366, 877, 1049, 637, 265, 35, 681, 1160, 214, 1093], 'image_id': 476934, 'image': tensor([[[ 96.,  95.,  98.,  ...,  35.,  36.,  30.],
         [ 95.,  96., 100.,  ...,  35.,  36.,  30.],
         [ 93., 100., 105.,  ...,  35.,  35.,  29.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 91.,  96., 100.,  ...,  39.,  39.,  34.],
         [ 92.,  96., 100.,  ...,  38.,  38.,  33.],
         [ 93.,  97., 101.,  ...,  37.,  36.,  31.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[144., 149., 150.,  ...,  59.,  53.,  50.],
         [144., 149., 151.,  ...,  58.,  52.,  50.],
         [143., 149., 152.,  ...,  55.,  49.,  49.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[663.7796, 621.6233, 901.1142, 918.0000]])), gt_classes: tensor([418])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000088988.jpg', 'height': 478, 'width': 640, 'not_exhaustive_category_ids': [304, 540], 'neg_category_ids': [476, 105, 377, 746, 136, 114, 1158, 40, 243, 751, 249, 532, 535, 408], 'image_id': 88988, 'annotations': [{'bbox': [518.46, 96.71, 24.55, 37.65], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 418}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000088988.jpg', 'height': 478, 'width': 640, 'not_exhaustive_category_ids': [304, 540], 'neg_category_ids': [476, 105, 377, 746, 136, 114, 1158, 40, 243, 751, 249, 532, 535, 408], 'image_id': 88988, 'image': tensor([[[ 61.,  48.,  37.,  ..., 255., 255., 255.],
         [ 62.,  48.,  35.,  ..., 255., 255., 255.],
         [ 66.,  49.,  35.,  ..., 255., 255., 255.],
         ...,
         [129., 127., 125.,  ...,  27.,  31.,  33.],
         [129., 127., 125.,  ...,  25.,  25.,  27.],
         [127., 125., 125.,  ...,  24.,  22.,  24.]],

        [[ 48.,  37.,  25.,  ..., 212., 209., 209.],
         [ 51.,  38.,  25.,  ..., 211., 207., 209.],
         [ 55.,  40.,  25.,  ..., 209., 205., 207.],
         ...,
         [137., 138., 138.,  ...,  46.,  49.,  53.],
         [137., 138., 138.,  ...,  44.,  44.,  48.],
         [138., 137., 137.,  ...,  42.,  40.,  40.]],

        [[ 61.,  48.,  35.,  ..., 236., 233., 233.],
         [ 64.,  49.,  35.,  ..., 233., 229., 231.],
         [ 70.,  53.,  37.,  ..., 229., 225., 229.],
         ...,
         [212., 211., 211.,  ..., 107., 112., 118.],
         [212., 211., 211.,  ..., 107., 109., 112.],
         [214., 212., 212.,  ..., 105., 107., 109.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000339796.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [236, 1023, 920, 1142, 220, 1050, 485, 841, 685], 'image_id': 339796, 'annotations': [{'bbox': [230.33, 115.53, 72.91, 129.05], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 418}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000339796.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [236, 1023, 920, 1142, 220, 1050, 485, 841, 685], 'image_id': 339796, 'image': tensor([[[167., 165., 165.,  ..., 173., 169., 165.],
         [169., 167., 167.,  ..., 173., 169., 165.],
         [170., 169., 169.,  ..., 172., 168., 165.],
         ...,
         [ 20.,  16.,  12.,  ...,  32.,  37.,  42.],
         [ 22.,  19.,  16.,  ...,  32.,  36.,  39.],
         [ 25.,  23.,  19.,  ...,  32.,  35.,  35.]],

        [[153., 152., 151.,  ..., 177., 173., 170.],
         [155., 154., 153.,  ..., 177., 173., 170.],
         [157., 156., 156.,  ..., 176., 173., 170.],
         ...,
         [ 92.,  88.,  85.,  ..., 106., 111., 116.],
         [ 93.,  90.,  88.,  ..., 106., 110., 112.],
         [ 95.,  93.,  91.,  ..., 105., 108., 109.]],

        [[ 80.,  79.,  78.,  ..., 170., 165., 161.],
         [ 81.,  81.,  80.,  ..., 170., 165., 161.],
         [ 82.,  82.,  82.,  ..., 169., 165., 161.],
         ...,
         [142., 138., 135.,  ..., 164., 170., 174.],
         [143., 140., 138.,  ..., 165., 170., 172.],
         [145., 143., 141.,  ..., 167., 169., 170.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 939.0303,  323.6062, 1024.0000,  689.5508]])), gt_classes: tensor([418])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000427238.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [218, 1047, 880, 1148, 485, 1134, 189, 962], 'image_id': 427238, 'annotations': [{'bbox': [127.66, 194.27, 51.92, 111.53], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 140}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000427238.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [218, 1047, 880, 1148, 485, 1134, 189, 962], 'image_id': 427238, 'image': tensor([[[ 72.,  72.,  72.,  ..., 127., 127., 128.],
         [ 72.,  73.,  73.,  ..., 124., 127., 130.],
         [ 73.,  74.,  74.,  ..., 131., 133., 136.],
         ...,
         [ 33.,  34.,  35.,  ...,  47.,  47.,  48.],
         [ 31.,  32.,  33.,  ...,  48.,  48.,  49.],
         [ 30.,  31.,  32.,  ...,  49.,  49.,  50.]],

        [[106., 106., 106.,  ..., 210., 214., 218.],
         [106., 107., 107.,  ..., 207., 213., 218.],
         [107., 108., 108.,  ..., 215., 219., 222.],
         ...,
         [ 52.,  54.,  55.,  ...,  50.,  50.,  50.],
         [ 50.,  52.,  53.,  ...,  51.,  51.,  51.],
         [ 49.,  51.,  52.,  ...,  52.,  52.,  52.]],

        [[100., 100., 100.,  ..., 215., 219., 222.],
         [100., 101., 101.,  ..., 212., 217., 222.],
         [101., 102., 102.,  ..., 220., 223., 226.],
         ...,
         [ 34.,  35.,  36.,  ...,  28.,  29.,  30.],
         [ 32.,  33.,  34.,  ...,  29.,  30.,  31.],
         [ 31.,  32.,  33.,  ...,  30.,  31.,  32.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[291.4905, 388.6723, 430.3765, 687.0150]])), gt_classes: tensor([140])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000562335.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [412, 631, 413, 393, 419, 526, 383, 870, 781], 'image_id': 562335, 'annotations': [{'bbox': [159.28, 194.49, 62.0, 115.51], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 140}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000562335.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [412, 631, 413, 393, 419, 526, 383, 870, 781], 'image_id': 562335, 'image': tensor([[[252., 252., 252.,  ..., 128., 128., 128.],
         [252., 252., 252.,  ..., 128., 128., 128.],
         [252., 252., 252.,  ..., 128., 128., 128.],
         ...,
         [ 36.,  36.,  36.,  ..., 128., 128., 128.],
         [ 35.,  34.,  35.,  ..., 128., 128., 128.],
         [ 37.,  36.,  36.,  ..., 128., 128., 128.]],

        [[254., 254., 254.,  ..., 128., 128., 128.],
         [254., 254., 254.,  ..., 128., 128., 128.],
         [254., 254., 254.,  ..., 128., 128., 128.],
         ...,
         [ 84.,  84.,  84.,  ..., 128., 128., 128.],
         [ 82.,  82.,  83.,  ..., 128., 128., 128.],
         [ 84.,  83.,  83.,  ..., 128., 128., 128.]],

        [[254., 254., 254.,  ..., 128., 128., 128.],
         [254., 254., 254.,  ..., 128., 128., 128.],
         [254., 254., 254.,  ..., 128., 128., 128.],
         ...,
         [ 86.,  86.,  86.,  ..., 128., 128., 128.],
         [ 85.,  85.,  85.,  ..., 128., 128., 128.],
         [ 87.,  87.,  86.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[492.6460, 178.4427, 610.7043, 398.4531]])), gt_classes: tensor([140])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000106356.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [878, 217, 2, 856, 1078, 1010, 720, 864, 1084, 38, 315, 246, 13, 845, 70, 875], 'image_id': 106356, 'annotations': [{'bbox': [2.84, 6.82, 61.12, 131.24], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 140}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000106356.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [878, 217, 2, 856, 1078, 1010, 720, 864, 1084, 38, 315, 246, 13, 845, 70, 875], 'image_id': 106356, 'image': tensor([[[ 26.,  29.,  31.,  ..., 208., 212., 203.],
         [ 29.,  29.,  29.,  ..., 202., 203., 199.],
         [ 31.,  31.,  26.,  ..., 195., 194., 195.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]],

        [[ 30.,  32.,  33.,  ..., 203., 206., 200.],
         [ 31.,  32.,  31.,  ..., 199., 200., 197.],
         [ 33.,  32.,  28.,  ..., 192., 192., 194.],
         ...,
         [116., 116., 116.,  ..., 116., 116., 116.],
         [116., 116., 116.,  ..., 116., 116., 116.],
         [116., 116., 116.,  ..., 116., 116., 116.]],

        [[ 30.,  31.,  32.,  ..., 200., 205., 195.],
         [ 31.,  31.,  30.,  ..., 196., 198., 194.],
         [ 33.,  32.,  28.,  ..., 191., 192., 193.],
         ...,
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000,  11.1535,  83.5346, 225.7856]])), gt_classes: tensor([140])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349737.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [430, 629, 324, 879, 1147, 563, 174, 906, 863, 189, 937, 663, 1164], 'image_id': 349737, 'annotations': [{'bbox': [547.22, 109.76, 84.6, 39.37], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 140}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349737.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [430, 629, 324, 879, 1147, 563, 174, 906, 863, 189, 937, 663, 1164], 'image_id': 349737, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 12.2190, 163.9944, 138.5902, 222.8178]])), gt_classes: tensor([140])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000466680.jpg', 'height': 360, 'width': 480, 'not_exhaustive_category_ids': [835], 'neg_category_ids': [809, 1048, 199, 567, 68, 1021], 'image_id': 466680, 'annotations': [{'bbox': [153.35, 248.05, 71.77, 68.09], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 140}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000466680.jpg', 'height': 360, 'width': 480, 'not_exhaustive_category_ids': [835], 'neg_category_ids': [809, 1048, 199, 567, 68, 1021], 'image_id': 466680, 'image': tensor([[[121., 119., 119.,  ..., 147., 147., 147.],
         [121., 119., 119.,  ..., 147., 147., 147.],
         [121., 119., 119.,  ..., 147., 147., 147.],
         ...,
         [134., 133., 133.,  ..., 146., 143., 144.],
         [134., 133., 133.,  ..., 146., 143., 144.],
         [134., 133., 133.,  ..., 146., 143., 144.]],

        [[122., 119., 119.,  ..., 146., 146., 146.],
         [122., 119., 119.,  ..., 146., 146., 146.],
         [122., 119., 119.,  ..., 146., 146., 146.],
         ...,
         [134., 132., 132.,  ..., 144., 141., 142.],
         [134., 132., 132.,  ..., 144., 141., 142.],
         [134., 132., 132.,  ..., 144., 141., 142.]],

        [[121., 118., 118.,  ..., 146., 146., 146.],
         [121., 118., 118.,  ..., 146., 146., 146.],
         [121., 118., 118.,  ..., 146., 146., 146.],
         ...,
         [132., 130., 130.,  ..., 143., 141., 141.],
         [132., 130., 130.,  ..., 143., 141., 141.],
         [132., 130., 130.,  ..., 143., 141., 141.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 657.0020,  794.8703,  917.4673, 1024.0000]])), gt_classes: tensor([140])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000504697.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [986, 505, 1034, 618, 680, 643, 1137, 556, 387], 'image_id': 504697, 'annotations': [{'bbox': [244.03, 213.02, 27.99, 64.05], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 319}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000504697.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [986, 505, 1034, 618, 680, 643, 1137, 556, 387], 'image_id': 504697, 'image': tensor([[[17., 17., 17.,  ..., 19., 19., 19.],
         [17., 17., 17.,  ..., 19., 19., 19.],
         [17., 17., 17.,  ..., 19., 19., 19.],
         ...,
         [19., 19., 19.,  ..., 19., 19., 19.],
         [19., 19., 19.,  ..., 19., 19., 19.],
         [19., 19., 19.,  ..., 19., 19., 19.]],

        [[35., 35., 35.,  ...,  8.,  8.,  8.],
         [35., 35., 35.,  ...,  8.,  8.,  8.],
         [35., 35., 35.,  ...,  8.,  8.,  8.],
         ...,
         [ 8.,  8.,  8.,  ...,  8.,  8.,  8.],
         [ 8.,  8.,  8.,  ...,  8.,  8.,  8.],
         [ 8.,  8.,  8.,  ...,  8.,  8.,  8.]],

        [[31., 31., 32.,  ...,  6.,  6.,  6.],
         [32., 32., 32.,  ...,  6.,  6.,  6.],
         [33., 33., 33.,  ...,  6.,  6.,  6.],
         ...,
         [ 6.,  6.,  6.,  ...,  6.,  6.,  6.],
         [ 6.,  6.,  6.,  ...,  6.,  6.,  6.],
         [ 6.,  6.,  6.,  ...,  6.,  6.,  6.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[385.2862, 360.1458, 432.5893, 468.4330]])), gt_classes: tensor([319])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000052305.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [829, 853, 126, 948, 790, 609, 30, 670, 718, 443, 618, 1115, 915], 'image_id': 52305, 'annotations': [{'bbox': [215.46, 341.7, 1.75, 26.06], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 319}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000052305.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [829, 853, 126, 948, 790, 609, 30, 670, 718, 443, 618, 1115, 915], 'image_id': 52305, 'image': tensor([[[140., 141., 141.,  ..., 140., 140., 140.],
         [140., 141., 141.,  ..., 140., 140., 140.],
         [140., 141., 141.,  ..., 140., 140., 140.],
         ...,
         [121., 128., 128.,  ...,  92.,  92.,  93.],
         [106., 107., 107.,  ...,  90.,  89.,  90.],
         [ 84.,  81.,  80.,  ...,  88.,  86.,  86.]],

        [[124., 125., 125.,  ..., 122., 122., 122.],
         [124., 125., 125.,  ..., 122., 122., 122.],
         [124., 125., 125.,  ..., 122., 122., 122.],
         ...,
         [ 96., 105., 104.,  ...,  66.,  66.,  67.],
         [ 81.,  84.,  84.,  ...,  63.,  61.,  64.],
         [ 59.,  59.,  58.,  ...,  61.,  59.,  60.]],

        [[101., 102., 102.,  ...,  99.,  99.,  99.],
         [101., 102., 102.,  ...,  99.,  99.,  99.],
         [101., 102., 102.,  ...,  99.,  99.,  99.],
         ...,
         [ 60.,  69.,  68.,  ...,  30.,  30.,  31.],
         [ 46.,  48.,  48.,  ...,  28.,  27.,  28.],
         [ 24.,  23.,  22.,  ...,  26.,  24.,  25.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[732.1631, 841.2623, 736.7542, 909.6164]])), gt_classes: tensor([319])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000456792.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1100, 241, 655, 1174, 486, 973, 723, 748, 1015], 'image_id': 456792, 'annotations': [{'bbox': [140.53, 147.76, 30.53, 86.38], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 319}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000456792.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1100, 241, 655, 1174, 486, 973, 723, 748, 1015], 'image_id': 456792, 'image': tensor([[[152., 152., 151.,  ..., 146., 146., 146.],
         [152., 152., 151.,  ..., 146., 146., 146.],
         [152., 152., 152.,  ..., 147., 146., 146.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[146., 146., 146.,  ..., 140., 140., 140.],
         [146., 146., 146.,  ..., 140., 140., 140.],
         [146., 146., 146.,  ..., 140., 140., 140.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[142., 142., 142.,  ..., 137., 137., 136.],
         [142., 142., 142.,  ..., 137., 137., 136.],
         [142., 142., 142.,  ..., 137., 137., 137.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  9.7533, 332.2005,  78.3504, 526.4037]])), gt_classes: tensor([319])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000055206.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [581, 517, 1121, 688, 762, 59, 1011, 408], 'image_id': 55206, 'annotations': [{'bbox': [163.45, 146.51, 31.12, 45.71], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 319}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000055206.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [581, 517, 1121, 688, 762, 59, 1011, 408], 'image_id': 55206, 'image': tensor([[[76., 76., 77.,  ..., 82., 81., 81.],
         [79., 79., 79.,  ..., 82., 81., 81.],
         [80., 80., 80.,  ..., 82., 81., 81.],
         ...,
         [78., 78., 78.,  ..., 80., 80., 80.],
         [77., 77., 77.,  ..., 80., 80., 80.],
         [77., 77., 77.,  ..., 79., 79., 80.]],

        [[78., 78., 79.,  ..., 83., 83., 83.],
         [80., 80., 81.,  ..., 83., 83., 82.],
         [81., 81., 82.,  ..., 83., 82., 82.],
         ...,
         [80., 80., 80.,  ..., 81., 81., 81.],
         [80., 79., 80.,  ..., 81., 81., 81.],
         [79., 79., 79.,  ..., 81., 81., 81.]],

        [[77., 77., 78.,  ..., 82., 82., 82.],
         [80., 80., 80.,  ..., 82., 82., 81.],
         [81., 81., 81.,  ..., 82., 82., 81.],
         ...,
         [79., 79., 79.,  ..., 81., 81., 81.],
         [78., 78., 79.,  ..., 81., 81., 81.],
         [78., 78., 78.,  ..., 80., 80., 81.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 978.1372,  328.2259, 1024.0000,  432.5019]])), gt_classes: tensor([319])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000289752.jpg', 'height': 566, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [28, 699, 242, 1132, 87, 679, 798, 843, 823, 919, 686], 'image_id': 289752, 'annotations': [{'bbox': [510.89, 33.24, 34.22, 100.27], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 319}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000289752.jpg', 'height': 566, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [28, 699, 242, 1132, 87, 679, 798, 843, 823, 919, 686], 'image_id': 289752, 'image': tensor([[[31., 31., 31.,  ..., 24., 24., 24.],
         [31., 31., 31.,  ..., 26., 26., 26.],
         [32., 31., 31.,  ..., 28., 27., 27.],
         ...,
         [25., 26., 26.,  ..., 26., 26., 26.],
         [25., 25., 25.,  ..., 26., 26., 26.],
         [24., 24., 24.,  ..., 26., 26., 25.]],

        [[25., 25., 25.,  ..., 20., 19., 19.],
         [26., 25., 25.,  ..., 22., 21., 21.],
         [27., 26., 26.,  ..., 24., 23., 22.],
         ...,
         [20., 21., 20.,  ..., 21., 21., 20.],
         [19., 19., 19.,  ..., 21., 21., 20.],
         [18., 18., 18.,  ..., 22., 21., 20.]],

        [[18., 17., 18.,  ..., 13., 13., 13.],
         [19., 18., 18.,  ..., 15., 15., 15.],
         [20., 19., 19.,  ..., 16., 16., 16.],
         ...,
         [11., 11., 11.,  ..., 13., 12., 11.],
         [10., 11., 10.,  ..., 13., 12., 11.],
         [10., 10., 10.,  ..., 12., 11., 11.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000181179.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [964, 1050, 522, 905, 7, 90, 337, 95, 1091], 'image_id': 181179, 'image': tensor([[[ 30.,  33.,  38.,  ...,  74.,  78.,  76.],
         [ 33.,  35.,  38.,  ...,  71.,  74.,  73.],
         [ 38.,  38.,  38.,  ...,  66.,  67.,  67.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[105., 108., 113.,  ..., 137., 138., 136.],
         [109., 111., 114.,  ..., 136., 137., 137.],
         [117., 116., 116.,  ..., 135., 136., 138.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[198., 200., 205.,  ..., 210., 216., 213.],
         [202., 203., 206.,  ..., 209., 214., 212.],
         [208., 208., 208.,  ..., 208., 211., 211.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[743.8118, 418.1702, 833.2315, 530.1083]])), gt_classes: tensor([418])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000331588.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [591, 832], 'neg_category_ids': [1184, 323, 368, 1156, 724, 1059, 445, 843, 408], 'image_id': 331588, 'image': tensor([[[255., 255., 255.,  ..., 253., 253., 255.],
         [255., 255., 255.,  ..., 253., 251., 251.],
         [255., 255., 255.,  ..., 251., 249., 249.],
         ...,
         [238., 242., 246.,  ..., 140., 141., 141.],
         [228., 230., 231.,  ..., 147., 149., 150.],
         [215., 217., 219.,  ..., 154., 156., 158.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [224., 228., 231.,  ..., 215., 217., 217.],
         [215., 217., 219.,  ..., 228., 230., 231.],
         [208., 206., 208.,  ..., 242., 244., 246.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [249., 255., 255.,  ..., 204., 206., 206.],
         [246., 247., 249.,  ..., 217., 219., 221.],
         [240., 242., 240.,  ..., 231., 233., 235.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[616.3300, 518.7083, 659.8857, 593.0754]])), gt_classes: tensor([418])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000476934.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [1025], 'neg_category_ids': [366, 877, 1049, 637, 265, 35, 681, 1160, 214, 1093], 'image_id': 476934, 'image': tensor([[[ 96.,  95.,  98.,  ...,  35.,  36.,  30.],
         [ 95.,  96., 100.,  ...,  35.,  36.,  30.],
         [ 93., 100., 105.,  ...,  35.,  35.,  29.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 91.,  96., 100.,  ...,  39.,  39.,  34.],
         [ 92.,  96., 100.,  ...,  38.,  38.,  33.],
         [ 93.,  97., 101.,  ...,  37.,  36.,  31.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[144., 149., 150.,  ...,  59.,  53.,  50.],
         [144., 149., 151.,  ...,  58.,  52.,  50.],
         [143., 149., 152.,  ...,  55.,  49.,  49.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[663.7796, 621.6233, 901.1142, 918.0000]])), gt_classes: tensor([418])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000339796.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [236, 1023, 920, 1142, 220, 1050, 485, 841, 685], 'image_id': 339796, 'image': tensor([[[167., 165., 165.,  ..., 173., 169., 165.],
         [169., 167., 167.,  ..., 173., 169., 165.],
         [170., 169., 169.,  ..., 172., 168., 165.],
         ...,
         [ 20.,  16.,  12.,  ...,  32.,  37.,  42.],
         [ 22.,  19.,  16.,  ...,  32.,  36.,  39.],
         [ 25.,  23.,  19.,  ...,  32.,  35.,  35.]],

        [[153., 152., 151.,  ..., 177., 173., 170.],
         [155., 154., 153.,  ..., 177., 173., 170.],
         [157., 156., 156.,  ..., 176., 173., 170.],
         ...,
         [ 92.,  88.,  85.,  ..., 106., 111., 116.],
         [ 93.,  90.,  88.,  ..., 106., 110., 112.],
         [ 95.,  93.,  91.,  ..., 105., 108., 109.]],

        [[ 80.,  79.,  78.,  ..., 170., 165., 161.],
         [ 81.,  81.,  80.,  ..., 170., 165., 161.],
         [ 82.,  82.,  82.,  ..., 169., 165., 161.],
         ...,
         [142., 138., 135.,  ..., 164., 170., 174.],
         [143., 140., 138.,  ..., 165., 170., 172.],
         [145., 143., 141.,  ..., 167., 169., 170.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 939.0303,  323.6062, 1024.0000,  689.5508]])), gt_classes: tensor([418])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000476934.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [1025], 'neg_category_ids': [366, 877, 1049, 637, 265, 35, 681, 1160, 214, 1093], 'image_id': 476934, 'image': tensor([[[ 96.,  95.,  98.,  ...,  35.,  36.,  30.],
         [ 95.,  96., 100.,  ...,  35.,  36.,  30.],
         [ 93., 100., 105.,  ...,  35.,  35.,  29.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 91.,  96., 100.,  ...,  39.,  39.,  34.],
         [ 92.,  96., 100.,  ...,  38.,  38.,  33.],
         [ 93.,  97., 101.,  ...,  37.,  36.,  31.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[144., 149., 150.,  ...,  59.,  53.,  50.],
         [144., 149., 151.,  ...,  58.,  52.,  50.],
         [143., 149., 152.,  ...,  55.,  49.,  49.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[663.7796, 621.6233, 901.1142, 918.0000]])), gt_classes: tensor([418])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000309139.jpg', 'height': 640, 'width': 428, 'not_exhaustive_category_ids': [133], 'neg_category_ids': [557, 736, 77, 969, 589, 571, 1197, 1059, 871, 214], 'image_id': 309139, 'annotations_cat_set': {133, 421, 591, 689, 415}, 'image': tensor([[[ 18.,  18.,  18.,  ..., 153., 153., 153.],
         [ 19.,  18.,  15.,  ..., 153., 153., 153.],
         [ 25.,  22.,  18.,  ..., 153., 153., 153.],
         ...,
         [117., 117., 118.,  ..., 153., 153., 153.],
         [120., 120., 120.,  ..., 153., 153., 153.],
         [118., 118., 118.,  ..., 153., 153., 153.]],

        [[ 79.,  79.,  79.,  ..., 120., 120., 120.],
         [ 80.,  79.,  78.,  ..., 120., 120., 120.],
         [ 83.,  81.,  80.,  ..., 120., 120., 120.],
         ...,
         [101., 101., 101.,  ..., 120., 120., 120.],
         [101., 101., 101.,  ..., 120., 120., 120.],
         [101., 101., 101.,  ..., 120., 120., 120.]],

        [[ 90.,  90.,  90.,  ..., 103., 103., 103.],
         [ 89.,  87.,  87.,  ..., 103., 103., 103.],
         [ 90.,  88.,  86.,  ..., 103., 103., 103.],
         ...,
         [ 97.,  97.,  97.,  ..., 103., 103., 103.],
         [ 97.,  97.,  97.,  ..., 103., 103., 103.],
         [ 97.,  97.,  97.,  ..., 103., 103., 103.]]]), 'instances': Instances(num_instances=34, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 509.4756,  711.6679,  543.0214,  770.4750],
        [ 484.8279,  665.5832,  518.0396,  734.5223],
        [ 461.0367,  878.0200,  508.3894,  972.2158],
        [ 427.9712,  661.4677,  462.2064,  740.6849],
        [ 440.9634,  487.8666,  547.8883,  581.0179],
        [ 330.9053,  297.3023,  368.9421,  378.2326],
        [ 457.9661,  688.0615,  483.6582,  752.6971],
        [ 535.6689,  687.6019,  577.7997,  780.8785],
        [ 542.0188,  503.8062,  616.6511,  604.3318],
        [ 283.7615,  124.4742,  298.4874,  159.7794],
        [ 314.2368,  111.7727,  346.7801,  160.8866],
        [ 517.3712,  672.7904,  542.7081,  712.5662],
        [ 608.3169,  201.9993,  637.5599,  285.9796],
        [   0.0000,  141.2703,  724.4742, 1024.0000],
        [ 494.6452,  815.3063,  529.7368,  859.5944],
        [ 462.4153,  800.4113,  501.6217,  846.0154],
        [ 477.4963,  722.8862,  513.9038,  762.1396],
        [ 564.7448,  250.7372,  608.2333,  285.1231],
        [ 289.2549,  285.8543,  334.5816,  380.6350],
        [ 330.1325,  288.9043,  370.0492,  378.7549],
        [ 269.4951,  413.9347,  306.5919,  509.0079],
        [ 553.9667,  840.7093,  589.9146,  885.9793],
        [ 522.7184,  825.5218,  557.0164,  873.1942],
        [ 266.9676,  402.5493,  300.6388,  417.1519],
        [ 249.6725,  417.6532,  271.9389,  439.1078],
        [ 509.2249,  371.2134,  535.9822,  386.7769],
        [ 535.3974,  375.3079,  561.7579,  388.3437],
        [ 483.8044,  372.4041,  508.4521,  383.3717],
        [ 563.4288,  384.3118,  581.5386,  390.0567],
        [ 461.1620,  371.4014,  482.8018,  382.0138],
        [ 611.9096,  377.5432,  639.6487,  395.0287],
        [ 587.9304,  380.3217,  614.2072,  392.8979],
        [ 442.0287,  488.0337,  547.5333,  580.6210],
        [ 540.2225,  504.3702,  616.8391,  605.0839]])), gt_classes: tensor([102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 299,
        418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 418, 295, 295, 295,
        295, 295, 295, 295, 485, 485])])}], 'support_set_target': tensor(418)}
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000427238.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [218, 1047, 880, 1148, 485, 1134, 189, 962], 'image_id': 427238, 'image': tensor([[[ 72.,  72.,  72.,  ..., 127., 127., 128.],
         [ 72.,  73.,  73.,  ..., 124., 127., 130.],
         [ 73.,  74.,  74.,  ..., 131., 133., 136.],
         ...,
         [ 33.,  34.,  35.,  ...,  47.,  47.,  48.],
         [ 31.,  32.,  33.,  ...,  48.,  48.,  49.],
         [ 30.,  31.,  32.,  ...,  49.,  49.,  50.]],

        [[106., 106., 106.,  ..., 210., 214., 218.],
         [106., 107., 107.,  ..., 207., 213., 218.],
         [107., 108., 108.,  ..., 215., 219., 222.],
         ...,
         [ 52.,  54.,  55.,  ...,  50.,  50.,  50.],
         [ 50.,  52.,  53.,  ...,  51.,  51.,  51.],
         [ 49.,  51.,  52.,  ...,  52.,  52.,  52.]],

        [[100., 100., 100.,  ..., 215., 219., 222.],
         [100., 101., 101.,  ..., 212., 217., 222.],
         [101., 102., 102.,  ..., 220., 223., 226.],
         ...,
         [ 34.,  35.,  36.,  ...,  28.,  29.,  30.],
         [ 32.,  33.,  34.,  ...,  29.,  30.,  31.],
         [ 31.,  32.,  33.,  ...,  30.,  31.,  32.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[291.4905, 388.6723, 430.3765, 687.0150]])), gt_classes: tensor([140])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000562335.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [412, 631, 413, 393, 419, 526, 383, 870, 781], 'image_id': 562335, 'image': tensor([[[252., 252., 252.,  ..., 128., 128., 128.],
         [252., 252., 252.,  ..., 128., 128., 128.],
         [252., 252., 252.,  ..., 128., 128., 128.],
         ...,
         [ 36.,  36.,  36.,  ..., 128., 128., 128.],
         [ 35.,  34.,  35.,  ..., 128., 128., 128.],
         [ 37.,  36.,  36.,  ..., 128., 128., 128.]],

        [[254., 254., 254.,  ..., 128., 128., 128.],
         [254., 254., 254.,  ..., 128., 128., 128.],
         [254., 254., 254.,  ..., 128., 128., 128.],
         ...,
         [ 84.,  84.,  84.,  ..., 128., 128., 128.],
         [ 82.,  82.,  83.,  ..., 128., 128., 128.],
         [ 84.,  83.,  83.,  ..., 128., 128., 128.]],

        [[254., 254., 254.,  ..., 128., 128., 128.],
         [254., 254., 254.,  ..., 128., 128., 128.],
         [254., 254., 254.,  ..., 128., 128., 128.],
         ...,
         [ 86.,  86.,  86.,  ..., 128., 128., 128.],
         [ 85.,  85.,  85.,  ..., 128., 128., 128.],
         [ 87.,  87.,  86.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[492.6460, 178.4427, 610.7043, 398.4531]])), gt_classes: tensor([140])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000106356.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [878, 217, 2, 856, 1078, 1010, 720, 864, 1084, 38, 315, 246, 13, 845, 70, 875], 'image_id': 106356, 'image': tensor([[[ 26.,  29.,  31.,  ..., 208., 212., 203.],
         [ 29.,  29.,  29.,  ..., 202., 203., 199.],
         [ 31.,  31.,  26.,  ..., 195., 194., 195.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]],

        [[ 30.,  32.,  33.,  ..., 203., 206., 200.],
         [ 31.,  32.,  31.,  ..., 199., 200., 197.],
         [ 33.,  32.,  28.,  ..., 192., 192., 194.],
         ...,
         [116., 116., 116.,  ..., 116., 116., 116.],
         [116., 116., 116.,  ..., 116., 116., 116.],
         [116., 116., 116.,  ..., 116., 116., 116.]],

        [[ 30.,  31.,  32.,  ..., 200., 205., 195.],
         [ 31.,  31.,  30.,  ..., 196., 198., 194.],
         [ 33.,  32.,  28.,  ..., 191., 192., 193.],
         ...,
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000,  11.1535,  83.5346, 225.7856]])), gt_classes: tensor([140])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349737.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [430, 629, 324, 879, 1147, 563, 174, 906, 863, 189, 937, 663, 1164], 'image_id': 349737, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 12.2190, 163.9944, 138.5902, 222.8178]])), gt_classes: tensor([140])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000466680.jpg', 'height': 360, 'width': 480, 'not_exhaustive_category_ids': [835], 'neg_category_ids': [809, 1048, 199, 567, 68, 1021], 'image_id': 466680, 'image': tensor([[[121., 119., 119.,  ..., 147., 147., 147.],
         [121., 119., 119.,  ..., 147., 147., 147.],
         [121., 119., 119.,  ..., 147., 147., 147.],
         ...,
         [134., 133., 133.,  ..., 146., 143., 144.],
         [134., 133., 133.,  ..., 146., 143., 144.],
         [134., 133., 133.,  ..., 146., 143., 144.]],

        [[122., 119., 119.,  ..., 146., 146., 146.],
         [122., 119., 119.,  ..., 146., 146., 146.],
         [122., 119., 119.,  ..., 146., 146., 146.],
         ...,
         [134., 132., 132.,  ..., 144., 141., 142.],
         [134., 132., 132.,  ..., 144., 141., 142.],
         [134., 132., 132.,  ..., 144., 141., 142.]],

        [[121., 118., 118.,  ..., 146., 146., 146.],
         [121., 118., 118.,  ..., 146., 146., 146.],
         [121., 118., 118.,  ..., 146., 146., 146.],
         ...,
         [132., 130., 130.,  ..., 143., 141., 141.],
         [132., 130., 130.,  ..., 143., 141., 141.],
         [132., 130., 130.,  ..., 143., 141., 141.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 657.0020,  794.8703,  917.4673, 1024.0000]])), gt_classes: tensor([140])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000018563.jpg', 'height': 512, 'width': 528, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 806, 897, 1121, 237, 903, 950, 794, 60, 1012, 1137, 958, 271], 'image_id': 18563, 'annotations_cat_set': {385, 739, 550, 838, 1042, 181, 185}, 'image': tensor([[[148., 146., 145.,  ...,  11.,  11.,  11.],
         [148., 146., 146.,  ...,  11.,  11.,  11.],
         [148., 148., 148.,  ...,  11.,  11.,  11.],
         ...,
         [ 23.,  24.,  24.,  ...,  11.,  11.,  11.],
         [ 24.,  25.,  25.,  ...,  10.,  10.,  10.],
         [ 25.,  27.,  27.,  ...,  10.,   8.,   8.]],

        [[ 97.,  98.,  98.,  ...,   8.,  10.,  10.],
         [ 97.,  98.,  98.,  ...,   8.,  10.,  10.],
         [ 97.,  97.,  97.,  ...,   8.,  10.,  10.],
         ...,
         [  5.,   5.,   5.,  ...,   5.,   5.,   5.],
         [  7.,   7.,   7.,  ...,   5.,   5.,   5.],
         [  8.,   8.,   8.,  ...,   5.,   5.,   5.]],

        [[ 58.,  58.,  58.,  ...,  12.,  10.,  10.],
         [ 58.,  58.,  58.,  ...,  12.,  10.,  10.],
         [ 58.,  58.,  58.,  ...,  12.,  10.,  10.],
         ...,
         [ 12.,  12.,  12.,  ...,  10.,  10.,  10.],
         [ 12.,  10.,  10.,  ...,  10.,  10.,  10.],
         [ 12.,  10.,  10.,  ...,  10.,  10.,  10.]]]), 'instances': Instances(num_instances=10, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 485.4508,  218.3281,  712.4133,  419.9551],
        [ 130.4269,  608.5059,  182.8087,  651.9238],
        [ 195.0159,  621.9883,  276.8371,  672.5664],
        [ 158.3690,  617.5956,  208.7712,  662.7148],
        [  86.2678,  269.6172,  506.9973, 1005.9960],
        [ 448.4739,  797.5898,  501.0333,  826.1035],
        [ 864.2038,  531.9023,  899.7595,  562.4472],
        [ 289.2981,  391.4922,  779.0326,  842.8614],
        [ 102.6879,    0.0000,  339.1167,  245.1660],
        [ 601.6602,   50.9023,  744.8220,  274.7969]])), gt_classes: tensor([392, 591, 591, 591, 523, 275, 275, 732, 137, 140])])}], 'support_set_target': tensor(140)}
0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000504697.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [986, 505, 1034, 618, 680, 643, 1137, 556, 387], 'image_id': 504697, 'image': tensor([[[17., 17., 17.,  ..., 19., 19., 19.],
         [17., 17., 17.,  ..., 19., 19., 19.],
         [17., 17., 17.,  ..., 19., 19., 19.],
         ...,
         [19., 19., 19.,  ..., 19., 19., 19.],
         [19., 19., 19.,  ..., 19., 19., 19.],
         [19., 19., 19.,  ..., 19., 19., 19.]],

        [[35., 35., 35.,  ...,  8.,  8.,  8.],
         [35., 35., 35.,  ...,  8.,  8.,  8.],
         [35., 35., 35.,  ...,  8.,  8.,  8.],
         ...,
         [ 8.,  8.,  8.,  ...,  8.,  8.,  8.],
         [ 8.,  8.,  8.,  ...,  8.,  8.,  8.],
         [ 8.,  8.,  8.,  ...,  8.,  8.,  8.]],

        [[31., 31., 32.,  ...,  6.,  6.,  6.],
         [32., 32., 32.,  ...,  6.,  6.,  6.],
         [33., 33., 33.,  ...,  6.,  6.,  6.],
         ...,
         [ 6.,  6.,  6.,  ...,  6.,  6.,  6.],
         [ 6.,  6.,  6.,  ...,  6.,  6.,  6.],
         [ 6.,  6.,  6.,  ...,  6.,  6.,  6.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[385.2862, 360.1458, 432.5893, 468.4330]])), gt_classes: tensor([319])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000052305.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [829, 853, 126, 948, 790, 609, 30, 670, 718, 443, 618, 1115, 915], 'image_id': 52305, 'image': tensor([[[140., 141., 141.,  ..., 140., 140., 140.],
         [140., 141., 141.,  ..., 140., 140., 140.],
         [140., 141., 141.,  ..., 140., 140., 140.],
         ...,
         [121., 128., 128.,  ...,  92.,  92.,  93.],
         [106., 107., 107.,  ...,  90.,  89.,  90.],
         [ 84.,  81.,  80.,  ...,  88.,  86.,  86.]],

        [[124., 125., 125.,  ..., 122., 122., 122.],
         [124., 125., 125.,  ..., 122., 122., 122.],
         [124., 125., 125.,  ..., 122., 122., 122.],
         ...,
         [ 96., 105., 104.,  ...,  66.,  66.,  67.],
         [ 81.,  84.,  84.,  ...,  63.,  61.,  64.],
         [ 59.,  59.,  58.,  ...,  61.,  59.,  60.]],

        [[101., 102., 102.,  ...,  99.,  99.,  99.],
         [101., 102., 102.,  ...,  99.,  99.,  99.],
         [101., 102., 102.,  ...,  99.,  99.,  99.],
         ...,
         [ 60.,  69.,  68.,  ...,  30.,  30.,  31.],
         [ 46.,  48.,  48.,  ...,  28.,  27.,  28.],
         [ 24.,  23.,  22.,  ...,  26.,  24.,  25.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[732.1631, 841.2623, 736.7542, 909.6164]])), gt_classes: tensor([319])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000456792.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1100, 241, 655, 1174, 486, 973, 723, 748, 1015], 'image_id': 456792, 'image': tensor([[[152., 152., 151.,  ..., 146., 146., 146.],
         [152., 152., 151.,  ..., 146., 146., 146.],
         [152., 152., 152.,  ..., 147., 146., 146.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[146., 146., 146.,  ..., 140., 140., 140.],
         [146., 146., 146.,  ..., 140., 140., 140.],
         [146., 146., 146.,  ..., 140., 140., 140.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[142., 142., 142.,  ..., 137., 137., 136.],
         [142., 142., 142.,  ..., 137., 137., 136.],
         [142., 142., 142.,  ..., 137., 137., 137.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  9.7533, 332.2005,  78.3504, 526.4037]])), gt_classes: tensor([319])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000055206.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [581, 517, 1121, 688, 762, 59, 1011, 408], 'image_id': 55206, 'image': tensor([[[76., 76., 77.,  ..., 82., 81., 81.],
         [79., 79., 79.,  ..., 82., 81., 81.],
         [80., 80., 80.,  ..., 82., 81., 81.],
         ...,
         [78., 78., 78.,  ..., 80., 80., 80.],
         [77., 77., 77.,  ..., 80., 80., 80.],
         [77., 77., 77.,  ..., 79., 79., 80.]],

        [[78., 78., 79.,  ..., 83., 83., 83.],
         [80., 80., 81.,  ..., 83., 83., 82.],
         [81., 81., 82.,  ..., 83., 82., 82.],
         ...,
         [80., 80., 80.,  ..., 81., 81., 81.],
         [80., 79., 80.,  ..., 81., 81., 81.],
         [79., 79., 79.,  ..., 81., 81., 81.]],

        [[77., 77., 78.,  ..., 82., 82., 82.],
         [80., 80., 80.,  ..., 82., 82., 81.],
         [81., 81., 81.,  ..., 82., 82., 81.],
         ...,
         [79., 79., 79.,  ..., 81., 81., 81.],
         [78., 78., 79.,  ..., 81., 81., 81.],
         [78., 78., 78.,  ..., 80., 80., 81.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 978.1372,  328.2259, 1024.0000,  432.5019]])), gt_classes: tensor([319])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000055206.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [581, 517, 1121, 688, 762, 59, 1011, 408], 'image_id': 55206, 'image': tensor([[[76., 76., 77.,  ..., 82., 81., 81.],
         [79., 79., 79.,  ..., 82., 81., 81.],
         [80., 80., 80.,  ..., 82., 81., 81.],
         ...,
         [78., 78., 78.,  ..., 80., 80., 80.],
         [77., 77., 77.,  ..., 80., 80., 80.],
         [77., 77., 77.,  ..., 79., 79., 80.]],

        [[78., 78., 79.,  ..., 83., 83., 83.],
         [80., 80., 81.,  ..., 83., 83., 82.],
         [81., 81., 82.,  ..., 83., 82., 82.],
         ...,
         [80., 80., 80.,  ..., 81., 81., 81.],
         [80., 79., 80.,  ..., 81., 81., 81.],
         [79., 79., 79.,  ..., 81., 81., 81.]],

        [[77., 77., 78.,  ..., 82., 82., 82.],
         [80., 80., 80.,  ..., 82., 82., 81.],
         [81., 81., 81.,  ..., 82., 82., 81.],
         ...,
         [79., 79., 79.,  ..., 81., 81., 81.],
         [78., 78., 79.,  ..., 81., 81., 81.],
         [78., 78., 78.,  ..., 80., 80., 81.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 978.1372,  328.2259, 1024.0000,  432.5019]])), gt_classes: tensor([319])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000126877.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [735, 924, 1100, 305, 1007, 521, 177, 906, 1173, 381, 1112, 1137, 1114, 208, 63, 42, 778, 428, 1019], 'image_id': 126877, 'annotations_cat_set': {450, 132, 104, 943, 401, 447}, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [130., 130., 130.,  ..., 130., 130., 130.],
         [130., 130., 130.,  ..., 130., 130., 130.],
         [130., 130., 130.,  ..., 130., 130., 130.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [130., 130., 130.,  ..., 130., 130., 130.],
         [130., 130., 130.,  ..., 130., 130., 130.],
         [130., 130., 130.,  ..., 130., 130., 130.]],

        [[ 13.,  13.,  13.,  ...,   1.,   1.,   1.],
         [ 13.,  13.,  13.,  ...,   2.,   2.,   2.],
         [ 11.,  11.,  11.,  ...,   6.,   6.,   6.],
         ...,
         [130., 130., 130.,  ..., 130., 130., 130.],
         [130., 130., 130.,  ..., 130., 130., 130.],
         [130., 130., 130.,  ..., 130., 130., 130.]]]), 'instances': Instances(num_instances=10, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 725.8425,   81.8212,  871.5104,  199.8374],
        [ 184.9606,   94.7358,  344.8554,  208.1852],
        [   0.0000,   72.4963, 1024.0000,  873.2902],
        [ 277.9883,  437.8665,  351.6292,  505.4773],
        [ 782.3048,  647.3049,  883.7414,  729.0623],
        [ 553.0372,  460.6795,  602.4072,  546.9614],
        [ 268.5815,  466.0111,  442.8096,  694.7153],
        [ 590.3460,  519.8151,  660.5256,  600.7229],
        [ 551.4022,  549.7015,  644.3450,  630.0995],
        [ 897.7136,  427.8831, 1019.5777,  494.8991]])), gt_classes: tensor([661, 661,  82, 317, 317, 317, 319, 101, 101, 286])])}], 'support_set_target': tensor(319)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000523883.jpg', 'height': 431, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [280, 335, 1187, 435, 1102, 903, 1109, 912, 445, 145], 'image_id': 523883, 'annotations': [{'bbox': [526.2, 0.12, 113.54, 430.48], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 716}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000523883.jpg', 'height': 431, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [280, 335, 1187, 435, 1102, 903, 1109, 912, 445, 145], 'image_id': 523883, 'image': tensor([[[254., 254., 254.,  ..., 127., 127., 127.],
         [254., 254., 254.,  ..., 127., 127., 127.],
         [254., 254., 254.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[249., 249., 249.,  ..., 127., 127., 127.],
         [249., 249., 249.,  ..., 127., 127., 127.],
         [249., 249., 249.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[234., 234., 234.,  ..., 127., 127., 127.],
         [234., 234., 234.,  ..., 127., 127., 127.],
         [234., 234., 234.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[6.7666e+02, 1.5452e-01, 8.2267e+02, 5.5448e+02]])), gt_classes: tensor([716])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000022530.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [21, 1050, 438, 309, 1081, 1113, 842, 1136, 447], 'image_id': 22530, 'annotations': [{'bbox': [342.63, 304.72, 80.57, 73.71], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 716}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000022530.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [21, 1050, 438, 309, 1081, 1113, 842, 1136, 447], 'image_id': 22530, 'image': tensor([[[ 31.,  32.,  35.,  ..., 128., 128., 128.],
         [ 30.,  31.,  34.,  ..., 128., 128., 128.],
         [ 30.,  31.,  34.,  ..., 128., 128., 128.],
         ...,
         [138., 138., 137.,  ..., 128., 128., 128.],
         [139., 139., 138.,  ..., 128., 128., 128.],
         [140., 140., 139.,  ..., 128., 128., 128.]],

        [[105., 106., 109.,  ..., 128., 128., 128.],
         [104., 105., 108.,  ..., 128., 128., 128.],
         [103., 104., 107.,  ..., 128., 128., 128.],
         ...,
         [162., 162., 161.,  ..., 128., 128., 128.],
         [163., 163., 162.,  ..., 128., 128., 128.],
         [164., 164., 163.,  ..., 128., 128., 128.]],

        [[137., 138., 142.,  ..., 128., 128., 128.],
         [136., 137., 141.,  ..., 128., 128., 128.],
         [135., 136., 140.,  ..., 128., 128., 128.],
         ...,
         [174., 174., 173.,  ..., 128., 128., 128.],
         [175., 175., 174.,  ..., 128., 128., 128.],
         [176., 176., 175.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  6.1784, 393.2885, 183.9620, 555.9112]])), gt_classes: tensor([716])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000425582.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [602, 921, 876, 737, 222, 792, 418, 741, 33, 68], 'image_id': 425582, 'annotations': [{'bbox': [0.0, 0.0, 640.0, 480.0], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 716}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000425582.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [602, 921, 876, 737, 222, 792, 418, 741, 33, 68], 'image_id': 425582, 'image': tensor([[[ 86.,  89.,  91.,  ..., 112., 112., 112.],
         [ 85.,  87.,  88.,  ..., 112., 112., 112.],
         [ 87.,  87.,  88.,  ..., 112., 112., 112.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]],

        [[ 94.,  95.,  94.,  ..., 112., 112., 112.],
         [ 95.,  95.,  94.,  ..., 112., 112., 112.],
         [ 95.,  95.,  95.,  ..., 112., 112., 112.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]],

        [[ 98.,  98.,  97.,  ..., 112., 112., 112.],
         [ 98.,  98.,  97.,  ..., 112., 112., 112.],
         [ 98.,  98.,  97.,  ..., 112., 112., 112.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.,   0., 864., 648.]])), gt_classes: tensor([716])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000393984.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [981], 'neg_category_ids': [410, 1069, 970, 306, 422, 134, 9, 243, 1158, 141, 338, 1018, 190], 'image_id': 393984, 'annotations': [{'bbox': [128.22, 187.07, 103.39, 308.81], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 716}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000393984.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [981], 'neg_category_ids': [410, 1069, 970, 306, 422, 134, 9, 243, 1158, 141, 338, 1018, 190], 'image_id': 393984, 'image': tensor([[[186., 188., 191.,  ..., 176., 182., 191.],
         [186., 187., 190.,  ..., 181., 184., 192.],
         [184., 184., 185.,  ..., 185., 189., 195.],
         ...,
         [162., 165., 162.,  ..., 141., 139., 138.],
         [165., 168., 166.,  ..., 140., 138., 137.],
         [168., 170., 167.,  ..., 139., 138., 137.]],

        [[174., 175., 176.,  ..., 229., 229., 233.],
         [173., 173., 174.,  ..., 233., 231., 233.],
         [171., 170., 169.,  ..., 236., 236., 238.],
         ...,
         [203., 206., 203.,  ..., 131., 129., 128.],
         [207., 210., 208.,  ..., 130., 128., 128.],
         [211., 213., 210.,  ..., 129., 128., 128.]],

        [[246., 247., 248.,  ..., 187., 191., 197.],
         [245., 245., 246.,  ..., 193., 194., 198.],
         [243., 242., 241.,  ..., 198., 199., 203.],
         ...,
         [206., 209., 206.,  ..., 144., 142., 140.],
         [209., 212., 210.,  ..., 143., 141., 139.],
         [211., 214., 211.,  ..., 142., 140., 138.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[651.4946, 318.8705, 829.3862, 850.2053]])), gt_classes: tensor([716])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000125109.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [48, 1045, 900, 1100, 130, 7, 132, 1108], 'image_id': 125109, 'annotations': [{'bbox': [149.37, 360.68, 164.32, 43.3], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 716}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000125109.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [48, 1045, 900, 1100, 130, 7, 132, 1108], 'image_id': 125109, 'image': tensor([[[ 59.,  58.,  58.,  ..., 127., 127., 127.],
         [ 59.,  58.,  58.,  ..., 127., 127., 127.],
         [ 59.,  58.,  58.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 60.,  59.,  59.,  ..., 127., 127., 127.],
         [ 60.,  59.,  59.,  ..., 127., 127., 127.],
         [ 60.,  59.,  59.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 61.,  60.,  60.,  ..., 127., 127., 127.],
         [ 61.,  60.,  60.,  ..., 127., 127., 127.],
         [ 61.,  60.,  60.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[186.1003, 449.1593, 390.8269, 503.0813]])), gt_classes: tensor([716])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000523883.jpg', 'height': 431, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [280, 335, 1187, 435, 1102, 903, 1109, 912, 445, 145], 'image_id': 523883, 'image': tensor([[[254., 254., 254.,  ..., 127., 127., 127.],
         [254., 254., 254.,  ..., 127., 127., 127.],
         [254., 254., 254.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[249., 249., 249.,  ..., 127., 127., 127.],
         [249., 249., 249.,  ..., 127., 127., 127.],
         [249., 249., 249.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[234., 234., 234.,  ..., 127., 127., 127.],
         [234., 234., 234.,  ..., 127., 127., 127.],
         [234., 234., 234.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[6.7666e+02, 1.5452e-01, 8.2267e+02, 5.5448e+02]])), gt_classes: tensor([716])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000022530.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [21, 1050, 438, 309, 1081, 1113, 842, 1136, 447], 'image_id': 22530, 'image': tensor([[[ 31.,  32.,  35.,  ..., 128., 128., 128.],
         [ 30.,  31.,  34.,  ..., 128., 128., 128.],
         [ 30.,  31.,  34.,  ..., 128., 128., 128.],
         ...,
         [138., 138., 137.,  ..., 128., 128., 128.],
         [139., 139., 138.,  ..., 128., 128., 128.],
         [140., 140., 139.,  ..., 128., 128., 128.]],

        [[105., 106., 109.,  ..., 128., 128., 128.],
         [104., 105., 108.,  ..., 128., 128., 128.],
         [103., 104., 107.,  ..., 128., 128., 128.],
         ...,
         [162., 162., 161.,  ..., 128., 128., 128.],
         [163., 163., 162.,  ..., 128., 128., 128.],
         [164., 164., 163.,  ..., 128., 128., 128.]],

        [[137., 138., 142.,  ..., 128., 128., 128.],
         [136., 137., 141.,  ..., 128., 128., 128.],
         [135., 136., 140.,  ..., 128., 128., 128.],
         ...,
         [174., 174., 173.,  ..., 128., 128., 128.],
         [175., 175., 174.,  ..., 128., 128., 128.],
         [176., 176., 175.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  6.1784, 393.2885, 183.9620, 555.9112]])), gt_classes: tensor([716])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000425582.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [602, 921, 876, 737, 222, 792, 418, 741, 33, 68], 'image_id': 425582, 'image': tensor([[[ 86.,  89.,  91.,  ..., 112., 112., 112.],
         [ 85.,  87.,  88.,  ..., 112., 112., 112.],
         [ 87.,  87.,  88.,  ..., 112., 112., 112.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]],

        [[ 94.,  95.,  94.,  ..., 112., 112., 112.],
         [ 95.,  95.,  94.,  ..., 112., 112., 112.],
         [ 95.,  95.,  95.,  ..., 112., 112., 112.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]],

        [[ 98.,  98.,  97.,  ..., 112., 112., 112.],
         [ 98.,  98.,  97.,  ..., 112., 112., 112.],
         [ 98.,  98.,  97.,  ..., 112., 112., 112.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.,   0., 864., 648.]])), gt_classes: tensor([716])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000393984.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [981], 'neg_category_ids': [410, 1069, 970, 306, 422, 134, 9, 243, 1158, 141, 338, 1018, 190], 'image_id': 393984, 'image': tensor([[[186., 188., 191.,  ..., 176., 182., 191.],
         [186., 187., 190.,  ..., 181., 184., 192.],
         [184., 184., 185.,  ..., 185., 189., 195.],
         ...,
         [162., 165., 162.,  ..., 141., 139., 138.],
         [165., 168., 166.,  ..., 140., 138., 137.],
         [168., 170., 167.,  ..., 139., 138., 137.]],

        [[174., 175., 176.,  ..., 229., 229., 233.],
         [173., 173., 174.,  ..., 233., 231., 233.],
         [171., 170., 169.,  ..., 236., 236., 238.],
         ...,
         [203., 206., 203.,  ..., 131., 129., 128.],
         [207., 210., 208.,  ..., 130., 128., 128.],
         [211., 213., 210.,  ..., 129., 128., 128.]],

        [[246., 247., 248.,  ..., 187., 191., 197.],
         [245., 245., 246.,  ..., 193., 194., 198.],
         [243., 242., 241.,  ..., 198., 199., 203.],
         ...,
         [206., 209., 206.,  ..., 144., 142., 140.],
         [209., 212., 210.,  ..., 143., 141., 139.],
         [211., 214., 211.,  ..., 142., 140., 138.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[651.4946, 318.8705, 829.3862, 850.2053]])), gt_classes: tensor([716])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000125109.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [48, 1045, 900, 1100, 130, 7, 132, 1108], 'image_id': 125109, 'image': tensor([[[ 59.,  58.,  58.,  ..., 127., 127., 127.],
         [ 59.,  58.,  58.,  ..., 127., 127., 127.],
         [ 59.,  58.,  58.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 60.,  59.,  59.,  ..., 127., 127., 127.],
         [ 60.,  59.,  59.,  ..., 127., 127., 127.],
         [ 60.,  59.,  59.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 61.,  60.,  60.,  ..., 127., 127., 127.],
         [ 61.,  60.,  60.,  ..., 127., 127., 127.],
         [ 61.,  60.,  60.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[186.1003, 449.1593, 390.8269, 503.0813]])), gt_classes: tensor([716])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000051355.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [807, 324, 736, 1047, 26, 1029, 417, 224, 329, 1055, 488, 525, 1060, 405, 495, 144], 'image_id': 51355, 'annotations_cat_set': {5, 229, 133, 1117, 1021}, 'image': tensor([[[175., 167., 160.,  ..., 127., 127., 127.],
         [173., 171., 167.,  ..., 127., 127., 127.],
         [171., 173., 174.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[142., 139., 137.,  ..., 127., 127., 127.],
         [141., 142., 142.,  ..., 127., 127., 127.],
         [140., 143., 145.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[127., 124., 123.,  ..., 127., 127., 127.],
         [127., 127., 128.,  ..., 127., 127., 127.],
         [127., 129., 131.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=7, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 92.0656,  23.8507, 233.5131, 433.2665],
        [ 97.5688, 194.8475, 230.2967, 521.2355],
        [  8.7787, 180.2745, 569.1393, 666.0952],
        [325.5787, 146.5265, 400.8836, 347.9082],
        [221.2672, 221.3238, 500.7836, 353.3068],
        [ 90.3098,  24.4112, 232.1115, 440.5382],
        [291.3639, 375.1810, 413.3213, 474.3895]])), gt_classes: tensor([102, 102, 716, 176, 796,   4,   4])])}], 'support_set_target': tensor(716)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000369443.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [194], 'neg_category_ids': [732, 666, 857, 133, 730, 725, 183, 752, 779], 'image_id': 369443, 'annotations': [{'bbox': [393.79, 146.78, 11.49, 9.87], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 396}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000369443.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [194], 'neg_category_ids': [732, 666, 857, 133, 730, 725, 183, 752, 779], 'image_id': 369443, 'image': tensor([[[120., 119., 120.,  ..., 128., 128., 128.],
         [114., 116., 116.,  ..., 128., 128., 128.],
         [123., 122., 118.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[112., 112., 114.,  ..., 128., 128., 128.],
         [106., 110., 111.,  ..., 128., 128., 128.],
         [115., 116., 113.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[142., 140., 141.,  ..., 128., 128., 128.],
         [136., 139., 139.,  ..., 128., 128., 128.],
         [145., 146., 142.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[292.6665, 183.1692, 306.9931, 195.4861]])), gt_classes: tensor([396])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000061621.jpg', 'height': 468, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1143, 713, 844, 162, 15, 144], 'image_id': 61621, 'annotations': [{'bbox': [1.64, 43.13, 636.83, 393.2], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 396}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000061621.jpg', 'height': 468, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1143, 713, 844, 162, 15, 144], 'image_id': 61621, 'image': tensor([[[242., 242., 242.,  ..., 240., 240., 239.],
         [242., 242., 242.,  ..., 240., 239., 238.],
         [242., 242., 242.,  ..., 239., 238., 237.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[236., 236., 236.,  ..., 235., 235., 235.],
         [236., 236., 236.,  ..., 233., 233., 233.],
         [236., 236., 236.,  ..., 231., 230., 229.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[225., 225., 225.,  ..., 226., 226., 225.],
         [225., 225., 225.,  ..., 224., 224., 223.],
         [225., 225., 225.,  ..., 222., 221., 220.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,   79.9011, 1024.0000,  808.3293]])), gt_classes: tensor([396])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116794.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [848], 'neg_category_ids': [1184, 695, 262, 440, 1059, 404, 1093], 'image_id': 116794, 'annotations': [{'bbox': [378.25, 12.49, 234.56, 87.39], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 396}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116794.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [848], 'neg_category_ids': [1184, 695, 262, 440, 1059, 404, 1093], 'image_id': 116794, 'image': tensor([[[182., 182., 183.,  ..., 175., 174., 175.],
         [183., 183., 184.,  ..., 175., 174., 175.],
         [184., 184., 184.,  ..., 175., 174., 175.],
         ...,
         [ 96.,  96.,  93.,  ..., 122., 121., 121.],
         [101.,  99.,  97.,  ..., 114., 111., 111.],
         [107., 102., 101.,  ..., 105., 102., 102.]],

        [[179., 179., 180.,  ..., 171., 170., 171.],
         [180., 180., 181.,  ..., 171., 170., 171.],
         [181., 181., 181.,  ..., 171., 170., 171.],
         ...,
         [ 96.,  96.,  93.,  ..., 122., 121., 121.],
         [101.,  99.,  97.,  ..., 114., 111., 111.],
         [107., 102., 101.,  ..., 105., 102., 102.]],

        [[178., 178., 179.,  ..., 168., 168., 169.],
         [178., 178., 179.,  ..., 168., 168., 169.],
         [179., 179., 179.,  ..., 169., 168., 169.],
         ...,
         [ 93.,  93.,  90.,  ..., 119., 118., 118.],
         [ 98.,  96.,  94.,  ..., 111., 108., 108.],
         [104.,  99.,  97.,  ..., 102.,  99.,  99.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000,   0.0000, 580.7156, 245.2662]])), gt_classes: tensor([396])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000369443.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [194], 'neg_category_ids': [732, 666, 857, 133, 730, 725, 183, 752, 779], 'image_id': 369443, 'annotations': [{'bbox': [415.32, 169.48, 25.97, 22.89], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 396}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000369443.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [194], 'neg_category_ids': [732, 666, 857, 133, 730, 725, 183, 752, 779], 'image_id': 369443, 'image': tensor([[[155., 155., 154.,  ..., 152., 152., 152.],
         [155., 155., 154.,  ..., 152., 152., 152.],
         [153., 154., 153.,  ..., 152., 152., 152.],
         ...,
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.]],

        [[156., 156., 155.,  ..., 154., 155., 155.],
         [155., 155., 155.,  ..., 154., 155., 155.],
         [154., 155., 155.,  ..., 154., 155., 155.],
         ...,
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.]],

        [[163., 163., 162.,  ..., 162., 163., 163.],
         [163., 163., 162.,  ..., 162., 163., 163.],
         [161., 162., 162.,  ..., 163., 163., 163.],
         ...,
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[208.5490, 322.0120, 257.8920, 365.5030]])), gt_classes: tensor([396])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000531309.jpg', 'height': 488, 'width': 640, 'not_exhaustive_category_ids': [1123, 207, 848], 'neg_category_ids': [1024, 73, 631, 879, 543, 642, 212, 188, 779], 'image_id': 531309, 'annotations': [{'bbox': [466.3, 112.84, 8.38, 12.02], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 396}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000531309.jpg', 'height': 488, 'width': 640, 'not_exhaustive_category_ids': [1123, 207, 848], 'neg_category_ids': [1024, 73, 631, 879, 543, 642, 212, 188, 779], 'image_id': 531309, 'image': tensor([[[185., 188., 191.,  ..., 226., 223., 220.],
         [189., 191., 186.,  ..., 222., 220., 219.],
         [194., 196., 178.,  ..., 217., 216., 217.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[174., 179., 180.,  ..., 221., 218., 215.],
         [178., 183., 177.,  ..., 217., 215., 214.],
         [183., 188., 173.,  ..., 212., 211., 212.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[176., 177., 182.,  ..., 222., 219., 217.],
         [181., 182., 176.,  ..., 218., 216., 216.],
         [189., 191., 167.,  ..., 213., 212., 213.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[762.0250, 197.4700, 776.6900, 218.5050]])), gt_classes: tensor([396])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000369443.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [194], 'neg_category_ids': [732, 666, 857, 133, 730, 725, 183, 752, 779], 'image_id': 369443, 'image': tensor([[[120., 119., 120.,  ..., 128., 128., 128.],
         [114., 116., 116.,  ..., 128., 128., 128.],
         [123., 122., 118.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[112., 112., 114.,  ..., 128., 128., 128.],
         [106., 110., 111.,  ..., 128., 128., 128.],
         [115., 116., 113.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[142., 140., 141.,  ..., 128., 128., 128.],
         [136., 139., 139.,  ..., 128., 128., 128.],
         [145., 146., 142.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[292.6665, 183.1692, 306.9931, 195.4861]])), gt_classes: tensor([396])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000061621.jpg', 'height': 468, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1143, 713, 844, 162, 15, 144], 'image_id': 61621, 'image': tensor([[[242., 242., 242.,  ..., 240., 240., 239.],
         [242., 242., 242.,  ..., 240., 239., 238.],
         [242., 242., 242.,  ..., 239., 238., 237.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[236., 236., 236.,  ..., 235., 235., 235.],
         [236., 236., 236.,  ..., 233., 233., 233.],
         [236., 236., 236.,  ..., 231., 230., 229.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[225., 225., 225.,  ..., 226., 226., 225.],
         [225., 225., 225.,  ..., 224., 224., 223.],
         [225., 225., 225.,  ..., 222., 221., 220.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,   79.9011, 1024.0000,  808.3293]])), gt_classes: tensor([396])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116794.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [848], 'neg_category_ids': [1184, 695, 262, 440, 1059, 404, 1093], 'image_id': 116794, 'image': tensor([[[182., 182., 183.,  ..., 175., 174., 175.],
         [183., 183., 184.,  ..., 175., 174., 175.],
         [184., 184., 184.,  ..., 175., 174., 175.],
         ...,
         [ 96.,  96.,  93.,  ..., 122., 121., 121.],
         [101.,  99.,  97.,  ..., 114., 111., 111.],
         [107., 102., 101.,  ..., 105., 102., 102.]],

        [[179., 179., 180.,  ..., 171., 170., 171.],
         [180., 180., 181.,  ..., 171., 170., 171.],
         [181., 181., 181.,  ..., 171., 170., 171.],
         ...,
         [ 96.,  96.,  93.,  ..., 122., 121., 121.],
         [101.,  99.,  97.,  ..., 114., 111., 111.],
         [107., 102., 101.,  ..., 105., 102., 102.]],

        [[178., 178., 179.,  ..., 168., 168., 169.],
         [178., 178., 179.,  ..., 168., 168., 169.],
         [179., 179., 179.,  ..., 169., 168., 169.],
         ...,
         [ 93.,  93.,  90.,  ..., 119., 118., 118.],
         [ 98.,  96.,  94.,  ..., 111., 108., 108.],
         [104.,  99.,  97.,  ..., 102.,  99.,  99.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000,   0.0000, 580.7156, 245.2662]])), gt_classes: tensor([396])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000369443.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [194], 'neg_category_ids': [732, 666, 857, 133, 730, 725, 183, 752, 779], 'image_id': 369443, 'image': tensor([[[155., 155., 154.,  ..., 152., 152., 152.],
         [155., 155., 154.,  ..., 152., 152., 152.],
         [153., 154., 153.,  ..., 152., 152., 152.],
         ...,
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.]],

        [[156., 156., 155.,  ..., 154., 155., 155.],
         [155., 155., 155.,  ..., 154., 155., 155.],
         [154., 155., 155.,  ..., 154., 155., 155.],
         ...,
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.]],

        [[163., 163., 162.,  ..., 162., 163., 163.],
         [163., 163., 162.,  ..., 162., 163., 163.],
         [161., 162., 162.,  ..., 163., 163., 163.],
         ...,
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[208.5490, 322.0120, 257.8920, 365.5030]])), gt_classes: tensor([396])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000531309.jpg', 'height': 488, 'width': 640, 'not_exhaustive_category_ids': [1123, 207, 848], 'neg_category_ids': [1024, 73, 631, 879, 543, 642, 212, 188, 779], 'image_id': 531309, 'image': tensor([[[185., 188., 191.,  ..., 226., 223., 220.],
         [189., 191., 186.,  ..., 222., 220., 219.],
         [194., 196., 178.,  ..., 217., 216., 217.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[174., 179., 180.,  ..., 221., 218., 215.],
         [178., 183., 177.,  ..., 217., 215., 214.],
         [183., 188., 173.,  ..., 212., 211., 212.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[176., 177., 182.,  ..., 222., 219., 217.],
         [181., 182., 176.,  ..., 218., 216., 216.],
         [189., 191., 167.,  ..., 213., 212., 213.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[762.0250, 197.4700, 776.6900, 218.5050]])), gt_classes: tensor([396])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000166798.jpg', 'height': 449, 'width': 640, 'not_exhaustive_category_ids': [848], 'neg_category_ids': [667, 877, 854, 521, 205, 1176, 531, 663], 'image_id': 166798, 'annotations_cat_set': {848, 3, 555}, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[199., 199., 199.,  ..., 193., 193., 193.],
         [199., 199., 199.,  ..., 193., 193., 193.],
         [197., 199., 199.,  ..., 195., 195., 195.],
         ...,
         [210., 210., 208.,  ..., 197., 197., 197.],
         [210., 210., 208.,  ..., 197., 197., 197.],
         [210., 210., 210.,  ..., 199., 199., 199.]],

        [[124., 124., 124.,  ..., 126., 126., 124.],
         [124., 124., 124.,  ..., 126., 126., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.],
         ...,
         [135., 135., 135.,  ..., 130., 130., 130.],
         [135., 135., 135.,  ..., 130., 130., 130.],
         [135., 135., 135.,  ..., 132., 132., 132.]]]), 'instances': Instances(num_instances=4, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 48.7059, 878.1917, 130.0793, 963.0137],
        [297.0722, 352.5039, 350.9035, 376.6393],
        [ 55.2956, 878.4006,  98.3142, 920.3358],
        [111.9112, 238.2784, 698.4862, 390.6564]])), gt_classes: tensor([396, 601, 601,   2])])}], 'support_set_target': tensor(396)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000432330.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [99], 'neg_category_ids': [1121, 965, 500, 1146, 1048, 1190, 284, 107, 108, 815, 306, 745, 909, 1117, 622, 361, 1065], 'image_id': 432330, 'annotations': [{'bbox': [259.49, 103.44, 31.98, 37.44], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 80}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000432330.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [99], 'neg_category_ids': [1121, 965, 500, 1146, 1048, 1190, 284, 107, 108, 815, 306, 745, 909, 1117, 622, 361, 1065], 'image_id': 432330, 'image': tensor([[[ 41.,  49.,  53.,  ..., 255., 255., 254.],
         [ 60.,  62.,  62.,  ..., 255., 255., 254.],
         [100.,  94.,  86.,  ..., 255., 255., 255.],
         ...,
         [176., 176., 176.,  ..., 176., 176., 176.],
         [176., 176., 176.,  ..., 176., 176., 176.],
         [176., 176., 176.,  ..., 176., 176., 176.]],

        [[ 52.,  61.,  76.,  ..., 243., 243., 243.],
         [ 62.,  66.,  76.,  ..., 243., 243., 243.],
         [ 92.,  85.,  79.,  ..., 243., 242., 243.],
         ...,
         [170., 170., 170.,  ..., 170., 170., 170.],
         [170., 170., 170.,  ..., 170., 170., 170.],
         [170., 170., 170.,  ..., 170., 170., 170.]],

        [[ 39.,  49.,  60.,  ..., 221., 220., 222.],
         [ 55.,  58.,  63.,  ..., 221., 221., 223.],
         [ 84.,  78.,  69.,  ..., 223., 223., 225.],
         ...,
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[497.0688, 233.2851, 569.1738, 317.7224]])), gt_classes: tensor([80])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000060774.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [99], 'neg_category_ids': [531, 570, 1054, 1042, 880], 'image_id': 60774, 'annotations': [{'bbox': [129.99, 137.68, 54.42, 51.27], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 80}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000060774.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [99], 'neg_category_ids': [531, 570, 1054, 1042, 880], 'image_id': 60774, 'image': tensor([[[208., 213., 218.,  ..., 117., 124., 126.],
         [207., 212., 218.,  ..., 114., 124., 126.],
         [200., 206., 213.,  ..., 109., 118., 120.],
         ...,
         [193., 217., 241.,  ..., 109., 110., 114.],
         [178., 210., 243.,  ..., 115., 117., 121.],
         [161., 200., 240.,  ..., 125., 127., 131.]],

        [[204., 209., 214.,  ..., 116., 123., 125.],
         [203., 208., 214.,  ..., 113., 123., 125.],
         [196., 202., 209.,  ..., 108., 117., 119.],
         ...,
         [193., 217., 241.,  ..., 100., 101., 105.],
         [177., 210., 243.,  ..., 106., 108., 112.],
         [160., 200., 240.,  ..., 116., 118., 122.]],

        [[205., 210., 215.,  ..., 115., 122., 124.],
         [204., 209., 215.,  ..., 112., 122., 124.],
         [197., 203., 210.,  ..., 107., 116., 118.],
         ...,
         [193., 217., 241.,  ..., 116., 117., 121.],
         [177., 210., 243.,  ..., 122., 124., 128.],
         [160., 200., 240.,  ..., 132., 134., 138.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[312.2780, 136.0987, 481.5281, 295.5164]])), gt_classes: tensor([80])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000252775.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [629, 395, 1006, 29, 885, 308, 309, 268, 578], 'image_id': 252775, 'annotations': [{'bbox': [88.97, 58.03, 193.24, 298.8], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 80}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000252775.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [629, 395, 1006, 29, 885, 308, 309, 268, 578], 'image_id': 252775, 'image': tensor([[[101., 101., 101.,  ..., 101., 101., 101.],
         [101., 101., 101.,  ..., 101., 101., 101.],
         [101., 101., 101.,  ..., 101., 101., 101.],
         ...,
         [255., 255., 255.,  ..., 133., 129., 129.],
         [255., 255., 255.,  ..., 134., 131., 131.],
         [255., 255., 255.,  ..., 134., 133., 131.]],

        [[101., 101., 101.,  ..., 101., 101., 101.],
         [101., 101., 101.,  ..., 101., 101., 101.],
         [101., 101., 101.,  ..., 101., 101., 101.],
         ...,
         [255., 255., 255.,  ..., 165., 163., 163.],
         [255., 255., 255.,  ..., 165., 165., 165.],
         [255., 255., 255.,  ..., 165., 165., 165.]],

        [[101., 101., 101.,  ..., 101., 101., 101.],
         [101., 101., 101.,  ..., 101., 101., 101.],
         [101., 101., 101.,  ..., 101., 101., 101.],
         ...,
         [255., 255., 255.,  ..., 183., 183., 183.],
         [255., 255., 255.,  ..., 185., 185., 185.],
         [255., 255., 255.,  ..., 185., 185., 185.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[385.9878,   0.0000, 926.2547, 596.0089]])), gt_classes: tensor([80])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000385405.jpg', 'height': 360, 'width': 640, 'not_exhaustive_category_ids': [719, 61, 102, 898], 'neg_category_ids': [127, 931, 10, 271, 1063, 96], 'image_id': 385405, 'annotations': [{'bbox': [399.75, 315.76, 47.25, 44.24], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 80}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000385405.jpg', 'height': 360, 'width': 640, 'not_exhaustive_category_ids': [719, 61, 102, 898], 'neg_category_ids': [127, 931, 10, 271, 1063, 96], 'image_id': 385405, 'image': tensor([[[123., 126., 128.,  ..., 160., 156., 151.],
         [123., 126., 128.,  ..., 160., 156., 151.],
         [122., 124., 125.,  ..., 161., 157., 151.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[127., 129., 131.,  ..., 161., 158., 154.],
         [127., 129., 131.,  ..., 161., 158., 154.],
         [126., 127., 128.,  ..., 162., 159., 154.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[138., 139., 141.,  ..., 155., 151., 146.],
         [138., 139., 141.,  ..., 155., 151., 146.],
         [136., 137., 138.,  ..., 154., 151., 145.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  13.1141,  888.5136,  146.0785, 1013.0000]])), gt_classes: tensor([80])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000250516.jpg', 'height': 360, 'width': 640, 'not_exhaustive_category_ids': [99, 102], 'neg_category_ids': [1024, 734, 1049, 438, 934, 916, 144], 'image_id': 250516, 'annotations': [{'bbox': [497.69, 118.93, 33.1, 25.12], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 80}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000250516.jpg', 'height': 360, 'width': 640, 'not_exhaustive_category_ids': [99, 102], 'neg_category_ids': [1024, 734, 1049, 438, 934, 916, 144], 'image_id': 250516, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 55.5220, 328.3789, 146.9090, 397.7381]])), gt_classes: tensor([80])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000320901.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [], 'neg_category_ids': [896, 943, 1100, 1171, 222, 970, 30, 225, 677, 36, 888, 382, 292, 358, 994, 823, 850], 'image_id': 320901, 'annotations': [{'bbox': [107.71, 0.0, 5.6, 143.17], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 442}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000320901.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [], 'neg_category_ids': [896, 943, 1100, 1171, 222, 970, 30, 225, 677, 36, 888, 382, 292, 358, 994, 823, 850], 'image_id': 320901, 'image': tensor([[[ 35.,  35.,  34.,  ..., 128., 128., 128.],
         [ 33.,  33.,  32.,  ..., 128., 128., 128.],
         [ 32.,  31.,  30.,  ..., 128., 128., 128.],
         ...,
         [ 53.,  56.,  60.,  ..., 128., 128., 128.],
         [ 59.,  60.,  62.,  ..., 128., 128., 128.],
         [ 57.,  57.,  55.,  ..., 128., 128., 128.]],

        [[ 21.,  21.,  22.,  ..., 128., 128., 128.],
         [ 20.,  19.,  20.,  ..., 128., 128., 128.],
         [ 19.,  18.,  18.,  ..., 128., 128., 128.],
         ...,
         [ 46.,  49.,  55.,  ..., 128., 128., 128.],
         [ 52.,  53.,  57.,  ..., 128., 128., 128.],
         [ 51.,  50.,  49.,  ..., 128., 128., 128.]],

        [[ 14.,  14.,  15.,  ..., 128., 128., 128.],
         [ 14.,  14.,  14.,  ..., 128., 128., 128.],
         [ 15.,  14.,  13.,  ..., 128., 128., 128.],
         ...,
         [ 53.,  55.,  58.,  ..., 128., 128., 128.],
         [ 59.,  59.,  60.,  ..., 128., 128., 128.],
         [ 57.,  56.,  54.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[753.0314,   0.0000, 764.5946, 105.5118]])), gt_classes: tensor([442])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000557127.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [1026, 827, 627], 'neg_category_ids': [585, 962, 4, 437, 1127, 396, 506, 157, 487, 400, 466, 425, 359, 622, 1065, 44, 365], 'image_id': 557127, 'annotations': [{'bbox': [243.25, 236.27, 33.6, 104.46], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 442}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000557127.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [1026, 827, 627], 'neg_category_ids': [585, 962, 4, 437, 1127, 396, 506, 157, 487, 400, 466, 425, 359, 622, 1065, 44, 365], 'image_id': 557127, 'image': tensor([[[140., 139., 138.,  ..., 214., 215., 216.],
         [138., 137., 136.,  ..., 217., 217., 217.],
         [136., 136., 135.,  ..., 219., 218., 217.],
         ...,
         [209., 221., 228.,  ..., 113., 116., 118.],
         [210., 222., 228.,  ..., 100., 105., 110.],
         [209., 221., 227.,  ...,  75.,  79.,  83.]],

        [[175., 175., 174.,  ..., 173., 173., 173.],
         [176., 176., 174.,  ..., 174., 173., 172.],
         [177., 176., 174.,  ..., 174., 173., 172.],
         ...,
         [215., 226., 232.,  ..., 101., 100., 100.],
         [216., 227., 232.,  ...,  94.,  97.,  99.],
         [216., 227., 232.,  ...,  69.,  72.,  74.]],

        [[200., 196., 188.,  ..., 136., 137., 139.],
         [196., 192., 186.,  ..., 137., 138., 138.],
         [192., 189., 183.,  ..., 137., 138., 138.],
         ...,
         [228., 237., 242.,  ...,  86.,  87.,  87.],
         [229., 238., 242.,  ...,  85.,  88.,  90.],
         [228., 237., 242.,  ...,  64.,  66.,  69.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 477.3282,  686.3646,  585.7890, 1023.4222]])), gt_classes: tensor([442])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000281835.jpg', 'height': 396, 'width': 640, 'not_exhaustive_category_ids': [627], 'neg_category_ids': [1122, 584, 477, 857, 64, 528, 165], 'image_id': 281835, 'annotations': [{'bbox': [610.18, 168.47, 14.18, 86.38], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 442}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000281835.jpg', 'height': 396, 'width': 640, 'not_exhaustive_category_ids': [627], 'neg_category_ids': [1122, 584, 477, 857, 64, 528, 165], 'image_id': 281835, 'image': tensor([[[117., 119., 122.,  ..., 114., 108., 104.],
         [115., 116., 118.,  ..., 112., 108., 106.],
         [112., 112., 113.,  ..., 109., 108., 109.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[105., 105., 106.,  ..., 102.,  98.,  95.],
         [104., 103., 104.,  ..., 100.,  98.,  97.],
         [102., 101., 100.,  ...,  97.,  98.,  99.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[101., 105., 108.,  ..., 101.,  93.,  88.],
         [ 99., 102., 104.,  ...,  99.,  93.,  90.],
         [ 96.,  97.,  99.,  ...,  96.,  93.,  92.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 15.9526, 279.5070,  39.4826, 422.8193]])), gt_classes: tensor([442])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000223091.jpg', 'height': 406, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 603, 1184, 1073, 1036, 402, 407], 'image_id': 223091, 'annotations': [{'bbox': [268.45, 26.12, 9.35, 128.62], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 442}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000223091.jpg', 'height': 406, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 603, 1184, 1073, 1036, 402, 407], 'image_id': 223091, 'image': tensor([[[ 18.,  18.,  19.,  ..., 131., 132., 130.],
         [ 30.,  27.,  25.,  ..., 130., 130., 128.],
         [ 58.,  51.,  43.,  ..., 125., 125., 122.],
         ...,
         [ 94.,  85.,  83.,  ..., 116., 108., 104.],
         [ 92.,  85.,  83.,  ..., 114., 106., 103.],
         [ 90.,  86.,  85.,  ..., 110., 104., 104.]],

        [[ 23.,  23.,  23.,  ..., 144., 146., 144.],
         [ 35.,  31.,  28.,  ..., 144., 145., 143.],
         [ 62.,  55.,  47.,  ..., 139., 140., 137.],
         ...,
         [103.,  95.,  91.,  ..., 118., 110., 106.],
         [102.,  95.,  92.,  ..., 116., 109., 106.],
         [102.,  97.,  95.,  ..., 111., 105., 105.]],

        [[ 25.,  26.,  27.,  ..., 143., 143., 141.],
         [ 37.,  35.,  33.,  ..., 142., 142., 140.],
         [ 64.,  59.,  51.,  ..., 139., 139., 137.],
         ...,
         [106.,  98.,  94.,  ..., 116., 108., 104.],
         [105.,  97.,  95.,  ..., 115., 107., 104.],
         [104., 100.,  98.,  ..., 110., 104., 104.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[315.9737,   0.0000, 344.5497, 288.9860]])), gt_classes: tensor([442])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000512217.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [344, 476, 259, 859, 570, 723, 513, 341], 'image_id': 512217, 'annotations': [{'bbox': [295.72, 165.24, 19.57, 116.34], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 442}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000512217.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [344, 476, 259, 859, 570, 723, 513, 341], 'image_id': 512217, 'image': tensor([[[239., 239., 244.,  ..., 204., 208., 210.],
         [239., 239., 244.,  ..., 206., 212., 214.],
         [239., 239., 244.,  ..., 210., 215., 216.],
         ...,
         [174., 171., 167.,  ...,  47.,  45.,  43.],
         [173., 171., 168.,  ...,  43.,  47.,  47.],
         [165., 162., 160.,  ...,  41.,  47.,  52.]],

        [[241., 241., 246.,  ..., 180., 179., 180.],
         [241., 241., 246.,  ..., 180., 179., 180.],
         [241., 241., 246.,  ..., 181., 179., 180.],
         ...,
         [166., 161., 157.,  ...,  60.,  60.,  60.],
         [175., 169., 163.,  ...,  58.,  58.,  58.],
         [166., 160., 155.,  ...,  58.,  58.,  58.]],

        [[244., 244., 246.,  ..., 139., 147., 145.],
         [244., 244., 246.,  ..., 139., 146., 144.],
         [244., 244., 246.,  ..., 139., 144., 142.],
         ...,
         [154., 154., 155.,  ...,  68.,  66.,  66.],
         [161., 160., 160.,  ...,  69.,  68.,  68.],
         [155., 155., 154.,  ...,  69.,  68.,  68.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[632.8902,  27.4024, 684.8322, 336.0670]])), gt_classes: tensor([442])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000432330.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [99], 'neg_category_ids': [1121, 965, 500, 1146, 1048, 1190, 284, 107, 108, 815, 306, 745, 909, 1117, 622, 361, 1065], 'image_id': 432330, 'image': tensor([[[ 41.,  49.,  53.,  ..., 255., 255., 254.],
         [ 60.,  62.,  62.,  ..., 255., 255., 254.],
         [100.,  94.,  86.,  ..., 255., 255., 255.],
         ...,
         [176., 176., 176.,  ..., 176., 176., 176.],
         [176., 176., 176.,  ..., 176., 176., 176.],
         [176., 176., 176.,  ..., 176., 176., 176.]],

        [[ 52.,  61.,  76.,  ..., 243., 243., 243.],
         [ 62.,  66.,  76.,  ..., 243., 243., 243.],
         [ 92.,  85.,  79.,  ..., 243., 242., 243.],
         ...,
         [170., 170., 170.,  ..., 170., 170., 170.],
         [170., 170., 170.,  ..., 170., 170., 170.],
         [170., 170., 170.,  ..., 170., 170., 170.]],

        [[ 39.,  49.,  60.,  ..., 221., 220., 222.],
         [ 55.,  58.,  63.,  ..., 221., 221., 223.],
         [ 84.,  78.,  69.,  ..., 223., 223., 225.],
         ...,
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[497.0688, 233.2851, 569.1738, 317.7224]])), gt_classes: tensor([80])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000060774.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [99], 'neg_category_ids': [531, 570, 1054, 1042, 880], 'image_id': 60774, 'image': tensor([[[208., 213., 218.,  ..., 117., 124., 126.],
         [207., 212., 218.,  ..., 114., 124., 126.],
         [200., 206., 213.,  ..., 109., 118., 120.],
         ...,
         [193., 217., 241.,  ..., 109., 110., 114.],
         [178., 210., 243.,  ..., 115., 117., 121.],
         [161., 200., 240.,  ..., 125., 127., 131.]],

        [[204., 209., 214.,  ..., 116., 123., 125.],
         [203., 208., 214.,  ..., 113., 123., 125.],
         [196., 202., 209.,  ..., 108., 117., 119.],
         ...,
         [193., 217., 241.,  ..., 100., 101., 105.],
         [177., 210., 243.,  ..., 106., 108., 112.],
         [160., 200., 240.,  ..., 116., 118., 122.]],

        [[205., 210., 215.,  ..., 115., 122., 124.],
         [204., 209., 215.,  ..., 112., 122., 124.],
         [197., 203., 210.,  ..., 107., 116., 118.],
         ...,
         [193., 217., 241.,  ..., 116., 117., 121.],
         [177., 210., 243.,  ..., 122., 124., 128.],
         [160., 200., 240.,  ..., 132., 134., 138.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[312.2780, 136.0987, 481.5281, 295.5164]])), gt_classes: tensor([80])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000252775.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [629, 395, 1006, 29, 885, 308, 309, 268, 578], 'image_id': 252775, 'image': tensor([[[101., 101., 101.,  ..., 101., 101., 101.],
         [101., 101., 101.,  ..., 101., 101., 101.],
         [101., 101., 101.,  ..., 101., 101., 101.],
         ...,
         [255., 255., 255.,  ..., 133., 129., 129.],
         [255., 255., 255.,  ..., 134., 131., 131.],
         [255., 255., 255.,  ..., 134., 133., 131.]],

        [[101., 101., 101.,  ..., 101., 101., 101.],
         [101., 101., 101.,  ..., 101., 101., 101.],
         [101., 101., 101.,  ..., 101., 101., 101.],
         ...,
         [255., 255., 255.,  ..., 165., 163., 163.],
         [255., 255., 255.,  ..., 165., 165., 165.],
         [255., 255., 255.,  ..., 165., 165., 165.]],

        [[101., 101., 101.,  ..., 101., 101., 101.],
         [101., 101., 101.,  ..., 101., 101., 101.],
         [101., 101., 101.,  ..., 101., 101., 101.],
         ...,
         [255., 255., 255.,  ..., 183., 183., 183.],
         [255., 255., 255.,  ..., 185., 185., 185.],
         [255., 255., 255.,  ..., 185., 185., 185.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[385.9878,   0.0000, 926.2547, 596.0089]])), gt_classes: tensor([80])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000385405.jpg', 'height': 360, 'width': 640, 'not_exhaustive_category_ids': [719, 61, 102, 898], 'neg_category_ids': [127, 931, 10, 271, 1063, 96], 'image_id': 385405, 'image': tensor([[[123., 126., 128.,  ..., 160., 156., 151.],
         [123., 126., 128.,  ..., 160., 156., 151.],
         [122., 124., 125.,  ..., 161., 157., 151.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[127., 129., 131.,  ..., 161., 158., 154.],
         [127., 129., 131.,  ..., 161., 158., 154.],
         [126., 127., 128.,  ..., 162., 159., 154.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[138., 139., 141.,  ..., 155., 151., 146.],
         [138., 139., 141.,  ..., 155., 151., 146.],
         [136., 137., 138.,  ..., 154., 151., 145.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  13.1141,  888.5136,  146.0785, 1013.0000]])), gt_classes: tensor([80])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000250516.jpg', 'height': 360, 'width': 640, 'not_exhaustive_category_ids': [99, 102], 'neg_category_ids': [1024, 734, 1049, 438, 934, 916, 144], 'image_id': 250516, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 55.5220, 328.3789, 146.9090, 397.7381]])), gt_classes: tensor([80])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000250516.jpg', 'height': 360, 'width': 640, 'not_exhaustive_category_ids': [99, 102], 'neg_category_ids': [1024, 734, 1049, 438, 934, 916, 144], 'image_id': 250516, 'annotations_cat_set': {99, 621, 102}, 'image': tensor([[[ 1.,  1.,  2.,  ..., 19., 19., 19.],
         [ 2.,  2.,  2.,  ..., 19., 19., 19.],
         [ 3.,  3.,  3.,  ..., 19., 19., 19.],
         ...,
         [19., 19., 19.,  ..., 19., 19., 19.],
         [19., 19., 19.,  ..., 19., 19., 19.],
         [19., 19., 19.,  ..., 19., 19., 19.]],

        [[ 2.,  2.,  2.,  ..., 19., 19., 19.],
         [ 3.,  3.,  3.,  ..., 19., 19., 19.],
         [ 3.,  3.,  3.,  ..., 19., 19., 19.],
         ...,
         [19., 19., 19.,  ..., 19., 19., 19.],
         [19., 19., 19.,  ..., 19., 19., 19.],
         [19., 19., 19.,  ..., 19., 19., 19.]],

        [[ 2.,  2.,  2.,  ..., 19., 19., 19.],
         [ 3.,  3.,  3.,  ..., 19., 19., 19.],
         [ 3.,  3.,  3.,  ..., 19., 19., 19.],
         ...,
         [19., 19., 19.,  ..., 19., 19., 19.],
         [19., 19., 19.,  ..., 19., 19., 19.],
         [19., 19., 19.,  ..., 19., 19., 19.]]]), 'instances': Instances(num_instances=60, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[238.6048, 136.3911, 350.0088, 205.2836],
        [ 54.7422,  43.1644, 103.4414,  82.5458],
        [348.9708, 215.7227, 457.1186, 281.2587],
        [130.2722, 374.3004, 216.0966, 451.0578],
        [344.7052,  77.5822, 399.0350, 129.8916],
        [240.9225, 216.0213, 349.6675, 285.8240],
        [291.7404,  73.9129, 349.6249, 128.3556],
        [112.8684, 169.5289, 157.1030, 204.4160],
        [ 44.2772, 217.9840, 213.5372, 290.5031],
        [348.9708, 139.7902, 454.4170, 204.7858],
        [155.9370, 133.9022, 199.9156, 170.5387],
        [147.8323,  49.2800, 193.6452,  86.4427],
        [ 63.9560, 168.7040, 113.6932, 205.2693],
        [102.8158,  46.6347, 148.6570,  84.5227],
        [104.1950,  82.4747, 149.2116, 119.6231],
        [241.7188, 294.6844, 298.7359, 365.1840],
        [297.1008, 292.5085, 350.5064, 360.6471],
        [ 95.6069, 294.0587, 214.3477, 373.8880],
        [581.7886, 188.7573, 645.1758, 250.1120],
        [237.9081,  71.3671, 295.4514, 126.4213],
        [ 19.6076, 241.6782,  66.6290, 279.4382],
        [348.5869, 290.9156, 360.8008, 354.4604],
        [109.3138, 133.1200, 156.4347, 169.8844],
        [148.4296,  84.8924, 192.7778, 120.7751],
        [ 56.2067,  80.9387, 104.4793, 118.9404],
        [458.9670, 358.4996, 545.4597, 435.9822],
        [723.7770, 150.1867, 758.7125, 202.9511],
        [155.2830, 169.1449, 202.3470, 204.8711],
        [788.1738, 150.9831, 865.4526, 194.3467],
        [ 61.3112, 131.5271, 109.9536, 169.8133],
        [258.7244, 242.2045, 265.9475, 252.1885],
        [287.8728, 243.7547, 300.9541, 251.9324],
        [165.2930, 176.8960, 180.2084, 191.1040],
        [ 69.9989, 180.6933,  84.7011, 189.7529],
        [114.2477, 245.9164, 128.3385, 272.1849],
        [169.6581, 242.5742, 186.4505, 261.7600],
        [240.5955, 165.6178, 259.4638, 179.2569],
        [168.4780, 140.8142, 191.6545, 155.9324],
        [110.3232,  93.1840, 128.3953, 104.9458],
        [139.1021, 220.9565, 159.9894, 241.5076],
        [109.3280, 304.3556, 123.9591, 321.6071],
        [120.6461, 193.1093, 130.5139, 202.1547],
        [262.5777, 179.2569, 279.6402, 191.0756],
        [ 66.2878,  52.8924,  82.7531,  66.7022],
        [ 66.9987, 145.3511,  85.7675, 154.6809],
        [119.9067, 326.7556, 128.3100, 335.4311],
        [172.7152, 328.0782, 183.0806, 339.1004],
        [264.7389,  92.9564, 279.8961, 108.5440],
        [180.0947, 327.2675, 195.5647, 340.8355],
        [161.6814,  60.1742, 187.5880,  71.4951],
        [121.5276, 140.8711, 134.2534, 154.7804],
        [ 60.1595,  96.6116,  73.3687, 103.1680],
        [158.3969, 332.1884, 175.0897, 351.2178],
        [ 80.3502, 243.9253,  97.7966, 261.9022],
        [351.8146, 238.4213, 368.9055, 253.8382],
        [170.3548,  93.0844, 179.2700, 107.3920],
        [111.6030,  57.6427, 124.6274,  68.9636],
        [631.8670,  51.5129, 656.8920, 172.1742],
        [583.1536, 138.2400, 604.3822, 215.4382],
        [603.3442,  49.0951, 621.5869, 172.3733]])), gt_classes: tensor([ 80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  80,
         80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  80,  80,
         80,  80,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,
         77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,  77,
         77, 437, 437, 437])])}], 'support_set_target': tensor(80)}
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000320901.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [], 'neg_category_ids': [896, 943, 1100, 1171, 222, 970, 30, 225, 677, 36, 888, 382, 292, 358, 994, 823, 850], 'image_id': 320901, 'image': tensor([[[ 35.,  35.,  34.,  ..., 128., 128., 128.],
         [ 33.,  33.,  32.,  ..., 128., 128., 128.],
         [ 32.,  31.,  30.,  ..., 128., 128., 128.],
         ...,
         [ 53.,  56.,  60.,  ..., 128., 128., 128.],
         [ 59.,  60.,  62.,  ..., 128., 128., 128.],
         [ 57.,  57.,  55.,  ..., 128., 128., 128.]],

        [[ 21.,  21.,  22.,  ..., 128., 128., 128.],
         [ 20.,  19.,  20.,  ..., 128., 128., 128.],
         [ 19.,  18.,  18.,  ..., 128., 128., 128.],
         ...,
         [ 46.,  49.,  55.,  ..., 128., 128., 128.],
         [ 52.,  53.,  57.,  ..., 128., 128., 128.],
         [ 51.,  50.,  49.,  ..., 128., 128., 128.]],

        [[ 14.,  14.,  15.,  ..., 128., 128., 128.],
         [ 14.,  14.,  14.,  ..., 128., 128., 128.],
         [ 15.,  14.,  13.,  ..., 128., 128., 128.],
         ...,
         [ 53.,  55.,  58.,  ..., 128., 128., 128.],
         [ 59.,  59.,  60.,  ..., 128., 128., 128.],
         [ 57.,  56.,  54.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[753.0314,   0.0000, 764.5946, 105.5118]])), gt_classes: tensor([442])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000557127.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [1026, 827, 627], 'neg_category_ids': [585, 962, 4, 437, 1127, 396, 506, 157, 487, 400, 466, 425, 359, 622, 1065, 44, 365], 'image_id': 557127, 'image': tensor([[[140., 139., 138.,  ..., 214., 215., 216.],
         [138., 137., 136.,  ..., 217., 217., 217.],
         [136., 136., 135.,  ..., 219., 218., 217.],
         ...,
         [209., 221., 228.,  ..., 113., 116., 118.],
         [210., 222., 228.,  ..., 100., 105., 110.],
         [209., 221., 227.,  ...,  75.,  79.,  83.]],

        [[175., 175., 174.,  ..., 173., 173., 173.],
         [176., 176., 174.,  ..., 174., 173., 172.],
         [177., 176., 174.,  ..., 174., 173., 172.],
         ...,
         [215., 226., 232.,  ..., 101., 100., 100.],
         [216., 227., 232.,  ...,  94.,  97.,  99.],
         [216., 227., 232.,  ...,  69.,  72.,  74.]],

        [[200., 196., 188.,  ..., 136., 137., 139.],
         [196., 192., 186.,  ..., 137., 138., 138.],
         [192., 189., 183.,  ..., 137., 138., 138.],
         ...,
         [228., 237., 242.,  ...,  86.,  87.,  87.],
         [229., 238., 242.,  ...,  85.,  88.,  90.],
         [228., 237., 242.,  ...,  64.,  66.,  69.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 477.3282,  686.3646,  585.7890, 1023.4222]])), gt_classes: tensor([442])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000281835.jpg', 'height': 396, 'width': 640, 'not_exhaustive_category_ids': [627], 'neg_category_ids': [1122, 584, 477, 857, 64, 528, 165], 'image_id': 281835, 'image': tensor([[[117., 119., 122.,  ..., 114., 108., 104.],
         [115., 116., 118.,  ..., 112., 108., 106.],
         [112., 112., 113.,  ..., 109., 108., 109.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[105., 105., 106.,  ..., 102.,  98.,  95.],
         [104., 103., 104.,  ..., 100.,  98.,  97.],
         [102., 101., 100.,  ...,  97.,  98.,  99.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[101., 105., 108.,  ..., 101.,  93.,  88.],
         [ 99., 102., 104.,  ...,  99.,  93.,  90.],
         [ 96.,  97.,  99.,  ...,  96.,  93.,  92.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 15.9526, 279.5070,  39.4826, 422.8193]])), gt_classes: tensor([442])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000223091.jpg', 'height': 406, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 603, 1184, 1073, 1036, 402, 407], 'image_id': 223091, 'image': tensor([[[ 18.,  18.,  19.,  ..., 131., 132., 130.],
         [ 30.,  27.,  25.,  ..., 130., 130., 128.],
         [ 58.,  51.,  43.,  ..., 125., 125., 122.],
         ...,
         [ 94.,  85.,  83.,  ..., 116., 108., 104.],
         [ 92.,  85.,  83.,  ..., 114., 106., 103.],
         [ 90.,  86.,  85.,  ..., 110., 104., 104.]],

        [[ 23.,  23.,  23.,  ..., 144., 146., 144.],
         [ 35.,  31.,  28.,  ..., 144., 145., 143.],
         [ 62.,  55.,  47.,  ..., 139., 140., 137.],
         ...,
         [103.,  95.,  91.,  ..., 118., 110., 106.],
         [102.,  95.,  92.,  ..., 116., 109., 106.],
         [102.,  97.,  95.,  ..., 111., 105., 105.]],

        [[ 25.,  26.,  27.,  ..., 143., 143., 141.],
         [ 37.,  35.,  33.,  ..., 142., 142., 140.],
         [ 64.,  59.,  51.,  ..., 139., 139., 137.],
         ...,
         [106.,  98.,  94.,  ..., 116., 108., 104.],
         [105.,  97.,  95.,  ..., 115., 107., 104.],
         [104., 100.,  98.,  ..., 110., 104., 104.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[315.9737,   0.0000, 344.5497, 288.9860]])), gt_classes: tensor([442])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000512217.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [344, 476, 259, 859, 570, 723, 513, 341], 'image_id': 512217, 'image': tensor([[[239., 239., 244.,  ..., 204., 208., 210.],
         [239., 239., 244.,  ..., 206., 212., 214.],
         [239., 239., 244.,  ..., 210., 215., 216.],
         ...,
         [174., 171., 167.,  ...,  47.,  45.,  43.],
         [173., 171., 168.,  ...,  43.,  47.,  47.],
         [165., 162., 160.,  ...,  41.,  47.,  52.]],

        [[241., 241., 246.,  ..., 180., 179., 180.],
         [241., 241., 246.,  ..., 180., 179., 180.],
         [241., 241., 246.,  ..., 181., 179., 180.],
         ...,
         [166., 161., 157.,  ...,  60.,  60.,  60.],
         [175., 169., 163.,  ...,  58.,  58.,  58.],
         [166., 160., 155.,  ...,  58.,  58.,  58.]],

        [[244., 244., 246.,  ..., 139., 147., 145.],
         [244., 244., 246.,  ..., 139., 146., 144.],
         [244., 244., 246.,  ..., 139., 144., 142.],
         ...,
         [154., 154., 155.,  ...,  68.,  66.,  66.],
         [161., 160., 160.,  ...,  69.,  68.,  68.],
         [155., 155., 154.,  ...,  69.,  68.,  68.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[632.8902,  27.4024, 684.8322, 336.0670]])), gt_classes: tensor([442])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000435347.jpg', 'height': 462, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [215, 149, 1125, 131, 770, 614, 1108, 360, 729], 'image_id': 435347, 'annotations_cat_set': {627, 29}, 'image': tensor([[[146., 145., 144.,  ..., 128., 128., 128.],
         [145., 145., 144.,  ..., 128., 128., 128.],
         [144., 144., 145.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[206., 206., 206.,  ..., 128., 128., 128.],
         [206., 206., 206.,  ..., 128., 128., 128.],
         [206., 206., 207.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[192., 192., 192.,  ..., 128., 128., 128.],
         [192., 192., 192.,  ..., 128., 128., 128.],
         [192., 192., 193.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=9, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[8.6392e+01, 2.6967e+02, 8.4334e+02, 4.4531e+02],
        [5.6975e+01, 5.3785e+02, 1.1559e+02, 5.4647e+02],
        [1.6273e+02, 5.3357e+02, 2.3773e+02, 5.4428e+02],
        [8.7313e-01, 5.4133e+02, 3.6989e+01, 5.4824e+02],
        [7.5875e+02, 5.0875e+02, 9.3221e+02, 5.3357e+02],
        [3.4957e+02, 5.2854e+02, 4.3996e+02, 5.4413e+02],
        [2.2082e+02, 4.0256e+02, 2.2763e+02, 5.6176e+02],
        [8.8467e+02, 2.0526e+02, 9.3142e+02, 5.6585e+02],
        [2.3765e+01, 4.5005e+02, 3.2893e+01, 5.5811e+02]])), gt_classes: tensor([ 23,  23,  23,  23,  23,  23, 442, 442, 442])])}], 'support_set_target': tensor(442)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000072370.jpg', 'height': 438, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [786, 879, 107, 460, 907, 1199, 892, 68], 'image_id': 72370, 'annotations': [{'bbox': [300.64, 34.69, 339.36, 103.2], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 435}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000072370.jpg', 'height': 438, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [786, 879, 107, 460, 907, 1199, 892, 68], 'image_id': 72370, 'image': tensor([[[ 24.,  24.,  22.,  ..., 172., 173., 173.],
         [ 23.,  23.,  21.,  ..., 172., 173., 173.],
         [ 22.,  22.,  21.,  ..., 172., 173., 173.],
         ...,
         [ 94.,  93.,  95.,  ..., 125., 124., 125.],
         [ 94.,  93.,  95.,  ..., 126., 125., 126.],
         [ 95.,  94.,  96.,  ..., 127., 126., 127.]],

        [[ 67.,  67.,  66.,  ..., 218., 218., 218.],
         [ 66.,  67.,  66.,  ..., 218., 218., 218.],
         [ 66.,  66.,  65.,  ..., 218., 218., 218.],
         ...,
         [125., 125., 126.,  ..., 183., 183., 184.],
         [125., 125., 127.,  ..., 183., 183., 184.],
         [126., 126., 128.,  ..., 184., 184., 185.]],

        [[ 88.,  88.,  87.,  ..., 202., 202., 202.],
         [ 87.,  88.,  87.,  ..., 202., 202., 202.],
         [ 87.,  87.,  86.,  ..., 202., 202., 202.],
         ...,
         [114., 114., 115.,  ..., 176., 175., 177.],
         [114., 114., 116.,  ..., 176., 175., 177.],
         [115., 115., 117.,  ..., 177., 176., 178.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000,   0.0000, 180.6422, 152.0588]])), gt_classes: tensor([435])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000008321.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [611, 1105, 930, 567, 1156, 229, 1037, 553, 625], 'image_id': 8321, 'annotations': [{'bbox': [350.54, 386.35, 176.17, 93.65], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 435}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000008321.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [611, 1105, 930, 567, 1156, 229, 1037, 553, 625], 'image_id': 8321, 'image': tensor([[[194., 194., 193.,  ...,   1.,   1.,   1.],
         [197., 196., 195.,  ...,   1.,   1.,   1.],
         [200., 199., 198.,  ...,   2.,   2.,   2.],
         ...,
         [153., 153., 153.,  ..., 196., 196., 196.],
         [154., 154., 154.,  ..., 195., 194., 194.],
         [155., 155., 155.,  ..., 193., 192., 191.]],

        [[216., 216., 216.,  ...,   1.,   1.,   1.],
         [218., 218., 217.,  ...,   1.,   1.,   1.],
         [220., 220., 219.,  ...,   2.,   2.,   2.],
         ...,
         [ 75.,  75.,  75.,  ..., 180., 180., 180.],
         [ 75.,  75.,  76.,  ..., 178., 178., 178.],
         [ 76.,  76.,  77.,  ..., 174., 174., 174.]],

        [[214., 214., 214.,  ...,   1.,   1.,   1.],
         [215., 215., 215.,  ...,   1.,   1.,   1.],
         [217., 217., 217.,  ...,   2.,   2.,   2.],
         ...,
         [  8.,   8.,   8.,  ..., 132., 133., 133.],
         [  8.,   8.,   9.,  ..., 129., 130., 130.],
         [  9.,   9.,  10.,  ..., 126., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  937.4402,  393.0231, 1024.0000]])), gt_classes: tensor([435])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000280607.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [615], 'neg_category_ids': [101, 1145, 650, 854, 810, 373, 970, 1173, 133, 614, 975, 749, 750, 95], 'image_id': 280607, 'annotations': [{'bbox': [238.68, 146.36, 61.73, 167.11], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 435}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000280607.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [615], 'neg_category_ids': [101, 1145, 650, 854, 810, 373, 970, 1173, 133, 614, 975, 749, 750, 95], 'image_id': 280607, 'image': tensor([[[52., 54., 55.,  ..., 29., 29., 29.],
         [48., 52., 53.,  ..., 29., 29., 29.],
         [46., 48., 49.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]],

        [[58., 58., 58.,  ..., 29., 29., 29.],
         [54., 57., 58.,  ..., 29., 29., 29.],
         [51., 53., 54.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]],

        [[56., 57., 57.,  ..., 29., 29., 29.],
         [52., 56., 57.,  ..., 29., 29., 29.],
         [50., 52., 53.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[253.0008, 154.9465, 318.4346, 331.8602]])), gt_classes: tensor([435])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000573476.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 193, 504, 1085, 1178, 660, 681, 187, 214], 'image_id': 573476, 'annotations': [{'bbox': [432.79, 423.3, 97.06, 56.16], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 435}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000573476.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 193, 504, 1085, 1178, 660, 681, 187, 214], 'image_id': 573476, 'image': tensor([[[ 72.,  70.,  74.,  ...,  31.,  31.,  31.],
         [ 72.,  70.,  74.,  ...,  31.,  31.,  31.],
         [ 72.,  70.,  72.,  ...,  31.,  29.,  29.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]],

        [[ 65.,  66.,  68.,  ...,  19.,  21.,  23.],
         [ 65.,  66.,  68.,  ...,  19.,  21.,  23.],
         [ 65.,  66.,  68.,  ...,  19.,  21.,  23.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]],

        [[ 46.,  48.,  49.,  ...,   6.,  12.,  14.],
         [ 46.,  48.,  49.,  ...,   6.,  10.,  12.],
         [ 48.,  48.,  49.,  ...,   6.,   8.,   8.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[174.3054, 685.2169, 331.4212, 776.1259]])), gt_classes: tensor([435])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000576676.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 559, 30, 1107, 309, 701, 335], 'image_id': 576676, 'annotations': [{'bbox': [208.96, 220.4, 20.78, 105.15], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 435}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000576676.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 559, 30, 1107, 309, 701, 335], 'image_id': 576676, 'image': tensor([[[163., 164., 164.,  ..., 140., 139., 140.],
         [166., 166., 165.,  ..., 141., 142., 141.],
         [167., 167., 165.,  ..., 142., 143., 141.],
         ...,
         [140., 138., 138.,  ..., 181., 181., 180.],
         [140., 138., 137.,  ..., 181., 181., 180.],
         [141., 140., 139.,  ..., 178., 179., 178.]],

        [[179., 179., 179.,  ..., 131., 131., 132.],
         [181., 180., 178.,  ..., 133., 134., 133.],
         [181., 181., 178.,  ..., 133., 135., 133.],
         ...,
         [144., 143., 143.,  ..., 179., 179., 177.],
         [143., 142., 142.,  ..., 178., 178., 176.],
         [144., 144., 144.,  ..., 175., 175., 174.]],

        [[195., 193., 193.,  ..., 142., 141., 142.],
         [196., 194., 192.,  ..., 143., 144., 143.],
         [196., 195., 192.,  ..., 144., 145., 143.],
         ...,
         [143., 142., 142.,  ..., 172., 172., 170.],
         [143., 142., 141.,  ..., 172., 172., 170.],
         [144., 143., 143.,  ..., 169., 170., 169.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[695.4173, 322.2237, 736.2630, 528.9092]])), gt_classes: tensor([435])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000072370.jpg', 'height': 438, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [786, 879, 107, 460, 907, 1199, 892, 68], 'image_id': 72370, 'image': tensor([[[ 24.,  24.,  22.,  ..., 172., 173., 173.],
         [ 23.,  23.,  21.,  ..., 172., 173., 173.],
         [ 22.,  22.,  21.,  ..., 172., 173., 173.],
         ...,
         [ 94.,  93.,  95.,  ..., 125., 124., 125.],
         [ 94.,  93.,  95.,  ..., 126., 125., 126.],
         [ 95.,  94.,  96.,  ..., 127., 126., 127.]],

        [[ 67.,  67.,  66.,  ..., 218., 218., 218.],
         [ 66.,  67.,  66.,  ..., 218., 218., 218.],
         [ 66.,  66.,  65.,  ..., 218., 218., 218.],
         ...,
         [125., 125., 126.,  ..., 183., 183., 184.],
         [125., 125., 127.,  ..., 183., 183., 184.],
         [126., 126., 128.,  ..., 184., 184., 185.]],

        [[ 88.,  88.,  87.,  ..., 202., 202., 202.],
         [ 87.,  88.,  87.,  ..., 202., 202., 202.],
         [ 87.,  87.,  86.,  ..., 202., 202., 202.],
         ...,
         [114., 114., 115.,  ..., 176., 175., 177.],
         [114., 114., 116.,  ..., 176., 175., 177.],
         [115., 115., 117.,  ..., 177., 176., 178.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000,   0.0000, 180.6422, 152.0588]])), gt_classes: tensor([435])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000008321.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [611, 1105, 930, 567, 1156, 229, 1037, 553, 625], 'image_id': 8321, 'image': tensor([[[194., 194., 193.,  ...,   1.,   1.,   1.],
         [197., 196., 195.,  ...,   1.,   1.,   1.],
         [200., 199., 198.,  ...,   2.,   2.,   2.],
         ...,
         [153., 153., 153.,  ..., 196., 196., 196.],
         [154., 154., 154.,  ..., 195., 194., 194.],
         [155., 155., 155.,  ..., 193., 192., 191.]],

        [[216., 216., 216.,  ...,   1.,   1.,   1.],
         [218., 218., 217.,  ...,   1.,   1.,   1.],
         [220., 220., 219.,  ...,   2.,   2.,   2.],
         ...,
         [ 75.,  75.,  75.,  ..., 180., 180., 180.],
         [ 75.,  75.,  76.,  ..., 178., 178., 178.],
         [ 76.,  76.,  77.,  ..., 174., 174., 174.]],

        [[214., 214., 214.,  ...,   1.,   1.,   1.],
         [215., 215., 215.,  ...,   1.,   1.,   1.],
         [217., 217., 217.,  ...,   2.,   2.,   2.],
         ...,
         [  8.,   8.,   8.,  ..., 132., 133., 133.],
         [  8.,   8.,   9.,  ..., 129., 130., 130.],
         [  9.,   9.,  10.,  ..., 126., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  937.4402,  393.0231, 1024.0000]])), gt_classes: tensor([435])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000280607.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [615], 'neg_category_ids': [101, 1145, 650, 854, 810, 373, 970, 1173, 133, 614, 975, 749, 750, 95], 'image_id': 280607, 'image': tensor([[[52., 54., 55.,  ..., 29., 29., 29.],
         [48., 52., 53.,  ..., 29., 29., 29.],
         [46., 48., 49.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]],

        [[58., 58., 58.,  ..., 29., 29., 29.],
         [54., 57., 58.,  ..., 29., 29., 29.],
         [51., 53., 54.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]],

        [[56., 57., 57.,  ..., 29., 29., 29.],
         [52., 56., 57.,  ..., 29., 29., 29.],
         [50., 52., 53.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[253.0008, 154.9465, 318.4346, 331.8602]])), gt_classes: tensor([435])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000573476.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 193, 504, 1085, 1178, 660, 681, 187, 214], 'image_id': 573476, 'image': tensor([[[ 72.,  70.,  74.,  ...,  31.,  31.,  31.],
         [ 72.,  70.,  74.,  ...,  31.,  31.,  31.],
         [ 72.,  70.,  72.,  ...,  31.,  29.,  29.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]],

        [[ 65.,  66.,  68.,  ...,  19.,  21.,  23.],
         [ 65.,  66.,  68.,  ...,  19.,  21.,  23.],
         [ 65.,  66.,  68.,  ...,  19.,  21.,  23.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]],

        [[ 46.,  48.,  49.,  ...,   6.,  12.,  14.],
         [ 46.,  48.,  49.,  ...,   6.,  10.,  12.],
         [ 48.,  48.,  49.,  ...,   6.,   8.,   8.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[174.3054, 685.2169, 331.4212, 776.1259]])), gt_classes: tensor([435])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000576676.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 559, 30, 1107, 309, 701, 335], 'image_id': 576676, 'image': tensor([[[163., 164., 164.,  ..., 140., 139., 140.],
         [166., 166., 165.,  ..., 141., 142., 141.],
         [167., 167., 165.,  ..., 142., 143., 141.],
         ...,
         [140., 138., 138.,  ..., 181., 181., 180.],
         [140., 138., 137.,  ..., 181., 181., 180.],
         [141., 140., 139.,  ..., 178., 179., 178.]],

        [[179., 179., 179.,  ..., 131., 131., 132.],
         [181., 180., 178.,  ..., 133., 134., 133.],
         [181., 181., 178.,  ..., 133., 135., 133.],
         ...,
         [144., 143., 143.,  ..., 179., 179., 177.],
         [143., 142., 142.,  ..., 178., 178., 176.],
         [144., 144., 144.,  ..., 175., 175., 174.]],

        [[195., 193., 193.,  ..., 142., 141., 142.],
         [196., 194., 192.,  ..., 143., 144., 143.],
         [196., 195., 192.,  ..., 144., 145., 143.],
         ...,
         [143., 142., 142.,  ..., 172., 172., 170.],
         [143., 142., 141.,  ..., 172., 172., 170.],
         [144., 143., 143.,  ..., 169., 170., 169.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[695.4173, 322.2237, 736.2630, 528.9092]])), gt_classes: tensor([435])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000537371.jpg', 'height': 429, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [806, 101, 521, 114, 797, 843, 360, 895], 'image_id': 537371, 'annotations_cat_set': {713, 615}, 'image': tensor([[[248., 248., 248.,  ...,  42.,  42.,  42.],
         [248., 248., 248.,  ...,  42.,  42.,  42.],
         [249., 248., 248.,  ...,  42.,  42.,  42.],
         ...,
         [ 42.,  42.,  42.,  ...,  42.,  42.,  42.],
         [ 42.,  42.,  42.,  ...,  42.,  42.,  42.],
         [ 42.,  42.,  42.,  ...,  42.,  42.,  42.]],

        [[248., 248., 248.,  ...,  34.,  34.,  34.],
         [248., 247., 247.,  ...,  34.,  34.,  34.],
         [249., 248., 248.,  ...,  34.,  34.,  34.],
         ...,
         [ 34.,  34.,  34.,  ...,  34.,  34.,  34.],
         [ 34.,  34.,  34.,  ...,  34.,  34.,  34.],
         [ 34.,  34.,  34.,  ...,  34.,  34.,  34.]],

        [[252., 252., 252.,  ...,  44.,  44.,  44.],
         [252., 252., 252.,  ...,  44.,  44.,  44.],
         [253., 252., 252.,  ...,  44.,  44.,  44.],
         ...,
         [ 44.,  44.,  44.,  ...,  44.,  44.,  44.],
         [ 44.,  44.,  44.,  ...,  44.,  44.,  44.],
         [ 44.,  44.,  44.,  ...,  44.,  44.,  44.]]]), 'instances': Instances(num_instances=4, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[4.5531e+02, 3.4186e+02, 6.3400e+02, 4.2500e+02],
        [4.1606e-01, 3.5495e+02, 1.0063e+02, 4.2460e+02],
        [0.0000e+00, 3.7242e+02, 8.3747e+01, 4.1327e+02],
        [4.3259e+02, 3.3922e+02, 6.0096e+02, 4.2422e+02]])), gt_classes: tensor([503, 503, 435, 435])])}], 'support_set_target': tensor(435)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000419483.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [645], 'neg_category_ids': [966, 1027, 1008, 377, 156, 656, 209, 1159], 'image_id': 419483, 'annotations': [{'bbox': [19.1, 288.89, 342.86, 191.11], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 15}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000419483.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [645], 'neg_category_ids': [966, 1027, 1008, 377, 156, 656, 209, 1159], 'image_id': 419483, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[384.0428, 399.0293, 857.6181, 663.0000]])), gt_classes: tensor([15])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000573784.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [711, 714, 438, 378, 744, 229, 1177, 822, 600, 471], 'image_id': 573784, 'annotations': [{'bbox': [86.55, 329.41, 157.48, 97.59], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 15}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000573784.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [711, 714, 438, 378, 744, 229, 1177, 822, 600, 471], 'image_id': 573784, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[433.0922, 360.2681, 605.3359, 467.0000]])), gt_classes: tensor([15])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000433023.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [19], 'neg_category_ids': [965, 35, 659, 842, 249, 937, 939], 'image_id': 433023, 'annotations': [{'bbox': [166.12, 250.77, 31.62, 61.05], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 15}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000433023.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [19], 'neg_category_ids': [965, 35, 659, 842, 249, 937, 939], 'image_id': 433023, 'image': tensor([[[  0.,   0.,   0.,  ...,  21.,  22.,  26.],
         [  0.,   0.,   0.,  ...,  21.,  24.,  30.],
         [  0.,   0.,   0.,  ...,  22.,  26.,  31.],
         ...,
         [  0.,   0.,   0.,  ...,  67.,  72.,  81.],
         [  0.,   0.,   0.,  ...,  90.,  94.,  99.],
         [  0.,   0.,   0.,  ..., 112., 115., 117.]],

        [[  0.,   0.,   0.,  ...,  35.,  37.,  42.],
         [  0.,   0.,   0.,  ...,  35.,  38.,  44.],
         [  0.,   0.,   0.,  ...,  38.,  42.,  47.],
         ...,
         [  0.,   0.,   0.,  ..., 103., 105., 110.],
         [  0.,   0.,   0.,  ..., 123., 124., 128.],
         [  0.,   0.,   0.,  ..., 144., 144., 146.]],

        [[  6.,   4.,   4.,  ...,  47.,  49.,  53.],
         [  4.,   3.,   3.,  ...,  47.,  49.,  53.],
         [  6.,   4.,   4.,  ...,  46.,  47.,  51.],
         ...,
         [  0.,   0.,   0.,  ...,  81.,  89.,  99.],
         [  0.,   0.,   0.,  ..., 108., 114., 121.],
         [  1.,   0.,   0.,  ..., 135., 139., 142.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[416.2853, 576.4614, 509.0373, 755.5096]])), gt_classes: tensor([15])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000405004.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [982], 'neg_category_ids': [1002, 1069, 123, 696, 1007, 1150, 905, 307, 397, 838, 331, 1156, 16, 940], 'image_id': 405004, 'annotations': [{'bbox': [391.72, 255.38, 108.28, 119.62], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 15}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000405004.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [982], 'neg_category_ids': [1002, 1069, 123, 696, 1007, 1150, 905, 307, 397, 838, 331, 1156, 16, 940], 'image_id': 405004, 'image': tensor([[[230., 230., 231.,  ..., 127., 127., 127.],
         [228., 228., 228.,  ..., 127., 127., 127.],
         [227., 226., 226.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[223., 224., 223.,  ..., 127., 127., 127.],
         [222., 223., 223.,  ..., 127., 127., 127.],
         [223., 223., 223.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[220., 219., 218.,  ..., 127., 127., 127.],
         [219., 219., 218.,  ..., 127., 127., 127.],
         [221., 220., 219.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 315.3092, 133.6175, 463.0000]])), gt_classes: tensor([15])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000153368.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [709, 1, 216, 966, 6, 988, 156, 1059, 95], 'image_id': 153368, 'annotations': [{'bbox': [1.08, 230.17, 157.88, 194.57], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 15}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000153368.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [709, 1, 216, 966, 6, 988, 156, 1059, 95], 'image_id': 153368, 'image': tensor([[[69., 69., 69.,  ..., 71., 71., 71.],
         [69., 69., 69.,  ..., 71., 71., 71.],
         [69., 69., 69.,  ..., 71., 71., 71.],
         ...,
         [72., 72., 72.,  ..., 72., 72., 72.],
         [72., 72., 72.,  ..., 72., 72., 72.],
         [72., 72., 72.,  ..., 72., 72., 72.]],

        [[71., 71., 71.,  ..., 74., 74., 74.],
         [71., 71., 71.,  ..., 74., 74., 74.],
         [71., 71., 71.,  ..., 74., 74., 74.],
         ...,
         [72., 72., 72.,  ..., 72., 72., 72.],
         [72., 72., 72.,  ..., 72., 72., 72.],
         [72., 72., 72.,  ..., 72., 72., 72.]],

        [[72., 73., 73.,  ..., 75., 75., 75.],
         [72., 73., 73.,  ..., 75., 75., 75.],
         [73., 73., 73.,  ..., 75., 75., 75.],
         ...,
         [72., 72., 72.,  ..., 72., 72., 72.],
         [72., 72., 72.,  ..., 72., 72., 72.],
         [72., 72., 72.,  ..., 72., 72., 72.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1014.0396,  506.8062, 1024.0000,  935.2256]])), gt_classes: tensor([15])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000419483.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [645], 'neg_category_ids': [966, 1027, 1008, 377, 156, 656, 209, 1159], 'image_id': 419483, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[384.0428, 399.0293, 857.6181, 663.0000]])), gt_classes: tensor([15])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000573784.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [711, 714, 438, 378, 744, 229, 1177, 822, 600, 471], 'image_id': 573784, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[433.0922, 360.2681, 605.3359, 467.0000]])), gt_classes: tensor([15])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000433023.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [19], 'neg_category_ids': [965, 35, 659, 842, 249, 937, 939], 'image_id': 433023, 'image': tensor([[[  0.,   0.,   0.,  ...,  21.,  22.,  26.],
         [  0.,   0.,   0.,  ...,  21.,  24.,  30.],
         [  0.,   0.,   0.,  ...,  22.,  26.,  31.],
         ...,
         [  0.,   0.,   0.,  ...,  67.,  72.,  81.],
         [  0.,   0.,   0.,  ...,  90.,  94.,  99.],
         [  0.,   0.,   0.,  ..., 112., 115., 117.]],

        [[  0.,   0.,   0.,  ...,  35.,  37.,  42.],
         [  0.,   0.,   0.,  ...,  35.,  38.,  44.],
         [  0.,   0.,   0.,  ...,  38.,  42.,  47.],
         ...,
         [  0.,   0.,   0.,  ..., 103., 105., 110.],
         [  0.,   0.,   0.,  ..., 123., 124., 128.],
         [  0.,   0.,   0.,  ..., 144., 144., 146.]],

        [[  6.,   4.,   4.,  ...,  47.,  49.,  53.],
         [  4.,   3.,   3.,  ...,  47.,  49.,  53.],
         [  6.,   4.,   4.,  ...,  46.,  47.,  51.],
         ...,
         [  0.,   0.,   0.,  ...,  81.,  89.,  99.],
         [  0.,   0.,   0.,  ..., 108., 114., 121.],
         [  1.,   0.,   0.,  ..., 135., 139., 142.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[416.2853, 576.4614, 509.0373, 755.5096]])), gt_classes: tensor([15])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000405004.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [982], 'neg_category_ids': [1002, 1069, 123, 696, 1007, 1150, 905, 307, 397, 838, 331, 1156, 16, 940], 'image_id': 405004, 'image': tensor([[[230., 230., 231.,  ..., 127., 127., 127.],
         [228., 228., 228.,  ..., 127., 127., 127.],
         [227., 226., 226.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[223., 224., 223.,  ..., 127., 127., 127.],
         [222., 223., 223.,  ..., 127., 127., 127.],
         [223., 223., 223.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[220., 219., 218.,  ..., 127., 127., 127.],
         [219., 219., 218.,  ..., 127., 127., 127.],
         [221., 220., 219.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 315.3092, 133.6175, 463.0000]])), gt_classes: tensor([15])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000153368.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [709, 1, 216, 966, 6, 988, 156, 1059, 95], 'image_id': 153368, 'image': tensor([[[69., 69., 69.,  ..., 71., 71., 71.],
         [69., 69., 69.,  ..., 71., 71., 71.],
         [69., 69., 69.,  ..., 71., 71., 71.],
         ...,
         [72., 72., 72.,  ..., 72., 72., 72.],
         [72., 72., 72.,  ..., 72., 72., 72.],
         [72., 72., 72.,  ..., 72., 72., 72.]],

        [[71., 71., 71.,  ..., 74., 74., 74.],
         [71., 71., 71.,  ..., 74., 74., 74.],
         [71., 71., 71.,  ..., 74., 74., 74.],
         ...,
         [72., 72., 72.,  ..., 72., 72., 72.],
         [72., 72., 72.,  ..., 72., 72., 72.],
         [72., 72., 72.,  ..., 72., 72., 72.]],

        [[72., 73., 73.,  ..., 75., 75., 75.],
         [72., 73., 73.,  ..., 75., 75., 75.],
         [73., 73., 73.,  ..., 75., 75., 75.],
         ...,
         [72., 72., 72.,  ..., 72., 72., 72.],
         [72., 72., 72.,  ..., 72., 72., 72.],
         [72., 72., 72.,  ..., 72., 72., 72.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1014.0396,  506.8062, 1024.0000,  935.2256]])), gt_classes: tensor([15])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000433023.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [19], 'neg_category_ids': [965, 35, 659, 842, 249, 937, 939], 'image_id': 433023, 'annotations_cat_set': {19, 1077}, 'image': tensor([[[140., 144., 145.,  ..., 128., 128., 128.],
         [142., 144., 145.,  ..., 128., 128., 128.],
         [144., 145., 147.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[166., 170., 172.,  ..., 128., 128., 128.],
         [167., 168., 168.,  ..., 128., 128., 128.],
         [167., 165., 165.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[180., 180., 180.,  ..., 128., 128., 128.],
         [175., 174., 174.,  ..., 128., 128., 128.],
         [171., 170., 169.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=15, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[325.9740, 215.1531, 394.7928, 280.5688],
        [489.5206, 434.8740, 580.7698, 546.3906],
        [578.4102, 416.4518, 633.1627, 526.0323],
        [514.0836, 465.7290, 598.9651, 577.9716],
        [539.9020, 508.8958, 653.5361, 702.8588],
        [ 26.8317, 506.6421, 213.3230, 778.9980],
        [426.9183, 379.2896, 474.7435, 471.6277],
        [115.2525, 431.2894, 236.3281, 548.1149],
        [468.2397, 394.2634, 600.6440, 509.0773],
        [183.1638, 375.5537, 259.9836, 459.0286],
        [677.9630, 757.5961, 726.0000, 966.5782],
        [458.0001, 369.9726, 514.5374, 469.3439],
        [110.3218, 462.7040, 231.6999, 606.8604],
        [126.2937, 406.3029, 243.1041, 516.6548],
        [  4.9761, 728.7074, 317.8368, 967.2892]])), gt_classes: tensor([759,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,  15,
         15])])}], 'support_set_target': tensor(15)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000254150.jpg', 'height': 533, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1094, 1169, 545, 673, 989, 442, 94, 960, 999], 'image_id': 254150, 'annotations': [{'bbox': [239.72, 370.42, 38.68, 40.63], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 787}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000254150.jpg', 'height': 533, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1094, 1169, 545, 673, 989, 442, 94, 960, 999], 'image_id': 254150, 'image': tensor([[[106., 107., 107.,  ..., 128., 128., 128.],
         [106., 106., 106.,  ..., 128., 128., 128.],
         [106., 105., 105.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[101., 102., 102.,  ..., 128., 128., 128.],
         [101., 101., 101.,  ..., 128., 128., 128.],
         [101., 100., 100.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[100.,  99.,  99.,  ..., 128., 128., 128.],
         [ 99.,  98.,  98.,  ..., 128., 128., 128.],
         [ 98.,  97.,  98.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[475.1650, 487.1753, 525.9929, 540.6118]])), gt_classes: tensor([787])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000320117.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [1026], 'neg_category_ids': [735, 101, 346, 152, 1033, 527, 996, 1042], 'image_id': 320117, 'annotations': [{'bbox': [264.55, 172.51, 49.22, 37.29], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 787}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000320117.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [1026], 'neg_category_ids': [735, 101, 346, 152, 1033, 527, 996, 1042], 'image_id': 320117, 'image': tensor([[[148., 121.,  94.,  ...,  71.,  73.,  73.],
         [187., 145., 100.,  ...,  73.,  76.,  77.],
         [229., 169., 108.,  ...,  76.,  79.,  82.],
         ...,
         [ 95.,  93.,  91.,  ...,  27.,  28.,  28.],
         [ 96.,  94.,  92.,  ...,  27.,  28.,  28.],
         [ 94.,  92.,  92.,  ...,  26.,  27.,  27.]],

        [[159., 140., 122.,  ..., 117., 117., 119.],
         [184., 152., 121.,  ..., 118., 120., 122.],
         [208., 164., 119.,  ..., 121., 124., 126.],
         ...,
         [129., 127., 125.,  ...,  27.,  28.,  28.],
         [130., 128., 126.,  ...,  27.,  28.,  28.],
         [128., 126., 122.,  ...,  26.,  27.,  27.]],

        [[155., 138., 120.,  ..., 115., 117., 120.],
         [180., 149., 117.,  ..., 121., 123., 125.],
         [204., 160., 114.,  ..., 126., 129., 133.],
         ...,
         [144., 142., 140.,  ...,  27.,  28.,  28.],
         [143., 143., 141.,  ...,  27.,  28.,  28.],
         [141., 139., 137.,  ...,  26.,  27.,  27.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 272.3991,  74.6096, 418.1781]])), gt_classes: tensor([787])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000066662.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [81, 306, 482, 1105, 488, 600, 1064, 277], 'image_id': 66662, 'annotations': [{'bbox': [160.92, 79.49, 389.58, 259.27], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 787}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000066662.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [81, 306, 482, 1105, 488, 600, 1064, 277], 'image_id': 66662, 'image': tensor([[[172., 165., 159.,  ..., 192., 198., 210.],
         [166., 162., 157.,  ..., 201., 208., 216.],
         [161., 158., 155.,  ..., 211., 218., 221.],
         ...,
         [ 82.,  77.,  73.,  ...,  67.,  69.,  75.],
         [ 86.,  80.,  73.,  ...,  66.,  69.,  77.],
         [ 84.,  80.,  76.,  ...,  74.,  75.,  81.]],

        [[172., 165., 159.,  ..., 192., 198., 210.],
         [166., 162., 157.,  ..., 201., 208., 216.],
         [161., 158., 155.,  ..., 211., 218., 221.],
         ...,
         [ 82.,  77.,  73.,  ...,  67.,  69.,  75.],
         [ 86.,  80.,  73.,  ...,  66.,  69.,  77.],
         [ 84.,  80.,  76.,  ...,  74.,  75.,  81.]],

        [[172., 165., 159.,  ..., 192., 198., 210.],
         [166., 162., 157.,  ..., 201., 208., 216.],
         [161., 158., 155.,  ..., 211., 218., 221.],
         ...,
         [ 82.,  77.,  73.,  ...,  67.,  69.,  75.],
         [ 86.,  80.,  73.,  ...,  66.,  69.,  77.],
         [ 84.,  80.,  76.,  ...,  74.,  75.,  81.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000,  50.7853, 891.3477, 868.7639]])), gt_classes: tensor([787])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000508252.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [709, 688, 540, 2, 196, 1048, 703, 996, 961], 'image_id': 508252, 'annotations': [{'bbox': [38.63, 49.71, 460.84, 375.63], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 787}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000508252.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [709, 688, 540, 2, 196, 1048, 703, 996, 961], 'image_id': 508252, 'image': tensor([[[ 13.,  14.,  14.,  ...,  57.,  58.,  58.],
         [ 15.,  15.,  15.,  ...,  56.,  57.,  57.],
         [ 15.,  15.,  16.,  ...,  55.,  56.,  56.],
         ...,
         [ 10.,   7.,   5.,  ..., 199., 199., 199.],
         [ 10.,   7.,   4.,  ..., 198., 197., 197.],
         [  9.,   6.,   4.,  ..., 197., 196., 196.]],

        [[ 13.,  14.,  14.,  ...,  30.,  31.,  31.],
         [ 15.,  15.,  15.,  ...,  30.,  31.,  31.],
         [ 15.,  15.,  16.,  ...,  29.,  30.,  30.],
         ...,
         [ 10.,   7.,   5.,  ..., 204., 204., 204.],
         [ 10.,   7.,   5.,  ..., 204., 204., 204.],
         [ 11.,   8.,   5.,  ..., 203., 204., 204.]],

        [[ 13.,  14.,  14.,  ...,  24.,  25.,  25.],
         [ 15.,  15.,  15.,  ...,  24.,  25.,  25.],
         [ 15.,  15.,  16.,  ...,  23.,  24.,  24.],
         ...,
         [ 10.,   7.,   5.,  ..., 213., 213., 213.],
         [ 10.,   7.,   5.,  ..., 213., 213., 213.],
         [ 11.,   8.,   5.,  ..., 214., 214., 214.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  64.1331,  129.4506, 1024.0000, 1024.0000]])), gt_classes: tensor([787])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000057617.jpg', 'height': 474, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [921, 1126, 152, 30, 180, 863, 952, 662, 686], 'image_id': 57617, 'annotations': [{'bbox': [80.56, 185.97, 406.18, 184.33], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 787}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000057617.jpg', 'height': 474, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [921, 1126, 152, 30, 180, 863, 952, 662, 686], 'image_id': 57617, 'image': tensor([[[197., 197., 199.,  ...,  51.,  39.,  28.],
         [196., 195., 197.,  ...,  71.,  56.,  43.],
         [196., 195., 197.,  ...,  90.,  77.,  66.],
         ...,
         [ 95.,  94.,  94.,  ...,  42.,  41.,  40.],
         [ 93.,  92.,  93.,  ...,  41.,  40.,  39.],
         [ 93.,  93.,  93.,  ...,  41.,  40.,  40.]],

        [[179., 180., 183.,  ...,  28.,  20.,  12.],
         [178., 180., 182.,  ...,  41.,  30.,  19.],
         [180., 181., 184.,  ...,  58.,  47.,  36.],
         ...,
         [103., 104., 105.,  ...,  51.,  50.,  49.],
         [102., 103., 104.,  ...,  50.,  50.,  49.],
         [102., 102., 103.,  ...,  50.,  50.,  49.]],

        [[208., 207., 208.,  ...,  40.,  30.,  20.],
         [205., 204., 205.,  ...,  57.,  45.,  32.],
         [202., 202., 203.,  ...,  80.,  67.,  54.],
         ...,
         [ 99.,  99.,  99.,  ...,  48.,  48.,  47.],
         [ 97.,  97.,  98.,  ...,  47.,  47.,  46.],
         [ 97.,  97.,  98.,  ...,  47.,  47.,  46.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  318.7280, 1024.0000,  901.2729]])), gt_classes: tensor([787])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484563.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1149, 194, 998, 17], 'image_id': 484563, 'annotations': [{'bbox': [346.86, 271.15, 80.14, 90.2], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 797}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484563.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1149, 194, 998, 17], 'image_id': 484563, 'image': tensor([[[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[376.9158, 294.4519, 464.0000, 392.4035]])), gt_classes: tensor([797])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000334171.jpg', 'height': 457, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [320, 1147, 1006, 874, 1085, 1012, 276, 1141, 98], 'image_id': 334171, 'annotations': [{'bbox': [47.44, 285.99, 102.67, 104.85], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 797}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000334171.jpg', 'height': 457, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [320, 1147, 1006, 874, 1085, 1012, 276, 1141, 98], 'image_id': 334171, 'image': tensor([[[161., 161., 161.,  ..., 128., 128., 128.],
         [161., 161., 161.,  ..., 128., 128., 128.],
         [161., 161., 161.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[125., 125., 125.,  ..., 128., 128., 128.],
         [125., 125., 125.,  ..., 128., 128., 128.],
         [125., 125., 125.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 95.,  95.,  95.,  ..., 128., 128., 128.],
         [ 95.,  95.,  95.,  ..., 128., 128., 128.],
         [ 95.,  95.,  95.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 71.6048, 431.8011, 226.5723, 590.1085]])), gt_classes: tensor([797])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000481736.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [494, 645, 434], 'image_id': 481736, 'annotations': [{'bbox': [85.62, 313.26, 22.09, 42.13], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 797}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000481736.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [494, 645, 434], 'image_id': 481736, 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484563.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1149, 194, 998, 17], 'image_id': 484563, 'annotations': [{'bbox': [110.73, 266.5, 279.15, 216.19], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 797}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484563.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1149, 194, 998, 17], 'image_id': 484563, 'image': tensor([[[255., 255., 255.,  ..., 240., 239., 237.],
         [255., 255., 255.,  ..., 239., 238., 236.],
         [255., 255., 255.,  ..., 239., 238., 236.],
         ...,
         [ 11.,   9.,   9.,  ...,  83.,  80.,  80.],
         [  9.,   8.,   5.,  ...,  82.,  83.,  84.],
         [  6.,   3.,   1.,  ...,  86.,  89.,  90.]],

        [[255., 255., 255.,  ..., 244., 244., 244.],
         [255., 255., 255.,  ..., 245., 244., 244.],
         [255., 255., 255.,  ..., 245., 244., 244.],
         ...,
         [  9.,   9.,   7.,  ...,  67.,  65.,  64.],
         [ 12.,   7.,   6.,  ...,  65.,  67.,  68.],
         [  7.,   6.,   2.,  ...,  69.,  72.,  74.]],

        [[255., 255., 255.,  ..., 243., 243., 243.],
         [255., 255., 255.,  ..., 243., 243., 243.],
         [255., 255., 255.,  ..., 243., 243., 243.],
         ...,
         [ 16.,  16.,  16.,  ...,  76.,  73.,  71.],
         [ 19.,  16.,  14.,  ...,  74.,  74.,  74.],
         [ 16.,  12.,   9.,  ...,  76.,  77.,  77.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 291.2190,  680.8844, 1024.0000, 1024.0000]])), gt_classes: tensor([797])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000085941.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 349, 309, 818, 442, 576, 977, 781], 'image_id': 85941, 'annotations': [{'bbox': [91.73, 409.99, 300.6, 203.68], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 797}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000085941.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 349, 309, 818, 442, 576, 977, 781], 'image_id': 85941, 'image': tensor([[[255., 254., 254.,  ..., 255., 255., 255.],
         [255., 254., 254.,  ..., 255., 255., 255.],
         [254., 253., 253.,  ..., 255., 255., 254.],
         ...,
         [176., 184., 192.,  ..., 128., 129., 214.],
         [189., 188., 187.,  ..., 215., 215., 214.],
         [201., 191., 183.,  ..., 215., 214., 213.]],

        [[240., 239., 239.,  ..., 231., 231., 231.],
         [240., 239., 239.,  ..., 231., 231., 231.],
         [241., 240., 240.,  ..., 232., 232., 232.],
         ...,
         [151., 156., 162.,  ..., 211., 212., 209.],
         [163., 160., 158.,  ..., 210., 210., 209.],
         [174., 164., 155.,  ..., 210., 209., 208.]],

        [[223., 223., 223.,  ..., 215., 215., 215.],
         [224., 223., 223.,  ..., 215., 215., 215.],
         [225., 224., 224.,  ..., 216., 216., 216.],
         ...,
         [123., 126., 130.,  ..., 212., 213., 210.],
         [142., 139., 136.,  ..., 211., 211., 210.],
         [161., 151., 142.,  ..., 211., 210., 209.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 148.6586,  916.2532,  990.9649, 1024.0000]])), gt_classes: tensor([797])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000254150.jpg', 'height': 533, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1094, 1169, 545, 673, 989, 442, 94, 960, 999], 'image_id': 254150, 'image': tensor([[[106., 107., 107.,  ..., 128., 128., 128.],
         [106., 106., 106.,  ..., 128., 128., 128.],
         [106., 105., 105.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[101., 102., 102.,  ..., 128., 128., 128.],
         [101., 101., 101.,  ..., 128., 128., 128.],
         [101., 100., 100.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[100.,  99.,  99.,  ..., 128., 128., 128.],
         [ 99.,  98.,  98.,  ..., 128., 128., 128.],
         [ 98.,  97.,  98.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[475.1650, 487.1753, 525.9929, 540.6118]])), gt_classes: tensor([787])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000320117.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [1026], 'neg_category_ids': [735, 101, 346, 152, 1033, 527, 996, 1042], 'image_id': 320117, 'image': tensor([[[148., 121.,  94.,  ...,  71.,  73.,  73.],
         [187., 145., 100.,  ...,  73.,  76.,  77.],
         [229., 169., 108.,  ...,  76.,  79.,  82.],
         ...,
         [ 95.,  93.,  91.,  ...,  27.,  28.,  28.],
         [ 96.,  94.,  92.,  ...,  27.,  28.,  28.],
         [ 94.,  92.,  92.,  ...,  26.,  27.,  27.]],

        [[159., 140., 122.,  ..., 117., 117., 119.],
         [184., 152., 121.,  ..., 118., 120., 122.],
         [208., 164., 119.,  ..., 121., 124., 126.],
         ...,
         [129., 127., 125.,  ...,  27.,  28.,  28.],
         [130., 128., 126.,  ...,  27.,  28.,  28.],
         [128., 126., 122.,  ...,  26.,  27.,  27.]],

        [[155., 138., 120.,  ..., 115., 117., 120.],
         [180., 149., 117.,  ..., 121., 123., 125.],
         [204., 160., 114.,  ..., 126., 129., 133.],
         ...,
         [144., 142., 140.,  ...,  27.,  28.,  28.],
         [143., 143., 141.,  ...,  27.,  28.,  28.],
         [141., 139., 137.,  ...,  26.,  27.,  27.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 272.3991,  74.6096, 418.1781]])), gt_classes: tensor([787])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000066662.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [81, 306, 482, 1105, 488, 600, 1064, 277], 'image_id': 66662, 'image': tensor([[[172., 165., 159.,  ..., 192., 198., 210.],
         [166., 162., 157.,  ..., 201., 208., 216.],
         [161., 158., 155.,  ..., 211., 218., 221.],
         ...,
         [ 82.,  77.,  73.,  ...,  67.,  69.,  75.],
         [ 86.,  80.,  73.,  ...,  66.,  69.,  77.],
         [ 84.,  80.,  76.,  ...,  74.,  75.,  81.]],

        [[172., 165., 159.,  ..., 192., 198., 210.],
         [166., 162., 157.,  ..., 201., 208., 216.],
         [161., 158., 155.,  ..., 211., 218., 221.],
         ...,
         [ 82.,  77.,  73.,  ...,  67.,  69.,  75.],
         [ 86.,  80.,  73.,  ...,  66.,  69.,  77.],
         [ 84.,  80.,  76.,  ...,  74.,  75.,  81.]],

        [[172., 165., 159.,  ..., 192., 198., 210.],
         [166., 162., 157.,  ..., 201., 208., 216.],
         [161., 158., 155.,  ..., 211., 218., 221.],
         ...,
         [ 82.,  77.,  73.,  ...,  67.,  69.,  75.],
         [ 86.,  80.,  73.,  ...,  66.,  69.,  77.],
         [ 84.,  80.,  76.,  ...,  74.,  75.,  81.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000,  50.7853, 891.3477, 868.7639]])), gt_classes: tensor([787])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000508252.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [709, 688, 540, 2, 196, 1048, 703, 996, 961], 'image_id': 508252, 'image': tensor([[[ 13.,  14.,  14.,  ...,  57.,  58.,  58.],
         [ 15.,  15.,  15.,  ...,  56.,  57.,  57.],
         [ 15.,  15.,  16.,  ...,  55.,  56.,  56.],
         ...,
         [ 10.,   7.,   5.,  ..., 199., 199., 199.],
         [ 10.,   7.,   4.,  ..., 198., 197., 197.],
         [  9.,   6.,   4.,  ..., 197., 196., 196.]],

        [[ 13.,  14.,  14.,  ...,  30.,  31.,  31.],
         [ 15.,  15.,  15.,  ...,  30.,  31.,  31.],
         [ 15.,  15.,  16.,  ...,  29.,  30.,  30.],
         ...,
         [ 10.,   7.,   5.,  ..., 204., 204., 204.],
         [ 10.,   7.,   5.,  ..., 204., 204., 204.],
         [ 11.,   8.,   5.,  ..., 203., 204., 204.]],

        [[ 13.,  14.,  14.,  ...,  24.,  25.,  25.],
         [ 15.,  15.,  15.,  ...,  24.,  25.,  25.],
         [ 15.,  15.,  16.,  ...,  23.,  24.,  24.],
         ...,
         [ 10.,   7.,   5.,  ..., 213., 213., 213.],
         [ 10.,   7.,   5.,  ..., 213., 213., 213.],
         [ 11.,   8.,   5.,  ..., 214., 214., 214.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  64.1331,  129.4506, 1024.0000, 1024.0000]])), gt_classes: tensor([787])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000057617.jpg', 'height': 474, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [921, 1126, 152, 30, 180, 863, 952, 662, 686], 'image_id': 57617, 'image': tensor([[[197., 197., 199.,  ...,  51.,  39.,  28.],
         [196., 195., 197.,  ...,  71.,  56.,  43.],
         [196., 195., 197.,  ...,  90.,  77.,  66.],
         ...,
         [ 95.,  94.,  94.,  ...,  42.,  41.,  40.],
         [ 93.,  92.,  93.,  ...,  41.,  40.,  39.],
         [ 93.,  93.,  93.,  ...,  41.,  40.,  40.]],

        [[179., 180., 183.,  ...,  28.,  20.,  12.],
         [178., 180., 182.,  ...,  41.,  30.,  19.],
         [180., 181., 184.,  ...,  58.,  47.,  36.],
         ...,
         [103., 104., 105.,  ...,  51.,  50.,  49.],
         [102., 103., 104.,  ...,  50.,  50.,  49.],
         [102., 102., 103.,  ...,  50.,  50.,  49.]],

        [[208., 207., 208.,  ...,  40.,  30.,  20.],
         [205., 204., 205.,  ...,  57.,  45.,  32.],
         [202., 202., 203.,  ...,  80.,  67.,  54.],
         ...,
         [ 99.,  99.,  99.,  ...,  48.,  48.,  47.],
         [ 97.,  97.,  98.,  ...,  47.,  47.,  46.],
         [ 97.,  97.,  98.,  ...,  47.,  47.,  46.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  318.7280, 1024.0000,  901.2729]])), gt_classes: tensor([787])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000448220.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [922, 1143, 347, 767, 440, 355, 681], 'image_id': 448220, 'annotations_cat_set': {1186, 1107, 173}, 'image': tensor([[[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=5, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[106.8362, 174.3731, 437.8139, 485.7305],
        [665.9202, 313.2925, 740.8409, 334.6071],
        [775.7899, 319.9454, 825.3703, 338.0960],
        [723.9097, 317.6147, 788.5024, 336.2174],
        [290.8789, 181.8453, 841.9205, 573.4044]])), gt_classes: tensor([130, 849, 849, 849, 787])])}], 'support_set_target': tensor(787)}
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484563.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1149, 194, 998, 17], 'image_id': 484563, 'image': tensor([[[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[376.9158, 294.4519, 464.0000, 392.4035]])), gt_classes: tensor([797])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000334171.jpg', 'height': 457, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [320, 1147, 1006, 874, 1085, 1012, 276, 1141, 98], 'image_id': 334171, 'image': tensor([[[161., 161., 161.,  ..., 128., 128., 128.],
         [161., 161., 161.,  ..., 128., 128., 128.],
         [161., 161., 161.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[125., 125., 125.,  ..., 128., 128., 128.],
         [125., 125., 125.,  ..., 128., 128., 128.],
         [125., 125., 125.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 95.,  95.,  95.,  ..., 128., 128., 128.],
         [ 95.,  95.,  95.,  ..., 128., 128., 128.],
         [ 95.,  95.,  95.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 71.6048, 431.8011, 226.5723, 590.1085]])), gt_classes: tensor([797])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484563.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1149, 194, 998, 17], 'image_id': 484563, 'image': tensor([[[255., 255., 255.,  ..., 240., 239., 237.],
         [255., 255., 255.,  ..., 239., 238., 236.],
         [255., 255., 255.,  ..., 239., 238., 236.],
         ...,
         [ 11.,   9.,   9.,  ...,  83.,  80.,  80.],
         [  9.,   8.,   5.,  ...,  82.,  83.,  84.],
         [  6.,   3.,   1.,  ...,  86.,  89.,  90.]],

        [[255., 255., 255.,  ..., 244., 244., 244.],
         [255., 255., 255.,  ..., 245., 244., 244.],
         [255., 255., 255.,  ..., 245., 244., 244.],
         ...,
         [  9.,   9.,   7.,  ...,  67.,  65.,  64.],
         [ 12.,   7.,   6.,  ...,  65.,  67.,  68.],
         [  7.,   6.,   2.,  ...,  69.,  72.,  74.]],

        [[255., 255., 255.,  ..., 243., 243., 243.],
         [255., 255., 255.,  ..., 243., 243., 243.],
         [255., 255., 255.,  ..., 243., 243., 243.],
         ...,
         [ 16.,  16.,  16.,  ...,  76.,  73.,  71.],
         [ 19.,  16.,  14.,  ...,  74.,  74.,  74.],
         [ 16.,  12.,   9.,  ...,  76.,  77.,  77.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 291.2190,  680.8844, 1024.0000, 1024.0000]])), gt_classes: tensor([797])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000085941.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 349, 309, 818, 442, 576, 977, 781], 'image_id': 85941, 'image': tensor([[[255., 254., 254.,  ..., 255., 255., 255.],
         [255., 254., 254.,  ..., 255., 255., 255.],
         [254., 253., 253.,  ..., 255., 255., 254.],
         ...,
         [176., 184., 192.,  ..., 128., 129., 214.],
         [189., 188., 187.,  ..., 215., 215., 214.],
         [201., 191., 183.,  ..., 215., 214., 213.]],

        [[240., 239., 239.,  ..., 231., 231., 231.],
         [240., 239., 239.,  ..., 231., 231., 231.],
         [241., 240., 240.,  ..., 232., 232., 232.],
         ...,
         [151., 156., 162.,  ..., 211., 212., 209.],
         [163., 160., 158.,  ..., 210., 210., 209.],
         [174., 164., 155.,  ..., 210., 209., 208.]],

        [[223., 223., 223.,  ..., 215., 215., 215.],
         [224., 223., 223.,  ..., 215., 215., 215.],
         [225., 224., 224.,  ..., 216., 216., 216.],
         ...,
         [123., 126., 130.,  ..., 212., 213., 210.],
         [142., 139., 136.,  ..., 211., 211., 210.],
         [161., 151., 142.,  ..., 211., 210., 209.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 148.6586,  916.2532,  990.9649, 1024.0000]])), gt_classes: tensor([797])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484563.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1149, 194, 998, 17], 'image_id': 484563, 'image': tensor([[[255., 255., 255.,  ..., 240., 239., 237.],
         [255., 255., 255.,  ..., 239., 238., 236.],
         [255., 255., 255.,  ..., 239., 238., 236.],
         ...,
         [ 11.,   9.,   9.,  ...,  83.,  80.,  80.],
         [  9.,   8.,   5.,  ...,  82.,  83.,  84.],
         [  6.,   3.,   1.,  ...,  86.,  89.,  90.]],

        [[255., 255., 255.,  ..., 244., 244., 244.],
         [255., 255., 255.,  ..., 245., 244., 244.],
         [255., 255., 255.,  ..., 245., 244., 244.],
         ...,
         [  9.,   9.,   7.,  ...,  67.,  65.,  64.],
         [ 12.,   7.,   6.,  ...,  65.,  67.,  68.],
         [  7.,   6.,   2.,  ...,  69.,  72.,  74.]],

        [[255., 255., 255.,  ..., 243., 243., 243.],
         [255., 255., 255.,  ..., 243., 243., 243.],
         [255., 255., 255.,  ..., 243., 243., 243.],
         ...,
         [ 16.,  16.,  16.,  ...,  76.,  73.,  71.],
         [ 19.,  16.,  14.,  ...,  74.,  74.,  74.],
         [ 16.,  12.,   9.,  ...,  76.,  77.,  77.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 291.2190,  680.8844, 1024.0000, 1024.0000]])), gt_classes: tensor([797])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484563.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1149, 194, 998, 17], 'image_id': 484563, 'annotations_cat_set': {1120, 556, 592, 948, 500, 1023}, 'image': tensor([[[  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=29, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[552.3982, 431.8187, 615.4453, 583.5743],
        [563.3922, 363.4287, 587.6551, 402.3103],
        [500.6047, 621.5399, 581.4405, 687.5179],
        [281.6273, 675.8856, 377.5493, 783.3556],
        [594.8928, 540.3878, 652.0000, 595.9547],
        [125.8650, 522.2217, 203.9065, 596.1837],
        [  1.3590, 458.2893, 226.1081, 604.0913],
        [169.0772, 406.8289, 595.3203, 736.8564],
        [619.8734, 632.3327, 652.0000, 753.9234],
        [529.6317, 413.9274, 652.0000, 551.6234],
        [117.2989, 323.4786, 146.5091, 421.0107],
        [288.2695, 287.8792, 302.6990, 302.6868],
        [629.5999, 275.0102, 652.0000, 299.8169],
        [ 66.6811, 302.1678, 112.4585, 348.4379],
        [403.4918, 254.7680, 430.5185, 320.5934],
        [ 19.1783, 318.1509,  93.9674, 445.0082],
        [211.3885, 286.3831, 236.1095, 321.4941],
        [473.4406, 289.3446, 530.4715, 330.4855],
        [257.0895, 150.9312, 379.3052, 244.4332],
        [599.4277, 236.2203, 650.8701, 280.0937],
        [207.6170, 234.1747, 273.8400, 287.9249],
        [ 17.5139, 194.8504,  71.0176, 239.7619],
        [381.1833, 208.7727, 454.4608, 320.2423],
        [ 34.2949, 227.7021, 136.8131, 348.0410],
        [326.4581, 102.7987, 377.2286, 159.0220],
        [453.6057, 220.1151, 527.6314, 287.5586],
        [180.6971, 445.8478, 228.5665, 487.2024],
        [277.1840, 227.9463, 330.8862, 299.6490],
        [419.2039, 428.4908, 474.4331, 518.6496]])), gt_classes: tensor([419, 419, 664, 664, 664, 664, 797, 797, 797, 797, 718, 718, 718, 718,
        718, 718, 718, 718, 397, 397, 397, 397, 397, 397, 397, 397, 357, 357,
        357])])}], 'support_set_target': tensor(797)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000080737.jpg', 'height': 438, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1143, 586, 422, 1035, 746, 1164], 'image_id': 80737, 'annotations': [{'bbox': [0.51, 400.45, 21.88, 18.53], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 858}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000080737.jpg', 'height': 438, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1143, 586, 422, 1035, 746, 1164], 'image_id': 80737, 'image': tensor([[[119., 120., 121.,  ..., 147., 147., 147.],
         [119., 120., 121.,  ..., 147., 147., 147.],
         [119., 119., 120.,  ..., 147., 147., 147.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[122., 123., 123.,  ..., 148., 148., 148.],
         [122., 123., 123.,  ..., 148., 148., 148.],
         [122., 122., 122.,  ..., 148., 148., 148.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]],

        [[123., 123., 124.,  ..., 148., 149., 150.],
         [123., 123., 124.,  ..., 148., 149., 149.],
         [123., 123., 123.,  ..., 148., 148., 148.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000530631.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [540, 390, 1196, 181], 'neg_category_ids': [366, 21, 48, 219, 105, 350, 671, 242, 745, 86, 400, 115, 773, 337, 296, 163, 277, 146], 'image_id': 530631, 'annotations': [{'bbox': [499.03, 215.19, 14.83, 2.13], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 858}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000530631.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [540, 390, 1196, 181], 'neg_category_ids': [366, 21, 48, 219, 105, 350, 671, 242, 745, 86, 400, 115, 773, 337, 296, 163, 277, 146], 'image_id': 530631, 'image': tensor([[[27., 33., 37.,  ..., 37., 37., 37.],
         [28., 33., 37.,  ..., 37., 37., 37.],
         [30., 34., 37.,  ..., 37., 37., 38.],
         ...,
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.]],

        [[29., 35., 38.,  ..., 39., 39., 39.],
         [30., 35., 38.,  ..., 39., 39., 39.],
         [31., 35., 38.,  ..., 39., 39., 39.],
         ...,
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.]],

        [[27., 33., 37.,  ..., 39., 39., 39.],
         [28., 33., 37.,  ..., 39., 39., 39.],
         [30., 34., 37.,  ..., 39., 39., 40.],
         ...,
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[799.9809, 378.8241, 826.0724, 382.5738]])), gt_classes: tensor([858])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000502271.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [573, 200, 107, 612], 'image_id': 502271, 'annotations': [{'bbox': [140.75, 323.92, 89.73, 223.24], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 858}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000502271.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [573, 200, 107, 612], 'image_id': 502271, 'image': tensor([[[ 23.,  24.,  24.,  ...,  26.,  25.,  25.],
         [ 23.,  24.,  24.,  ...,  26.,  25.,  24.],
         [ 24.,  24.,  24.,  ...,  27.,  25.,  24.],
         ...,
         [ 41.,  44.,  43.,  ...,  33.,  32.,  32.],
         [ 41.,  43.,  43.,  ...,  40.,  40.,  40.],
         [ 42.,  43.,  42.,  ...,  46.,  46.,  47.]],

        [[ 49.,  49.,  49.,  ...,  91.,  90.,  89.],
         [ 49.,  49.,  49.,  ...,  91.,  90.,  89.],
         [ 49.,  49.,  49.,  ...,  92.,  91.,  90.],
         ...,
         [125., 127., 126.,  ...,  68.,  75.,  82.],
         [125., 125., 124.,  ...,  87.,  92.,  96.],
         [125., 124., 123.,  ..., 105., 107., 109.]],

        [[ 82.,  83.,  83.,  ..., 172., 171., 170.],
         [ 82.,  83.,  83.,  ..., 172., 171., 170.],
         [ 83.,  82.,  82.,  ..., 173., 172., 171.],
         ...,
         [108., 111., 111.,  ...,  97., 106., 116.],
         [108., 110., 109.,  ..., 122., 129., 135.],
         [108., 109., 108.,  ..., 146., 150., 154.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 546.8313,  549.7227,  780.8771, 1024.0000]])), gt_classes: tensor([858])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000025457.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [1196], 'neg_category_ids': [215, 256, 373, 28, 286, 56, 400, 1135, 1084, 1197, 526, 1115, 249], 'image_id': 25457, 'annotations': [{'bbox': [21.25, 77.2, 53.77, 16.43], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 858}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000025457.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [1196], 'neg_category_ids': [215, 256, 373, 28, 286, 56, 400, 1135, 1084, 1197, 526, 1115, 249], 'image_id': 25457, 'image': tensor([[[178., 170., 156.,  ..., 128., 128., 128.],
         [177., 166., 152.,  ..., 128., 128., 128.],
         [174., 163., 148.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[162., 161., 145.,  ..., 128., 128., 128.],
         [160., 159., 141.,  ..., 128., 128., 128.],
         [158., 156., 135.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[146., 147., 140.,  ..., 128., 128., 128.],
         [147., 144., 136.,  ..., 128., 128., 128.],
         [145., 141., 132.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[572.9250,  78.2873, 627.4512,  94.9487]])), gt_classes: tensor([858])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000333247.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [711, 860, 419, 1056, 207, 724, 246, 683, 253], 'image_id': 333247, 'annotations': [{'bbox': [17.85, 182.61, 83.58, 7.64], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 858}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000333247.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [711, 860, 419, 1056, 207, 724, 246, 683, 253], 'image_id': 333247, 'image': tensor([[[155., 155., 155.,  ..., 214., 214., 214.],
         [155., 155., 155.,  ..., 214., 214., 214.],
         [155., 156., 156.,  ..., 215., 215., 215.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[154., 154., 154.,  ..., 212., 212., 212.],
         [154., 154., 154.,  ..., 212., 212., 212.],
         [154., 155., 155.,  ..., 213., 213., 213.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[156., 156., 156.,  ..., 212., 212., 212.],
         [156., 156., 157.,  ..., 212., 212., 212.],
         [157., 157., 158.,  ..., 213., 213., 213.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 968.9703,  370.9266, 1024.0000,  386.4453]])), gt_classes: tensor([858])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000088214.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1022, 1069, 432, 455, 230, 912, 826], 'image_id': 88214, 'annotations': [{'bbox': [54.65, 366.94, 72.47, 72.47], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 261}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000088214.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1022, 1069, 432, 455, 230, 912, 826], 'image_id': 88214, 'image': tensor([[[104., 108., 114.,  ..., 128., 128., 128.],
         [109., 112., 118.,  ..., 128., 128., 128.],
         [114., 114., 115.,  ..., 128., 128., 128.],
         ...,
         [  8.,   7.,   5.,  ..., 128., 128., 128.],
         [  7.,   6.,   5.,  ..., 128., 128., 128.],
         [  7.,   7.,   7.,  ..., 128., 128., 128.]],

        [[ 63.,  71.,  84.,  ..., 128., 128., 128.],
         [ 60.,  67.,  77.,  ..., 128., 128., 128.],
         [ 59.,  64.,  72.,  ..., 128., 128., 128.],
         ...,
         [  8.,   7.,   4.,  ..., 128., 128., 128.],
         [  7.,   6.,   4.,  ..., 128., 128., 128.],
         [  7.,   7.,   6.,  ..., 128., 128., 128.]],

        [[ 74.,  80.,  91.,  ..., 128., 128., 128.],
         [ 77.,  82.,  91.,  ..., 128., 128., 128.],
         [ 80.,  84.,  88.,  ..., 128., 128., 128.],
         ...,
         [  8.,   8.,   7.,  ..., 128., 128., 128.],
         [  7.,   7.,   7.,  ..., 128., 128., 128.],
         [  7.,   8.,   9.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 93.0189, 594.3713, 216.3688, 717.6836]])), gt_classes: tensor([261])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000103758.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [279, 126, 505, 754, 974, 1112, 1042], 'image_id': 103758, 'annotations': [{'bbox': [173.28, 279.45, 22.58, 15.71], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 261}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000103758.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [279, 126, 505, 754, 974, 1112, 1042], 'image_id': 103758, 'image': tensor([[[213., 212., 211.,  ..., 166., 163., 158.],
         [213., 212., 210.,  ..., 165., 162., 157.],
         [212., 211., 209.,  ..., 165., 161., 156.],
         ...,
         [198., 199., 199.,  ..., 225., 225., 226.],
         [199., 200., 200.,  ..., 226., 226., 225.],
         [199., 200., 200.,  ..., 226., 226., 225.]],

        [[182., 181., 180.,  ..., 153., 149., 145.],
         [182., 181., 179.,  ..., 153., 149., 145.],
         [182., 181., 179.,  ..., 153., 149., 145.],
         ...,
         [177., 178., 178.,  ..., 221., 222., 223.],
         [178., 179., 179.,  ..., 222., 223., 223.],
         [178., 179., 179.,  ..., 223., 224., 223.]],

        [[117., 116., 116.,  ..., 142., 140., 136.],
         [117., 116., 116.,  ..., 142., 139., 135.],
         [117., 116., 116.,  ..., 142., 139., 135.],
         ...,
         [126., 126., 126.,  ..., 219., 221., 222.],
         [126., 127., 127.,  ..., 220., 222., 223.],
         [126., 127., 127.,  ..., 221., 223., 223.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[655.2321, 813.9764, 733.9459, 868.7310]])), gt_classes: tensor([261])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116696.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [859, 217], 'neg_category_ids': [557, 122, 92, 345, 776, 501, 737, 197, 789, 405, 703, 66, 892, 68], 'image_id': 116696, 'annotations': [{'bbox': [121.36, 328.04, 50.92, 139.17], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 261}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116696.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [859, 217], 'neg_category_ids': [557, 122, 92, 345, 776, 501, 737, 197, 789, 405, 703, 66, 892, 68], 'image_id': 116696, 'image': tensor([[[ 97.,  97.,  97.,  ..., 113., 113., 113.],
         [ 98.,  98.,  97.,  ..., 113., 113., 113.],
         [ 98.,  98.,  97.,  ..., 113., 113., 113.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]],

        [[ 98.,  98.,  98.,  ..., 113., 113., 113.],
         [ 98.,  98.,  98.,  ..., 113., 113., 113.],
         [ 98.,  98.,  98.,  ..., 113., 113., 113.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]],

        [[ 98.,  98.,  98.,  ..., 113., 113., 113.],
         [ 99.,  99.,  98.,  ..., 113., 113., 113.],
         [ 99.,  99.,  98.,  ..., 113., 113., 113.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[305.7968, 325.9897, 356.3985, 464.2899]])), gt_classes: tensor([261])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116696.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [859, 217], 'neg_category_ids': [557, 122, 92, 345, 776, 501, 737, 197, 789, 405, 703, 66, 892, 68], 'image_id': 116696, 'annotations': [{'bbox': [220.6, 340.13, 47.77, 20.77], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 261}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116696.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [859, 217], 'neg_category_ids': [557, 122, 92, 345, 776, 501, 737, 197, 789, 405, 703, 66, 892, 68], 'image_id': 116696, 'image': tensor([[[ 9.,  9.,  7.,  ..., 46., 46., 46.],
         [11.,  9.,  7.,  ..., 46., 46., 46.],
         [11.,  9.,  7.,  ..., 46., 46., 46.],
         ...,
         [46., 46., 46.,  ..., 46., 46., 46.],
         [46., 46., 46.,  ..., 46., 46., 46.],
         [46., 46., 46.,  ..., 46., 46., 46.]],

        [[ 6.,  6.,  5.,  ..., 46., 46., 46.],
         [ 7.,  6.,  5.,  ..., 46., 46., 46.],
         [ 7.,  6.,  6.,  ..., 46., 46., 46.],
         ...,
         [46., 46., 46.,  ..., 46., 46., 46.],
         [46., 46., 46.,  ..., 46., 46., 46.],
         [46., 46., 46.,  ..., 46., 46., 46.]],

        [[ 7.,  7.,  6.,  ..., 42., 42., 42.],
         [ 8.,  7.,  7.,  ..., 42., 42., 42.],
         [ 8.,  7.,  7.,  ..., 42., 42., 42.],
         ...,
         [42., 42., 42.,  ..., 42., 42., 42.],
         [42., 42., 42.,  ..., 42., 42., 42.],
         [42., 42., 42.,  ..., 42., 42., 42.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[182.5309, 293.8936, 223.7325, 311.8401]])), gt_classes: tensor([261])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000175476.jpg', 'height': 500, 'width': 383, 'not_exhaustive_category_ids': [], 'neg_category_ids': [649, 808, 812, 77, 1099, 91], 'image_id': 175476, 'annotations': [{'bbox': [54.31, 434.85, 170.05, 65.15], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 261}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000175476.jpg', 'height': 500, 'width': 383, 'not_exhaustive_category_ids': [], 'neg_category_ids': [649, 808, 812, 77, 1099, 91], 'image_id': 175476, 'image': tensor([[[ 86.,  59.,  28.,  ..., 133., 133., 133.],
         [ 73.,  48.,  21.,  ..., 133., 133., 133.],
         [ 57.,  32.,  10.,  ..., 133., 133., 133.],
         ...,
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.]],

        [[110.,  84.,  57.,  ..., 133., 133., 133.],
         [110.,  84.,  59.,  ..., 133., 133., 133.],
         [106.,  82.,  61.,  ..., 133., 133., 133.],
         ...,
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.]],

        [[139., 115.,  90.,  ..., 133., 133., 133.],
         [139., 113.,  88.,  ..., 133., 133., 133.],
         [135., 110.,  84.,  ..., 133., 133., 133.],
         ...,
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[242.3091, 663.5811, 502.0461, 763.0000]])), gt_classes: tensor([261])])}, len instances: 1
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000530631.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [540, 390, 1196, 181], 'neg_category_ids': [366, 21, 48, 219, 105, 350, 671, 242, 745, 86, 400, 115, 773, 337, 296, 163, 277, 146], 'image_id': 530631, 'image': tensor([[[27., 33., 37.,  ..., 37., 37., 37.],
         [28., 33., 37.,  ..., 37., 37., 37.],
         [30., 34., 37.,  ..., 37., 37., 38.],
         ...,
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.]],

        [[29., 35., 38.,  ..., 39., 39., 39.],
         [30., 35., 38.,  ..., 39., 39., 39.],
         [31., 35., 38.,  ..., 39., 39., 39.],
         ...,
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.]],

        [[27., 33., 37.,  ..., 39., 39., 39.],
         [28., 33., 37.,  ..., 39., 39., 39.],
         [30., 34., 37.,  ..., 39., 39., 40.],
         ...,
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[799.9809, 378.8241, 826.0724, 382.5738]])), gt_classes: tensor([858])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000502271.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [181], 'neg_category_ids': [573, 200, 107, 612], 'image_id': 502271, 'image': tensor([[[ 23.,  24.,  24.,  ...,  26.,  25.,  25.],
         [ 23.,  24.,  24.,  ...,  26.,  25.,  24.],
         [ 24.,  24.,  24.,  ...,  27.,  25.,  24.],
         ...,
         [ 41.,  44.,  43.,  ...,  33.,  32.,  32.],
         [ 41.,  43.,  43.,  ...,  40.,  40.,  40.],
         [ 42.,  43.,  42.,  ...,  46.,  46.,  47.]],

        [[ 49.,  49.,  49.,  ...,  91.,  90.,  89.],
         [ 49.,  49.,  49.,  ...,  91.,  90.,  89.],
         [ 49.,  49.,  49.,  ...,  92.,  91.,  90.],
         ...,
         [125., 127., 126.,  ...,  68.,  75.,  82.],
         [125., 125., 124.,  ...,  87.,  92.,  96.],
         [125., 124., 123.,  ..., 105., 107., 109.]],

        [[ 82.,  83.,  83.,  ..., 172., 171., 170.],
         [ 82.,  83.,  83.,  ..., 172., 171., 170.],
         [ 83.,  82.,  82.,  ..., 173., 172., 171.],
         ...,
         [108., 111., 111.,  ...,  97., 106., 116.],
         [108., 110., 109.,  ..., 122., 129., 135.],
         [108., 109., 108.,  ..., 146., 150., 154.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 546.8313,  549.7227,  780.8771, 1024.0000]])), gt_classes: tensor([858])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000025457.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [1196], 'neg_category_ids': [215, 256, 373, 28, 286, 56, 400, 1135, 1084, 1197, 526, 1115, 249], 'image_id': 25457, 'image': tensor([[[178., 170., 156.,  ..., 128., 128., 128.],
         [177., 166., 152.,  ..., 128., 128., 128.],
         [174., 163., 148.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[162., 161., 145.,  ..., 128., 128., 128.],
         [160., 159., 141.,  ..., 128., 128., 128.],
         [158., 156., 135.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[146., 147., 140.,  ..., 128., 128., 128.],
         [147., 144., 136.,  ..., 128., 128., 128.],
         [145., 141., 132.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[572.9250,  78.2873, 627.4512,  94.9487]])), gt_classes: tensor([858])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000333247.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [711, 860, 419, 1056, 207, 724, 246, 683, 253], 'image_id': 333247, 'image': tensor([[[155., 155., 155.,  ..., 214., 214., 214.],
         [155., 155., 155.,  ..., 214., 214., 214.],
         [155., 156., 156.,  ..., 215., 215., 215.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[154., 154., 154.,  ..., 212., 212., 212.],
         [154., 154., 154.,  ..., 212., 212., 212.],
         [154., 155., 155.,  ..., 213., 213., 213.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[156., 156., 156.,  ..., 212., 212., 212.],
         [156., 156., 157.,  ..., 212., 212., 212.],
         [157., 157., 158.,  ..., 213., 213., 213.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 968.9703,  370.9266, 1024.0000,  386.4453]])), gt_classes: tensor([858])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000333247.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [711, 860, 419, 1056, 207, 724, 246, 683, 253], 'image_id': 333247, 'image': tensor([[[155., 155., 155.,  ..., 214., 214., 214.],
         [155., 155., 155.,  ..., 214., 214., 214.],
         [155., 156., 156.,  ..., 215., 215., 215.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[154., 154., 154.,  ..., 212., 212., 212.],
         [154., 154., 154.,  ..., 212., 212., 212.],
         [154., 155., 155.,  ..., 213., 213., 213.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[156., 156., 156.,  ..., 212., 212., 212.],
         [156., 156., 157.,  ..., 212., 212., 212.],
         [157., 157., 158.,  ..., 213., 213., 213.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 968.9703,  370.9266, 1024.0000,  386.4453]])), gt_classes: tensor([858])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000363114.jpg', 'height': 354, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [169, 102, 416, 927, 1008, 884, 484, 227, 1058, 528, 429], 'image_id': 363114, 'annotations_cat_set': {177, 962, 740, 1196}, 'image': tensor([[[ 29.,  29.,  29.,  ...,  48.,  47.,  47.],
         [ 17.,  17.,  17.,  ...,  50.,  48.,  48.],
         [  5.,   5.,   5.,  ...,  52.,  50.,  49.],
         ...,
         [133., 134., 134.,  ..., 143., 141., 140.],
         [135., 136., 136.,  ..., 143., 141., 138.],
         [137., 138., 137.,  ..., 143., 140., 137.]],

        [[ 52.,  51.,  51.,  ...,  63.,  62.,  61.],
         [ 42.,  41.,  40.,  ...,  65.,  63.,  62.],
         [ 31.,  30.,  29.,  ...,  66.,  65.,  64.],
         ...,
         [138., 139., 141.,  ..., 116., 115., 113.],
         [140., 141., 142.,  ..., 116., 114., 111.],
         [142., 143., 143.,  ..., 116., 113., 110.]],

        [[ 60.,  59.,  58.,  ...,  62.,  61.,  60.],
         [ 48.,  47.,  46.,  ...,  66.,  64.,  62.],
         [ 37.,  36.,  35.,  ...,  69.,  67.,  65.],
         ...,
         [108., 108., 109.,  ..., 120., 119., 118.],
         [110., 110., 109.,  ..., 120., 118., 115.],
         [112., 112., 110.,  ..., 120., 117., 113.]]]), 'instances': Instances(num_instances=10, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 255.8880,  810.1272,  545.0580, 1024.0000],
        [ 978.9263,  855.7156, 1013.1407,  892.3937],
        [ 779.5692,  625.4083,  792.1080,  639.6324],
        [ 808.9884,  631.9534,  834.1309,  660.5311],
        [ 661.4064,  535.4304, 1024.0000, 1024.0000],
        [ 186.2280,  988.4954,  546.6780, 1024.0000],
        [ 229.2876,  840.4546,  505.0440,  888.6675],
        [ 253.3608,  825.6797,  515.7360,  869.1944],
        [ 194.9436,  936.4268,  508.0247,  985.3201],
        [ 335.2032,  893.1713,  522.8640,  924.6005]])), gt_classes: tensor([675, 134, 134, 134, 524, 858, 858, 858, 858, 858])])}], 'support_set_target': tensor(858)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000319155.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [735, 12], 'neg_category_ids': [255, 946, 857, 1006, 770, 992, 867], 'image_id': 319155, 'annotations': [{'bbox': [433.86, 309.25, 15.74, 11.96], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 519}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000319155.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [735, 12], 'neg_category_ids': [255, 946, 857, 1006, 770, 992, 867], 'image_id': 319155, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[841.9907, 750.3322, 880.6274, 779.6987]])), gt_classes: tensor([519])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000133161.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [735], 'neg_category_ids': [108, 861, 155, 289, 468, 91, 252], 'image_id': 133161, 'annotations': [{'bbox': [541.78, 0.0, 16.13, 9.53], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 519}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000133161.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [735], 'neg_category_ids': [108, 861, 155, 289, 468, 91, 252], 'image_id': 133161, 'image': tensor([[[133., 132., 132.,  ..., 145., 145., 146.],
         [133., 132., 132.,  ..., 145., 145., 146.],
         [133., 132., 132.,  ..., 144., 145., 146.],
         ...,
         [130., 130., 130.,  ..., 129., 130., 131.],
         [130., 130., 130.,  ..., 129., 130., 131.],
         [129., 129., 130.,  ..., 130., 130., 132.]],

        [[131., 130., 130.,  ..., 158., 158., 159.],
         [131., 130., 130.,  ..., 158., 158., 159.],
         [131., 130., 130.,  ..., 158., 158., 159.],
         ...,
         [127., 128., 128.,  ..., 136., 136., 137.],
         [127., 128., 128.,  ..., 137., 137., 138.],
         [127., 127., 128.,  ..., 138., 139., 140.]],

        [[153., 153., 153.,  ..., 160., 160., 161.],
         [153., 153., 153.,  ..., 160., 160., 161.],
         [153., 153., 153.,  ..., 160., 160., 161.],
         ...,
         [124., 124., 124.,  ..., 145., 145., 146.],
         [123., 123., 124.,  ..., 146., 146., 147.],
         [123., 123., 123.,  ..., 147., 147., 148.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000367689.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [967, 718, 310, 663, 889, 680, 576, 161, 252, 246, 895], 'image_id': 367689, 'annotations': [{'bbox': [177.94, 244.22, 70.8, 67.65], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 519}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000367689.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [967, 718, 310, 663, 889, 680, 576, 161, 252, 246, 895], 'image_id': 367689, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128.,   0.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[361.4406, 384.4535, 505.2531, 521.9732]])), gt_classes: tensor([519])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000327153.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [645], 'neg_category_ids': [1169, 480, 225, 1109, 137, 525, 140, 803], 'image_id': 327153, 'annotations': [{'bbox': [595.32, 226.01, 37.25, 39.4], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 519}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000327153.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [645], 'neg_category_ids': [1169, 480, 225, 1109, 137, 525, 140, 803], 'image_id': 327153, 'image': tensor([[[157., 159., 155.,  ..., 137., 143., 144.],
         [156., 158., 156.,  ..., 136., 139., 138.],
         [155., 155., 157.,  ..., 134., 133., 129.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[160., 163., 159.,  ..., 148., 153., 153.],
         [159., 162., 160.,  ..., 145., 147., 146.],
         [158., 159., 161.,  ..., 140., 138., 134.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[167., 171., 168.,  ..., 158., 163., 163.],
         [166., 170., 169.,  ..., 155., 157., 156.],
         [165., 167., 170.,  ..., 149., 148., 144.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 389.9468,  29.0730, 457.9257]])), gt_classes: tensor([519])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038862.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [776, 735, 12], 'neg_category_ids': [323, 197, 948, 263, 1082, 910, 1175, 1059, 1013], 'image_id': 38862, 'annotations': [{'bbox': [293.19, 119.73, 32.25, 35.33], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 519}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038862.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [776, 735, 12], 'neg_category_ids': [323, 197, 948, 263, 1082, 910, 1175, 1059, 1013], 'image_id': 38862, 'image': tensor([[[175., 174., 172.,  ..., 127., 127., 127.],
         [181., 178., 175.,  ..., 127., 127., 127.],
         [180., 178., 175.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[192., 179., 177.,  ..., 127., 127., 127.],
         [198., 184., 180.,  ..., 127., 127., 127.],
         [197., 185., 180.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[213., 204., 197.,  ..., 127., 127., 127.],
         [217., 209., 201.,  ..., 127., 127., 127.],
         [215., 210., 203.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[364.1970, 148.6788, 404.2575, 192.5510]])), gt_classes: tensor([519])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000088214.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1022, 1069, 432, 455, 230, 912, 826], 'image_id': 88214, 'image': tensor([[[104., 108., 114.,  ..., 128., 128., 128.],
         [109., 112., 118.,  ..., 128., 128., 128.],
         [114., 114., 115.,  ..., 128., 128., 128.],
         ...,
         [  8.,   7.,   5.,  ..., 128., 128., 128.],
         [  7.,   6.,   5.,  ..., 128., 128., 128.],
         [  7.,   7.,   7.,  ..., 128., 128., 128.]],

        [[ 63.,  71.,  84.,  ..., 128., 128., 128.],
         [ 60.,  67.,  77.,  ..., 128., 128., 128.],
         [ 59.,  64.,  72.,  ..., 128., 128., 128.],
         ...,
         [  8.,   7.,   4.,  ..., 128., 128., 128.],
         [  7.,   6.,   4.,  ..., 128., 128., 128.],
         [  7.,   7.,   6.,  ..., 128., 128., 128.]],

        [[ 74.,  80.,  91.,  ..., 128., 128., 128.],
         [ 77.,  82.,  91.,  ..., 128., 128., 128.],
         [ 80.,  84.,  88.,  ..., 128., 128., 128.],
         ...,
         [  8.,   8.,   7.,  ..., 128., 128., 128.],
         [  7.,   7.,   7.,  ..., 128., 128., 128.],
         [  7.,   8.,   9.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 93.0189, 594.3713, 216.3688, 717.6836]])), gt_classes: tensor([261])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000103758.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [279, 126, 505, 754, 974, 1112, 1042], 'image_id': 103758, 'image': tensor([[[213., 212., 211.,  ..., 166., 163., 158.],
         [213., 212., 210.,  ..., 165., 162., 157.],
         [212., 211., 209.,  ..., 165., 161., 156.],
         ...,
         [198., 199., 199.,  ..., 225., 225., 226.],
         [199., 200., 200.,  ..., 226., 226., 225.],
         [199., 200., 200.,  ..., 226., 226., 225.]],

        [[182., 181., 180.,  ..., 153., 149., 145.],
         [182., 181., 179.,  ..., 153., 149., 145.],
         [182., 181., 179.,  ..., 153., 149., 145.],
         ...,
         [177., 178., 178.,  ..., 221., 222., 223.],
         [178., 179., 179.,  ..., 222., 223., 223.],
         [178., 179., 179.,  ..., 223., 224., 223.]],

        [[117., 116., 116.,  ..., 142., 140., 136.],
         [117., 116., 116.,  ..., 142., 139., 135.],
         [117., 116., 116.,  ..., 142., 139., 135.],
         ...,
         [126., 126., 126.,  ..., 219., 221., 222.],
         [126., 127., 127.,  ..., 220., 222., 223.],
         [126., 127., 127.,  ..., 221., 223., 223.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[655.2321, 813.9764, 733.9459, 868.7310]])), gt_classes: tensor([261])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116696.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [859, 217], 'neg_category_ids': [557, 122, 92, 345, 776, 501, 737, 197, 789, 405, 703, 66, 892, 68], 'image_id': 116696, 'image': tensor([[[ 97.,  97.,  97.,  ..., 113., 113., 113.],
         [ 98.,  98.,  97.,  ..., 113., 113., 113.],
         [ 98.,  98.,  97.,  ..., 113., 113., 113.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]],

        [[ 98.,  98.,  98.,  ..., 113., 113., 113.],
         [ 98.,  98.,  98.,  ..., 113., 113., 113.],
         [ 98.,  98.,  98.,  ..., 113., 113., 113.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]],

        [[ 98.,  98.,  98.,  ..., 113., 113., 113.],
         [ 99.,  99.,  98.,  ..., 113., 113., 113.],
         [ 99.,  99.,  98.,  ..., 113., 113., 113.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[305.7968, 325.9897, 356.3985, 464.2899]])), gt_classes: tensor([261])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116696.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [859, 217], 'neg_category_ids': [557, 122, 92, 345, 776, 501, 737, 197, 789, 405, 703, 66, 892, 68], 'image_id': 116696, 'image': tensor([[[ 9.,  9.,  7.,  ..., 46., 46., 46.],
         [11.,  9.,  7.,  ..., 46., 46., 46.],
         [11.,  9.,  7.,  ..., 46., 46., 46.],
         ...,
         [46., 46., 46.,  ..., 46., 46., 46.],
         [46., 46., 46.,  ..., 46., 46., 46.],
         [46., 46., 46.,  ..., 46., 46., 46.]],

        [[ 6.,  6.,  5.,  ..., 46., 46., 46.],
         [ 7.,  6.,  5.,  ..., 46., 46., 46.],
         [ 7.,  6.,  6.,  ..., 46., 46., 46.],
         ...,
         [46., 46., 46.,  ..., 46., 46., 46.],
         [46., 46., 46.,  ..., 46., 46., 46.],
         [46., 46., 46.,  ..., 46., 46., 46.]],

        [[ 7.,  7.,  6.,  ..., 42., 42., 42.],
         [ 8.,  7.,  7.,  ..., 42., 42., 42.],
         [ 8.,  7.,  7.,  ..., 42., 42., 42.],
         ...,
         [42., 42., 42.,  ..., 42., 42., 42.],
         [42., 42., 42.,  ..., 42., 42., 42.],
         [42., 42., 42.,  ..., 42., 42., 42.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[182.5309, 293.8936, 223.7325, 311.8401]])), gt_classes: tensor([261])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000175476.jpg', 'height': 500, 'width': 383, 'not_exhaustive_category_ids': [], 'neg_category_ids': [649, 808, 812, 77, 1099, 91], 'image_id': 175476, 'image': tensor([[[ 86.,  59.,  28.,  ..., 133., 133., 133.],
         [ 73.,  48.,  21.,  ..., 133., 133., 133.],
         [ 57.,  32.,  10.,  ..., 133., 133., 133.],
         ...,
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.]],

        [[110.,  84.,  57.,  ..., 133., 133., 133.],
         [110.,  84.,  59.,  ..., 133., 133., 133.],
         [106.,  82.,  61.,  ..., 133., 133., 133.],
         ...,
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.]],

        [[139., 115.,  90.,  ..., 133., 133., 133.],
         [139., 113.,  88.,  ..., 133., 133., 133.],
         [135., 110.,  84.,  ..., 133., 133., 133.],
         ...,
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[242.3091, 663.5811, 502.0461, 763.0000]])), gt_classes: tensor([261])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000418604.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [121, 299, 632, 260, 608, 697, 109, 154, 698, 229, 37, 444, 335, 705, 512, 707], 'image_id': 418604, 'annotations_cat_set': {363, 804, 77, 110}, 'image': tensor([[[ 78.,  76.,  76.,  ...,   0.,   0.,   0.],
         [ 81.,  80.,  80.,  ...,   0.,   0.,   0.],
         [ 83.,  83.,  83.,  ...,   0.,   0.,   0.],
         ...,
         [196., 196., 199.,  ..., 183., 185., 183.],
         [198., 197., 197.,  ..., 183., 185., 185.],
         [199., 198., 196.,  ..., 185., 186., 186.]],

        [[ 82.,  81.,  81.,  ...,   0.,   0.,   0.],
         [ 85.,  85.,  85.,  ...,   0.,   0.,   0.],
         [ 89.,  89.,  89.,  ...,   0.,   0.,   0.],
         ...,
         [244., 242., 243.,  ..., 127., 113., 104.],
         [248., 245., 247.,  ..., 157., 137., 121.],
         [250., 249., 250.,  ..., 188., 161., 138.]],

        [[120., 117., 117.,  ...,   0.,   0.,   0.],
         [122., 119., 120.,  ...,   0.,   0.,   0.],
         [125., 122., 124.,  ...,   0.,   0.,   0.],
         ...,
         [ 30.,  30.,  29.,  ..., 135., 121., 112.],
         [ 29.,  29.,  29.,  ..., 165., 143., 126.],
         [ 27.,  28.,  30.,  ..., 196., 165., 139.]]]), 'instances': Instances(num_instances=9, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,    0.0000,  204.8330,  441.0328],
        [   0.0000,  948.0357, 1024.0000, 1024.0000],
        [  70.5558,   19.1589,  994.7977,  419.0945],
        [ 498.8208,  595.4677,  746.0703,  745.0358],
        [   0.0000,    0.0000, 1024.0000, 1024.0000],
        [   0.0000,  721.8489, 1024.0000, 1024.0000],
        [ 866.8916,   15.5662, 1024.0000,  414.8393],
        [   0.0000,  278.6481,  392.2707,  806.7995],
        [   0.0000,  280.9413, 1024.0000,  929.7920]])), gt_classes: tensor([569, 569, 569, 261,  59,  86,  86,  86,  86])])}], 'support_set_target': tensor(261)}
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000319155.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [735, 12], 'neg_category_ids': [255, 946, 857, 1006, 770, 992, 867], 'image_id': 319155, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[841.9907, 750.3322, 880.6274, 779.6987]])), gt_classes: tensor([519])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000367689.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [967, 718, 310, 663, 889, 680, 576, 161, 252, 246, 895], 'image_id': 367689, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128.,   0.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[361.4406, 384.4535, 505.2531, 521.9732]])), gt_classes: tensor([519])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000327153.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [645], 'neg_category_ids': [1169, 480, 225, 1109, 137, 525, 140, 803], 'image_id': 327153, 'image': tensor([[[157., 159., 155.,  ..., 137., 143., 144.],
         [156., 158., 156.,  ..., 136., 139., 138.],
         [155., 155., 157.,  ..., 134., 133., 129.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[160., 163., 159.,  ..., 148., 153., 153.],
         [159., 162., 160.,  ..., 145., 147., 146.],
         [158., 159., 161.,  ..., 140., 138., 134.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[167., 171., 168.,  ..., 158., 163., 163.],
         [166., 170., 169.,  ..., 155., 157., 156.],
         [165., 167., 170.,  ..., 149., 148., 144.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 389.9468,  29.0730, 457.9257]])), gt_classes: tensor([519])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038862.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [776, 735, 12], 'neg_category_ids': [323, 197, 948, 263, 1082, 910, 1175, 1059, 1013], 'image_id': 38862, 'image': tensor([[[175., 174., 172.,  ..., 127., 127., 127.],
         [181., 178., 175.,  ..., 127., 127., 127.],
         [180., 178., 175.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[192., 179., 177.,  ..., 127., 127., 127.],
         [198., 184., 180.,  ..., 127., 127., 127.],
         [197., 185., 180.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[213., 204., 197.,  ..., 127., 127., 127.],
         [217., 209., 201.,  ..., 127., 127., 127.],
         [215., 210., 203.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[364.1970, 148.6788, 404.2575, 192.5510]])), gt_classes: tensor([519])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038862.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [776, 735, 12], 'neg_category_ids': [323, 197, 948, 263, 1082, 910, 1175, 1059, 1013], 'image_id': 38862, 'image': tensor([[[175., 174., 172.,  ..., 127., 127., 127.],
         [181., 178., 175.,  ..., 127., 127., 127.],
         [180., 178., 175.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[192., 179., 177.,  ..., 127., 127., 127.],
         [198., 184., 180.,  ..., 127., 127., 127.],
         [197., 185., 180.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[213., 204., 197.,  ..., 127., 127., 127.],
         [217., 209., 201.,  ..., 127., 127., 127.],
         [215., 210., 203.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[364.1970, 148.6788, 404.2575, 192.5510]])), gt_classes: tensor([519])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000391132.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [735], 'neg_category_ids': [896, 1142, 1098, 633, 1170, 670, 399, 65, 274], 'image_id': 391132, 'annotations_cat_set': {289, 609, 615, 622, 253, 735}, 'image': tensor([[[ 96.,  94.,  93.,  ...,  46.,  46.,  46.],
         [ 96.,  94.,  93.,  ...,  46.,  46.,  46.],
         [ 95.,  93.,  93.,  ...,  45.,  46.,  46.],
         ...,
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.],
         [133., 133., 133.,  ..., 133., 133., 133.]],

        [[ 49.,  48.,  47.,  ...,  12.,  12.,  12.],
         [ 49.,  48.,  47.,  ...,  12.,  12.,  12.],
         [ 47.,  47.,  46.,  ...,  12.,  12.,  12.],
         ...,
         [ 89.,  89.,  89.,  ...,  89.,  89.,  89.],
         [ 89.,  89.,  89.,  ...,  89.,  89.,  89.],
         [ 89.,  89.,  89.,  ...,  89.,  89.,  89.]],

        [[ 42.,  41.,  41.,  ...,  13.,  13.,  13.],
         [ 42.,  41.,  41.,  ...,  13.,  13.,  13.],
         [ 41.,  40.,  40.,  ...,  12.,  12.,  12.],
         ...,
         [ 65.,  65.,  65.,  ...,  65.,  65.,  65.],
         [ 65.,  65.,  65.,  ...,  65.,  65.,  65.],
         [ 65.,  65.,  65.,  ...,  65.,  65.,  65.]]]), 'instances': Instances(num_instances=72, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 166.3970,  492.6955,  623.0852,  813.6972],
        [ 140.0676,  275.1737,  475.7230,  796.0350],
        [ 324.2265,    4.0195,  410.1634,  323.6716],
        [  69.8462,  455.8453,  468.8914,  591.0117],
        [ 230.6664,  569.0071,  409.2252,  742.8721],
        [ 845.9466,  259.9759, 1024.0000,  530.9540],
        [ 150.0950,  310.9677,  237.6446,  404.1787],
        [  86.7932,  241.5508,  139.5692,  292.7186],
        [ 622.5282,  306.5961,  646.1602,  334.4391],
        [ 728.8425,  312.4933,  758.3090,  343.8277],
        [ 558.4640,  455.9627,  576.7304,  476.1775],
        [ 560.1646,  303.2808,  603.7634,  339.2801],
        [ 208.4125,  242.6363,  280.8036,  333.0895],
        [ 595.6417,  339.7789,  629.4477,  368.1794],
        [ 551.2806,  484.6272,  592.7684,  514.9054],
        [  29.1207,  270.5674,  112.6827,  353.8031],
        [ 207.9434,  371.3187,  295.0824,  459.0139],
        [ 532.5745,  441.9385,  555.7080,  467.0529],
        [ 587.1096,  409.4011,  643.9904,  459.6007],
        [  16.1613,  343.7984,  103.3003,  436.8627],
        [ 139.4226,  411.6310,  239.0519,  512.4702],
        [ 724.5032,  448.6865,  757.2829,  475.8254],
        [ 684.2468,  449.7427,  723.1251,  479.1994],
        [ 647.0104,  401.9489,  685.7421,  433.8408],
        [ 684.7159,  494.9547,  735.7327,  536.8806],
        [ 654.3697,  458.9553,  684.8332,  494.7492],
        [ 226.3564,  323.5542,  292.9128,  391.8562],
        [ 137.5167,  205.6981,  225.5940,  282.4205],
        [ 698.5843,  469.6348,  732.6541,  498.5634],
        [ 617.9836,  378.3308,  665.8338,  424.0415],
        [ 709.0808,  371.2893,  767.9553,  427.4742],
        [ 547.4690,  247.1546,  627.3660,  297.0901],
        [ 530.6100,  345.5881,  568.8140,  386.1644],
        [ 643.1695,  235.0374,  687.1495,  273.1786],
        [ 547.1758,  382.2329,  596.0229,  415.7971],
        [ 776.3409,  377.4213,  804.4882,  405.5577],
        [ 724.2979,  418.5550,  781.5305,  456.7842],
        [ 719.0790,  265.6971,  775.1388,  319.5347],
        [ 186.5691,  278.5770,  218.6745,  316.3661],
        [ 765.3752,  427.7382,  814.1931,  473.7423],
        [ 574.2382,  451.7085,  624.1115,  491.3166],
        [ 649.6492,  270.6848,  677.3566,  305.9506],
        [ 635.3704,  327.3977,  689.6710,  370.9666],
        [ 741.9193,  306.6548,  794.6659,  371.2307],
        [ 764.8475,  348.3460,  804.1071,  395.7584],
        [ 109.2523,  265.0809,  193.8405,  329.2461],
        [ 715.7951,  328.9820,  751.5069,  374.3993],
        [ 559.9594,  284.0635,  604.8776,  317.5984],
        [ 747.3435,  466.3488,  795.2523,  499.2088],
        [ 755.0253,  393.8806,  811.3198,  434.2809],
        [ 630.6792,  468.8427,  659.2368,  503.1990],
        [ 731.2761,  495.1013,  772.7932,  533.4479],
        [ 622.2350,  261.6189,  656.5980,  296.3273],
        [ 592.7391,  488.0893,  640.0909,  537.8781],
        [ 677.3566,  290.2247,  733.3870,  344.0624],
        [ 151.1213,  397.4013,  193.5180,  417.0587],
        [ 657.0672,  286.0879,  684.3055,  331.4759],
        [ 674.4833,  247.2133,  730.8657,  309.6767],
        [ 599.7759,  303.9849,  628.3335,  341.0111],
        [ 620.8569,  523.5312,  641.4396,  548.9097],
        [ 101.3945,  322.7034,  169.7981,  407.7874],
        [ 637.6573,  502.3188,  677.1221,  554.4255],
        [ 550.6063,  472.0406,  600.0397,  491.7860],
        [ 556.5289,  336.5515,  590.7454,  368.3554],
        [ 561.0148,  407.7875,  590.3348,  447.8944],
        [ 519.1459,  388.6582,  566.2338,  430.6135],
        [ 588.4290,  369.7050,  621.7659,  401.8609],
        [ 643.7852,  359.7883,  679.4090,  400.3059],
        [  81.2517,  399.2204,  151.0040,  470.6910],
        [ 701.3110,  430.4668,  741.2155,  444.5790],
        [ 691.7820,  342.4488,  717.0558,  368.9715],
        [ 734.6479,  159.0486, 1024.0000,  781.5120]])), gt_classes: tensor([188, 438, 438, 438, 435, 213, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 430])])}], 'support_set_target': tensor(519)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000091883.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [127, 154], 'neg_category_ids': [628, 558, 649, 343, 258, 832, 326, 789, 3, 329, 181, 274, 826, 98], 'image_id': 91883, 'annotations': [{'bbox': [324.87, 254.54, 286.27, 115.95], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 231}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000091883.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [127, 154], 'neg_category_ids': [628, 558, 649, 343, 258, 832, 326, 789, 3, 329, 181, 274, 826, 98], 'image_id': 91883, 'image': tensor([[[ 66.,  64.,  64.,  ...,  67.,  66.,  66.],
         [ 64.,  62.,  62.,  ...,  73.,  73.,  73.],
         [ 60.,  59.,  59.,  ...,  83.,  83.,  83.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[114., 112., 112.,  ...,  88.,  88.,  88.],
         [112., 110., 109.,  ...,  92.,  92.,  92.],
         [109., 106., 105.,  ..., 100., 100., 100.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[150., 148., 147.,  ..., 100., 100.,  99.],
         [149., 147., 146.,  ..., 104., 104., 104.],
         [146., 145., 145.,  ..., 112., 112., 112.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 31.1814, 451.2782, 538.8633, 656.8479]])), gt_classes: tensor([231])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116911.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [204, 916, 297, 320], 'neg_category_ids': [922, 735, 1098, 737, 326, 1191, 181, 401, 646], 'image_id': 116911, 'annotations': [{'bbox': [481.03, 328.81, 54.97, 18.93], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 231}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000116911.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [204, 916, 297, 320], 'neg_category_ids': [922, 735, 1098, 737, 326, 1191, 181, 401, 646], 'image_id': 116911, 'image': tensor([[[ 59.,  60.,  62.,  ..., 100., 105.,  95.],
         [ 61.,  61.,  64.,  ...,  94.,  96.,  86.],
         [ 64.,  62.,  66.,  ...,  88.,  88.,  78.],
         ...,
         [  5.,   7.,   6.,  ...,   8.,   9.,   8.],
         [  6.,   8.,   7.,  ...,   7.,   5.,   4.],
         [  6.,   9.,   7.,  ...,   6.,   4.,   2.]],

        [[ 65.,  64.,  65.,  ...,  36.,  39.,  32.],
         [ 68.,  65.,  68.,  ...,  33.,  33.,  28.],
         [ 71.,  67.,  71.,  ...,  30.,  27.,  24.],
         ...,
         [  7.,   8.,   8.,  ...,   6.,   8.,   9.],
         [  6.,  10.,  10.,  ...,   5.,   4.,   4.],
         [  6.,  11.,  11.,  ...,   4.,   3.,   2.]],

        [[ 68.,  69.,  71.,  ...,  28.,  34.,  23.],
         [ 70.,  69.,  72.,  ...,  25.,  27.,  20.],
         [ 72.,  70.,  74.,  ...,  21.,  21.,  17.],
         ...,
         [ 18.,  17.,  17.,  ...,  11.,  12.,  11.],
         [ 15.,  16.,  16.,  ...,  10.,   8.,   6.],
         [ 14.,  16.,  16.,  ...,   9.,   7.,   4.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000423093.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [320], 'neg_category_ids': [409, 305, 835, 307, 1083, 63, 137, 403, 1042, 686], 'image_id': 423093, 'annotations': [{'bbox': [384.35, 394.58, 104.89, 60.0], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 231}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000423093.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [320], 'neg_category_ids': [409, 305, 835, 307, 1083, 63, 137, 403, 1042, 686], 'image_id': 423093, 'image': tensor([[[  4.,   8.,  10.,  ..., 237., 238., 241.],
         [  7.,  10.,  10.,  ..., 230., 232., 234.],
         [ 12.,  14.,  10.,  ..., 220., 221., 224.],
         ...,
         [118., 118., 118.,  ..., 118., 118., 118.],
         [118., 118., 118.,  ..., 118., 118., 118.],
         [118., 118., 118.,  ..., 118., 118., 118.]],

        [[ 36.,  35.,  34.,  ..., 224., 229., 232.],
         [ 38.,  39.,  39.,  ..., 217., 219., 220.],
         [ 40.,  44.,  46.,  ..., 212., 213., 214.],
         ...,
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.]],

        [[ 37.,  41.,  45.,  ..., 229., 232., 232.],
         [ 41.,  43.,  45.,  ..., 218., 220., 220.],
         [ 46.,  45.,  44.,  ..., 213., 214., 214.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[240.6294, 635.4382, 409.4367, 732.0632]])), gt_classes: tensor([231])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000229852.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [118, 125, 320], 'neg_category_ids': [47, 1048, 742, 338, 746, 661], 'image_id': 229852, 'annotations': [{'bbox': [110.75, 244.77, 122.4, 36.34], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 231}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000229852.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [118, 125, 320], 'neg_category_ids': [47, 1048, 742, 338, 746, 661], 'image_id': 229852, 'image': tensor([[[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000385444.jpg', 'height': 400, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [279, 411, 901, 129, 815, 976, 1042], 'image_id': 385444, 'annotations': [{'bbox': [216.7, 185.18, 71.2, 65.45], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 231}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000385444.jpg', 'height': 400, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [279, 411, 901, 129, 815, 976, 1042], 'image_id': 385444, 'image': tensor([[[131., 130., 130.,  ..., 142., 142., 142.],
         [130., 130., 129.,  ..., 143., 142., 143.],
         [129., 129., 128.,  ..., 144., 143., 144.],
         ...,
         [223., 218., 213.,  ..., 117., 115., 120.],
         [224., 219., 214.,  ..., 123., 122., 125.],
         [226., 220., 214.,  ..., 129., 129., 132.]],

        [[129., 129., 128.,  ..., 142., 142., 142.],
         [129., 129., 128.,  ..., 140., 140., 141.],
         [129., 129., 128.,  ..., 140., 140., 141.],
         ...,
         [211., 211., 210.,  ..., 139., 139., 139.],
         [210., 209., 209.,  ..., 140., 140., 140.],
         [207., 207., 206.,  ..., 142., 143., 142.]],

        [[137., 137., 137.,  ..., 147., 146., 146.],
         [138., 138., 138.,  ..., 147., 146., 146.],
         [138., 138., 138.,  ..., 147., 146., 146.],
         ...,
         [196., 198., 200.,  ..., 140., 140., 142.],
         [198., 198., 200.,  ..., 142., 142., 143.],
         [199., 199., 200.,  ..., 144., 144., 145.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[189.8834, 354.1300, 439.2258, 583.2050]])), gt_classes: tensor([231])])}, len instances: 1
not 0
entering support set: 2
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000091883.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [127, 154], 'neg_category_ids': [628, 558, 649, 343, 258, 832, 326, 789, 3, 329, 181, 274, 826, 98], 'image_id': 91883, 'image': tensor([[[ 66.,  64.,  64.,  ...,  67.,  66.,  66.],
         [ 64.,  62.,  62.,  ...,  73.,  73.,  73.],
         [ 60.,  59.,  59.,  ...,  83.,  83.,  83.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[114., 112., 112.,  ...,  88.,  88.,  88.],
         [112., 110., 109.,  ...,  92.,  92.,  92.],
         [109., 106., 105.,  ..., 100., 100., 100.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[150., 148., 147.,  ..., 100., 100.,  99.],
         [149., 147., 146.,  ..., 104., 104., 104.],
         [146., 145., 145.,  ..., 112., 112., 112.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 31.1814, 451.2782, 538.8633, 656.8479]])), gt_classes: tensor([231])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000423093.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [320], 'neg_category_ids': [409, 305, 835, 307, 1083, 63, 137, 403, 1042, 686], 'image_id': 423093, 'image': tensor([[[  4.,   8.,  10.,  ..., 237., 238., 241.],
         [  7.,  10.,  10.,  ..., 230., 232., 234.],
         [ 12.,  14.,  10.,  ..., 220., 221., 224.],
         ...,
         [118., 118., 118.,  ..., 118., 118., 118.],
         [118., 118., 118.,  ..., 118., 118., 118.],
         [118., 118., 118.,  ..., 118., 118., 118.]],

        [[ 36.,  35.,  34.,  ..., 224., 229., 232.],
         [ 38.,  39.,  39.,  ..., 217., 219., 220.],
         [ 40.,  44.,  46.,  ..., 212., 213., 214.],
         ...,
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.]],

        [[ 37.,  41.,  45.,  ..., 229., 232., 232.],
         [ 41.,  43.,  45.,  ..., 218., 220., 220.],
         [ 46.,  45.,  44.,  ..., 213., 214., 214.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[240.6294, 635.4382, 409.4367, 732.0632]])), gt_classes: tensor([231])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000385444.jpg', 'height': 400, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [279, 411, 901, 129, 815, 976, 1042], 'image_id': 385444, 'image': tensor([[[131., 130., 130.,  ..., 142., 142., 142.],
         [130., 130., 129.,  ..., 143., 142., 143.],
         [129., 129., 128.,  ..., 144., 143., 144.],
         ...,
         [223., 218., 213.,  ..., 117., 115., 120.],
         [224., 219., 214.,  ..., 123., 122., 125.],
         [226., 220., 214.,  ..., 129., 129., 132.]],

        [[129., 129., 128.,  ..., 142., 142., 142.],
         [129., 129., 128.,  ..., 140., 140., 141.],
         [129., 129., 128.,  ..., 140., 140., 141.],
         ...,
         [211., 211., 210.,  ..., 139., 139., 139.],
         [210., 209., 209.,  ..., 140., 140., 140.],
         [207., 207., 206.,  ..., 142., 143., 142.]],

        [[137., 137., 137.,  ..., 147., 146., 146.],
         [138., 138., 138.,  ..., 147., 146., 146.],
         [138., 138., 138.,  ..., 147., 146., 146.],
         ...,
         [196., 198., 200.,  ..., 140., 140., 142.],
         [198., 198., 200.,  ..., 142., 142., 143.],
         [199., 199., 200.,  ..., 144., 144., 145.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[189.8834, 354.1300, 439.2258, 583.2050]])), gt_classes: tensor([231])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000423093.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [320], 'neg_category_ids': [409, 305, 835, 307, 1083, 63, 137, 403, 1042, 686], 'image_id': 423093, 'image': tensor([[[  4.,   8.,  10.,  ..., 237., 238., 241.],
         [  7.,  10.,  10.,  ..., 230., 232., 234.],
         [ 12.,  14.,  10.,  ..., 220., 221., 224.],
         ...,
         [118., 118., 118.,  ..., 118., 118., 118.],
         [118., 118., 118.,  ..., 118., 118., 118.],
         [118., 118., 118.,  ..., 118., 118., 118.]],

        [[ 36.,  35.,  34.,  ..., 224., 229., 232.],
         [ 38.,  39.,  39.,  ..., 217., 219., 220.],
         [ 40.,  44.,  46.,  ..., 212., 213., 214.],
         ...,
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.]],

        [[ 37.,  41.,  45.,  ..., 229., 232., 232.],
         [ 41.,  43.,  45.,  ..., 218., 220., 220.],
         [ 46.,  45.,  44.,  ..., 213., 214., 214.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[240.6294, 635.4382, 409.4367, 732.0632]])), gt_classes: tensor([231])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000423093.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [320], 'neg_category_ids': [409, 305, 835, 307, 1083, 63, 137, 403, 1042, 686], 'image_id': 423093, 'image': tensor([[[  4.,   8.,  10.,  ..., 237., 238., 241.],
         [  7.,  10.,  10.,  ..., 230., 232., 234.],
         [ 12.,  14.,  10.,  ..., 220., 221., 224.],
         ...,
         [118., 118., 118.,  ..., 118., 118., 118.],
         [118., 118., 118.,  ..., 118., 118., 118.],
         [118., 118., 118.,  ..., 118., 118., 118.]],

        [[ 36.,  35.,  34.,  ..., 224., 229., 232.],
         [ 38.,  39.,  39.,  ..., 217., 219., 220.],
         [ 40.,  44.,  46.,  ..., 212., 213., 214.],
         ...,
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.]],

        [[ 37.,  41.,  45.,  ..., 229., 232., 232.],
         [ 41.,  43.,  45.,  ..., 218., 220., 220.],
         [ 46.,  45.,  44.,  ..., 213., 214., 214.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[240.6294, 635.4382, 409.4367, 732.0632]])), gt_classes: tensor([231])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000229852.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [118, 125, 320], 'neg_category_ids': [47, 1048, 742, 338, 746, 661], 'image_id': 229852, 'annotations_cat_set': {320, 740, 305, 118, 125, 447}, 'image': tensor([[[150., 191., 194.,  ..., 253., 253., 253.],
         [141., 145., 148.,  ..., 253., 253., 254.],
         [115., 119., 124.,  ..., 254., 254., 254.],
         ...,
         [150., 150., 150.,  ..., 150., 150., 150.],
         [150., 150., 150.,  ..., 150., 150., 150.],
         [150., 150., 150.,  ..., 150., 150., 150.]],

        [[177., 179., 181.,  ..., 253., 253., 254.],
         [130., 169., 172.,  ..., 253., 254., 254.],
         [112., 113., 117.,  ..., 254., 254., 254.],
         ...,
         [130., 130., 130.,  ..., 130., 130., 130.],
         [130., 130., 130.,  ..., 130., 130., 130.],
         [130., 130., 130.,  ..., 130., 130., 130.]],

        [[126., 127., 128.,  ..., 253., 254., 254.],
         [122., 123., 124.,  ..., 254., 254., 254.],
         [112., 113., 115.,  ..., 255., 255., 255.],
         ...,
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.]]]), 'instances': Instances(num_instances=16, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1011.8715,    0.0000, 1024.0000,  212.3836],
        [ 671.9814,  183.7986, 1024.0000,  367.2087],
        [  25.2945,  103.2168,  752.2395,  841.9690],
        [ 957.3026,  457.1963, 1024.0000,  549.5760],
        [ 807.9333,  506.2487, 1024.0000,  612.0214],
        [ 810.4492,  429.7972, 1010.5625,  532.3596],
        [ 990.7843,  536.5717, 1024.0000,  640.0543],
        [ 825.9322,  368.5173, 1024.0000,  501.1165],
        [ 779.1354,  500.4827, 1024.0000,  574.7873],
        [ 316.2198,  590.6951,  646.3537,  813.8134],
        [ 886.1257,  193.7359,  896.1273,  199.1339],
        [ 893.1002,  184.4938,  902.4064,  191.4458],
        [ 950.7371,  190.4234,  964.5839,  197.0074],
        [ 942.8831,  196.9665,  960.4728,  206.6993],
        [ 747.1672,  408.0211, 1024.0000,  868.1821],
        [  52.7426,  650.4005,  677.6061,  869.0000]])), gt_classes: tensor([ 92,  92, 524, 231, 231, 231, 231, 231, 231, 317,  97,  97,  97,  97,
        221, 221])])}], 'support_set_target': tensor(231)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000340528.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [335], 'neg_category_ids': [980, 454, 124, 693, 227, 1037, 12, 705, 578], 'image_id': 340528, 'annotations': [{'bbox': [242.02, 262.77, 14.16, 18.58], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 241}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000340528.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [335], 'neg_category_ids': [980, 454, 124, 693, 227, 1037, 12, 705, 578], 'image_id': 340528, 'image': tensor([[[  0.,   0.,   6.,  ...,   1.,   1.,   0.],
         [  0.,   0.,   3.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 41.,  40.,  40.,  ...,  40.,  40.,  40.],
         [ 41.,  41.,  40.,  ...,  41.,  42.,  40.],
         [ 41.,  41.,  40.,  ...,  43.,  43.,  41.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 73.,  74.,  75.,  ...,  72.,  72.,  71.],
         [ 71.,  73.,  74.,  ...,  73.,  72.,  72.],
         [ 70.,  71.,  72.,  ...,  75.,  73.,  75.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[320.3424, 516.2335, 348.1535, 552.7355]])), gt_classes: tensor([241])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000269325.jpg', 'height': 640, 'width': 423, 'not_exhaustive_category_ids': [811], 'neg_category_ids': [148, 1024, 897, 1069, 1147, 1129, 157, 167], 'image_id': 269325, 'annotations': [{'bbox': [316.76, 370.9, 8.2, 13.63], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 241}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000269325.jpg', 'height': 640, 'width': 423, 'not_exhaustive_category_ids': [811], 'neg_category_ids': [148, 1024, 897, 1069, 1147, 1129, 157, 167], 'image_id': 269325, 'image': tensor([[[ 12.,  14.,  14.,  ..., 128., 128., 128.],
         [ 19.,  16.,  13.,  ..., 128., 128., 128.],
         [ 24.,  18.,  13.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 42.,  41.,  40.,  ..., 128., 128., 128.],
         [ 44.,  42.,  39.,  ..., 128., 128., 128.],
         [ 45.,  42.,  39.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 17.,  14.,  12.,  ..., 128., 128., 128.],
         [ 20.,  18.,  17.,  ..., 128., 128., 128.],
         [ 22.,  21.,  20.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[473.2679, 554.6114, 485.5195, 574.9925]])), gt_classes: tensor([241])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000228867.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [72, 498, 583, 391, 898, 1172, 637, 1080, 613, 291, 994, 644, 555, 387], 'image_id': 228867, 'annotations': [{'bbox': [405.24, 103.4, 15.31, 41.09], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 241}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000228867.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [72, 498, 583, 391, 898, 1172, 637, 1080, 613, 291, 994, 644, 555, 387], 'image_id': 228867, 'image': tensor([[[142., 142., 142.,  ...,  51.,  52.,  53.],
         [143., 143., 143.,  ...,  55.,  56.,  58.],
         [143., 143., 143.,  ...,  58.,  58.,  59.],
         ...,
         [ 49.,  50.,  50.,  ..., 170., 170., 171.],
         [ 49.,  49.,  49.,  ..., 170., 170., 171.],
         [ 48.,  48.,  48.,  ..., 170., 170., 171.]],

        [[143., 143., 143.,  ...,  64.,  64.,  65.],
         [144., 144., 144.,  ...,  68.,  69.,  70.],
         [144., 144., 144.,  ...,  71.,  71.,  72.],
         ...,
         [ 52.,  53.,  53.,  ..., 166., 166., 166.],
         [ 52.,  52.,  52.,  ..., 166., 166., 166.],
         [ 51.,  51.,  51.,  ..., 166., 166., 166.]],

        [[143., 143., 143.,  ...,  67.,  67.,  68.],
         [144., 144., 144.,  ...,  71.,  72.,  73.],
         [144., 144., 144.,  ...,  74.,  74.,  75.],
         ...,
         [ 56.,  57.,  57.,  ..., 163., 163., 164.],
         [ 56.,  56.,  56.,  ..., 163., 163., 164.],
         [ 55.,  55.,  55.,  ..., 163., 163., 164.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[664.3751, 245.0780, 701.2626, 344.0589]])), gt_classes: tensor([241])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000017600.jpg', 'height': 450, 'width': 350, 'not_exhaustive_category_ids': [335], 'neg_category_ids': [149, 1145, 584, 396, 889, 356, 781], 'image_id': 17600, 'annotations': [{'bbox': [115.09, 182.02, 13.81, 24.83], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 241}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000017600.jpg', 'height': 450, 'width': 350, 'not_exhaustive_category_ids': [335], 'neg_category_ids': [149, 1145, 584, 396, 889, 356, 781], 'image_id': 17600, 'image': tensor([[[253., 253., 253.,  ..., 254., 254., 254.],
         [253., 253., 253.,  ..., 254., 254., 254.],
         [253., 253., 253.,  ..., 254., 254., 254.],
         ...,
         [132., 117., 103.,  ...,  74.,  80.,  98.],
         [110.,  95.,  82.,  ...,  83.,  89., 106.],
         [ 88.,  77.,  66.,  ..., 101., 107., 122.]],

        [[236., 236., 236.,  ..., 250., 250., 250.],
         [236., 236., 236.,  ..., 250., 250., 250.],
         [236., 236., 236.,  ..., 250., 250., 250.],
         ...,
         [112.,  96.,  79.,  ...,  78.,  87., 105.],
         [ 94.,  80.,  65.,  ...,  86.,  94., 112.],
         [ 83.,  72.,  61.,  ..., 103., 110., 127.]],

        [[185., 186., 186.,  ..., 221., 221., 221.],
         [186., 186., 186.,  ..., 221., 221., 221.],
         [186., 187., 187.,  ..., 221., 221., 221.],
         ...,
         [ 96.,  80.,  65.,  ..., 104., 113., 130.],
         [ 79.,  65.,  51.,  ..., 108., 117., 133.],
         [ 67.,  57.,  47.,  ..., 121., 129., 144.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[511.5086, 806.3708, 574.2060, 919.0990]])), gt_classes: tensor([241])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000443797.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [687, 877, 585, 984, 765, 833, 929, 523, 862, 953, 595, 865, 442, 703, 1183], 'image_id': 443797, 'annotations': [{'bbox': [194.4, 77.19, 32.32, 51.59], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 241}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000443797.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [687, 877, 585, 984, 765, 833, 929, 523, 862, 953, 595, 865, 442, 703, 1183], 'image_id': 443797, 'image': tensor([[[153., 154., 156.,  ..., 127., 127., 127.],
         [160., 160., 161.,  ..., 127., 127., 127.],
         [165., 164., 163.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[113., 112., 112.,  ..., 127., 127., 127.],
         [110., 109., 109.,  ..., 127., 127., 127.],
         [109., 107., 106.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 65.,  64.,  62.,  ..., 127., 127., 127.],
         [ 63.,  62.,  61.,  ..., 127., 127., 127.],
         [ 62.,  61.,  60.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[243.6075,  96.7135, 284.1085, 161.3520]])), gt_classes: tensor([241])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000229478.jpg', 'height': 640, 'width': 483, 'not_exhaustive_category_ids': [], 'neg_category_ids': [215, 477, 713, 1050, 199, 482, 483, 509, 510, 933, 295, 232, 1065, 707], 'image_id': 229478, 'annotations': [{'bbox': [72.4, 160.86, 121.18, 92.08], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 7}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000229478.jpg', 'height': 640, 'width': 483, 'not_exhaustive_category_ids': [], 'neg_category_ids': [215, 477, 713, 1050, 199, 482, 483, 509, 510, 933, 295, 232, 1065, 707], 'image_id': 229478, 'image': tensor([[[16., 21., 27.,  ..., 17., 17., 17.],
         [ 6.,  7.,  9.,  ..., 17., 17., 17.],
         [ 6.,  6.,  6.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]],

        [[17., 22., 28.,  ..., 17., 17., 17.],
         [ 7.,  8., 10.,  ..., 17., 17., 17.],
         [ 7.,  7.,  7.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]],

        [[15., 20., 26.,  ..., 17., 17., 17.],
         [ 6.,  7.,  9.,  ..., 17., 17., 17.],
         [ 7.,  7.,  7.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[334.9602, 186.2457, 475.2079, 292.8571]])), gt_classes: tensor([7])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000454129.jpg', 'height': 360, 'width': 640, 'not_exhaustive_category_ids': [1186], 'neg_category_ids': [322, 255, 432, 1165, 1142, 151, 418, 35, 993, 92, 644, 278], 'image_id': 454129, 'annotations': [{'bbox': [154.26, 69.68, 101.9, 103.49], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 7}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000454129.jpg', 'height': 360, 'width': 640, 'not_exhaustive_category_ids': [1186], 'neg_category_ids': [322, 255, 432, 1165, 1142, 151, 418, 35, 993, 92, 644, 278], 'image_id': 454129, 'image': tensor([[[255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]],

        [[255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]],

        [[255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[179.5683,  81.0998, 298.1862, 201.5506]])), gt_classes: tensor([7])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000093280.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1027, 627], 'neg_category_ids': [1142, 1051, 859, 224, 770, 137, 141, 1017, 16], 'image_id': 93280, 'annotations': [{'bbox': [352.23, 419.53, 12.56, 14.48], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 7}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000093280.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1027, 627], 'neg_category_ids': [1142, 1051, 859, 224, 770, 137, 141, 1017, 16], 'image_id': 93280, 'image': tensor([[[161., 161., 160.,  ..., 136., 137., 137.],
         [160., 160., 160.,  ..., 136., 137., 137.],
         [159., 159., 160.,  ..., 137., 137., 137.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[108., 108., 109.,  ...,  86.,  85.,  85.],
         [108., 108., 109.,  ...,  86.,  86.,  86.],
         [108., 108., 109.,  ...,  87.,  87.,  87.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 65.,  65.,  66.,  ...,  44.,  44.,  44.],
         [ 65.,  65.,  66.,  ...,  44.,  44.,  44.],
         [ 65.,  65.,  66.,  ...,  45.,  45.,  45.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[563.5680, 671.2480, 583.6640, 694.4160]])), gt_classes: tensor([7])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000198176.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1095, 122, 538, 371, 543, 903, 131, 422, 205, 1156, 381, 992, 618, 533, 755], 'image_id': 198176, 'annotations': [{'bbox': [4.94, 93.03, 112.06, 168.81], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 7}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000198176.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1095, 122, 538, 371, 543, 903, 131, 422, 205, 1156, 381, 992, 618, 533, 755], 'image_id': 198176, 'image': tensor([[[113., 110., 104.,  ..., 217., 243., 250.],
         [114., 111., 105.,  ..., 224., 244., 251.],
         [114., 111., 105.,  ..., 227., 245., 251.],
         ...,
         [189., 189., 189.,  ..., 224., 224., 221.],
         [192., 192., 192.,  ..., 221., 221., 217.],
         [194., 192., 194.,  ..., 221., 219., 214.]],

        [[112., 109., 103.,  ..., 186., 239., 249.],
         [112., 110., 104.,  ..., 191., 240., 249.],
         [112., 110., 104.,  ..., 196., 241., 250.],
         ...,
         [191., 188., 188.,  ..., 223., 223., 221.],
         [193., 191., 191.,  ..., 221., 221., 216.],
         [193., 191., 193.,  ..., 221., 218., 213.]],

        [[112., 109., 103.,  ..., 191., 240., 249.],
         [112., 110., 104.,  ..., 196., 241., 250.],
         [112., 110., 104.,  ..., 201., 242., 250.],
         ...,
         [191., 188., 188.,  ..., 223., 223., 221.],
         [193., 191., 191.,  ..., 221., 221., 216.],
         [193., 191., 193.,  ..., 221., 218., 213.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000122252.jpg', 'height': 614, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [829, 785, 358, 788, 739, 483, 768, 1108, 399, 10, 577, 1137, 470, 1180, 893, 139, 825, 731], 'image_id': 122252, 'annotations': [{'bbox': [23.03, 165.72, 391.62, 377.89], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 7}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000122252.jpg', 'height': 614, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [829, 785, 358, 788, 739, 483, 768, 1108, 399, 10, 577, 1137, 470, 1180, 893, 139, 825, 731], 'image_id': 122252, 'image': tensor([[[11., 11., 10.,  ..., 51., 51., 51.],
         [ 9.,  9.,  8.,  ..., 51., 51., 51.],
         [ 4.,  4.,  4.,  ..., 51., 51., 51.],
         ...,
         [21., 21., 22.,  ...,  2.,  2.,  2.],
         [21., 22., 22.,  ...,  2.,  3.,  3.],
         [20., 20., 20.,  ...,  3.,  3.,  3.]],

        [[11., 11., 10.,  ..., 20., 20., 20.],
         [ 9.,  9.,  8.,  ..., 19., 20., 20.],
         [ 4.,  4.,  4.,  ..., 19., 19., 19.],
         ...,
         [22., 23., 22.,  ...,  1.,  1.,  1.],
         [23., 23., 22.,  ...,  1.,  2.,  2.],
         [21., 21., 21.,  ...,  2.,  2.,  2.]],

        [[11., 10.,  9.,  ...,  0.,  1.,  0.],
         [ 9.,  8.,  7.,  ...,  0.,  1.,  0.],
         [ 4.,  4.,  3.,  ...,  0.,  0.,  1.],
         ...,
         [22., 22., 21.,  ...,  0.,  0.,  0.],
         [22., 22., 21.,  ...,  0.,  0.,  0.],
         [21., 21., 20.,  ...,  0.,  0.,  0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 526.5298,  380.0475, 1024.0000, 1024.0000]])), gt_classes: tensor([7])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000049581.jpg', 'height': 500, 'width': 374, 'not_exhaustive_category_ids': [], 'neg_category_ids': [561, 1189, 438, 697, 422, 137, 1138, 934], 'image_id': 49581, 'annotations': [{'bbox': [295.22, 180.26, 66.61, 53.84], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 194}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000049581.jpg', 'height': 500, 'width': 374, 'not_exhaustive_category_ids': [], 'neg_category_ids': [561, 1189, 438, 697, 422, 137, 1138, 934], 'image_id': 49581, 'image': tensor([[[ 44.,  42.,  39.,  ..., 139., 139., 139.],
         [ 39.,  38.,  35.,  ..., 139., 139., 139.],
         [ 35.,  33.,  32.,  ..., 138., 138., 138.],
         ...,
         [166., 166., 166.,  ..., 130., 129., 129.],
         [166., 166., 166.,  ..., 130., 129., 129.],
         [166., 166., 166.,  ..., 130., 129., 129.]],

        [[ 55.,  54.,  51.,  ..., 143., 143., 143.],
         [ 51.,  49.,  47.,  ..., 143., 143., 143.],
         [ 46.,  45.,  44.,  ..., 143., 143., 143.],
         ...,
         [172., 172., 172.,  ..., 139., 139., 139.],
         [172., 172., 172.,  ..., 139., 139., 139.],
         [172., 172., 172.,  ..., 139., 139., 139.]],

        [[ 56.,  55.,  51.,  ..., 154., 154., 154.],
         [ 53.,  51.,  49.,  ..., 153., 153., 153.],
         [ 50.,  48.,  46.,  ..., 152., 152., 152.],
         ...,
         [171., 171., 171.,  ..., 143., 143., 143.],
         [171., 171., 171.,  ..., 143., 143., 143.],
         [171., 171., 171.,  ..., 143., 143., 143.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 259.8580, 147.1425, 437.5300]])), gt_classes: tensor([194])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000250789.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [], 'neg_category_ids': [633, 394, 416, 906, 818, 934, 646], 'image_id': 250789, 'annotations': [{'bbox': [96.01, 359.44, 20.0, 96.65], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 194}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000250789.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [], 'neg_category_ids': [633, 394, 416, 906, 818, 934, 646], 'image_id': 250789, 'image': tensor([[[162., 162., 160.,  ..., 201., 201., 201.],
         [161., 161., 160.,  ..., 201., 201., 201.],
         [160., 160., 159.,  ..., 201., 201., 201.],
         ...,
         [ 75.,  75.,  73.,  ..., 123., 123., 127.],
         [ 75.,  74.,  73.,  ..., 122., 123., 123.],
         [ 75.,  75.,  71.,  ..., 120., 120., 120.]],

        [[158., 158., 156.,  ..., 200., 200., 200.],
         [157., 157., 156.,  ..., 201., 201., 201.],
         [156., 156., 155.,  ..., 201., 201., 201.],
         ...,
         [ 77.,  76.,  73.,  ..., 160., 160., 161.],
         [ 77.,  76.,  73.,  ..., 160., 160., 160.],
         [ 77.,  77.,  73.,  ..., 159., 159., 160.]],

        [[148., 148., 146.,  ..., 197., 197., 198.],
         [147., 147., 145.,  ..., 197., 197., 198.],
         [146., 146., 145.,  ..., 198., 198., 198.],
         ...,
         [109., 105.,  92.,  ..., 161., 161., 161.],
         [109., 105.,  92.,  ..., 161., 161., 161.],
         [109., 109.,  92.,  ..., 161., 161., 161.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 233.9399,  861.1350,  282.6723, 1024.0000]])), gt_classes: tensor([194])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000193476.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [1155], 'neg_category_ids': [433, 1027, 9, 379, 618, 185], 'image_id': 193476, 'annotations': [{'bbox': [136.55, 264.52, 96.9, 79.05], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 194}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000193476.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [1155], 'neg_category_ids': [433, 1027, 9, 379, 618, 185], 'image_id': 193476, 'image': tensor([[[220., 219., 217.,  ..., 104., 104., 104.],
         [220., 219., 219.,  ..., 104., 104., 104.],
         [219., 219., 220.,  ..., 104., 104., 104.],
         ...,
         [104., 104., 104.,  ..., 104., 104., 104.],
         [104., 104., 104.,  ..., 104., 104., 104.],
         [104., 104., 104.,  ..., 104., 104., 104.]],

        [[218., 218., 217.,  ..., 187., 187., 187.],
         [217., 217., 217.,  ..., 187., 187., 187.],
         [216., 216., 217.,  ..., 187., 187., 187.],
         ...,
         [187., 187., 187.,  ..., 187., 187., 187.],
         [187., 187., 187.,  ..., 187., 187., 187.],
         [187., 187., 187.,  ..., 187., 187., 187.]],

        [[216., 216., 215.,  ..., 212., 212., 212.],
         [212., 212., 212.,  ..., 212., 212., 212.],
         [131., 132., 133.,  ..., 212., 212., 212.],
         ...,
         [212., 212., 212.,  ..., 212., 212., 212.],
         [212., 212., 212.,  ..., 212., 212., 212.],
         [212., 212., 212.,  ..., 212., 212., 212.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[380.0979, 407.9394, 529.4854, 529.8494]])), gt_classes: tensor([194])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000235699.jpg', 'height': 374, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [150, 1188, 52, 3, 833, 108, 109, 10, 891, 252], 'image_id': 235699, 'annotations': [{'bbox': [91.46, 178.14, 71.85, 70.38], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 194}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000235699.jpg', 'height': 374, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [150, 1188, 52, 3, 833, 108, 109, 10, 891, 252], 'image_id': 235699, 'image': tensor([[[ 3.,  0.,  0.,  ..., 17., 17., 17.],
         [ 3.,  0.,  0.,  ..., 17., 17., 17.],
         [ 3.,  3.,  3.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]],

        [[ 3.,  0.,  0.,  ..., 17., 17., 17.],
         [ 3.,  0.,  0.,  ..., 17., 17., 17.],
         [ 3.,  3.,  3.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]],

        [[ 3.,  0.,  0.,  ..., 32., 32., 32.],
         [ 3.,  0.,  0.,  ..., 32., 32., 32.],
         [ 3.,  3.,  3.,  ..., 32., 32., 32.],
         ...,
         [32., 32., 32.,  ..., 32., 32., 32.],
         [32., 32., 32.,  ..., 32., 32., 32.],
         [32., 32., 32.,  ..., 32., 32., 32.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[117.4689, 228.6289, 209.7513, 318.9561]])), gt_classes: tensor([194])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000143984.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [239, 904, 769, 863, 1110, 136, 89, 163, 1018, 940], 'image_id': 143984, 'annotations': [{'bbox': [0.0, 157.49, 60.32, 130.84], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 194}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000143984.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [239, 904, 769, 863, 1110, 136, 89, 163, 1018, 940], 'image_id': 143984, 'image': tensor([[[219., 219., 219.,  ...,  94.,  95.,  95.],
         [219., 219., 219.,  ...,  94.,  95.,  95.],
         [218., 218., 218.,  ...,  94.,  95.,  95.],
         ...,
         [207., 207., 208.,  ...,  95.,  94.,  94.],
         [206., 206., 207.,  ...,  95.,  94.,  94.],
         [206., 206., 207.,  ...,  95.,  94.,  94.]],

        [[227., 227., 227.,  ...,  97.,  97.,  97.],
         [227., 227., 227.,  ...,  97.,  97.,  97.],
         [227., 227., 227.,  ...,  97.,  97.,  97.],
         ...,
         [214., 213., 214.,  ...,  98.,  98.,  98.],
         [213., 213., 213.,  ...,  98.,  98.,  98.],
         [213., 213., 213.,  ...,  98.,  98.,  98.]],

        [[234., 234., 234.,  ...,  95.,  95.,  95.],
         [234., 234., 234.,  ...,  95.,  95.,  95.],
         [234., 234., 234.,  ...,  95.,  95.,  95.],
         ...,
         [216., 215., 215.,  ...,  96.,  96.,  96.],
         [215., 214., 214.,  ...,  96.,  96.,  96.],
         [214., 213., 213.,  ...,  96.,  96.,  96.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000229478.jpg', 'height': 640, 'width': 483, 'not_exhaustive_category_ids': [], 'neg_category_ids': [215, 477, 713, 1050, 199, 482, 483, 509, 510, 933, 295, 232, 1065, 707], 'image_id': 229478, 'image': tensor([[[16., 21., 27.,  ..., 17., 17., 17.],
         [ 6.,  7.,  9.,  ..., 17., 17., 17.],
         [ 6.,  6.,  6.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]],

        [[17., 22., 28.,  ..., 17., 17., 17.],
         [ 7.,  8., 10.,  ..., 17., 17., 17.],
         [ 7.,  7.,  7.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]],

        [[15., 20., 26.,  ..., 17., 17., 17.],
         [ 6.,  7.,  9.,  ..., 17., 17., 17.],
         [ 7.,  7.,  7.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[334.9602, 186.2457, 475.2079, 292.8571]])), gt_classes: tensor([7])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000454129.jpg', 'height': 360, 'width': 640, 'not_exhaustive_category_ids': [1186], 'neg_category_ids': [322, 255, 432, 1165, 1142, 151, 418, 35, 993, 92, 644, 278], 'image_id': 454129, 'image': tensor([[[255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]],

        [[255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]],

        [[255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         [255., 255., 255.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[179.5683,  81.0998, 298.1862, 201.5506]])), gt_classes: tensor([7])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000093280.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1027, 627], 'neg_category_ids': [1142, 1051, 859, 224, 770, 137, 141, 1017, 16], 'image_id': 93280, 'image': tensor([[[161., 161., 160.,  ..., 136., 137., 137.],
         [160., 160., 160.,  ..., 136., 137., 137.],
         [159., 159., 160.,  ..., 137., 137., 137.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[108., 108., 109.,  ...,  86.,  85.,  85.],
         [108., 108., 109.,  ...,  86.,  86.,  86.],
         [108., 108., 109.,  ...,  87.,  87.,  87.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 65.,  65.,  66.,  ...,  44.,  44.,  44.],
         [ 65.,  65.,  66.,  ...,  44.,  44.,  44.],
         [ 65.,  65.,  66.,  ...,  45.,  45.,  45.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[563.5680, 671.2480, 583.6640, 694.4160]])), gt_classes: tensor([7])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000122252.jpg', 'height': 614, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [829, 785, 358, 788, 739, 483, 768, 1108, 399, 10, 577, 1137, 470, 1180, 893, 139, 825, 731], 'image_id': 122252, 'image': tensor([[[11., 11., 10.,  ..., 51., 51., 51.],
         [ 9.,  9.,  8.,  ..., 51., 51., 51.],
         [ 4.,  4.,  4.,  ..., 51., 51., 51.],
         ...,
         [21., 21., 22.,  ...,  2.,  2.,  2.],
         [21., 22., 22.,  ...,  2.,  3.,  3.],
         [20., 20., 20.,  ...,  3.,  3.,  3.]],

        [[11., 11., 10.,  ..., 20., 20., 20.],
         [ 9.,  9.,  8.,  ..., 19., 20., 20.],
         [ 4.,  4.,  4.,  ..., 19., 19., 19.],
         ...,
         [22., 23., 22.,  ...,  1.,  1.,  1.],
         [23., 23., 22.,  ...,  1.,  2.,  2.],
         [21., 21., 21.,  ...,  2.,  2.,  2.]],

        [[11., 10.,  9.,  ...,  0.,  1.,  0.],
         [ 9.,  8.,  7.,  ...,  0.,  1.,  0.],
         [ 4.,  4.,  3.,  ...,  0.,  0.,  1.],
         ...,
         [22., 22., 21.,  ...,  0.,  0.,  0.],
         [22., 22., 21.,  ...,  0.,  0.,  0.],
         [21., 21., 20.,  ...,  0.,  0.,  0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 526.5298,  380.0475, 1024.0000, 1024.0000]])), gt_classes: tensor([7])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000229478.jpg', 'height': 640, 'width': 483, 'not_exhaustive_category_ids': [], 'neg_category_ids': [215, 477, 713, 1050, 199, 482, 483, 509, 510, 933, 295, 232, 1065, 707], 'image_id': 229478, 'image': tensor([[[16., 21., 27.,  ..., 17., 17., 17.],
         [ 6.,  7.,  9.,  ..., 17., 17., 17.],
         [ 6.,  6.,  6.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]],

        [[17., 22., 28.,  ..., 17., 17., 17.],
         [ 7.,  8., 10.,  ..., 17., 17., 17.],
         [ 7.,  7.,  7.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]],

        [[15., 20., 26.,  ..., 17., 17., 17.],
         [ 6.,  7.,  9.,  ..., 17., 17., 17.],
         [ 7.,  7.,  7.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[334.9602, 186.2457, 475.2079, 292.8571]])), gt_classes: tensor([7])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000049885.jpg', 'height': 468, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1075, 55, 310, 548, 228, 402, 514], 'image_id': 49885, 'annotations_cat_set': {1056, 8, 880, 1141, 1178, 1020}, 'image': tensor([[[202., 193., 183.,  ..., 248., 248., 249.],
         [216., 210., 203.,  ..., 248., 248., 249.],
         [241., 240., 238.,  ..., 249., 249., 249.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[146., 135., 124.,  ..., 220., 220., 220.],
         [178., 167., 156.,  ..., 220., 220., 220.],
         [234., 225., 214.,  ..., 221., 221., 220.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[125., 111.,  97.,  ..., 190., 191., 193.],
         [162., 150., 138.,  ..., 190., 191., 193.],
         [229., 221., 211.,  ..., 191., 192., 193.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=36, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 952.3503,  269.2739, 1008.8627,  338.5146],
        [ 936.8419,   77.3635,  991.9033,  149.2427],
        [ 944.9447,  477.5804,  991.7526,  539.3581],
        [ 769.6036,  326.0950,  833.6158,  397.9931],
        [ 931.8860,  611.3127,  956.0625,  643.7469],
        [ 603.2510,  703.8284,  634.9650,  738.1473],
        [ 995.6344,  485.1754, 1024.0000,  548.5739],
        [   3.6429,    0.0000, 1024.0000,  843.8177],
        [ 203.1417,  359.8108,  224.5294,  380.9939],
        [ 331.0153,  281.4296,  402.7723,  318.5000],
        [ 638.6773,  159.7777,  641.4285,  172.0088],
        [ 574.3259,  133.7700,  702.9344,  202.4077],
        [ 229.0142,  341.4169,  252.1731,  362.1289],
        [ 991.3945,  484.9304, 1024.0000,  546.8212],
        [ 944.6809,  478.8242,  989.4913,  541.3558],
        [ 936.0693,  267.0123, 1008.7685,  345.0165],
        [ 769.3586,  319.7061,  848.1632,  403.4396],
        [ 925.8748,  682.5889,  947.5452,  714.2881],
        [ 196.6595,  475.4131,  215.9177,  507.1500],
        [ 798.9245,  723.8242,  823.3837,  754.0912],
        [ 103.1756,  499.4420,  116.1212,  523.9043],
        [ 937.0869,  266.9557, 1008.4293,  346.4488],
        [ 365.0471,  430.2765,  397.9295,  477.4296],
        [  81.2604,  567.7781,   91.3417,  574.9961],
        [ 816.8260,  109.2323,  851.2347,  133.4308],
        [ 603.2133,  703.8850,  634.9650,  738.1661],
        [ 918.7519,   75.1396,  992.7513,  157.8365],
        [ 156.3337,  636.3969,  170.6173,  655.0923],
        [ 932.6021,  611.4069,  955.9683,  643.4454],
        [ 942.7023,  477.8631,  989.7552,  542.7315],
        [ 768.0396,  324.6438,  834.3130,  397.7669],
        [ 988.6434,  484.9492, 1024.0000,  546.9343],
        [ 252.2108,  645.1792,  258.8061,  659.8416],
        [  58.3463,  640.1661,   64.3198,  653.3961],
        [ 275.8785,  654.3950,  383.9474,  832.0389],
        [  74.2882,  631.1954,  107.0951,  722.3542]])), gt_classes: tensor([741, 741, 741, 741, 741, 741, 741,   7, 814, 814, 814, 814, 814, 715,
        715, 715, 715, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620, 620,
        620, 620, 620, 620, 620, 620, 841, 841])])}], 'support_set_target': tensor(7)}
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000340528.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [335], 'neg_category_ids': [980, 454, 124, 693, 227, 1037, 12, 705, 578], 'image_id': 340528, 'image': tensor([[[  0.,   0.,   6.,  ...,   1.,   1.,   0.],
         [  0.,   0.,   3.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 41.,  40.,  40.,  ...,  40.,  40.,  40.],
         [ 41.,  41.,  40.,  ...,  41.,  42.,  40.],
         [ 41.,  41.,  40.,  ...,  43.,  43.,  41.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 73.,  74.,  75.,  ...,  72.,  72.,  71.],
         [ 71.,  73.,  74.,  ...,  73.,  72.,  72.],
         [ 70.,  71.,  72.,  ...,  75.,  73.,  75.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[320.3424, 516.2335, 348.1535, 552.7355]])), gt_classes: tensor([241])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000269325.jpg', 'height': 640, 'width': 423, 'not_exhaustive_category_ids': [811], 'neg_category_ids': [148, 1024, 897, 1069, 1147, 1129, 157, 167], 'image_id': 269325, 'image': tensor([[[ 12.,  14.,  14.,  ..., 128., 128., 128.],
         [ 19.,  16.,  13.,  ..., 128., 128., 128.],
         [ 24.,  18.,  13.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 42.,  41.,  40.,  ..., 128., 128., 128.],
         [ 44.,  42.,  39.,  ..., 128., 128., 128.],
         [ 45.,  42.,  39.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 17.,  14.,  12.,  ..., 128., 128., 128.],
         [ 20.,  18.,  17.,  ..., 128., 128., 128.],
         [ 22.,  21.,  20.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[473.2679, 554.6114, 485.5195, 574.9925]])), gt_classes: tensor([241])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000228867.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [72, 498, 583, 391, 898, 1172, 637, 1080, 613, 291, 994, 644, 555, 387], 'image_id': 228867, 'image': tensor([[[142., 142., 142.,  ...,  51.,  52.,  53.],
         [143., 143., 143.,  ...,  55.,  56.,  58.],
         [143., 143., 143.,  ...,  58.,  58.,  59.],
         ...,
         [ 49.,  50.,  50.,  ..., 170., 170., 171.],
         [ 49.,  49.,  49.,  ..., 170., 170., 171.],
         [ 48.,  48.,  48.,  ..., 170., 170., 171.]],

        [[143., 143., 143.,  ...,  64.,  64.,  65.],
         [144., 144., 144.,  ...,  68.,  69.,  70.],
         [144., 144., 144.,  ...,  71.,  71.,  72.],
         ...,
         [ 52.,  53.,  53.,  ..., 166., 166., 166.],
         [ 52.,  52.,  52.,  ..., 166., 166., 166.],
         [ 51.,  51.,  51.,  ..., 166., 166., 166.]],

        [[143., 143., 143.,  ...,  67.,  67.,  68.],
         [144., 144., 144.,  ...,  71.,  72.,  73.],
         [144., 144., 144.,  ...,  74.,  74.,  75.],
         ...,
         [ 56.,  57.,  57.,  ..., 163., 163., 164.],
         [ 56.,  56.,  56.,  ..., 163., 163., 164.],
         [ 55.,  55.,  55.,  ..., 163., 163., 164.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[664.3751, 245.0780, 701.2626, 344.0589]])), gt_classes: tensor([241])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000017600.jpg', 'height': 450, 'width': 350, 'not_exhaustive_category_ids': [335], 'neg_category_ids': [149, 1145, 584, 396, 889, 356, 781], 'image_id': 17600, 'image': tensor([[[253., 253., 253.,  ..., 254., 254., 254.],
         [253., 253., 253.,  ..., 254., 254., 254.],
         [253., 253., 253.,  ..., 254., 254., 254.],
         ...,
         [132., 117., 103.,  ...,  74.,  80.,  98.],
         [110.,  95.,  82.,  ...,  83.,  89., 106.],
         [ 88.,  77.,  66.,  ..., 101., 107., 122.]],

        [[236., 236., 236.,  ..., 250., 250., 250.],
         [236., 236., 236.,  ..., 250., 250., 250.],
         [236., 236., 236.,  ..., 250., 250., 250.],
         ...,
         [112.,  96.,  79.,  ...,  78.,  87., 105.],
         [ 94.,  80.,  65.,  ...,  86.,  94., 112.],
         [ 83.,  72.,  61.,  ..., 103., 110., 127.]],

        [[185., 186., 186.,  ..., 221., 221., 221.],
         [186., 186., 186.,  ..., 221., 221., 221.],
         [186., 187., 187.,  ..., 221., 221., 221.],
         ...,
         [ 96.,  80.,  65.,  ..., 104., 113., 130.],
         [ 79.,  65.,  51.,  ..., 108., 117., 133.],
         [ 67.,  57.,  47.,  ..., 121., 129., 144.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[511.5086, 806.3708, 574.2060, 919.0990]])), gt_classes: tensor([241])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000443797.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [687, 877, 585, 984, 765, 833, 929, 523, 862, 953, 595, 865, 442, 703, 1183], 'image_id': 443797, 'image': tensor([[[153., 154., 156.,  ..., 127., 127., 127.],
         [160., 160., 161.,  ..., 127., 127., 127.],
         [165., 164., 163.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[113., 112., 112.,  ..., 127., 127., 127.],
         [110., 109., 109.,  ..., 127., 127., 127.],
         [109., 107., 106.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 65.,  64.,  62.,  ..., 127., 127., 127.],
         [ 63.,  62.,  61.,  ..., 127., 127., 127.],
         [ 62.,  61.,  60.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[243.6075,  96.7135, 284.1085, 161.3520]])), gt_classes: tensor([241])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000294973.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [809, 760, 487, 466, 137, 357, 895], 'image_id': 294973, 'annotations_cat_set': {451, 1092, 76, 335, 48, 1110, 127}, 'image': tensor([[[ 26.,  27.,  27.,  ..., 162., 151., 146.],
         [ 26.,  27.,  27.,  ..., 164., 152., 147.],
         [ 27.,  27.,  27.,  ..., 172., 156., 150.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 21.,  22.,  23.,  ..., 151., 146., 149.],
         [ 21.,  22.,  23.,  ..., 152., 146., 149.],
         [ 22.,  22.,  23.,  ..., 158., 146., 148.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 22.,  22.,  22.,  ..., 161., 155., 153.],
         [ 22.,  22.,  22.,  ..., 162., 155., 153.],
         [ 22.,  22.,  22.,  ..., 168., 155., 153.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=13, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 482.9713,  468.6771,  618.5656,  556.3055],
        [ 268.9665,  686.9299,  725.6813,  865.8369],
        [ 417.3270,  660.5986,  638.6089,  683.1288],
        [ 418.2587,  641.3410,  633.8751,  665.6333],
        [ 417.0500,  675.3754,  642.6628,  697.6538],
        [ 422.9170,  604.4621,  636.5441,  648.0623],
        [   0.0000,  582.5361, 1024.0000,  742.3616],
        [ 781.3543,  549.2570,  865.3549,  648.5406],
        [ 419.3163,  323.4522,  679.4005,  622.2093],
        [   0.0000,  153.1797,   89.2317,  575.9407],
        [  34.8680,  213.0923,  148.1277,  602.3223],
        [ 271.7363,  687.0810,  724.9763,  866.4410],
        [ 422.1364,  321.1866,  679.6271,  621.9827]])), gt_classes: tensor([ 36,  36,  98,  98,  98,  98, 772, 241, 790, 320, 320, 320,  58])])}], 'support_set_target': tensor(241)}
0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000049581.jpg', 'height': 500, 'width': 374, 'not_exhaustive_category_ids': [], 'neg_category_ids': [561, 1189, 438, 697, 422, 137, 1138, 934], 'image_id': 49581, 'image': tensor([[[ 44.,  42.,  39.,  ..., 139., 139., 139.],
         [ 39.,  38.,  35.,  ..., 139., 139., 139.],
         [ 35.,  33.,  32.,  ..., 138., 138., 138.],
         ...,
         [166., 166., 166.,  ..., 130., 129., 129.],
         [166., 166., 166.,  ..., 130., 129., 129.],
         [166., 166., 166.,  ..., 130., 129., 129.]],

        [[ 55.,  54.,  51.,  ..., 143., 143., 143.],
         [ 51.,  49.,  47.,  ..., 143., 143., 143.],
         [ 46.,  45.,  44.,  ..., 143., 143., 143.],
         ...,
         [172., 172., 172.,  ..., 139., 139., 139.],
         [172., 172., 172.,  ..., 139., 139., 139.],
         [172., 172., 172.,  ..., 139., 139., 139.]],

        [[ 56.,  55.,  51.,  ..., 154., 154., 154.],
         [ 53.,  51.,  49.,  ..., 153., 153., 153.],
         [ 50.,  48.,  46.,  ..., 152., 152., 152.],
         ...,
         [171., 171., 171.,  ..., 143., 143., 143.],
         [171., 171., 171.,  ..., 143., 143., 143.],
         [171., 171., 171.,  ..., 143., 143., 143.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 259.8580, 147.1425, 437.5300]])), gt_classes: tensor([194])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000250789.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [], 'neg_category_ids': [633, 394, 416, 906, 818, 934, 646], 'image_id': 250789, 'image': tensor([[[162., 162., 160.,  ..., 201., 201., 201.],
         [161., 161., 160.,  ..., 201., 201., 201.],
         [160., 160., 159.,  ..., 201., 201., 201.],
         ...,
         [ 75.,  75.,  73.,  ..., 123., 123., 127.],
         [ 75.,  74.,  73.,  ..., 122., 123., 123.],
         [ 75.,  75.,  71.,  ..., 120., 120., 120.]],

        [[158., 158., 156.,  ..., 200., 200., 200.],
         [157., 157., 156.,  ..., 201., 201., 201.],
         [156., 156., 155.,  ..., 201., 201., 201.],
         ...,
         [ 77.,  76.,  73.,  ..., 160., 160., 161.],
         [ 77.,  76.,  73.,  ..., 160., 160., 160.],
         [ 77.,  77.,  73.,  ..., 159., 159., 160.]],

        [[148., 148., 146.,  ..., 197., 197., 198.],
         [147., 147., 145.,  ..., 197., 197., 198.],
         [146., 146., 145.,  ..., 198., 198., 198.],
         ...,
         [109., 105.,  92.,  ..., 161., 161., 161.],
         [109., 105.,  92.,  ..., 161., 161., 161.],
         [109., 109.,  92.,  ..., 161., 161., 161.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 233.9399,  861.1350,  282.6723, 1024.0000]])), gt_classes: tensor([194])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000193476.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [1155], 'neg_category_ids': [433, 1027, 9, 379, 618, 185], 'image_id': 193476, 'image': tensor([[[220., 219., 217.,  ..., 104., 104., 104.],
         [220., 219., 219.,  ..., 104., 104., 104.],
         [219., 219., 220.,  ..., 104., 104., 104.],
         ...,
         [104., 104., 104.,  ..., 104., 104., 104.],
         [104., 104., 104.,  ..., 104., 104., 104.],
         [104., 104., 104.,  ..., 104., 104., 104.]],

        [[218., 218., 217.,  ..., 187., 187., 187.],
         [217., 217., 217.,  ..., 187., 187., 187.],
         [216., 216., 217.,  ..., 187., 187., 187.],
         ...,
         [187., 187., 187.,  ..., 187., 187., 187.],
         [187., 187., 187.,  ..., 187., 187., 187.],
         [187., 187., 187.,  ..., 187., 187., 187.]],

        [[216., 216., 215.,  ..., 212., 212., 212.],
         [212., 212., 212.,  ..., 212., 212., 212.],
         [131., 132., 133.,  ..., 212., 212., 212.],
         ...,
         [212., 212., 212.,  ..., 212., 212., 212.],
         [212., 212., 212.,  ..., 212., 212., 212.],
         [212., 212., 212.,  ..., 212., 212., 212.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[380.0979, 407.9394, 529.4854, 529.8494]])), gt_classes: tensor([194])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000235699.jpg', 'height': 374, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [150, 1188, 52, 3, 833, 108, 109, 10, 891, 252], 'image_id': 235699, 'image': tensor([[[ 3.,  0.,  0.,  ..., 17., 17., 17.],
         [ 3.,  0.,  0.,  ..., 17., 17., 17.],
         [ 3.,  3.,  3.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]],

        [[ 3.,  0.,  0.,  ..., 17., 17., 17.],
         [ 3.,  0.,  0.,  ..., 17., 17., 17.],
         [ 3.,  3.,  3.,  ..., 17., 17., 17.],
         ...,
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 17.,  ..., 17., 17., 17.]],

        [[ 3.,  0.,  0.,  ..., 32., 32., 32.],
         [ 3.,  0.,  0.,  ..., 32., 32., 32.],
         [ 3.,  3.,  3.,  ..., 32., 32., 32.],
         ...,
         [32., 32., 32.,  ..., 32., 32., 32.],
         [32., 32., 32.,  ..., 32., 32., 32.],
         [32., 32., 32.,  ..., 32., 32., 32.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[117.4689, 228.6289, 209.7513, 318.9561]])), gt_classes: tensor([194])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000250789.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [], 'neg_category_ids': [633, 394, 416, 906, 818, 934, 646], 'image_id': 250789, 'image': tensor([[[162., 162., 160.,  ..., 201., 201., 201.],
         [161., 161., 160.,  ..., 201., 201., 201.],
         [160., 160., 159.,  ..., 201., 201., 201.],
         ...,
         [ 75.,  75.,  73.,  ..., 123., 123., 127.],
         [ 75.,  74.,  73.,  ..., 122., 123., 123.],
         [ 75.,  75.,  71.,  ..., 120., 120., 120.]],

        [[158., 158., 156.,  ..., 200., 200., 200.],
         [157., 157., 156.,  ..., 201., 201., 201.],
         [156., 156., 155.,  ..., 201., 201., 201.],
         ...,
         [ 77.,  76.,  73.,  ..., 160., 160., 161.],
         [ 77.,  76.,  73.,  ..., 160., 160., 160.],
         [ 77.,  77.,  73.,  ..., 159., 159., 160.]],

        [[148., 148., 146.,  ..., 197., 197., 198.],
         [147., 147., 145.,  ..., 197., 197., 198.],
         [146., 146., 145.,  ..., 198., 198., 198.],
         ...,
         [109., 105.,  92.,  ..., 161., 161., 161.],
         [109., 105.,  92.,  ..., 161., 161., 161.],
         [109., 109.,  92.,  ..., 161., 161., 161.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 233.9399,  861.1350,  282.6723, 1024.0000]])), gt_classes: tensor([194])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000316766.jpg', 'height': 640, 'width': 424, 'not_exhaustive_category_ids': [], 'neg_category_ids': [687, 499, 1145, 391, 501, 675, 163, 496], 'image_id': 316766, 'annotations_cat_set': {261, 1097, 617, 1109, 633, 955}, 'image': tensor([[[ 37.,  35.,  33.,  ..., 136., 136., 136.],
         [ 36.,  35.,  33.,  ..., 136., 136., 136.],
         [ 36.,  35.,  33.,  ..., 136., 136., 136.],
         ...,
         [ 53.,  58.,  63.,  ..., 178., 177., 178.],
         [ 53.,  58.,  63.,  ..., 177., 176., 177.],
         [ 53.,  58.,  63.,  ..., 177., 176., 177.]],

        [[ 97.,  95.,  92.,  ..., 173., 173., 173.],
         [ 97.,  94.,  91.,  ..., 173., 173., 173.],
         [ 96.,  94.,  91.,  ..., 173., 173., 173.],
         ...,
         [140., 142., 143.,  ..., 195., 195., 196.],
         [141., 142., 143.,  ..., 195., 195., 196.],
         [141., 142., 143.,  ..., 195., 195., 196.]],

        [[140., 138., 136.,  ..., 200., 200., 200.],
         [139., 137., 135.,  ..., 200., 200., 200.],
         [139., 137., 135.,  ..., 200., 200., 200.],
         ...,
         [200., 201., 202.,  ..., 213., 211., 212.],
         [200., 201., 202.,  ..., 213., 211., 212.],
         [200., 201., 203.,  ..., 213., 212., 213.]]]), 'instances': Instances(num_instances=4, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 482.4873,  380.6192,  959.7615,  441.0991],
        [ 449.6948,  416.0057,  474.1750,  437.5056],
        [ 975.1683,  614.0729, 1024.0000,  912.8790],
        [ 696.7203,  614.9866, 1024.0000, 1024.0000]])), gt_classes: tensor([789, 436, 194, 777])])}], 'support_set_target': tensor(194)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000077667.jpg', 'height': 500, 'width': 376, 'not_exhaustive_category_ids': [125, 811], 'neg_category_ids': [343, 350, 1009, 288, 1043, 939], 'image_id': 77667, 'annotations': [{'bbox': [49.67, 204.29, 60.41, 50.97], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 699}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000077667.jpg', 'height': 500, 'width': 376, 'not_exhaustive_category_ids': [125, 811], 'neg_category_ids': [343, 350, 1009, 288, 1043, 939], 'image_id': 77667, 'image': tensor([[[175., 175., 181.,  ...,  76.,  76.,  76.],
         [181., 189., 209.,  ...,  76.,  76.,  76.],
         [181., 189., 209.,  ...,  76.,  76.,  76.],
         ...,
         [175., 199.,  18.,  ...,  76.,  76.,  76.],
         [169., 181.,  18.,  ...,  76.,  76.,  76.],
         [169., 189.,  26.,  ...,  76.,  76.,  76.]],

        [[184., 184., 189.,  ...,  79.,  79.,  79.],
         [189., 195., 207.,  ...,  79.,  79.,  79.],
         [189., 195., 207.,  ...,  79.,  79.,  79.],
         ...,
         [164., 174., 201.,  ...,  79.,  79.,  79.],
         [169., 174., 201.,  ...,  79.,  79.,  79.],
         [179., 189., 207.,  ...,  79.,  79.,  79.]],

        [[ 33.,  33.,  29.,  ...,  85.,  85.,  85.],
         [ 25.,  21.,  14.,  ...,  85.,  85.,  85.],
         [ 25.,  21.,  14.,  ...,  85.,  85.,  85.],
         ...,
         [189., 192., 198.,  ...,  85.,  85.,  85.],
         [192., 196., 205.,  ...,  85.,  85.,  85.],
         [200., 205., 218.,  ...,  85.,  85.,  85.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[584.1753, 417.0294, 716.8845, 529.0615]])), gt_classes: tensor([699])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000335076.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [90], 'neg_category_ids': [299, 1096, 23, 1058, 243, 1086, 385, 961], 'image_id': 335076, 'annotations': [{'bbox': [193.05, 154.16, 38.91, 66.7], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 699}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000335076.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [90], 'neg_category_ids': [299, 1096, 23, 1058, 243, 1086, 385, 961], 'image_id': 335076, 'image': tensor([[[139., 143., 141.,  ..., 188., 188., 189.],
         [136., 136., 134.,  ..., 187., 182., 178.],
         [133., 129., 127.,  ..., 186., 179., 167.],
         ...,
         [ 99.,  92., 104.,  ..., 172., 170., 167.],
         [103., 104., 115.,  ..., 168., 164., 161.],
         [107., 112., 120.,  ..., 160., 158., 155.]],

        [[111., 116., 114.,  ..., 168., 170., 171.],
         [111., 110., 107.,  ..., 167., 167., 167.],
         [110., 104., 101.,  ..., 165., 164., 163.],
         ...,
         [123., 106., 114.,  ..., 167., 169., 171.],
         [125., 118., 126.,  ..., 161., 162., 164.],
         [127., 125., 131.,  ..., 155., 156., 156.]],

        [[124., 117., 113.,  ..., 188., 206., 226.],
         [113., 110., 108.,  ..., 188., 202., 218.],
         [103., 101., 102.,  ..., 187., 198., 210.],
         ...,
         [108., 111., 127.,  ..., 163., 164., 166.],
         [121., 123., 135.,  ..., 159., 159., 158.],
         [134., 131., 138.,  ..., 154., 153., 150.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[791.1213, 322.2687, 884.8702, 482.9045]])), gt_classes: tensor([699])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000077667.jpg', 'height': 500, 'width': 376, 'not_exhaustive_category_ids': [125, 811], 'neg_category_ids': [343, 350, 1009, 288, 1043, 939], 'image_id': 77667, 'annotations': [{'bbox': [302.97, 153.65, 55.68, 70.53], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 699}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000077667.jpg', 'height': 500, 'width': 376, 'not_exhaustive_category_ids': [125, 811], 'neg_category_ids': [343, 350, 1009, 288, 1043, 939], 'image_id': 77667, 'image': tensor([[[41., 41., 41.,  ..., 65., 65., 65.],
         [41., 41., 41.,  ..., 65., 65., 65.],
         [41., 41., 41.,  ..., 65., 65., 65.],
         ...,
         [42., 42., 42.,  ..., 65., 65., 65.],
         [42., 42., 42.,  ..., 65., 65., 65.],
         [42., 42., 42.,  ..., 65., 65., 65.]],

        [[42., 42., 42.,  ..., 65., 65., 65.],
         [42., 42., 42.,  ..., 65., 65., 65.],
         [42., 42., 42.,  ..., 65., 65., 65.],
         ...,
         [44., 44., 44.,  ..., 65., 65., 65.],
         [44., 44., 44.,  ..., 65., 65., 65.],
         [44., 44., 44.,  ..., 65., 65., 65.]],

        [[42., 42., 42.,  ..., 65., 65., 65.],
         [42., 42., 43.,  ..., 65., 65., 65.],
         [42., 42., 43.,  ..., 65., 65., 65.],
         ...,
         [48., 48., 48.,  ..., 65., 65., 65.],
         [47., 47., 47.,  ..., 65., 65., 65.],
         [47., 47., 47.,  ..., 65., 65., 65.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[815.4406, 113.6258, 965.3027, 303.4926]])), gt_classes: tensor([699])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000291630.jpg', 'height': 168, 'width': 210, 'not_exhaustive_category_ids': [], 'neg_category_ids': [433, 437, 957, 384, 892, 727, 43], 'image_id': 291630, 'annotations': [{'bbox': [129.13, 135.83, 30.25, 21.25], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 699}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000291630.jpg', 'height': 168, 'width': 210, 'not_exhaustive_category_ids': [], 'neg_category_ids': [433, 437, 957, 384, 892, 727, 43], 'image_id': 291630, 'image': tensor([[[ 99.,  98.,  96.,  ...,  98.,  98.,  98.],
         [ 95.,  94.,  92.,  ...,  99.,  98.,  98.],
         [ 92.,  89.,  87.,  ...,  99.,  99.,  98.],
         ...,
         [ 24.,  21.,  19.,  ...,   6.,   6.,   6.],
         [ 23.,  21.,  18.,  ...,   6.,   6.,   6.],
         [ 23.,  20.,  18.,  ...,   6.,   6.,   6.]],

        [[200., 200., 199.,  ..., 136., 136., 138.],
         [202., 201., 200.,  ..., 136., 136., 137.],
         [204., 202., 201.,  ..., 135., 136., 137.],
         ...,
         [ 93.,  86.,  80.,  ...,   6.,   6.,   6.],
         [ 92.,  87.,  81.,  ...,   6.,   6.,   6.],
         [ 92.,  87.,  82.,  ...,   6.,   6.,   6.]],

        [[183., 187., 190.,  ..., 162., 162., 164.],
         [190., 192., 195.,  ..., 162., 162., 164.],
         [196., 198., 200.,  ..., 162., 163., 163.],
         ...,
         [165., 159., 154.,  ...,   6.,   6.,   6.],
         [165., 160., 155.,  ...,   6.,   6.,   6.],
         [165., 160., 156.,  ...,   6.,   6.,   6.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  859.6826,  179.2705, 1024.0000]])), gt_classes: tensor([699])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000325332.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [279, 898, 481, 178, 463, 615, 489, 916], 'image_id': 325332, 'annotations': [{'bbox': [76.25, 56.43, 38.33, 39.78], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 699}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000325332.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [279, 898, 481, 178, 463, 615, 489, 916], 'image_id': 325332, 'image': tensor([[[ 89.,  93.,  99.,  ..., 193., 194., 195.],
         [ 90.,  93.,  98.,  ..., 194., 195., 195.],
         [ 90.,  92.,  98.,  ..., 195., 195., 196.],
         ...,
         [ 10.,   9.,  11.,  ...,  17.,  21.,  26.],
         [ 14.,  16.,  20.,  ...,  13.,  17.,  25.],
         [ 18.,  23.,  29.,  ...,   9.,  13.,  24.]],

        [[112., 116., 121.,  ..., 211., 212., 213.],
         [113., 116., 121.,  ..., 212., 213., 213.],
         [113., 115., 120.,  ..., 213., 213., 214.],
         ...,
         [ 17.,  17.,  19.,  ...,  19.,  24.,  30.],
         [ 21.,  24.,  28.,  ...,  15.,  20.,  29.],
         [ 25.,  31.,  37.,  ...,  12.,  16.,  27.]],

        [[127., 131., 136.,  ..., 218., 219., 220.],
         [128., 131., 136.,  ..., 219., 220., 220.],
         [128., 130., 135.,  ..., 220., 220., 221.],
         ...,
         [ 31.,  31.,  33.,  ...,  28.,  33.,  38.],
         [ 37.,  39.,  44.,  ...,  24.,  28.,  36.],
         [ 42.,  47.,  54.,  ...,  20.,  23.,  34.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000077667.jpg', 'height': 500, 'width': 376, 'not_exhaustive_category_ids': [125, 811], 'neg_category_ids': [343, 350, 1009, 288, 1043, 939], 'image_id': 77667, 'image': tensor([[[175., 175., 181.,  ...,  76.,  76.,  76.],
         [181., 189., 209.,  ...,  76.,  76.,  76.],
         [181., 189., 209.,  ...,  76.,  76.,  76.],
         ...,
         [175., 199.,  18.,  ...,  76.,  76.,  76.],
         [169., 181.,  18.,  ...,  76.,  76.,  76.],
         [169., 189.,  26.,  ...,  76.,  76.,  76.]],

        [[184., 184., 189.,  ...,  79.,  79.,  79.],
         [189., 195., 207.,  ...,  79.,  79.,  79.],
         [189., 195., 207.,  ...,  79.,  79.,  79.],
         ...,
         [164., 174., 201.,  ...,  79.,  79.,  79.],
         [169., 174., 201.,  ...,  79.,  79.,  79.],
         [179., 189., 207.,  ...,  79.,  79.,  79.]],

        [[ 33.,  33.,  29.,  ...,  85.,  85.,  85.],
         [ 25.,  21.,  14.,  ...,  85.,  85.,  85.],
         [ 25.,  21.,  14.,  ...,  85.,  85.,  85.],
         ...,
         [189., 192., 198.,  ...,  85.,  85.,  85.],
         [192., 196., 205.,  ...,  85.,  85.,  85.],
         [200., 205., 218.,  ...,  85.,  85.,  85.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[584.1753, 417.0294, 716.8845, 529.0615]])), gt_classes: tensor([699])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000335076.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [90], 'neg_category_ids': [299, 1096, 23, 1058, 243, 1086, 385, 961], 'image_id': 335076, 'image': tensor([[[139., 143., 141.,  ..., 188., 188., 189.],
         [136., 136., 134.,  ..., 187., 182., 178.],
         [133., 129., 127.,  ..., 186., 179., 167.],
         ...,
         [ 99.,  92., 104.,  ..., 172., 170., 167.],
         [103., 104., 115.,  ..., 168., 164., 161.],
         [107., 112., 120.,  ..., 160., 158., 155.]],

        [[111., 116., 114.,  ..., 168., 170., 171.],
         [111., 110., 107.,  ..., 167., 167., 167.],
         [110., 104., 101.,  ..., 165., 164., 163.],
         ...,
         [123., 106., 114.,  ..., 167., 169., 171.],
         [125., 118., 126.,  ..., 161., 162., 164.],
         [127., 125., 131.,  ..., 155., 156., 156.]],

        [[124., 117., 113.,  ..., 188., 206., 226.],
         [113., 110., 108.,  ..., 188., 202., 218.],
         [103., 101., 102.,  ..., 187., 198., 210.],
         ...,
         [108., 111., 127.,  ..., 163., 164., 166.],
         [121., 123., 135.,  ..., 159., 159., 158.],
         [134., 131., 138.,  ..., 154., 153., 150.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[791.1213, 322.2687, 884.8702, 482.9045]])), gt_classes: tensor([699])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000077667.jpg', 'height': 500, 'width': 376, 'not_exhaustive_category_ids': [125, 811], 'neg_category_ids': [343, 350, 1009, 288, 1043, 939], 'image_id': 77667, 'image': tensor([[[41., 41., 41.,  ..., 65., 65., 65.],
         [41., 41., 41.,  ..., 65., 65., 65.],
         [41., 41., 41.,  ..., 65., 65., 65.],
         ...,
         [42., 42., 42.,  ..., 65., 65., 65.],
         [42., 42., 42.,  ..., 65., 65., 65.],
         [42., 42., 42.,  ..., 65., 65., 65.]],

        [[42., 42., 42.,  ..., 65., 65., 65.],
         [42., 42., 42.,  ..., 65., 65., 65.],
         [42., 42., 42.,  ..., 65., 65., 65.],
         ...,
         [44., 44., 44.,  ..., 65., 65., 65.],
         [44., 44., 44.,  ..., 65., 65., 65.],
         [44., 44., 44.,  ..., 65., 65., 65.]],

        [[42., 42., 42.,  ..., 65., 65., 65.],
         [42., 42., 43.,  ..., 65., 65., 65.],
         [42., 42., 43.,  ..., 65., 65., 65.],
         ...,
         [48., 48., 48.,  ..., 65., 65., 65.],
         [47., 47., 47.,  ..., 65., 65., 65.],
         [47., 47., 47.,  ..., 65., 65., 65.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[815.4406, 113.6258, 965.3027, 303.4926]])), gt_classes: tensor([699])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000291630.jpg', 'height': 168, 'width': 210, 'not_exhaustive_category_ids': [], 'neg_category_ids': [433, 437, 957, 384, 892, 727, 43], 'image_id': 291630, 'image': tensor([[[ 99.,  98.,  96.,  ...,  98.,  98.,  98.],
         [ 95.,  94.,  92.,  ...,  99.,  98.,  98.],
         [ 92.,  89.,  87.,  ...,  99.,  99.,  98.],
         ...,
         [ 24.,  21.,  19.,  ...,   6.,   6.,   6.],
         [ 23.,  21.,  18.,  ...,   6.,   6.,   6.],
         [ 23.,  20.,  18.,  ...,   6.,   6.,   6.]],

        [[200., 200., 199.,  ..., 136., 136., 138.],
         [202., 201., 200.,  ..., 136., 136., 137.],
         [204., 202., 201.,  ..., 135., 136., 137.],
         ...,
         [ 93.,  86.,  80.,  ...,   6.,   6.,   6.],
         [ 92.,  87.,  81.,  ...,   6.,   6.,   6.],
         [ 92.,  87.,  82.,  ...,   6.,   6.,   6.]],

        [[183., 187., 190.,  ..., 162., 162., 164.],
         [190., 192., 195.,  ..., 162., 162., 164.],
         [196., 198., 200.,  ..., 162., 163., 163.],
         ...,
         [165., 159., 154.,  ...,   6.,   6.,   6.],
         [165., 160., 155.,  ...,   6.,   6.,   6.],
         [165., 160., 156.,  ...,   6.,   6.,   6.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  859.6826,  179.2705, 1024.0000]])), gt_classes: tensor([699])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000291630.jpg', 'height': 168, 'width': 210, 'not_exhaustive_category_ids': [], 'neg_category_ids': [433, 437, 957, 384, 892, 727, 43], 'image_id': 291630, 'image': tensor([[[ 99.,  98.,  96.,  ...,  98.,  98.,  98.],
         [ 95.,  94.,  92.,  ...,  99.,  98.,  98.],
         [ 92.,  89.,  87.,  ...,  99.,  99.,  98.],
         ...,
         [ 24.,  21.,  19.,  ...,   6.,   6.,   6.],
         [ 23.,  21.,  18.,  ...,   6.,   6.,   6.],
         [ 23.,  20.,  18.,  ...,   6.,   6.,   6.]],

        [[200., 200., 199.,  ..., 136., 136., 138.],
         [202., 201., 200.,  ..., 136., 136., 137.],
         [204., 202., 201.,  ..., 135., 136., 137.],
         ...,
         [ 93.,  86.,  80.,  ...,   6.,   6.,   6.],
         [ 92.,  87.,  81.,  ...,   6.,   6.,   6.],
         [ 92.,  87.,  82.,  ...,   6.,   6.,   6.]],

        [[183., 187., 190.,  ..., 162., 162., 164.],
         [190., 192., 195.,  ..., 162., 162., 164.],
         [196., 198., 200.,  ..., 162., 163., 163.],
         ...,
         [165., 159., 154.,  ...,   6.,   6.,   6.],
         [165., 160., 155.,  ...,   6.,   6.,   6.],
         [165., 160., 156.,  ...,   6.,   6.,   6.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  859.6826,  179.2705, 1024.0000]])), gt_classes: tensor([699])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000263875.jpg', 'height': 521, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [451, 1184, 602, 711, 696, 713, 418, 6, 574, 620, 447, 825, 46], 'image_id': 263875, 'annotations_cat_set': {997, 1050, 835, 589}, 'image': tensor([[[32., 33., 35.,  ...,  7.,  5.,  3.],
         [31., 34., 37.,  ...,  5.,  5.,  4.],
         [31., 34., 36.,  ...,  5.,  5.,  4.],
         ...,
         [44., 43., 43.,  ...,  5.,  5.,  5.],
         [43., 42., 42.,  ...,  5.,  5.,  5.],
         [42., 42., 42.,  ...,  5.,  5.,  5.]],

        [[33., 33., 34.,  ...,  8.,  6.,  4.],
         [32., 35., 37.,  ...,  6.,  5.,  5.],
         [32., 35., 37.,  ...,  5.,  5.,  5.],
         ...,
         [40., 39., 39.,  ...,  8.,  8.,  8.],
         [39., 38., 38.,  ...,  8.,  8.,  8.],
         [38., 38., 38.,  ...,  8.,  8.,  8.]],

        [[33., 33., 33.,  ...,  8.,  7.,  5.],
         [34., 36., 37.,  ...,  7.,  6.,  5.],
         [35., 37., 38.,  ...,  6.,  6.,  6.],
         ...,
         [35., 35., 35.,  ..., 15., 15., 15.],
         [35., 34., 34.,  ..., 15., 15., 15.],
         [34., 34., 34.,  ..., 15., 15., 15.]]]), 'instances': Instances(num_instances=6, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 345.9344,  792.5343,  596.8520, 1024.0000],
        [ 135.1649,  994.7225,  186.7309, 1024.0000],
        [ 729.4856,  776.6086,  779.3853,  828.5522],
        [ 777.5953,  546.5812,  831.4758,  604.5742],
        [ 635.4262,  705.2517,  695.6636,  739.0783],
        [  92.0235,  697.8444,  155.4086,  733.5845]])), gt_classes: tensor([416, 699, 699, 699, 588, 588])])}], 'support_set_target': tensor(699)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000520041.jpg', 'height': 424, 'width': 640, 'not_exhaustive_category_ids': [170], 'neg_category_ids': [1022, 762, 1099, 986, 638, 117, 273, 361], 'image_id': 520041, 'annotations': [{'bbox': [73.22, 289.0, 168.64, 71.02], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 128}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000520041.jpg', 'height': 424, 'width': 640, 'not_exhaustive_category_ids': [170], 'neg_category_ids': [1022, 762, 1099, 986, 638, 117, 273, 361], 'image_id': 520041, 'image': tensor([[[132., 132., 132.,  ..., 111., 112., 114.],
         [131., 132., 132.,  ..., 107., 109., 110.],
         [130., 131., 131.,  ..., 103., 106., 107.],
         ...,
         [131., 129., 127.,  ...,  50.,  51.,  51.],
         [130., 127., 129.,  ...,  50.,  51.,  51.],
         [130., 130., 129.,  ...,  50.,  51.,  51.]],

        [[137., 137., 137.,  ..., 100., 101.,  99.],
         [136., 137., 137.,  ...,  96.,  96.,  95.],
         [135., 136., 136.,  ...,  93.,  90.,  90.],
         ...,
         [126., 124., 124.,  ...,  49.,  50.,  50.],
         [125., 125., 124.,  ...,  49.,  50.,  50.],
         [125., 125., 124.,  ...,  49.,  50.,  50.]],

        [[144., 144., 144.,  ..., 193., 194., 192.],
         [143., 144., 144.,  ..., 194., 196., 195.],
         [142., 143., 143.,  ..., 197., 197., 196.],
         ...,
         [138., 136., 136.,  ...,  56.,  57.,  57.],
         [139., 136., 138.,  ...,  56.,  57.,  57.],
         [141., 141., 140.,  ...,  56.,  57.,  57.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[344.1002, 642.2877, 822.3527, 843.6227]])), gt_classes: tensor([128])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000104310.jpg', 'height': 640, 'width': 428, 'not_exhaustive_category_ids': [], 'neg_category_ids': [148, 1004, 1016, 58, 268, 996, 14, 1161, 1182], 'image_id': 104310, 'annotations': [{'bbox': [0.0, 286.86, 147.11, 143.65], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 128}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000104310.jpg', 'height': 640, 'width': 428, 'not_exhaustive_category_ids': [], 'neg_category_ids': [148, 1004, 1016, 58, 268, 996, 14, 1161, 1182], 'image_id': 104310, 'image': tensor([[[ 58.,  59.,  60.,  ..., 128., 128., 128.],
         [ 59.,  60.,  61.,  ..., 128., 128., 128.],
         [ 60.,  61.,  61.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 57.,  58.,  58.,  ..., 128., 128., 128.],
         [ 58.,  59.,  59.,  ..., 128., 128., 128.],
         [ 59.,  60.,  60.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 53.,  55.,  57.,  ..., 128., 128., 128.],
         [ 54.,  56.,  58.,  ..., 128., 128., 128.],
         [ 55.,  57.,  58.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[387.2082, 395.3289, 590.0000, 593.2966]])), gt_classes: tensor([128])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000046168.jpg', 'height': 486, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [985, 1127, 460, 993, 822, 41, 648], 'image_id': 46168, 'annotations': [{'bbox': [184.43, 6.41, 416.94, 479.59], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 128}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000046168.jpg', 'height': 486, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [985, 1127, 460, 993, 822, 41, 648], 'image_id': 46168, 'image': tensor([[[ 80.,  80.,  80.,  ...,  87.,  88.,  89.],
         [ 80.,  80.,  80.,  ...,  85.,  86.,  86.],
         [ 79.,  79.,  79.,  ...,  84.,  85.,  85.],
         ...,
         [ 34.,  34.,  35.,  ...,  23.,  22.,  22.],
         [ 32.,  33.,  34.,  ...,  22.,  21.,  21.],
         [ 29.,  30.,  31.,  ...,  23.,  22.,  22.]],

        [[216., 216., 216.,  ..., 225., 225., 225.],
         [216., 216., 216.,  ..., 226., 226., 225.],
         [216., 216., 216.,  ..., 226., 226., 225.],
         ...,
         [100.,  99.,  99.,  ...,  80.,  79.,  79.],
         [ 98.,  98.,  98.,  ...,  79.,  78.,  78.],
         [ 94.,  94.,  94.,  ...,  80.,  79.,  79.]],

        [[238., 238., 238.,  ..., 236., 236., 235.],
         [238., 238., 238.,  ..., 236., 236., 236.],
         [238., 238., 238.,  ..., 237., 237., 236.],
         ...,
         [187., 187., 187.,  ..., 185., 184., 184.],
         [187., 187., 187.,  ..., 184., 183., 183.],
         [185., 186., 186.,  ..., 185., 184., 184.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  43.2664,    0.0000, 1024.0000, 1024.0000]])), gt_classes: tensor([128])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000148706.jpg', 'height': 640, 'width': 428, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 632, 228, 747, 847, 1066, 145, 497], 'image_id': 148706, 'annotations': [{'bbox': [0.54, 211.93, 140.92, 42.1], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 128}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000148706.jpg', 'height': 640, 'width': 428, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 632, 228, 747, 847, 1066, 145, 497], 'image_id': 148706, 'image': tensor([[[ 90.,  90.,  90.,  ..., 128., 128., 128.],
         [ 91.,  91.,  91.,  ..., 128., 128., 128.],
         [ 93.,  93.,  92.,  ..., 128., 128., 128.],
         ...,
         [ 12.,  11.,  11.,  ..., 128., 128., 128.],
         [  9.,   8.,   7.,  ..., 128., 128., 128.],
         [  9.,   8.,   7.,  ..., 128., 128., 128.]],

        [[117., 117., 117.,  ..., 128., 128., 128.],
         [117., 117., 118.,  ..., 128., 128., 128.],
         [118., 118., 119.,  ..., 128., 128., 128.],
         ...,
         [ 16.,  15.,  15.,  ..., 128., 128., 128.],
         [ 15.,  14.,  13.,  ..., 128., 128., 128.],
         [ 16.,  15.,  14.,  ..., 128., 128., 128.]],

        [[127., 127., 127.,  ..., 128., 128., 128.],
         [127., 127., 128.,  ..., 128., 128., 128.],
         [128., 128., 129.,  ..., 128., 128., 128.],
         ...,
         [ 19.,  19.,  19.,  ..., 128., 128., 128.],
         [ 18.,  17.,  17.,  ..., 128., 128., 128.],
         [ 19.,  18.,  16.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[532.9108, 330.0573, 794.9957, 408.3370]])), gt_classes: tensor([128])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000016342.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1001, 431, 303, 218, 605, 1053, 212, 553, 825], 'image_id': 16342, 'annotations': [{'bbox': [263.81, 140.94, 64.71, 35.3], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 128}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000016342.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1001, 431, 303, 218, 605, 1053, 212, 553, 825], 'image_id': 16342, 'image': tensor([[[120., 121., 121.,  ..., 133., 133., 133.],
         [117., 118., 119.,  ..., 132., 133., 134.],
         [115., 116., 116.,  ..., 132., 133., 134.],
         ...,
         [178., 180., 182.,  ...,  44.,  44.,  44.],
         [179., 181., 183.,  ...,  45.,  45.,  45.],
         [179., 181., 183.,  ...,  45.,  45.,  45.]],

        [[122., 124., 124.,  ..., 136., 136., 136.],
         [120., 121., 122.,  ..., 135., 136., 137.],
         [118., 119., 119.,  ..., 135., 136., 137.],
         ...,
         [179., 181., 183.,  ...,  47.,  47.,  47.],
         [180., 182., 184.,  ...,  48.,  48.,  48.],
         [180., 182., 184.,  ...,  48.,  48.,  48.]],

        [[125., 127., 127.,  ..., 139., 139., 139.],
         [123., 124., 125.,  ..., 138., 139., 140.],
         [121., 122., 122.,  ..., 138., 139., 140.],
         ...,
         [179., 181., 183.,  ...,  51.,  52.,  52.],
         [180., 182., 184.,  ...,  52.,  52.,  52.],
         [181., 183., 185.,  ...,  52.,  52.,  52.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[749.0599, 337.7646, 942.2798, 443.1498]])), gt_classes: tensor([128])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000520041.jpg', 'height': 424, 'width': 640, 'not_exhaustive_category_ids': [170], 'neg_category_ids': [1022, 762, 1099, 986, 638, 117, 273, 361], 'image_id': 520041, 'image': tensor([[[132., 132., 132.,  ..., 111., 112., 114.],
         [131., 132., 132.,  ..., 107., 109., 110.],
         [130., 131., 131.,  ..., 103., 106., 107.],
         ...,
         [131., 129., 127.,  ...,  50.,  51.,  51.],
         [130., 127., 129.,  ...,  50.,  51.,  51.],
         [130., 130., 129.,  ...,  50.,  51.,  51.]],

        [[137., 137., 137.,  ..., 100., 101.,  99.],
         [136., 137., 137.,  ...,  96.,  96.,  95.],
         [135., 136., 136.,  ...,  93.,  90.,  90.],
         ...,
         [126., 124., 124.,  ...,  49.,  50.,  50.],
         [125., 125., 124.,  ...,  49.,  50.,  50.],
         [125., 125., 124.,  ...,  49.,  50.,  50.]],

        [[144., 144., 144.,  ..., 193., 194., 192.],
         [143., 144., 144.,  ..., 194., 196., 195.],
         [142., 143., 143.,  ..., 197., 197., 196.],
         ...,
         [138., 136., 136.,  ...,  56.,  57.,  57.],
         [139., 136., 138.,  ...,  56.,  57.,  57.],
         [141., 141., 140.,  ...,  56.,  57.,  57.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[344.1002, 642.2877, 822.3527, 843.6227]])), gt_classes: tensor([128])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000104310.jpg', 'height': 640, 'width': 428, 'not_exhaustive_category_ids': [], 'neg_category_ids': [148, 1004, 1016, 58, 268, 996, 14, 1161, 1182], 'image_id': 104310, 'image': tensor([[[ 58.,  59.,  60.,  ..., 128., 128., 128.],
         [ 59.,  60.,  61.,  ..., 128., 128., 128.],
         [ 60.,  61.,  61.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 57.,  58.,  58.,  ..., 128., 128., 128.],
         [ 58.,  59.,  59.,  ..., 128., 128., 128.],
         [ 59.,  60.,  60.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 53.,  55.,  57.,  ..., 128., 128., 128.],
         [ 54.,  56.,  58.,  ..., 128., 128., 128.],
         [ 55.,  57.,  58.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[387.2082, 395.3289, 590.0000, 593.2966]])), gt_classes: tensor([128])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000046168.jpg', 'height': 486, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [985, 1127, 460, 993, 822, 41, 648], 'image_id': 46168, 'image': tensor([[[ 80.,  80.,  80.,  ...,  87.,  88.,  89.],
         [ 80.,  80.,  80.,  ...,  85.,  86.,  86.],
         [ 79.,  79.,  79.,  ...,  84.,  85.,  85.],
         ...,
         [ 34.,  34.,  35.,  ...,  23.,  22.,  22.],
         [ 32.,  33.,  34.,  ...,  22.,  21.,  21.],
         [ 29.,  30.,  31.,  ...,  23.,  22.,  22.]],

        [[216., 216., 216.,  ..., 225., 225., 225.],
         [216., 216., 216.,  ..., 226., 226., 225.],
         [216., 216., 216.,  ..., 226., 226., 225.],
         ...,
         [100.,  99.,  99.,  ...,  80.,  79.,  79.],
         [ 98.,  98.,  98.,  ...,  79.,  78.,  78.],
         [ 94.,  94.,  94.,  ...,  80.,  79.,  79.]],

        [[238., 238., 238.,  ..., 236., 236., 235.],
         [238., 238., 238.,  ..., 236., 236., 236.],
         [238., 238., 238.,  ..., 237., 237., 236.],
         ...,
         [187., 187., 187.,  ..., 185., 184., 184.],
         [187., 187., 187.,  ..., 184., 183., 183.],
         [185., 186., 186.,  ..., 185., 184., 184.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  43.2664,    0.0000, 1024.0000, 1024.0000]])), gt_classes: tensor([128])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000148706.jpg', 'height': 640, 'width': 428, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 632, 228, 747, 847, 1066, 145, 497], 'image_id': 148706, 'image': tensor([[[ 90.,  90.,  90.,  ..., 128., 128., 128.],
         [ 91.,  91.,  91.,  ..., 128., 128., 128.],
         [ 93.,  93.,  92.,  ..., 128., 128., 128.],
         ...,
         [ 12.,  11.,  11.,  ..., 128., 128., 128.],
         [  9.,   8.,   7.,  ..., 128., 128., 128.],
         [  9.,   8.,   7.,  ..., 128., 128., 128.]],

        [[117., 117., 117.,  ..., 128., 128., 128.],
         [117., 117., 118.,  ..., 128., 128., 128.],
         [118., 118., 119.,  ..., 128., 128., 128.],
         ...,
         [ 16.,  15.,  15.,  ..., 128., 128., 128.],
         [ 15.,  14.,  13.,  ..., 128., 128., 128.],
         [ 16.,  15.,  14.,  ..., 128., 128., 128.]],

        [[127., 127., 127.,  ..., 128., 128., 128.],
         [127., 127., 128.,  ..., 128., 128., 128.],
         [128., 128., 129.,  ..., 128., 128., 128.],
         ...,
         [ 19.,  19.,  19.,  ..., 128., 128., 128.],
         [ 18.,  17.,  17.,  ..., 128., 128., 128.],
         [ 19.,  18.,  16.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[532.9108, 330.0573, 794.9957, 408.3370]])), gt_classes: tensor([128])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000016342.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1001, 431, 303, 218, 605, 1053, 212, 553, 825], 'image_id': 16342, 'image': tensor([[[120., 121., 121.,  ..., 133., 133., 133.],
         [117., 118., 119.,  ..., 132., 133., 134.],
         [115., 116., 116.,  ..., 132., 133., 134.],
         ...,
         [178., 180., 182.,  ...,  44.,  44.,  44.],
         [179., 181., 183.,  ...,  45.,  45.,  45.],
         [179., 181., 183.,  ...,  45.,  45.,  45.]],

        [[122., 124., 124.,  ..., 136., 136., 136.],
         [120., 121., 122.,  ..., 135., 136., 137.],
         [118., 119., 119.,  ..., 135., 136., 137.],
         ...,
         [179., 181., 183.,  ...,  47.,  47.,  47.],
         [180., 182., 184.,  ...,  48.,  48.,  48.],
         [180., 182., 184.,  ...,  48.,  48.,  48.]],

        [[125., 127., 127.,  ..., 139., 139., 139.],
         [123., 124., 125.,  ..., 138., 139., 140.],
         [121., 122., 122.,  ..., 138., 139., 140.],
         ...,
         [179., 181., 183.,  ...,  51.,  52.,  52.],
         [180., 182., 184.,  ...,  52.,  52.,  52.],
         [181., 183., 185.,  ...,  52.,  52.,  52.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[749.0599, 337.7646, 942.2798, 443.1498]])), gt_classes: tensor([128])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000016342.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1001, 431, 303, 218, 605, 1053, 212, 553, 825], 'image_id': 16342, 'annotations_cat_set': {804, 170, 589, 440, 1023}, 'image': tensor([[[ 98.,  99.,  99.,  ...,  88.,  89.,  89.],
         [ 98.,  99.,  99.,  ...,  87.,  88.,  89.],
         [ 97.,  98.,  99.,  ...,  86.,  87.,  87.],
         ...,
         [103., 103., 103.,  ...,  89.,  88.,  87.],
         [100., 100., 101.,  ...,  89.,  89.,  89.],
         [ 98.,  98.,  99.,  ...,  89.,  89.,  90.]],

        [[127., 128., 128.,  ..., 100., 100., 100.],
         [127., 128., 128.,  ...,  99., 100., 100.],
         [126., 127., 128.,  ...,  99.,  99.,  99.],
         ...,
         [ 88.,  87.,  87.,  ...,  91.,  91.,  90.],
         [ 85.,  85.,  86.,  ...,  90.,  90.,  91.],
         [ 83.,  83.,  84.,  ...,  89.,  90.,  91.]],

        [[164., 165., 165.,  ..., 116., 116., 116.],
         [164., 165., 165.,  ..., 115., 116., 116.],
         [163., 164., 165.,  ..., 115., 116., 116.],
         ...,
         [ 69.,  68.,  68.,  ...,  95.,  94.,  92.],
         [ 66.,  66.,  67.,  ...,  94.,  95.,  94.],
         [ 65.,  64.,  65.,  ...,  94.,  95.,  94.]]]), 'instances': Instances(num_instances=30, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[2.0082e+02, 3.6115e+02, 2.2852e+02, 4.1418e+02],
        [6.9225e+02, 3.3489e+02, 6.9929e+02, 3.6913e+02],
        [1.3822e+01, 7.6718e+02, 4.5825e+01, 8.0814e+02],
        [5.6424e+02, 5.7693e+01, 6.0995e+02, 8.6113e+01],
        [5.5131e-01, 2.0366e+02, 3.2871e+02, 2.9815e+02],
        [0.0000e+00, 5.0886e+02, 3.3040e+02, 6.0164e+02],
        [3.7746e+02, 2.5192e+02, 5.3475e+02, 2.9448e+02],
        [2.0807e+01, 8.1334e+02, 3.6361e+02, 9.2388e+02],
        [7.2728e+02, 4.8252e+02, 1.0240e+03, 6.0226e+02],
        [6.3144e+02, 6.3678e+02, 7.6723e+02, 6.8963e+02],
        [7.1321e+02, 1.9392e+02, 1.0240e+03, 3.2461e+02],
        [6.2880e+02, 4.2309e+02, 8.6566e+02, 4.8798e+02],
        [6.1826e+02, 2.3935e+02, 7.9598e+02, 3.1925e+02],
        [4.0011e+02, 5.5625e+02, 5.4954e+02, 6.1638e+02],
        [6.8781e+02, 7.7066e+02, 9.4741e+02, 8.7980e+02],
        [3.8749e+02, 4.0958e+02, 4.1558e+02, 4.4347e+02],
        [3.9405e+02, 4.4156e+02, 4.1522e+02, 4.6758e+02],
        [0.0000e+00, 8.1488e+02, 3.6448e+02, 1.0240e+03],
        [6.8631e+02, 8.4920e+02, 1.0240e+03, 1.0240e+03],
        [3.8788e+02, 4.0963e+02, 5.3746e+02, 5.5311e+02],
        [3.9528e+02, 6.0920e+02, 5.4074e+02, 8.0751e+02],
        [6.1766e+02, 2.3870e+02, 7.9416e+02, 3.3602e+02],
        [0.0000e+00, 5.9294e+02, 3.4208e+02, 1.0240e+03],
        [6.2866e+02, 3.6442e+02, 9.5856e+02, 6.0625e+02],
        [3.6091e+02, 2.3861e+02, 5.1732e+02, 3.2391e+02],
        [7.1362e+02, 1.8471e+02, 1.0240e+03, 3.8087e+02],
        [0.0000e+00, 1.9013e+02, 3.0065e+02, 4.1814e+02],
        [6.3997e+02, 6.6106e+02, 7.9189e+02, 8.9449e+02],
        [7.2783e+02, 4.8199e+02, 1.0240e+03, 1.0240e+03],
        [4.1553e+02, 3.3261e+02, 5.4060e+02, 5.9712e+02]])), gt_classes: tensor([718, 718, 718, 311, 569, 569, 569, 569, 569, 569, 569, 569, 569, 569,
        569, 569, 569, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
        128, 416])])}], 'support_set_target': tensor(128)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000074458.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 688, 784, 711, 1170, 27, 903, 94, 57, 315, 384, 91, 234, 978, 647, 97], 'image_id': 74458, 'annotations': [{'bbox': [493.87, 83.94, 44.73, 144.77], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 254}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000074458.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 688, 784, 711, 1170, 27, 903, 94, 57, 315, 384, 91, 234, 978, 647, 97], 'image_id': 74458, 'image': tensor([[[238., 242., 249.,  ..., 128., 128., 128.],
         [234., 242., 240.,  ..., 128., 128., 128.],
         [225., 233., 238.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[169., 166., 162.,  ..., 128., 128., 128.],
         [169., 169., 160.,  ..., 128., 128., 128.],
         [162., 158., 156.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 87.,  82.,  80.,  ..., 128., 128., 128.],
         [ 89.,  87.,  80.,  ..., 128., 128., 128.],
         [ 82.,  93.,  87.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[500.8150,  85.1195, 546.1740, 231.9237]])), gt_classes: tensor([254])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349791.jpg', 'height': 368, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [967, 1105, 717, 1179, 775, 68, 386, 407, 166], 'image_id': 349791, 'annotations': [{'bbox': [44.14, 70.25, 99.6, 106.35], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 254}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349791.jpg', 'height': 368, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [967, 1105, 717, 1179, 775, 68, 386, 407, 166], 'image_id': 349791, 'image': tensor([[[222., 224., 224.,  ..., 221., 222., 221.],
         [222., 224., 224.,  ..., 219., 220., 221.],
         [221., 223., 223.,  ..., 217., 218., 220.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[229., 231., 232.,  ..., 227., 229., 228.],
         [229., 231., 231.,  ..., 225., 227., 227.],
         [228., 230., 230.,  ..., 223., 224., 226.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[231., 232., 232.,  ..., 231., 232., 231.],
         [231., 232., 232.,  ..., 230., 231., 231.],
         [231., 233., 232.,  ..., 227., 228., 231.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 126.1827, 178.2828, 317.2082]])), gt_classes: tensor([254])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000238171.jpg', 'height': 466, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [146, 1169, 737, 221, 305, 1093, 1107, 676, 955, 874, 96, 731, 1000], 'image_id': 238171, 'annotations': [{'bbox': [268.61, 0.48, 371.28, 254.93], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 254}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000238171.jpg', 'height': 466, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [146, 1169, 737, 221, 305, 1093, 1107, 676, 955, 874, 96, 731, 1000], 'image_id': 238171, 'image': tensor([[[29., 29., 29.,  ..., 27., 26., 27.],
         [29., 29., 29.,  ..., 28., 27., 27.],
         [29., 29., 29.,  ..., 29., 28., 29.],
         ...,
         [ 5.,  5.,  4.,  ..., 24., 25., 25.],
         [ 5.,  4.,  4.,  ..., 25., 25., 25.],
         [ 4.,  4.,  4.,  ..., 25., 25., 25.]],

        [[27., 27., 27.,  ..., 25., 24., 24.],
         [27., 27., 27.,  ..., 26., 25., 25.],
         [27., 27., 27.,  ..., 27., 26., 26.],
         ...,
         [ 5.,  5.,  4.,  ..., 30., 30., 30.],
         [ 5.,  4.,  3.,  ..., 30., 30., 30.],
         [ 5.,  4.,  4.,  ..., 30., 30., 30.]],

        [[26., 27., 27.,  ..., 23., 22., 22.],
         [26., 26., 27.,  ..., 24., 23., 23.],
         [26., 26., 26.,  ..., 25., 24., 25.],
         ...,
         [ 4.,  4.,  3.,  ..., 35., 35., 35.],
         [ 4.,  3.,  3.,  ..., 35., 35., 35.],
         [ 4.,  3.,  3.,  ..., 35., 35., 35.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 403.2955,    0.0000, 1024.0000,  566.4182]])), gt_classes: tensor([254])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000549873.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [350], 'neg_category_ids': [498, 941, 345, 125, 1007, 698, 1179, 493, 1043], 'image_id': 549873, 'annotations': [{'bbox': [127.77, 64.89, 66.89, 279.28], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 254}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000549873.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [350], 'neg_category_ids': [498, 941, 345, 125, 1007, 698, 1179, 493, 1043], 'image_id': 549873, 'image': tensor([[[228., 229., 232.,  ...,   0.,   0.,   0.],
         [229., 229., 232.,  ...,   0.,   0.,   0.],
         [230., 230., 231.,  ...,   0.,   0.,   0.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[219., 220., 221.,  ...,   0.,   0.,   0.],
         [219., 220., 221.,  ...,   0.,   0.,   0.],
         [220., 220., 220.,  ...,   0.,   0.,   0.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[199., 200., 201.,  ...,   0.,   0.,   0.],
         [199., 200., 201.,  ...,   0.,   0.,   0.],
         [200., 200., 200.,  ...,   0.,   0.,   0.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 58.5148, 136.9561, 199.6109, 726.4011]])), gt_classes: tensor([254])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000306095.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 220, 607, 240, 1007, 1105, 698, 863, 1139, 514], 'image_id': 306095, 'annotations': [{'bbox': [106.66, 47.22, 49.16, 261.75], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 254}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000306095.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 220, 607, 240, 1007, 1105, 698, 863, 1139, 514], 'image_id': 306095, 'image': tensor([[[ 89.,  96., 111.,  ..., 128., 128., 128.],
         [ 93.,  81.,  93.,  ..., 128., 128., 128.],
         [ 96.,  90.,  96.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[122., 129., 144.,  ..., 128., 128., 128.],
         [126., 114., 126.,  ..., 128., 128., 128.],
         [129., 123., 129.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[145., 152., 167.,  ..., 128., 128., 128.],
         [149., 137., 149.,  ..., 128., 128., 128.],
         [152., 146., 152.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[478.8843,  46.6671, 527.5066, 305.3521]])), gt_classes: tensor([254])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000183646.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [666, 829, 1099, 819, 548, 356, 357, 271, 1090, 977], 'image_id': 183646, 'annotations': [{'bbox': [139.94, 200.01, 88.45, 25.78], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 599}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000183646.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [666, 829, 1099, 819, 548, 356, 357, 271, 1090, 977], 'image_id': 183646, 'image': tensor([[[182., 182., 182.,  ..., 196., 195., 195.],
         [182., 182., 182.,  ..., 196., 195., 195.],
         [182., 182., 182.,  ..., 196., 196., 196.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[186., 186., 186.,  ..., 196., 195., 195.],
         [186., 186., 186.,  ..., 196., 195., 195.],
         [186., 186., 186.,  ..., 196., 196., 196.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[187., 187., 188.,  ..., 196., 195., 195.],
         [187., 187., 188.,  ..., 196., 195., 195.],
         [187., 187., 188.,  ..., 196., 196., 196.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[769.5848, 408.4316, 950.2162, 461.0758]])), gt_classes: tensor([599])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000275761.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1123, 711, 736, 348, 304, 587, 260, 612, 461, 990, 266, 158, 63, 401, 1200, 428, 514, 235], 'image_id': 275761, 'annotations': [{'bbox': [429.41, 241.81, 47.47, 11.54], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 599}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000275761.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1123, 711, 736, 348, 304, 587, 260, 612, 461, 990, 266, 158, 63, 401, 1200, 428, 514, 235], 'image_id': 275761, 'image': tensor([[[35., 35., 35.,  ..., 24., 24., 24.],
         [35., 35., 35.,  ..., 24., 24., 24.],
         [35., 35., 35.,  ..., 24., 24., 24.],
         ...,
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.]],

        [[34., 34., 34.,  ..., 24., 24., 24.],
         [34., 34., 34.,  ..., 24., 24., 24.],
         [34., 34., 34.,  ..., 24., 24., 24.],
         ...,
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.]],

        [[33., 33., 33.,  ..., 24., 24., 24.],
         [33., 33., 33.,  ..., 24., 24., 24.],
         [33., 33., 33.,  ..., 24., 24., 24.],
         ...,
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[347.5537, 195.9397, 385.9748, 205.2906]])), gt_classes: tensor([599])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000279343.jpg', 'height': 418, 'width': 600, 'not_exhaustive_category_ids': [3], 'neg_category_ids': [1094, 1043, 631, 259, 899, 984, 186, 108, 1106, 111, 592, 66, 141, 914, 162, 1163], 'image_id': 279343, 'annotations': [{'bbox': [553.7, 313.54, 35.73, 16.69], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 599}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000279343.jpg', 'height': 418, 'width': 600, 'not_exhaustive_category_ids': [3], 'neg_category_ids': [1094, 1043, 631, 259, 899, 984, 186, 108, 1106, 111, 592, 66, 141, 914, 162, 1163], 'image_id': 279343, 'image': tensor([[[ 66.,  66.,  66.,  ...,   7.,   7.,   7.],
         [ 66.,  66.,  66.,  ...,   7.,   7.,   7.],
         [ 65.,  65.,  65.,  ...,   7.,   7.,   7.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 82.,  82.,  82.,  ...,   7.,   7.,   7.],
         [ 82.,  82.,  82.,  ...,   7.,   7.,   7.],
         [ 81.,  81.,  81.,  ...,   7.,   7.,   7.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 98.,  98.,  98.,  ...,   7.,   7.,   7.],
         [ 98.,  98.,  98.,  ...,   7.,   7.,   7.],
         [ 97.,  97.,  97.,  ...,   7.,   7.,   7.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000209179.jpg', 'height': 560, 'width': 640, 'not_exhaustive_category_ids': [846], 'neg_category_ids': [1075, 969, 507, 989, 291, 250, 1202, 97], 'image_id': 209179, 'annotations': [{'bbox': [284.88, 365.87, 60.45, 53.51], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 599}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000209179.jpg', 'height': 560, 'width': 640, 'not_exhaustive_category_ids': [846], 'neg_category_ids': [1075, 969, 507, 989, 291, 250, 1202, 97], 'image_id': 209179, 'image': tensor([[[ 16.,  16.,  14.,  ..., 193., 193., 193.],
         [ 16.,  16.,  15.,  ..., 192., 192., 192.],
         [ 17.,  15.,  16.,  ..., 192., 192., 192.],
         ...,
         [ 74.,  74.,  86.,  ...,  75.,  74.,  74.],
         [ 74.,  74.,  86.,  ...,  75.,  74.,  74.],
         [ 86.,  86.,  86.,  ...,  75.,  74.,  74.]],

        [[ 25.,  25.,  25.,  ...,  91.,  91.,  91.],
         [ 23.,  25.,  24.,  ...,  90.,  90.,  90.],
         [ 19.,  22.,  21.,  ...,  90.,  90.,  90.],
         ...,
         [ 80.,  80., 103.,  ...,  71.,  80.,  80.],
         [ 80.,  80., 103.,  ...,  71.,  80.,  80.],
         [103., 103., 103.,  ...,  71.,  80.,  80.]],

        [[ 33.,  33.,  31.,  ...,  42.,  42.,  42.],
         [ 31.,  31.,  30.,  ...,  60.,  60.,  60.],
         [ 30.,  30.,  29.,  ...,  60.,  60.,  60.],
         ...,
         [121., 121., 141.,  ..., 160., 121., 121.],
         [121., 121., 141.,  ..., 160., 121., 121.],
         [141., 141., 141.,  ..., 160., 121., 121.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[235.1392, 625.0234, 418.5672, 787.3690]])), gt_classes: tensor([599])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000466901.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1024, 194, 668, 348, 765, 697, 592, 837, 1036, 291, 444, 1116, 1139], 'image_id': 466901, 'annotations': [{'bbox': [129.18, 320.88, 224.08, 79.32], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 599}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000466901.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1024, 194, 668, 348, 765, 697, 592, 837, 1036, 291, 444, 1116, 1139], 'image_id': 466901, 'image': tensor([[[ 11.,  13.,  16.,  ..., 128., 128., 128.],
         [  5.,   6.,  14.,  ..., 128., 128., 128.],
         [  1.,   3.,   5.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 19.,  21.,  24.,  ..., 128., 128., 128.],
         [ 10.,  12.,  20.,  ..., 128., 128., 128.],
         [  4.,   6.,  10.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 18.,  20.,  23.,  ..., 128., 128., 128.],
         [  9.,  11.,  19.,  ..., 128., 128., 128.],
         [  4.,   5.,   9.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[297.0447, 332.1521, 529.1776, 414.2586]])), gt_classes: tensor([599])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000072275.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [519, 898, 413, 501, 544, 658, 1178, 403, 404, 553, 1139, 318, 535], 'image_id': 72275, 'annotations': [{'bbox': [330.59, 364.73, 90.9, 92.9], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 549}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000072275.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [519, 898, 413, 501, 544, 658, 1178, 403, 404, 553, 1139, 318, 535], 'image_id': 72275, 'image': tensor([[[  0.,   3.,  13.,  ..., 157., 157., 157.],
         [  3.,  18.,  28.,  ..., 157., 157., 157.],
         [  8.,  28.,  28.,  ..., 157., 157., 157.],
         ...,
         [157., 157., 157.,  ..., 157., 157., 157.],
         [157., 157., 157.,  ..., 157., 157., 157.],
         [157., 157., 157.,  ..., 157., 157., 157.]],

        [[  3.,   0.,   0.,  ..., 140., 140., 140.],
         [  2.,   3.,   2.,  ..., 140., 140., 140.],
         [  1.,   3.,   2.,  ..., 140., 140., 140.],
         ...,
         [140., 140., 140.,  ..., 140., 140., 140.],
         [140., 140., 140.,  ..., 140., 140., 140.],
         [140., 140., 140.,  ..., 140., 140., 140.]],

        [[  1.,  14.,  18.,  ...,  97.,  97.,  97.],
         [  3.,  15.,  15.,  ...,  97.,  97.,  97.],
         [  2.,   8.,   8.,  ...,  97.,  97.,  97.],
         ...,
         [ 97.,  97.,  97.,  ...,  97.,  97.,  97.],
         [ 97.,  97.,  97.,  ...,  97.,  97.,  97.],
         [ 97.,  97.,  97.,  ...,  97.,  97.,  97.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[277.5760, 463.3211, 393.0474, 581.3331]])), gt_classes: tensor([549])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000146917.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1117, 735, 143, 774], 'neg_category_ids': [732, 517, 852, 373, 480, 55, 375, 264, 837, 35, 1083, 529, 250, 19], 'image_id': 146917, 'annotations': [{'bbox': [203.71, 308.21, 37.01, 19.84], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 549}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000146917.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1117, 735, 143, 774], 'neg_category_ids': [732, 517, 852, 373, 480, 55, 375, 264, 837, 35, 1083, 529, 250, 19], 'image_id': 146917, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ..., 128.,   0., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[819.0489, 674.8860, 900.0660, 718.3296]])), gt_classes: tensor([549])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000065280.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [61, 774], 'neg_category_ids': [921, 1069, 858, 59, 136, 230, 141, 997, 684, 1164], 'image_id': 65280, 'annotations': [{'bbox': [289.63, 53.58, 9.39, 9.63], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 549}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000065280.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [61, 774], 'neg_category_ids': [921, 1069, 858, 59, 136, 230, 141, 997, 684, 1164], 'image_id': 65280, 'image': tensor([[[159., 160., 159.,  ..., 123., 123., 123.],
         [161., 161., 160.,  ..., 124., 124., 126.],
         [162., 162., 161.,  ..., 126., 126., 127.],
         ...,
         [162., 170., 178.,  ...,  96., 102., 108.],
         [159., 168., 177.,  ...,  95., 100., 105.],
         [157., 166., 175.,  ...,  93.,  97., 101.]],

        [[166., 167., 166.,  ..., 134., 134., 134.],
         [168., 168., 167.,  ..., 135., 135., 135.],
         [169., 167., 168.,  ..., 135., 135., 136.],
         ...,
         [161., 169., 177.,  ...,  96., 101., 107.],
         [158., 167., 176.,  ...,  95., 100., 106.],
         [156., 165., 174.,  ...,  95.,  99., 104.]],

        [[170., 169., 168.,  ..., 139., 139., 139.],
         [170., 170., 169.,  ..., 140., 140., 140.],
         [171., 169., 170.,  ..., 140., 140., 141.],
         ...,
         [166., 174., 180.,  ..., 104., 108., 112.],
         [165., 172., 179.,  ..., 103., 107., 110.],
         [163., 170., 177.,  ..., 102., 104., 108.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000215910.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1025, 45], 'neg_category_ids': [1023, 583, 651, 1006, 378, 495, 387], 'image_id': 215910, 'annotations': [{'bbox': [16.22, 95.9, 36.05, 19.07], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 549}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000215910.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1025, 45], 'neg_category_ids': [1023, 583, 651, 1006, 378, 495, 387], 'image_id': 215910, 'image': tensor([[[ 92.,  61.,  54.,  ...,  45.,  47.,  48.],
         [ 97.,  85.,  75.,  ...,  47.,  48.,  52.],
         [110., 136., 118.,  ...,  52.,  54.,  57.],
         ...,
         [223., 223., 223.,  ..., 223., 223., 223.],
         [223., 223., 223.,  ..., 223., 223., 223.],
         [223., 223., 223.,  ..., 223., 223., 223.]],

        [[ 85.,  45.,  27.,  ...,  20.,  20.,  22.],
         [ 90.,  71.,  50.,  ...,  22.,  22.,  24.],
         [ 99., 124.,  99.,  ...,  24.,  26.,  29.],
         ...,
         [223., 223., 223.,  ..., 223., 223., 223.],
         [223., 223., 223.,  ..., 223., 223., 223.],
         [223., 223., 223.,  ..., 223., 223., 223.]],

        [[ 99., 113., 146.,  ...,  10.,  10.,  12.],
         [ 96., 118., 152.,  ...,   8.,   8.,  12.],
         [ 89., 131., 160.,  ...,   6.,   6.,  10.],
         ...,
         [223., 223., 223.,  ..., 223., 223., 223.],
         [223., 223., 223.,  ..., 223., 223., 223.],
         [223., 223., 223.,  ..., 223., 223., 223.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 987.9899,  194.3973, 1024.0000,  233.0538]])), gt_classes: tensor([549])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000143017.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [774, 735, 510, 613, 12], 'neg_category_ids': [585, 521, 309, 640, 746, 618, 1088, 1066], 'image_id': 143017, 'annotations': [{'bbox': [86.34, 174.44, 24.26, 21.31], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 549}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000143017.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [774, 735, 510, 613, 12], 'neg_category_ids': [585, 521, 309, 640, 746, 618, 1088, 1066], 'image_id': 143017, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [  0.,   0., 128.,  ...,   0.,   0.,   0.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[161.9341, 460.7906, 231.0372, 521.4797]])), gt_classes: tensor([549])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000205614.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [630, 808, 351, 1151, 716, 613, 378, 598, 338], 'image_id': 205614, 'annotations': [{'bbox': [97.91, 157.34, 68.92, 121.94], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 813}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000205614.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [630, 808, 351, 1151, 716, 613, 378, 598, 338], 'image_id': 205614, 'image': tensor([[[238., 238., 247.,  ..., 255., 255., 255.],
         [251., 244., 247.,  ..., 255., 255., 255.],
         [235., 235., 247.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[254., 247., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [254., 251., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [247., 247., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 87.3541, 140.3900, 148.8436, 249.1936]])), gt_classes: tensor([813])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000052066.jpg', 'height': 402, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [126, 415, 1101, 1170, 657, 724, 1179, 316, 755, 1183], 'image_id': 52066, 'annotations': [{'bbox': [134.63, 146.9, 42.46, 57.32], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 813}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000052066.jpg', 'height': 402, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [126, 415, 1101, 1170, 657, 724, 1179, 316, 755, 1183], 'image_id': 52066, 'image': tensor([[[245., 245., 245.,  ...,  93.,  84.,  80.],
         [245., 245., 245.,  ...,  87.,  81.,  73.],
         [245., 245., 245.,  ...,  68.,  73.,  58.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[236., 236., 236.,  ..., 122., 116., 113.],
         [236., 236., 236.,  ..., 112., 110., 103.],
         [236., 236., 236.,  ...,  82.,  92.,  80.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[227., 227., 227.,  ..., 127., 121., 121.],
         [227., 227., 227.,  ..., 119., 117., 111.],
         [227., 227., 227.,  ...,  92., 103.,  90.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[718.8149, 304.7627, 806.8531, 423.6803]])), gt_classes: tensor([813])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000412697.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [583, 23, 787, 221, 81, 461, 462, 531], 'image_id': 412697, 'annotations': [{'bbox': [0.0, 26.06, 74.15, 188.39], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 813}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000412697.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [583, 23, 787, 221, 81, 461, 462, 531], 'image_id': 412697, 'image': tensor([[[160., 160., 157.,  ..., 164., 170., 175.],
         [158., 160., 157.,  ..., 149., 160., 172.],
         [156., 159., 157.,  ..., 138., 153., 170.],
         ...,
         [150., 148., 148.,  ..., 126., 130., 135.],
         [153., 154., 152.,  ..., 130., 132., 134.],
         [156., 157., 156.,  ..., 121., 126., 130.]],

        [[160., 158., 157.,  ..., 194., 199., 204.],
         [159., 159., 158.,  ..., 202., 205., 207.],
         [158., 159., 159.,  ..., 209., 210., 210.],
         ...,
         [208., 213., 211.,  ..., 160., 161., 162.],
         [211., 217., 214.,  ..., 160., 160., 159.],
         [207., 211., 208.,  ..., 155., 159., 163.]],

        [[198., 198., 199.,  ..., 225., 131., 137.],
         [195., 195., 196.,  ..., 132., 136., 141.],
         [193., 193., 194.,  ..., 137., 140., 144.],
         ...,
         [141., 143., 141.,  ..., 219., 220., 218.],
         [145., 148., 145.,  ..., 213., 215., 215.],
         [142., 143., 141.,  ..., 194., 201., 208.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000238691.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [133, 832], 'neg_category_ids': [148, 806, 811, 305, 1128, 886, 1054, 155, 641, 958, 1037, 705, 19, 730, 1067], 'image_id': 238691, 'annotations': [{'bbox': [111.67, 17.31, 138.59, 189.17], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 813}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000238691.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [133, 832], 'neg_category_ids': [148, 806, 811, 305, 1128, 886, 1054, 155, 641, 958, 1037, 705, 19, 730, 1067], 'image_id': 238691, 'image': tensor([[[100., 100., 101.,  ..., 127., 127., 127.],
         [ 99., 100., 100.,  ..., 127., 127., 127.],
         [100., 100., 100.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 88.,  88.,  89.,  ..., 127., 127., 127.],
         [ 87.,  87.,  87.,  ..., 127., 127., 127.],
         [ 86.,  86.,  87.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 88.,  88.,  89.,  ..., 127., 127., 127.],
         [ 87.,  88.,  88.,  ..., 127., 127., 127.],
         [ 87.,  87.,  88.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[316.6638,  14.0644, 429.2681, 167.7650]])), gt_classes: tensor([813])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000579127.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [985, 1104, 612, 83, 1132, 524, 1014, 247, 162, 1161, 276], 'image_id': 579127, 'annotations': [{'bbox': [388.25, 282.43, 7.22, 15.99], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 813}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000579127.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [985, 1104, 612, 83, 1132, 524, 1014, 247, 162, 1161, 276], 'image_id': 579127, 'image': tensor([[[  1.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  1.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  1.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[285.0303, 328.7300, 293.4461, 347.3413]])), gt_classes: tensor([813])])}, len instances: 1
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000205614.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [630, 808, 351, 1151, 716, 613, 378, 598, 338], 'image_id': 205614, 'image': tensor([[[238., 238., 247.,  ..., 255., 255., 255.],
         [251., 244., 247.,  ..., 255., 255., 255.],
         [235., 235., 247.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[254., 247., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [254., 251., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [247., 247., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 87.3541, 140.3900, 148.8436, 249.1936]])), gt_classes: tensor([813])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000052066.jpg', 'height': 402, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [126, 415, 1101, 1170, 657, 724, 1179, 316, 755, 1183], 'image_id': 52066, 'image': tensor([[[245., 245., 245.,  ...,  93.,  84.,  80.],
         [245., 245., 245.,  ...,  87.,  81.,  73.],
         [245., 245., 245.,  ...,  68.,  73.,  58.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[236., 236., 236.,  ..., 122., 116., 113.],
         [236., 236., 236.,  ..., 112., 110., 103.],
         [236., 236., 236.,  ...,  82.,  92.,  80.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[227., 227., 227.,  ..., 127., 121., 121.],
         [227., 227., 227.,  ..., 119., 117., 111.],
         [227., 227., 227.,  ...,  92., 103.,  90.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[718.8149, 304.7627, 806.8531, 423.6803]])), gt_classes: tensor([813])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000238691.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [133, 832], 'neg_category_ids': [148, 806, 811, 305, 1128, 886, 1054, 155, 641, 958, 1037, 705, 19, 730, 1067], 'image_id': 238691, 'image': tensor([[[100., 100., 101.,  ..., 127., 127., 127.],
         [ 99., 100., 100.,  ..., 127., 127., 127.],
         [100., 100., 100.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 88.,  88.,  89.,  ..., 127., 127., 127.],
         [ 87.,  87.,  87.,  ..., 127., 127., 127.],
         [ 86.,  86.,  87.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 88.,  88.,  89.,  ..., 127., 127., 127.],
         [ 87.,  88.,  88.,  ..., 127., 127., 127.],
         [ 87.,  87.,  88.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[316.6638,  14.0644, 429.2681, 167.7650]])), gt_classes: tensor([813])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000579127.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [985, 1104, 612, 83, 1132, 524, 1014, 247, 162, 1161, 276], 'image_id': 579127, 'image': tensor([[[  1.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  1.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  1.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[285.0303, 328.7300, 293.4461, 347.3413]])), gt_classes: tensor([813])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000052066.jpg', 'height': 402, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [126, 415, 1101, 1170, 657, 724, 1179, 316, 755, 1183], 'image_id': 52066, 'image': tensor([[[245., 245., 245.,  ...,  93.,  84.,  80.],
         [245., 245., 245.,  ...,  87.,  81.,  73.],
         [245., 245., 245.,  ...,  68.,  73.,  58.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[236., 236., 236.,  ..., 122., 116., 113.],
         [236., 236., 236.,  ..., 112., 110., 103.],
         [236., 236., 236.,  ...,  82.,  92.,  80.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[227., 227., 227.,  ..., 127., 121., 121.],
         [227., 227., 227.,  ..., 119., 117., 111.],
         [227., 227., 227.,  ...,  92., 103.,  90.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[718.8149, 304.7627, 806.8531, 423.6803]])), gt_classes: tensor([813])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000026362.jpg', 'height': 640, 'width': 512, 'not_exhaustive_category_ids': [], 'neg_category_ids': [694, 4, 130, 223, 699, 59], 'image_id': 26362, 'annotations_cat_set': {378, 35, 1140, 94}, 'image': tensor([[[252., 249., 241.,  ..., 128., 128., 128.],
         [249., 247., 219.,  ..., 128., 128., 128.],
         [253., 242., 202.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 248., 236.,  ..., 128., 128., 128.],
         [250., 246., 216.,  ..., 128., 128., 128.],
         [254., 240., 199.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[253., 247., 232.,  ..., 128., 128., 128.],
         [248., 244., 211.,  ..., 128., 128., 128.],
         [250., 235., 193.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=7, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 14.4663, 251.9724,  29.3208, 288.9478],
        [ 53.7936, 249.2322,  70.7337, 275.6242],
        [ 88.8831, 310.9578, 151.4408, 364.2411],
        [262.6445, 123.0297, 520.1859, 580.2253],
        [311.4792,  92.8325, 338.9251, 148.8226],
        [387.4936, 282.6355, 497.4548, 346.9237],
        [287.6277, 373.7040, 297.7563, 398.8979]])), gt_classes: tensor([ 72,  72,  27, 813, 270, 270, 270])])}], 'support_set_target': tensor(813)}
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000074458.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [254, 688, 784, 711, 1170, 27, 903, 94, 57, 315, 384, 91, 234, 978, 647, 97], 'image_id': 74458, 'image': tensor([[[238., 242., 249.,  ..., 128., 128., 128.],
         [234., 242., 240.,  ..., 128., 128., 128.],
         [225., 233., 238.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[169., 166., 162.,  ..., 128., 128., 128.],
         [169., 169., 160.,  ..., 128., 128., 128.],
         [162., 158., 156.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 87.,  82.,  80.,  ..., 128., 128., 128.],
         [ 89.,  87.,  80.,  ..., 128., 128., 128.],
         [ 82.,  93.,  87.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[500.8150,  85.1195, 546.1740, 231.9237]])), gt_classes: tensor([254])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349791.jpg', 'height': 368, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [967, 1105, 717, 1179, 775, 68, 386, 407, 166], 'image_id': 349791, 'image': tensor([[[222., 224., 224.,  ..., 221., 222., 221.],
         [222., 224., 224.,  ..., 219., 220., 221.],
         [221., 223., 223.,  ..., 217., 218., 220.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[229., 231., 232.,  ..., 227., 229., 228.],
         [229., 231., 231.,  ..., 225., 227., 227.],
         [228., 230., 230.,  ..., 223., 224., 226.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[231., 232., 232.,  ..., 231., 232., 231.],
         [231., 232., 232.,  ..., 230., 231., 231.],
         [231., 233., 232.,  ..., 227., 228., 231.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 126.1827, 178.2828, 317.2082]])), gt_classes: tensor([254])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000238171.jpg', 'height': 466, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [146, 1169, 737, 221, 305, 1093, 1107, 676, 955, 874, 96, 731, 1000], 'image_id': 238171, 'image': tensor([[[29., 29., 29.,  ..., 27., 26., 27.],
         [29., 29., 29.,  ..., 28., 27., 27.],
         [29., 29., 29.,  ..., 29., 28., 29.],
         ...,
         [ 5.,  5.,  4.,  ..., 24., 25., 25.],
         [ 5.,  4.,  4.,  ..., 25., 25., 25.],
         [ 4.,  4.,  4.,  ..., 25., 25., 25.]],

        [[27., 27., 27.,  ..., 25., 24., 24.],
         [27., 27., 27.,  ..., 26., 25., 25.],
         [27., 27., 27.,  ..., 27., 26., 26.],
         ...,
         [ 5.,  5.,  4.,  ..., 30., 30., 30.],
         [ 5.,  4.,  3.,  ..., 30., 30., 30.],
         [ 5.,  4.,  4.,  ..., 30., 30., 30.]],

        [[26., 27., 27.,  ..., 23., 22., 22.],
         [26., 26., 27.,  ..., 24., 23., 23.],
         [26., 26., 26.,  ..., 25., 24., 25.],
         ...,
         [ 4.,  4.,  3.,  ..., 35., 35., 35.],
         [ 4.,  3.,  3.,  ..., 35., 35., 35.],
         [ 4.,  3.,  3.,  ..., 35., 35., 35.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 403.2955,    0.0000, 1024.0000,  566.4182]])), gt_classes: tensor([254])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000549873.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [350], 'neg_category_ids': [498, 941, 345, 125, 1007, 698, 1179, 493, 1043], 'image_id': 549873, 'image': tensor([[[228., 229., 232.,  ...,   0.,   0.,   0.],
         [229., 229., 232.,  ...,   0.,   0.,   0.],
         [230., 230., 231.,  ...,   0.,   0.,   0.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[219., 220., 221.,  ...,   0.,   0.,   0.],
         [219., 220., 221.,  ...,   0.,   0.,   0.],
         [220., 220., 220.,  ...,   0.,   0.,   0.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[199., 200., 201.,  ...,   0.,   0.,   0.],
         [199., 200., 201.,  ...,   0.,   0.,   0.],
         [200., 200., 200.,  ...,   0.,   0.,   0.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 58.5148, 136.9561, 199.6109, 726.4011]])), gt_classes: tensor([254])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000306095.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 220, 607, 240, 1007, 1105, 698, 863, 1139, 514], 'image_id': 306095, 'image': tensor([[[ 89.,  96., 111.,  ..., 128., 128., 128.],
         [ 93.,  81.,  93.,  ..., 128., 128., 128.],
         [ 96.,  90.,  96.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[122., 129., 144.,  ..., 128., 128., 128.],
         [126., 114., 126.,  ..., 128., 128., 128.],
         [129., 123., 129.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[145., 152., 167.,  ..., 128., 128., 128.],
         [149., 137., 149.,  ..., 128., 128., 128.],
         [152., 146., 152.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[478.8843,  46.6671, 527.5066, 305.3521]])), gt_classes: tensor([254])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000538223.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [50, 521, 522, 637, 337, 1059, 401, 680, 511, 144], 'image_id': 538223, 'annotations_cat_set': {961, 66, 68, 133, 694, 23, 350}, 'image': tensor([[[144., 143., 143.,  ..., 176., 177., 180.],
         [144., 142., 142.,  ..., 176., 177., 180.],
         [143., 141., 141.,  ..., 177., 178., 180.],
         ...,
         [139., 140., 141.,  ..., 229., 230., 229.],
         [141., 142., 144.,  ..., 229., 229., 229.],
         [142., 144., 145.,  ..., 229., 229., 229.]],

        [[150., 151., 151.,  ..., 179., 174., 176.],
         [150., 151., 151.,  ..., 179., 174., 176.],
         [151., 151., 151.,  ..., 179., 175., 177.],
         ...,
         [134., 134., 135.,  ..., 227., 227., 227.],
         [135., 136., 137.,  ..., 226., 226., 226.],
         [137., 137., 138.,  ..., 226., 226., 226.]],

        [[151., 152., 152.,  ..., 172., 170., 171.],
         [151., 152., 152.,  ..., 173., 170., 171.],
         [152., 151., 151.,  ..., 174., 171., 172.],
         ...,
         [135., 135., 135.,  ..., 214., 214., 214.],
         [136., 136., 136.,  ..., 213., 213., 213.],
         [138., 137., 137.,  ..., 214., 214., 214.]]]), 'instances': Instances(num_instances=10, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  838.3328,  295.2082, 1024.0000],
        [ 976.9077,    0.0000, 1024.0000,  595.8317],
        [ 725.8470,  406.2043,  808.8438,  616.3348],
        [ 656.3337,  403.8813,  736.3763,  603.9622],
        [ 887.5480,  395.6497,  967.7925,  578.5355],
        [ 863.5858,  438.8777,  911.3335,  574.0915],
        [ 751.4000,    0.0000, 1024.0000,  595.8065],
        [ 399.1625,  962.1588,  670.3980, 1024.0000],
        [   0.0000,  675.5964,  521.8522, 1024.0000],
        [ 282.1287,  541.7463, 1024.0000, 1024.0000]])), gt_classes: tensor([ 50, 254, 102, 102, 102, 102, 487,  17,  52, 674])])}], 'support_set_target': tensor(254)}
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000183646.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [666, 829, 1099, 819, 548, 356, 357, 271, 1090, 977], 'image_id': 183646, 'image': tensor([[[182., 182., 182.,  ..., 196., 195., 195.],
         [182., 182., 182.,  ..., 196., 195., 195.],
         [182., 182., 182.,  ..., 196., 196., 196.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[186., 186., 186.,  ..., 196., 195., 195.],
         [186., 186., 186.,  ..., 196., 195., 195.],
         [186., 186., 186.,  ..., 196., 196., 196.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[187., 187., 188.,  ..., 196., 195., 195.],
         [187., 187., 188.,  ..., 196., 195., 195.],
         [187., 187., 188.,  ..., 196., 196., 196.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[769.5848, 408.4316, 950.2162, 461.0758]])), gt_classes: tensor([599])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000275761.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1123, 711, 736, 348, 304, 587, 260, 612, 461, 990, 266, 158, 63, 401, 1200, 428, 514, 235], 'image_id': 275761, 'image': tensor([[[35., 35., 35.,  ..., 24., 24., 24.],
         [35., 35., 35.,  ..., 24., 24., 24.],
         [35., 35., 35.,  ..., 24., 24., 24.],
         ...,
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.]],

        [[34., 34., 34.,  ..., 24., 24., 24.],
         [34., 34., 34.,  ..., 24., 24., 24.],
         [34., 34., 34.,  ..., 24., 24., 24.],
         ...,
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.]],

        [[33., 33., 33.,  ..., 24., 24., 24.],
         [33., 33., 33.,  ..., 24., 24., 24.],
         [33., 33., 33.,  ..., 24., 24., 24.],
         ...,
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[347.5537, 195.9397, 385.9748, 205.2906]])), gt_classes: tensor([599])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000209179.jpg', 'height': 560, 'width': 640, 'not_exhaustive_category_ids': [846], 'neg_category_ids': [1075, 969, 507, 989, 291, 250, 1202, 97], 'image_id': 209179, 'image': tensor([[[ 16.,  16.,  14.,  ..., 193., 193., 193.],
         [ 16.,  16.,  15.,  ..., 192., 192., 192.],
         [ 17.,  15.,  16.,  ..., 192., 192., 192.],
         ...,
         [ 74.,  74.,  86.,  ...,  75.,  74.,  74.],
         [ 74.,  74.,  86.,  ...,  75.,  74.,  74.],
         [ 86.,  86.,  86.,  ...,  75.,  74.,  74.]],

        [[ 25.,  25.,  25.,  ...,  91.,  91.,  91.],
         [ 23.,  25.,  24.,  ...,  90.,  90.,  90.],
         [ 19.,  22.,  21.,  ...,  90.,  90.,  90.],
         ...,
         [ 80.,  80., 103.,  ...,  71.,  80.,  80.],
         [ 80.,  80., 103.,  ...,  71.,  80.,  80.],
         [103., 103., 103.,  ...,  71.,  80.,  80.]],

        [[ 33.,  33.,  31.,  ...,  42.,  42.,  42.],
         [ 31.,  31.,  30.,  ...,  60.,  60.,  60.],
         [ 30.,  30.,  29.,  ...,  60.,  60.,  60.],
         ...,
         [121., 121., 141.,  ..., 160., 121., 121.],
         [121., 121., 141.,  ..., 160., 121., 121.],
         [141., 141., 141.,  ..., 160., 121., 121.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[235.1392, 625.0234, 418.5672, 787.3690]])), gt_classes: tensor([599])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000466901.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1024, 194, 668, 348, 765, 697, 592, 837, 1036, 291, 444, 1116, 1139], 'image_id': 466901, 'image': tensor([[[ 11.,  13.,  16.,  ..., 128., 128., 128.],
         [  5.,   6.,  14.,  ..., 128., 128., 128.],
         [  1.,   3.,   5.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 19.,  21.,  24.,  ..., 128., 128., 128.],
         [ 10.,  12.,  20.,  ..., 128., 128., 128.],
         [  4.,   6.,  10.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 18.,  20.,  23.,  ..., 128., 128., 128.],
         [  9.,  11.,  19.,  ..., 128., 128., 128.],
         [  4.,   5.,   9.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[297.0447, 332.1521, 529.1776, 414.2586]])), gt_classes: tensor([599])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000275761.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1123, 711, 736, 348, 304, 587, 260, 612, 461, 990, 266, 158, 63, 401, 1200, 428, 514, 235], 'image_id': 275761, 'image': tensor([[[35., 35., 35.,  ..., 24., 24., 24.],
         [35., 35., 35.,  ..., 24., 24., 24.],
         [35., 35., 35.,  ..., 24., 24., 24.],
         ...,
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.]],

        [[34., 34., 34.,  ..., 24., 24., 24.],
         [34., 34., 34.,  ..., 24., 24., 24.],
         [34., 34., 34.,  ..., 24., 24., 24.],
         ...,
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.]],

        [[33., 33., 33.,  ..., 24., 24., 24.],
         [33., 33., 33.,  ..., 24., 24., 24.],
         [33., 33., 33.,  ..., 24., 24., 24.],
         ...,
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.],
         [24., 24., 24.,  ..., 24., 24., 24.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[347.5537, 195.9397, 385.9748, 205.2906]])), gt_classes: tensor([599])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000549708.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [434, 415, 418, 569, 642, 996, 513, 1020], 'image_id': 549708, 'annotations_cat_set': {1178, 436, 846}, 'image': tensor([[[150., 150., 150.,  ..., 150., 150., 149.],
         [150., 150., 150.,  ..., 150., 150., 149.],
         [150., 150., 150.,  ..., 150., 150., 150.],
         ...,
         [140., 140., 140.,  ..., 140., 140., 140.],
         [140., 140., 140.,  ..., 140., 140., 140.],
         [140., 140., 140.,  ..., 140., 140., 140.]],

        [[149., 149., 149.,  ..., 148., 148., 148.],
         [149., 149., 149.,  ..., 148., 148., 148.],
         [149., 149., 149.,  ..., 148., 148., 148.],
         ...,
         [140., 140., 140.,  ..., 140., 140., 140.],
         [140., 140., 140.,  ..., 140., 140., 140.],
         [140., 140., 140.,  ..., 140., 140., 140.]],

        [[148., 148., 148.,  ..., 148., 148., 147.],
         [148., 148., 148.,  ..., 148., 148., 147.],
         [148., 148., 148.,  ..., 148., 148., 148.],
         ...,
         [140., 140., 140.,  ..., 140., 140., 140.],
         [140., 140., 140.,  ..., 140., 140., 140.],
         [140., 140., 140.,  ..., 140., 140., 140.]]]), 'instances': Instances(num_instances=10, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,   45.4257, 1024.0000,  672.0675],
        [ 985.6047,  405.2877, 1024.0000,  466.8907],
        [ 143.5952,  486.8622,  270.1073,  588.4083],
        [ 596.7859,  483.5267,  737.2738,  586.0525],
        [ 521.1707,  546.7767,  587.8998,  599.6448],
        [ 903.0641,  481.6296,  960.5943,  515.0057],
        [ 431.5380,  571.1885,  471.8174,  614.4879],
        [ 568.0000,  592.8903,  600.7284,  671.4629],
        [ 464.3080,  617.6150,  505.8599,  672.7137],
        [ 267.1661,  594.2662,  297.1828,  669.8577]])), gt_classes: tensor([308, 599, 599, 599, 599, 599, 599, 841, 841, 841])])}], 'support_set_target': tensor(599)}
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000072275.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [519, 898, 413, 501, 544, 658, 1178, 403, 404, 553, 1139, 318, 535], 'image_id': 72275, 'image': tensor([[[  0.,   3.,  13.,  ..., 157., 157., 157.],
         [  3.,  18.,  28.,  ..., 157., 157., 157.],
         [  8.,  28.,  28.,  ..., 157., 157., 157.],
         ...,
         [157., 157., 157.,  ..., 157., 157., 157.],
         [157., 157., 157.,  ..., 157., 157., 157.],
         [157., 157., 157.,  ..., 157., 157., 157.]],

        [[  3.,   0.,   0.,  ..., 140., 140., 140.],
         [  2.,   3.,   2.,  ..., 140., 140., 140.],
         [  1.,   3.,   2.,  ..., 140., 140., 140.],
         ...,
         [140., 140., 140.,  ..., 140., 140., 140.],
         [140., 140., 140.,  ..., 140., 140., 140.],
         [140., 140., 140.,  ..., 140., 140., 140.]],

        [[  1.,  14.,  18.,  ...,  97.,  97.,  97.],
         [  3.,  15.,  15.,  ...,  97.,  97.,  97.],
         [  2.,   8.,   8.,  ...,  97.,  97.,  97.],
         ...,
         [ 97.,  97.,  97.,  ...,  97.,  97.,  97.],
         [ 97.,  97.,  97.,  ...,  97.,  97.,  97.],
         [ 97.,  97.,  97.,  ...,  97.,  97.,  97.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[277.5760, 463.3211, 393.0474, 581.3331]])), gt_classes: tensor([549])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000146917.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1117, 735, 143, 774], 'neg_category_ids': [732, 517, 852, 373, 480, 55, 375, 264, 837, 35, 1083, 529, 250, 19], 'image_id': 146917, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ..., 128.,   0., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[819.0489, 674.8860, 900.0660, 718.3296]])), gt_classes: tensor([549])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000215910.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1025, 45], 'neg_category_ids': [1023, 583, 651, 1006, 378, 495, 387], 'image_id': 215910, 'image': tensor([[[ 92.,  61.,  54.,  ...,  45.,  47.,  48.],
         [ 97.,  85.,  75.,  ...,  47.,  48.,  52.],
         [110., 136., 118.,  ...,  52.,  54.,  57.],
         ...,
         [223., 223., 223.,  ..., 223., 223., 223.],
         [223., 223., 223.,  ..., 223., 223., 223.],
         [223., 223., 223.,  ..., 223., 223., 223.]],

        [[ 85.,  45.,  27.,  ...,  20.,  20.,  22.],
         [ 90.,  71.,  50.,  ...,  22.,  22.,  24.],
         [ 99., 124.,  99.,  ...,  24.,  26.,  29.],
         ...,
         [223., 223., 223.,  ..., 223., 223., 223.],
         [223., 223., 223.,  ..., 223., 223., 223.],
         [223., 223., 223.,  ..., 223., 223., 223.]],

        [[ 99., 113., 146.,  ...,  10.,  10.,  12.],
         [ 96., 118., 152.,  ...,   8.,   8.,  12.],
         [ 89., 131., 160.,  ...,   6.,   6.,  10.],
         ...,
         [223., 223., 223.,  ..., 223., 223., 223.],
         [223., 223., 223.,  ..., 223., 223., 223.],
         [223., 223., 223.,  ..., 223., 223., 223.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 987.9899,  194.3973, 1024.0000,  233.0538]])), gt_classes: tensor([549])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000143017.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [774, 735, 510, 613, 12], 'neg_category_ids': [585, 521, 309, 640, 746, 618, 1088, 1066], 'image_id': 143017, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [  0.,   0., 128.,  ...,   0.,   0.,   0.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[161.9341, 460.7906, 231.0372, 521.4797]])), gt_classes: tensor([549])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000146917.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1117, 735, 143, 774], 'neg_category_ids': [732, 517, 852, 373, 480, 55, 375, 264, 837, 35, 1083, 529, 250, 19], 'image_id': 146917, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ..., 128.,   0., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[819.0489, 674.8860, 900.0660, 718.3296]])), gt_classes: tensor([549])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000184813.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [1055, 61, 774], 'neg_category_ids': [254, 446, 314, 841, 444, 294, 295, 273], 'image_id': 184813, 'annotations_cat_set': {61, 774, 1055}, 'image': tensor([[[108., 109., 110.,  ..., 202., 202., 202.],
         [109., 108., 109.,  ..., 202., 202., 202.],
         [109., 107., 107.,  ..., 202., 202., 202.],
         ...,
         [158., 159., 158.,  ...,  89.,  88.,  88.],
         [150., 153., 153.,  ...,  86.,  86.,  87.],
         [141., 146., 149.,  ...,  83.,  84.,  85.]],

        [[109., 110., 110.,  ..., 239., 239., 239.],
         [110., 109., 109.,  ..., 239., 239., 239.],
         [110., 108., 107.,  ..., 239., 239., 239.],
         ...,
         [217., 216., 214.,  ...,  95.,  93.,  91.],
         [211., 212., 211.,  ...,  94.,  93.,  92.],
         [205., 207., 208.,  ...,  94.,  93.,  92.]],

        [[120., 121., 122.,  ..., 237., 237., 237.],
         [121., 120., 121.,  ..., 237., 237., 237.],
         [121., 119., 119.,  ..., 237., 237., 237.],
         ...,
         [244., 243., 241.,  ..., 114., 113., 112.],
         [235., 236., 235.,  ..., 115., 115., 114.],
         [227., 228., 229.,  ..., 116., 116., 116.]]]), 'instances': Instances(num_instances=13, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 588.5752,  854.6193,  669.5574, 1024.0000],
        [   7.1578,  993.3296,   30.0986, 1024.0000],
        [  92.4650,  865.7762,  155.8969, 1000.0363],
        [ 130.0103, 1017.3986,  156.5551, 1024.0000],
        [ 214.1889,  892.0704,  286.6468, 1014.9228],
        [ 394.9887,  913.1621,  456.4776,  938.7355],
        [ 169.9684, 1021.8488,  188.6471, 1024.0000],
        [  30.7254, 1003.8284,   65.8575, 1024.0000],
        [ 862.7676,  891.5377,  993.7370, 1024.0000],
        [  18.6910,  892.6032,   72.3135,  990.4463],
        [   0.0000,  899.3726,   14.3034,  966.7534],
        [  19.1296,  901.9738,   47.2102,  972.7079],
        [ 106.5054, 1015.2988,  135.0246, 1024.0000]])), gt_classes: tensor([740, 740, 740, 740, 740, 740, 740, 740, 740, 740, 740, 740, 740])])}], 'support_set_target': tensor(549)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000089734.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [101, 211, 1109, 1134, 494, 683, 1092], 'image_id': 89734, 'annotations': [{'bbox': [256.0, 80.98, 106.9, 246.82], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 330}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000089734.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [101, 211, 1109, 1134, 494, 683, 1092], 'image_id': 89734, 'image': tensor([[[101.,  97.,  94.,  ..., 118., 117., 115.],
         [ 98.,  95.,  93.,  ..., 117., 116., 114.],
         [ 97.,  95.,  94.,  ..., 116., 116., 114.],
         ...,
         [119., 119., 119.,  ..., 178., 176., 174.],
         [119., 117., 115.,  ..., 175., 173., 172.],
         [118., 114., 112.,  ..., 172., 170., 169.]],

        [[ 88.,  85.,  82.,  ..., 105., 103., 101.],
         [ 86.,  84.,  82.,  ..., 106., 104., 101.],
         [ 86.,  84.,  83.,  ..., 105., 104., 101.],
         ...,
         [ 74.,  74.,  75.,  ..., 145., 143., 141.],
         [ 74.,  72.,  72.,  ..., 140., 139., 137.],
         [ 73.,  71.,  70.,  ..., 138., 137., 135.]],

        [[ 76.,  72.,  69.,  ...,  96.,  93.,  90.],
         [ 73.,  70.,  68.,  ...,  96.,  93.,  90.],
         [ 72.,  70.,  68.,  ...,  95.,  93.,  90.],
         ...,
         [103., 104., 106.,  ..., 172., 171., 170.],
         [103., 102., 103.,  ..., 168., 167., 167.],
         [102., 100., 100.,  ..., 165., 164., 164.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 105.9484,  108.1360,  533.9760, 1024.0000]])), gt_classes: tensor([330])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000486910.jpg', 'height': 510, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [148, 829, 1096, 325, 795, 526, 1183], 'image_id': 486910, 'annotations': [{'bbox': [13.4, 7.63, 438.92, 451.15], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 330}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000486910.jpg', 'height': 510, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [148, 829, 1096, 325, 795, 526, 1183], 'image_id': 486910, 'image': tensor([[[156., 150., 141.,  ..., 127., 122., 122.],
         [145., 139., 132.,  ..., 111., 106., 106.],
         [136., 131., 124.,  ..., 106., 102., 102.],
         ...,
         [192., 177., 131.,  ...,  91.,  73.,  57.],
         [194., 184., 143.,  ...,  73.,  42.,  29.],
         [177., 179., 157.,  ...,  73.,  45.,  35.]],

        [[153., 147., 138.,  ...,  55.,  52.,  50.],
         [142., 136., 127.,  ...,  48.,  44.,  44.],
         [134., 127., 119.,  ...,  44.,  41.,  41.],
         ...,
         [196., 174., 117.,  ...,  73.,  52.,  46.],
         [203., 181., 127.,  ...,  55.,  28.,  23.],
         [194., 183., 147.,  ...,  57.,  32.,  28.]],

        [[228., 226., 219.,  ...,  12.,  12.,  12.],
         [222., 219., 211.,  ...,  10.,   9.,   9.],
         [215., 209., 203.,  ...,   9.,   9.,   9.],
         ...,
         [129.,  98.,  46.,  ...,  17.,  10.,   7.],
         [132., 101.,  48.,  ...,  10.,   3.,   2.],
         [132., 118.,  76.,  ...,  11.,   4.,   4.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.,    0., 1024., 1024.]])), gt_classes: tensor([330])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000527504.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1094, 1185, 218, 1051, 263, 66, 387], 'image_id': 527504, 'annotations': [{'bbox': [347.24, 120.27, 119.43, 224.65], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 330}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000527504.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1094, 1185, 218, 1051, 263, 66, 387], 'image_id': 527504, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [  0.,   0., 128.,  ...,   0., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[482.6228, 232.7987, 811.9883, 852.5591]])), gt_classes: tensor([330])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000073669.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [517, 416, 972, 951, 1179, 871, 495], 'image_id': 73669, 'annotations': [{'bbox': [290.69, 161.46, 141.29, 234.88], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 330}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000073669.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [517, 416, 972, 951, 1179, 871, 495], 'image_id': 73669, 'image': tensor([[[253., 253., 253.,  ..., 128., 128., 128.],
         [253., 254., 254.,  ..., 128., 128., 128.],
         [253., 254., 254.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[232., 232., 232.,  ..., 128., 128., 128.],
         [232., 233., 233.,  ..., 128., 128., 128.],
         [232., 233., 233.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[181., 181., 181.,  ..., 128., 128., 128.],
         [181., 182., 182.,  ..., 128., 128., 128.],
         [181., 182., 182.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[283.4273, 220.0696, 475.9349, 540.2105]])), gt_classes: tensor([330])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000086094.jpg', 'height': 418, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 603, 127, 79, 55, 612, 1056, 1063], 'image_id': 86094, 'annotations': [{'bbox': [84.07, 48.53, 496.51, 368.4], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 330}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000086094.jpg', 'height': 418, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 603, 127, 79, 55, 612, 1056, 1063], 'image_id': 86094, 'image': tensor([[[  6.,   6.,   6.,  ...,  12.,   5.,   3.],
         [  8.,   7.,   5.,  ...,   8.,   4.,   3.],
         [ 12.,   8.,   4.,  ...,   1.,   1.,   4.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 20.,  19.,  18.,  ...,  35.,  31.,  29.],
         [ 22.,  20.,  19.,  ...,  30.,  28.,  27.],
         [ 25.,  23.,  20.,  ...,  23.,  24.,  24.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 37.,  34.,  30.,  ...,  66.,  65.,  57.],
         [ 38.,  36.,  32.,  ...,  57.,  56.,  53.],
         [ 41.,  39.,  36.,  ...,  44.,  43.,  47.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 59.6479,  85.2178, 931.6437, 732.1211]])), gt_classes: tensor([330])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000089734.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [101, 211, 1109, 1134, 494, 683, 1092], 'image_id': 89734, 'image': tensor([[[101.,  97.,  94.,  ..., 118., 117., 115.],
         [ 98.,  95.,  93.,  ..., 117., 116., 114.],
         [ 97.,  95.,  94.,  ..., 116., 116., 114.],
         ...,
         [119., 119., 119.,  ..., 178., 176., 174.],
         [119., 117., 115.,  ..., 175., 173., 172.],
         [118., 114., 112.,  ..., 172., 170., 169.]],

        [[ 88.,  85.,  82.,  ..., 105., 103., 101.],
         [ 86.,  84.,  82.,  ..., 106., 104., 101.],
         [ 86.,  84.,  83.,  ..., 105., 104., 101.],
         ...,
         [ 74.,  74.,  75.,  ..., 145., 143., 141.],
         [ 74.,  72.,  72.,  ..., 140., 139., 137.],
         [ 73.,  71.,  70.,  ..., 138., 137., 135.]],

        [[ 76.,  72.,  69.,  ...,  96.,  93.,  90.],
         [ 73.,  70.,  68.,  ...,  96.,  93.,  90.],
         [ 72.,  70.,  68.,  ...,  95.,  93.,  90.],
         ...,
         [103., 104., 106.,  ..., 172., 171., 170.],
         [103., 102., 103.,  ..., 168., 167., 167.],
         [102., 100., 100.,  ..., 165., 164., 164.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 105.9484,  108.1360,  533.9760, 1024.0000]])), gt_classes: tensor([330])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000486910.jpg', 'height': 510, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [148, 829, 1096, 325, 795, 526, 1183], 'image_id': 486910, 'image': tensor([[[156., 150., 141.,  ..., 127., 122., 122.],
         [145., 139., 132.,  ..., 111., 106., 106.],
         [136., 131., 124.,  ..., 106., 102., 102.],
         ...,
         [192., 177., 131.,  ...,  91.,  73.,  57.],
         [194., 184., 143.,  ...,  73.,  42.,  29.],
         [177., 179., 157.,  ...,  73.,  45.,  35.]],

        [[153., 147., 138.,  ...,  55.,  52.,  50.],
         [142., 136., 127.,  ...,  48.,  44.,  44.],
         [134., 127., 119.,  ...,  44.,  41.,  41.],
         ...,
         [196., 174., 117.,  ...,  73.,  52.,  46.],
         [203., 181., 127.,  ...,  55.,  28.,  23.],
         [194., 183., 147.,  ...,  57.,  32.,  28.]],

        [[228., 226., 219.,  ...,  12.,  12.,  12.],
         [222., 219., 211.,  ...,  10.,   9.,   9.],
         [215., 209., 203.,  ...,   9.,   9.,   9.],
         ...,
         [129.,  98.,  46.,  ...,  17.,  10.,   7.],
         [132., 101.,  48.,  ...,  10.,   3.,   2.],
         [132., 118.,  76.,  ...,  11.,   4.,   4.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.,    0., 1024., 1024.]])), gt_classes: tensor([330])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000527504.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1094, 1185, 218, 1051, 263, 66, 387], 'image_id': 527504, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [  0.,   0., 128.,  ...,   0., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[482.6228, 232.7987, 811.9883, 852.5591]])), gt_classes: tensor([330])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000073669.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [517, 416, 972, 951, 1179, 871, 495], 'image_id': 73669, 'image': tensor([[[253., 253., 253.,  ..., 128., 128., 128.],
         [253., 254., 254.,  ..., 128., 128., 128.],
         [253., 254., 254.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[232., 232., 232.,  ..., 128., 128., 128.],
         [232., 233., 233.,  ..., 128., 128., 128.],
         [232., 233., 233.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[181., 181., 181.,  ..., 128., 128., 128.],
         [181., 182., 182.,  ..., 128., 128., 128.],
         [181., 182., 182.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[283.4273, 220.0696, 475.9349, 540.2105]])), gt_classes: tensor([330])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000086094.jpg', 'height': 418, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 603, 127, 79, 55, 612, 1056, 1063], 'image_id': 86094, 'image': tensor([[[  6.,   6.,   6.,  ...,  12.,   5.,   3.],
         [  8.,   7.,   5.,  ...,   8.,   4.,   3.],
         [ 12.,   8.,   4.,  ...,   1.,   1.,   4.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 20.,  19.,  18.,  ...,  35.,  31.,  29.],
         [ 22.,  20.,  19.,  ...,  30.,  28.,  27.],
         [ 25.,  23.,  20.,  ...,  23.,  24.,  24.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 37.,  34.,  30.,  ...,  66.,  65.,  57.],
         [ 38.,  36.,  32.,  ...,  57.,  56.,  53.],
         [ 41.,  39.,  36.,  ...,  44.,  43.,  47.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 59.6479,  85.2178, 931.6437, 732.1211]])), gt_classes: tensor([330])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000453442.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [941, 3, 289, 35, 19, 191], 'image_id': 453442, 'annotations_cat_set': {463}, 'image': tensor([[[ 51.,  55.,  60.,  ..., 128., 128., 128.],
         [ 54.,  60.,  70.,  ..., 128., 128., 128.],
         [ 58.,  69.,  82.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 66.,  70.,  75.,  ..., 128., 128., 128.],
         [ 69.,  75.,  85.,  ..., 128., 128., 128.],
         [ 74.,  84.,  96.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 69.,  73.,  78.,  ..., 128., 128., 128.],
         [ 72.,  78.,  88.,  ..., 128., 128., 128.],
         [ 77.,  87., 100.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[363.9683, 205.9596, 684.5956, 452.7313]])), gt_classes: tensor([330])])}], 'support_set_target': tensor(330)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000569389.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [573, 515], 'neg_category_ids': [457, 105, 260, 1102, 655, 1034, 1137, 141, 1067], 'image_id': 569389, 'annotations': [{'bbox': [181.66, 302.49, 43.58, 47.17], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 407}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000569389.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [573, 515], 'neg_category_ids': [457, 105, 260, 1102, 655, 1034, 1137, 141, 1067], 'image_id': 569389, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[408.8868, 626.0156, 510.8166, 736.4229]])), gt_classes: tensor([407])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000132494.jpg', 'height': 640, 'width': 359, 'not_exhaustive_category_ids': [], 'neg_category_ids': [303, 305, 233, 509, 1109, 821, 976, 580], 'image_id': 132494, 'annotations': [{'bbox': [182.88, 209.72, 45.17, 145.58], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 407}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000132494.jpg', 'height': 640, 'width': 359, 'not_exhaustive_category_ids': [], 'neg_category_ids': [303, 305, 233, 509, 1109, 821, 976, 580], 'image_id': 132494, 'image': tensor([[[255., 255., 250.,  ..., 136., 136., 136.],
         [255., 255., 255.,  ..., 136., 136., 136.],
         [253., 255., 255.,  ..., 136., 136., 136.],
         ...,
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.]],

        [[255., 250., 226.,  ..., 136., 136., 136.],
         [244., 242., 233.,  ..., 136., 136., 136.],
         [231., 239., 239.,  ..., 136., 136., 136.],
         ...,
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.]],

        [[253., 233., 211.,  ..., 136., 136., 136.],
         [241., 237., 230.,  ..., 136., 136., 136.],
         [233., 241., 241.,  ..., 136., 136., 136.],
         ...,
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[178.3692, 286.0712, 239.8960, 484.6514]])), gt_classes: tensor([407])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000021451.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [734, 55, 523, 268, 524, 1065], 'image_id': 21451, 'annotations': [{'bbox': [424.57, 0.83, 67.01, 85.52], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 407}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000021451.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [734, 55, 523, 268, 524, 1065], 'image_id': 21451, 'image': tensor([[[113., 114., 113.,  ..., 138., 136., 136.],
         [114., 114., 113.,  ..., 137., 134., 136.],
         [114., 113., 113.,  ..., 140., 137., 137.],
         ...,
         [139., 143., 148.,  ..., 143., 142., 141.],
         [141., 144., 147.,  ..., 147., 146., 146.],
         [143., 143., 145.,  ..., 150., 149., 150.]],

        [[113., 114., 113.,  ..., 144., 143., 143.],
         [114., 114., 113.,  ..., 143., 141., 143.],
         [114., 113., 113.,  ..., 145., 142., 143.],
         ...,
         [143., 147., 152.,  ..., 154., 153., 152.],
         [145., 148., 151.,  ..., 159., 158., 157.],
         [147., 147., 149.,  ..., 165., 164., 163.]],

        [[113., 114., 113.,  ..., 139., 138., 138.],
         [114., 114., 113.,  ..., 138., 136., 138.],
         [114., 113., 113.,  ..., 140., 137., 138.],
         ...,
         [144., 148., 153.,  ..., 162., 161., 160.],
         [146., 149., 152.,  ..., 168., 167., 166.],
         [148., 148., 150.,  ..., 173., 172., 171.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[134.5107,   0.0000, 287.7961, 163.5256]])), gt_classes: tensor([407])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000527828.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [1180, 108, 872], 'neg_category_ids': [964, 1, 500, 171, 502, 78, 586, 306, 225, 33, 932, 863, 353, 526, 445, 960, 556], 'image_id': 527828, 'annotations': [{'bbox': [183.06, 33.95, 12.6, 27.58], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 407}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000527828.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [1180, 108, 872], 'neg_category_ids': [964, 1, 500, 171, 502, 78, 586, 306, 225, 33, 932, 863, 353, 526, 445, 960, 556], 'image_id': 527828, 'image': tensor([[[120., 120., 119.,  ..., 130., 130., 132.],
         [120., 119., 119.,  ..., 130., 130., 132.],
         [119., 119., 118.,  ..., 130., 130., 132.],
         ...,
         [139., 139., 139.,  ..., 186., 188., 191.],
         [139., 139., 139.,  ..., 186., 189., 191.],
         [138., 138., 138.,  ..., 186., 189., 190.]],

        [[106., 106., 105.,  ..., 130., 128., 129.],
         [106., 105., 105.,  ..., 130., 130., 130.],
         [105., 105., 104.,  ..., 131., 131., 131.],
         ...,
         [179., 179., 179.,  ..., 134., 139., 144.],
         [179., 179., 179.,  ..., 135., 139., 144.],
         [178., 178., 178.,  ..., 134., 139., 143.]],

        [[140., 140., 139.,  ..., 167., 168., 170.],
         [140., 139., 139.,  ..., 168., 169., 170.],
         [139., 139., 138.,  ..., 168., 170., 171.],
         ...,
         [147., 147., 147.,  ..., 193., 196., 198.],
         [147., 147., 147.,  ..., 193., 196., 199.],
         [146., 146., 146.,  ..., 193., 196., 198.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[833.5679,   0.0000, 862.1238,  29.4479]])), gt_classes: tensor([407])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000490286.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [920, 255, 237, 239, 57, 461, 288, 1054, 398, 228, 1036, 1035, 83, 551, 491, 272, 19], 'image_id': 490286, 'annotations': [{'bbox': [108.87, 65.24, 29.69, 102.58], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 407}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000490286.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [920, 255, 237, 239, 57, 461, 288, 1054, 398, 228, 1036, 1035, 83, 551, 491, 272, 19], 'image_id': 490286, 'image': tensor([[[195., 196., 201.,  ..., 111., 101.,  96.],
         [193., 195., 196.,  ..., 111., 101.,  95.],
         [189., 188., 188.,  ..., 111., 101.,  96.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[190., 193., 201.,  ..., 106.,  96.,  91.],
         [193., 195., 200.,  ..., 106.,  96.,  92.],
         [196., 197., 199.,  ..., 107.,  98.,  93.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 64.,  65.,  70.,  ...,  70.,  53.,  44.],
         [ 65.,  67.,  69.,  ...,  70.,  53.,  45.],
         [ 69.,  68.,  70.,  ...,  69.,  55.,  46.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[164.4873, 127.8976, 222.7075, 328.9971]])), gt_classes: tensor([407])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000416660.jpg', 'height': 640, 'width': 519, 'not_exhaustive_category_ids': [598, 271], 'neg_category_ids': [807, 692, 831, 694, 29, 439, 817, 767, 81, 114, 442, 748, 552], 'image_id': 416660, 'annotations': [{'bbox': [359.04, 444.33, 19.38, 4.76], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 423}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000416660.jpg', 'height': 640, 'width': 519, 'not_exhaustive_category_ids': [598, 271], 'neg_category_ids': [807, 692, 831, 694, 29, 439, 817, 767, 81, 114, 442, 748, 552], 'image_id': 416660, 'image': tensor([[[229., 225., 223.,  ..., 194., 191., 204.],
         [231., 227., 223.,  ..., 177., 171., 163.],
         [233., 229., 224.,  ..., 161., 151., 119.],
         ...,
         [238., 239., 237.,  ..., 172., 184., 173.],
         [239., 239., 237.,  ..., 183., 208., 199.],
         [237., 237., 238.,  ...,  93., 110., 125.]],

        [[229., 225., 223.,  ..., 194., 191., 204.],
         [231., 227., 223.,  ..., 177., 171., 163.],
         [233., 229., 224.,  ..., 161., 151., 119.],
         ...,
         [238., 239., 237.,  ..., 172., 184., 173.],
         [239., 239., 237.,  ..., 183., 208., 199.],
         [237., 237., 238.,  ...,  93., 110., 125.]],

        [[229., 225., 223.,  ..., 194., 191., 204.],
         [231., 227., 223.,  ..., 177., 171., 163.],
         [233., 229., 224.,  ..., 161., 151., 119.],
         ...,
         [238., 239., 237.,  ..., 172., 184., 173.],
         [239., 239., 237.,  ..., 183., 208., 199.],
         [237., 237., 238.,  ...,  93., 110., 125.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[755.5121, 926.9528, 796.4006, 937.0009]])), gt_classes: tensor([423])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000251508.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [630, 123, 1186, 652, 175, 903, 522, 505, 504, 211, 721, 1155, 748, 750, 493, 682, 708], 'image_id': 251508, 'annotations': [{'bbox': [171.98, 404.33, 52.12, 74.38], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 423}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000251508.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [630, 123, 1186, 652, 175, 903, 522, 505, 504, 211, 721, 1155, 748, 750, 493, 682, 708], 'image_id': 251508, 'image': tensor([[[ 59.,  68.,  83.,  ...,  50.,  50.,  50.],
         [ 65.,  74.,  88.,  ...,  50.,  50.,  50.],
         [ 68.,  81.,  92.,  ...,  50.,  50.,  50.],
         ...,
         [123., 141., 141.,  ...,  48.,  48.,  46.],
         [114., 136., 140.,  ...,  48.,  48.,  46.],
         [107., 129., 136.,  ...,  48.,  48.,  48.]],

        [[ 61.,  68.,  83.,  ...,  50.,  50.,  50.],
         [ 65.,  76.,  90.,  ...,  50.,  50.,  50.],
         [ 68.,  83.,  96.,  ...,  50.,  50.,  50.],
         ...,
         [125., 145., 145.,  ...,  48.,  46.,  46.],
         [116., 140., 143.,  ...,  48.,  48.,  46.],
         [108., 132., 140.,  ...,  48.,  48.,  48.]],

        [[ 65.,  76.,  96.,  ...,  50.,  50.,  50.],
         [ 72.,  87., 105.,  ...,  50.,  50.,  50.],
         [ 77.,  97., 114.,  ...,  50.,  50.,  50.],
         ...,
         [127., 145., 147.,  ...,  48.,  48.,  48.],
         [118., 141., 145.,  ...,  48.,  48.,  48.],
         [108., 134., 140.,  ...,  48.,  48.,  48.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[475.2013, 522.7380, 613.5364, 720.0775]])), gt_classes: tensor([423])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000416660.jpg', 'height': 640, 'width': 519, 'not_exhaustive_category_ids': [598, 271], 'neg_category_ids': [807, 692, 831, 694, 29, 439, 817, 767, 81, 114, 442, 748, 552], 'image_id': 416660, 'annotations': [{'bbox': [408.63, 443.44, 12.71, 3.29], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 423}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000416660.jpg', 'height': 640, 'width': 519, 'not_exhaustive_category_ids': [598, 271], 'neg_category_ids': [807, 692, 831, 694, 29, 439, 817, 767, 81, 114, 442, 748, 552], 'image_id': 416660, 'image': tensor([[[136., 136., 136.,  ..., 119., 119., 119.],
         [136., 137., 137.,  ..., 119., 119., 119.],
         [136., 135., 136.,  ..., 119., 119., 119.],
         ...,
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.]],

        [[136., 136., 136.,  ..., 119., 119., 119.],
         [136., 137., 137.,  ..., 119., 119., 119.],
         [136., 135., 136.,  ..., 119., 119., 119.],
         ...,
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.]],

        [[136., 136., 136.,  ..., 119., 119., 119.],
         [136., 137., 137.,  ..., 119., 119., 119.],
         [136., 135., 136.,  ..., 119., 119., 119.],
         ...,
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[429.8882, 466.3049, 443.2594, 469.7645]])), gt_classes: tensor([423])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000416660.jpg', 'height': 640, 'width': 519, 'not_exhaustive_category_ids': [598, 271], 'neg_category_ids': [807, 692, 831, 694, 29, 439, 817, 767, 81, 114, 442, 748, 552], 'image_id': 416660, 'annotations': [{'bbox': [460.32, 473.86, 26.76, 8.19], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 423}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000416660.jpg', 'height': 640, 'width': 519, 'not_exhaustive_category_ids': [598, 271], 'neg_category_ids': [807, 692, 831, 694, 29, 439, 817, 767, 81, 114, 442, 748, 552], 'image_id': 416660, 'image': tensor([[[229., 227., 227.,  ..., 128., 128., 128.],
         [230., 230., 230.,  ..., 128., 128., 128.],
         [231., 230., 230.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[229., 227., 227.,  ..., 128., 128., 128.],
         [230., 230., 230.,  ..., 128., 128., 128.],
         [231., 230., 230.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[229., 227., 227.,  ..., 128., 128., 128.],
         [230., 230., 230.,  ..., 128., 128., 128.],
         [231., 230., 230.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[688.2627, 708.5688, 728.2738, 720.8154]])), gt_classes: tensor([423])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000079720.jpg', 'height': 496, 'width': 640, 'not_exhaustive_category_ids': [1045], 'neg_category_ids': [921, 1, 1147, 1128, 59, 440, 1195, 446, 1181, 1018], 'image_id': 79720, 'annotations': [{'bbox': [451.58, 326.17, 3.14, 7.61], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 423}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000079720.jpg', 'height': 496, 'width': 640, 'not_exhaustive_category_ids': [1045], 'neg_category_ids': [921, 1, 1147, 1128, 59, 440, 1195, 446, 1181, 1018], 'image_id': 79720, 'image': tensor([[[206., 206., 206.,  ...,  49.,  51.,  48.],
         [206., 206., 206.,  ...,  49.,  50.,  48.],
         [206., 206., 206.,  ...,  49.,  50.,  48.],
         ...,
         [136., 145., 153.,  ..., 135., 136., 137.],
         [117., 128., 137.,  ..., 137., 138., 138.],
         [112., 117., 122.,  ..., 136., 138., 137.]],

        [[179., 179., 179.,  ...,  72.,  71.,  71.],
         [179., 179., 179.,  ...,  72.,  72.,  72.],
         [179., 179., 179.,  ...,  73.,  72.,  72.],
         ...,
         [139., 147., 155.,  ..., 158., 160., 161.],
         [120., 131., 140.,  ..., 160., 162., 162.],
         [116., 121., 125.,  ..., 159., 162., 161.]],

        [[158., 159., 159.,  ..., 106., 106., 106.],
         [158., 158., 158.,  ..., 106., 107., 106.],
         [158., 158., 158.,  ..., 107., 107., 107.],
         ...,
         [145., 153., 160.,  ..., 205., 206., 206.],
         [127., 137., 145.,  ..., 207., 208., 207.],
         [123., 127., 130.,  ..., 206., 208., 206.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[846.2218, 715.7820, 855.4505, 738.1517]])), gt_classes: tensor([423])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000569389.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [573, 515], 'neg_category_ids': [457, 105, 260, 1102, 655, 1034, 1137, 141, 1067], 'image_id': 569389, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[408.8868, 626.0156, 510.8166, 736.4229]])), gt_classes: tensor([407])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000132494.jpg', 'height': 640, 'width': 359, 'not_exhaustive_category_ids': [], 'neg_category_ids': [303, 305, 233, 509, 1109, 821, 976, 580], 'image_id': 132494, 'image': tensor([[[255., 255., 250.,  ..., 136., 136., 136.],
         [255., 255., 255.,  ..., 136., 136., 136.],
         [253., 255., 255.,  ..., 136., 136., 136.],
         ...,
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.]],

        [[255., 250., 226.,  ..., 136., 136., 136.],
         [244., 242., 233.,  ..., 136., 136., 136.],
         [231., 239., 239.,  ..., 136., 136., 136.],
         ...,
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.]],

        [[253., 233., 211.,  ..., 136., 136., 136.],
         [241., 237., 230.,  ..., 136., 136., 136.],
         [233., 241., 241.,  ..., 136., 136., 136.],
         ...,
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[178.3692, 286.0712, 239.8960, 484.6514]])), gt_classes: tensor([407])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000021451.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [734, 55, 523, 268, 524, 1065], 'image_id': 21451, 'image': tensor([[[113., 114., 113.,  ..., 138., 136., 136.],
         [114., 114., 113.,  ..., 137., 134., 136.],
         [114., 113., 113.,  ..., 140., 137., 137.],
         ...,
         [139., 143., 148.,  ..., 143., 142., 141.],
         [141., 144., 147.,  ..., 147., 146., 146.],
         [143., 143., 145.,  ..., 150., 149., 150.]],

        [[113., 114., 113.,  ..., 144., 143., 143.],
         [114., 114., 113.,  ..., 143., 141., 143.],
         [114., 113., 113.,  ..., 145., 142., 143.],
         ...,
         [143., 147., 152.,  ..., 154., 153., 152.],
         [145., 148., 151.,  ..., 159., 158., 157.],
         [147., 147., 149.,  ..., 165., 164., 163.]],

        [[113., 114., 113.,  ..., 139., 138., 138.],
         [114., 114., 113.,  ..., 138., 136., 138.],
         [114., 113., 113.,  ..., 140., 137., 138.],
         ...,
         [144., 148., 153.,  ..., 162., 161., 160.],
         [146., 149., 152.,  ..., 168., 167., 166.],
         [148., 148., 150.,  ..., 173., 172., 171.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[134.5107,   0.0000, 287.7961, 163.5256]])), gt_classes: tensor([407])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000527828.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [1180, 108, 872], 'neg_category_ids': [964, 1, 500, 171, 502, 78, 586, 306, 225, 33, 932, 863, 353, 526, 445, 960, 556], 'image_id': 527828, 'image': tensor([[[120., 120., 119.,  ..., 130., 130., 132.],
         [120., 119., 119.,  ..., 130., 130., 132.],
         [119., 119., 118.,  ..., 130., 130., 132.],
         ...,
         [139., 139., 139.,  ..., 186., 188., 191.],
         [139., 139., 139.,  ..., 186., 189., 191.],
         [138., 138., 138.,  ..., 186., 189., 190.]],

        [[106., 106., 105.,  ..., 130., 128., 129.],
         [106., 105., 105.,  ..., 130., 130., 130.],
         [105., 105., 104.,  ..., 131., 131., 131.],
         ...,
         [179., 179., 179.,  ..., 134., 139., 144.],
         [179., 179., 179.,  ..., 135., 139., 144.],
         [178., 178., 178.,  ..., 134., 139., 143.]],

        [[140., 140., 139.,  ..., 167., 168., 170.],
         [140., 139., 139.,  ..., 168., 169., 170.],
         [139., 139., 138.,  ..., 168., 170., 171.],
         ...,
         [147., 147., 147.,  ..., 193., 196., 198.],
         [147., 147., 147.,  ..., 193., 196., 199.],
         [146., 146., 146.,  ..., 193., 196., 198.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[833.5679,   0.0000, 862.1238,  29.4479]])), gt_classes: tensor([407])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000490286.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [920, 255, 237, 239, 57, 461, 288, 1054, 398, 228, 1036, 1035, 83, 551, 491, 272, 19], 'image_id': 490286, 'image': tensor([[[195., 196., 201.,  ..., 111., 101.,  96.],
         [193., 195., 196.,  ..., 111., 101.,  95.],
         [189., 188., 188.,  ..., 111., 101.,  96.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[190., 193., 201.,  ..., 106.,  96.,  91.],
         [193., 195., 200.,  ..., 106.,  96.,  92.],
         [196., 197., 199.,  ..., 107.,  98.,  93.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 64.,  65.,  70.,  ...,  70.,  53.,  44.],
         [ 65.,  67.,  69.,  ...,  70.,  53.,  45.],
         [ 69.,  68.,  70.,  ...,  69.,  55.,  46.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[164.4873, 127.8976, 222.7075, 328.9971]])), gt_classes: tensor([407])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000442214.jpg', 'height': 640, 'width': 481, 'not_exhaustive_category_ids': [387], 'neg_category_ids': [193, 760, 126, 305, 176, 84, 62, 114, 270, 271, 576, 165, 846, 625, 648, 515], 'image_id': 442214, 'annotations_cat_set': {898, 771, 387, 708, 1093, 615, 297, 556, 143, 338, 658, 378, 573}, 'image': tensor([[[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=42, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1.9929e+02, 2.7673e+02, 2.9289e+02, 3.3171e+02],
        [2.1081e+02, 3.3527e+02, 2.9419e+02, 4.0976e+02],
        [1.5971e+02, 3.9170e+02, 1.6679e+02, 3.9536e+02],
        [1.5712e+02, 3.7441e+02, 1.6118e+02, 3.7826e+02],
        [1.4953e+02, 3.5579e+02, 1.5065e+02, 3.5734e+02],
        [1.8777e+02, 3.7700e+02, 1.9490e+02, 3.7903e+02],
        [1.5931e+02, 3.4669e+02, 1.6936e+02, 3.5175e+02],
        [1.4551e+02, 3.3369e+02, 1.5223e+02, 3.3982e+02],
        [1.5176e+02, 3.5153e+02, 1.5270e+02, 3.5332e+02],
        [1.8573e+02, 1.0775e+02, 2.2182e+02, 2.1649e+02],
        [1.4844e+02, 8.7361e+01, 2.2620e+02, 1.2227e+02],
        [1.7216e+01, 0.0000e+00, 1.5583e+02, 2.2714e+02],
        [3.2922e+02, 8.1258e+01, 4.3396e+02, 1.6953e+02],
        [1.8546e+02, 1.0808e+02, 2.2180e+02, 2.1670e+02],
        [2.2291e+02, 1.2180e+01, 3.5776e+02, 1.4649e+02],
        [2.4707e+02, 1.6135e+02, 2.8567e+02, 1.8659e+02],
        [2.1337e+02, 1.4851e+02, 2.7517e+02, 1.8718e+02],
        [1.4918e+02, 3.6582e+02, 2.1523e+02, 4.5081e+02],
        [2.7962e+01, 2.4145e+02, 1.0464e+02, 3.2067e+02],
        [2.8471e+02, 1.9058e+02, 3.5187e+02, 2.5444e+02],
        [2.0638e+02, 2.5538e+02, 2.5502e+02, 2.8587e+02],
        [2.2378e+02, 2.3311e+02, 2.7521e+02, 2.6405e+02],
        [1.5451e+02, 2.1464e+02, 1.9556e+02, 2.4095e+02],
        [1.6655e+02, 2.3645e+02, 2.1613e+02, 2.7194e+02],
        [1.2746e+02, 2.3874e+02, 1.7081e+02, 2.7238e+02],
        [1.9528e+02, 2.1162e+02, 2.7110e+02, 2.4599e+02],
        [1.4872e+02, 2.5947e+02, 1.9910e+02, 2.9480e+02],
        [0.0000e+00, 1.7522e+02, 5.0014e+01, 2.2756e+02],
        [1.5795e+02, 3.0159e+02, 2.2744e+02, 3.7274e+02],
        [2.1723e+02, 3.3115e+02, 2.8422e+02, 4.0621e+02],
        [1.2637e+02, 2.2555e+02, 1.7072e+02, 2.5421e+02],
        [1.5880e+01, 4.1991e+02, 1.0803e+02, 5.0089e+02],
        [1.5452e+02, 2.1467e+02, 1.9555e+02, 2.4094e+02],
        [2.2371e+02, 2.3351e+02, 2.7617e+02, 2.6368e+02],
        [2.0637e+02, 2.5527e+02, 2.5502e+02, 2.8585e+02],
        [1.2812e+02, 2.3876e+02, 1.7147e+02, 2.7211e+02],
        [1.6725e+02, 2.3643e+02, 2.1664e+02, 2.7246e+02],
        [1.8680e+02, 2.3405e+02, 2.2151e+02, 2.5852e+02],
        [1.2601e+02, 2.2557e+02, 1.6977e+02, 2.5436e+02],
        [2.1738e+02, 3.3128e+02, 2.8410e+02, 4.0672e+02],
        [1.4864e+02, 2.5942e+02, 1.9895e+02, 2.9479e+02],
        [3.2484e-01, 1.7461e+02, 4.9211e+01, 2.2706e+02]])), gt_classes: tensor([773, 773, 244, 244, 244, 244, 244, 244, 244, 217, 464, 631, 397, 407,
        109, 109, 109, 435, 500, 500, 547, 547, 547, 547, 547, 547, 547, 547,
        547, 547, 547, 270, 277, 277, 277, 277, 277, 277, 277, 277, 277, 277])])}], 'support_set_target': tensor(407)}
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000416660.jpg', 'height': 640, 'width': 519, 'not_exhaustive_category_ids': [598, 271], 'neg_category_ids': [807, 692, 831, 694, 29, 439, 817, 767, 81, 114, 442, 748, 552], 'image_id': 416660, 'image': tensor([[[229., 225., 223.,  ..., 194., 191., 204.],
         [231., 227., 223.,  ..., 177., 171., 163.],
         [233., 229., 224.,  ..., 161., 151., 119.],
         ...,
         [238., 239., 237.,  ..., 172., 184., 173.],
         [239., 239., 237.,  ..., 183., 208., 199.],
         [237., 237., 238.,  ...,  93., 110., 125.]],

        [[229., 225., 223.,  ..., 194., 191., 204.],
         [231., 227., 223.,  ..., 177., 171., 163.],
         [233., 229., 224.,  ..., 161., 151., 119.],
         ...,
         [238., 239., 237.,  ..., 172., 184., 173.],
         [239., 239., 237.,  ..., 183., 208., 199.],
         [237., 237., 238.,  ...,  93., 110., 125.]],

        [[229., 225., 223.,  ..., 194., 191., 204.],
         [231., 227., 223.,  ..., 177., 171., 163.],
         [233., 229., 224.,  ..., 161., 151., 119.],
         ...,
         [238., 239., 237.,  ..., 172., 184., 173.],
         [239., 239., 237.,  ..., 183., 208., 199.],
         [237., 237., 238.,  ...,  93., 110., 125.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[755.5121, 926.9528, 796.4006, 937.0009]])), gt_classes: tensor([423])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000251508.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [630, 123, 1186, 652, 175, 903, 522, 505, 504, 211, 721, 1155, 748, 750, 493, 682, 708], 'image_id': 251508, 'image': tensor([[[ 59.,  68.,  83.,  ...,  50.,  50.,  50.],
         [ 65.,  74.,  88.,  ...,  50.,  50.,  50.],
         [ 68.,  81.,  92.,  ...,  50.,  50.,  50.],
         ...,
         [123., 141., 141.,  ...,  48.,  48.,  46.],
         [114., 136., 140.,  ...,  48.,  48.,  46.],
         [107., 129., 136.,  ...,  48.,  48.,  48.]],

        [[ 61.,  68.,  83.,  ...,  50.,  50.,  50.],
         [ 65.,  76.,  90.,  ...,  50.,  50.,  50.],
         [ 68.,  83.,  96.,  ...,  50.,  50.,  50.],
         ...,
         [125., 145., 145.,  ...,  48.,  46.,  46.],
         [116., 140., 143.,  ...,  48.,  48.,  46.],
         [108., 132., 140.,  ...,  48.,  48.,  48.]],

        [[ 65.,  76.,  96.,  ...,  50.,  50.,  50.],
         [ 72.,  87., 105.,  ...,  50.,  50.,  50.],
         [ 77.,  97., 114.,  ...,  50.,  50.,  50.],
         ...,
         [127., 145., 147.,  ...,  48.,  48.,  48.],
         [118., 141., 145.,  ...,  48.,  48.,  48.],
         [108., 134., 140.,  ...,  48.,  48.,  48.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[475.2013, 522.7380, 613.5364, 720.0775]])), gt_classes: tensor([423])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000416660.jpg', 'height': 640, 'width': 519, 'not_exhaustive_category_ids': [598, 271], 'neg_category_ids': [807, 692, 831, 694, 29, 439, 817, 767, 81, 114, 442, 748, 552], 'image_id': 416660, 'image': tensor([[[136., 136., 136.,  ..., 119., 119., 119.],
         [136., 137., 137.,  ..., 119., 119., 119.],
         [136., 135., 136.,  ..., 119., 119., 119.],
         ...,
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.]],

        [[136., 136., 136.,  ..., 119., 119., 119.],
         [136., 137., 137.,  ..., 119., 119., 119.],
         [136., 135., 136.,  ..., 119., 119., 119.],
         ...,
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.]],

        [[136., 136., 136.,  ..., 119., 119., 119.],
         [136., 137., 137.,  ..., 119., 119., 119.],
         [136., 135., 136.,  ..., 119., 119., 119.],
         ...,
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.],
         [119., 119., 119.,  ..., 119., 119., 119.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[429.8882, 466.3049, 443.2594, 469.7645]])), gt_classes: tensor([423])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000416660.jpg', 'height': 640, 'width': 519, 'not_exhaustive_category_ids': [598, 271], 'neg_category_ids': [807, 692, 831, 694, 29, 439, 817, 767, 81, 114, 442, 748, 552], 'image_id': 416660, 'image': tensor([[[229., 227., 227.,  ..., 128., 128., 128.],
         [230., 230., 230.,  ..., 128., 128., 128.],
         [231., 230., 230.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[229., 227., 227.,  ..., 128., 128., 128.],
         [230., 230., 230.,  ..., 128., 128., 128.],
         [231., 230., 230.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[229., 227., 227.,  ..., 128., 128., 128.],
         [230., 230., 230.,  ..., 128., 128., 128.],
         [231., 230., 230.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[688.2627, 708.5688, 728.2738, 720.8154]])), gt_classes: tensor([423])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000079720.jpg', 'height': 496, 'width': 640, 'not_exhaustive_category_ids': [1045], 'neg_category_ids': [921, 1, 1147, 1128, 59, 440, 1195, 446, 1181, 1018], 'image_id': 79720, 'image': tensor([[[206., 206., 206.,  ...,  49.,  51.,  48.],
         [206., 206., 206.,  ...,  49.,  50.,  48.],
         [206., 206., 206.,  ...,  49.,  50.,  48.],
         ...,
         [136., 145., 153.,  ..., 135., 136., 137.],
         [117., 128., 137.,  ..., 137., 138., 138.],
         [112., 117., 122.,  ..., 136., 138., 137.]],

        [[179., 179., 179.,  ...,  72.,  71.,  71.],
         [179., 179., 179.,  ...,  72.,  72.,  72.],
         [179., 179., 179.,  ...,  73.,  72.,  72.],
         ...,
         [139., 147., 155.,  ..., 158., 160., 161.],
         [120., 131., 140.,  ..., 160., 162., 162.],
         [116., 121., 125.,  ..., 159., 162., 161.]],

        [[158., 159., 159.,  ..., 106., 106., 106.],
         [158., 158., 158.,  ..., 106., 107., 106.],
         [158., 158., 158.,  ..., 107., 107., 107.],
         ...,
         [145., 153., 160.,  ..., 205., 206., 206.],
         [127., 137., 145.,  ..., 207., 208., 207.],
         [123., 127., 130.,  ..., 206., 208., 206.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[846.2218, 715.7820, 855.4505, 738.1517]])), gt_classes: tensor([423])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000011156.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [409, 146, 598, 788], 'neg_category_ids': [1001, 101, 1126, 24, 669, 413, 26, 174, 285, 18, 1136, 491, 823, 532, 45], 'image_id': 11156, 'annotations_cat_set': {288, 3, 1156, 296, 715, 782, 146, 598, 409}, 'image': tensor([[[ 29.,  31.,  35.,  ..., 128., 128., 128.],
         [ 33.,  35.,  38.,  ..., 128., 128., 128.],
         [ 41.,  42.,  43.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 24.,  26.,  30.,  ..., 131., 131., 131.],
         [ 28.,  30.,  34.,  ..., 131., 131., 131.],
         [ 37.,  38.,  39.,  ..., 131., 131., 131.],
         ...,
         [131., 131., 131.,  ..., 131., 131., 131.],
         [131., 131., 131.,  ..., 131., 131., 131.],
         [131., 131., 131.,  ..., 131., 131., 131.]],

        [[ 20.,  22.,  26.,  ..., 132., 132., 132.],
         [ 24.,  26.,  30.,  ..., 132., 132., 132.],
         [ 33.,  34.,  35.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]]]), 'instances': Instances(num_instances=23, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[530.1595, 640.1844, 591.3245, 711.0000],
        [338.3791, 263.0131, 423.9456, 324.9175],
        [620.1058, 157.6903, 945.2887, 497.0554],
        [  0.0000,   0.0000, 286.2770,  98.7247],
        [106.6879, 292.0030, 244.0910, 382.7076],
        [117.1538, 273.2894, 243.8635, 346.4940],
        [123.6572, 276.1145, 259.1263, 372.0142],
        [ 90.5150, 283.0349, 156.1166, 382.1198],
        [121.7611, 265.5348, 228.3922, 351.7838],
        [422.3150, 404.8529, 480.4085, 453.6938],
        [417.1389, 484.8831, 454.1299, 523.2581],
        [412.5316, 426.5242, 441.1613, 456.5568],
        [470.8526, 436.4402, 513.2093, 474.2465],
        [451.5893, 503.6155, 490.9882, 541.8768],
        [407.6021, 508.4693, 447.9490, 546.0859],
        [446.8303, 467.7053, 503.4638, 514.9536],
        [435.5302, 450.0535, 476.2183, 484.3711],
        [193.3731, 352.8077, 309.4272, 422.4099],
        [108.4702, 341.3748, 198.2647, 381.8734],
        [191.2495, 352.6371, 307.1141, 421.0258],
        [122.9746, 276.6833, 258.5196, 371.9383],
        [409.7446, 235.5780, 716.7639, 380.7357],
        [457.6755, 267.2412, 624.4666, 347.0249]])), gt_classes: tensor([292,   2, 824, 216, 111, 111, 111, 111, 111, 212, 212, 212, 212, 212,
        212, 212, 212, 504, 423, 423, 423, 555, 555])])}], 'support_set_target': tensor(423)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000576040.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [781], 'neg_category_ids': [1184, 734, 92, 375, 57, 592, 113, 291, 96, 801, 1043], 'image_id': 576040, 'annotations': [{'bbox': [549.05, 291.4, 73.68, 51.11], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 292}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000576040.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [781], 'neg_category_ids': [1184, 734, 92, 375, 57, 592, 113, 291, 96, 801, 1043], 'image_id': 576040, 'image': tensor([[[10., 10., 10.,  ...,  8.,  7.,  7.],
         [10., 10., 10.,  ...,  8.,  8.,  7.],
         [10., 10.,  9.,  ...,  8.,  8.,  7.],
         ...,
         [28., 28., 28.,  ..., 26., 26., 26.],
         [28., 28., 28.,  ..., 26., 26., 26.],
         [28., 28., 28.,  ..., 26., 26., 26.]],

        [[10., 10., 11.,  ...,  8.,  8.,  8.],
         [10., 10., 10.,  ...,  8.,  8.,  8.],
         [10., 10., 10.,  ...,  8.,  8.,  8.],
         ...,
         [29., 29., 29.,  ..., 26., 26., 26.],
         [29., 29., 29.,  ..., 26., 26., 26.],
         [29., 29., 29.,  ..., 26., 26., 26.]],

        [[14., 14., 14.,  ..., 10., 10.,  9.],
         [14., 14., 13.,  ..., 10., 10., 10.],
         [14., 13., 13.,  ..., 10., 10., 10.],
         ...,
         [30., 30., 30.,  ..., 26., 26., 26.],
         [29., 30., 30.,  ..., 26., 26., 26.],
         [29., 30., 30.,  ..., 26., 26., 26.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000237337.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [388, 477, 880, 589, 289, 229, 1084], 'image_id': 237337, 'annotations': [{'bbox': [0.0, 185.31, 70.85, 91.29], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 292}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000237337.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [388, 477, 880, 589, 289, 229, 1084], 'image_id': 237337, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000450674.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [323, 926, 1174, 991, 570, 312, 113, 993, 334, 1038, 184, 243, 164, 1091, 496, 1120], 'image_id': 450674, 'annotations': [{'bbox': [532.17, 104.7, 21.41, 30.36], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 292}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000450674.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [323, 926, 1174, 991, 570, 312, 113, 993, 334, 1038, 184, 243, 164, 1091, 496, 1120], 'image_id': 450674, 'image': tensor([[[ 16.,  14.,  14.,  ...,  33.,  30.,  27.],
         [ 16.,  15.,  14.,  ...,  28.,  28.,  29.],
         [ 17.,  16.,  14.,  ...,  26.,  28.,  31.],
         ...,
         [184., 180., 177.,  ..., 161., 165., 170.],
         [195., 189., 180.,  ..., 154., 165., 172.],
         [188., 183., 174.,  ..., 149., 158., 165.]],

        [[ 16.,  14.,  14.,  ...,  33.,  30.,  27.],
         [ 16.,  15.,  14.,  ...,  28.,  28.,  29.],
         [ 17.,  16.,  14.,  ...,  26.,  28.,  31.],
         ...,
         [184., 180., 177.,  ..., 161., 165., 170.],
         [195., 189., 180.,  ..., 154., 165., 172.],
         [188., 183., 174.,  ..., 149., 158., 165.]],

        [[ 16.,  14.,  14.,  ...,  33.,  30.,  27.],
         [ 16.,  15.,  14.,  ...,  28.,  28.,  29.],
         [ 17.,  16.,  14.,  ...,  26.,  28.,  31.],
         ...,
         [184., 180., 177.,  ..., 161., 165., 170.],
         [195., 189., 180.,  ..., 154., 165., 172.],
         [188., 183., 174.,  ..., 149., 158., 165.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[174.5355, 259.7162, 228.4284, 336.1863]])), gt_classes: tensor([292])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000519432.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [104, 565, 263, 115, 444, 384], 'image_id': 519432, 'annotations': [{'bbox': [170.21, 146.57, 48.57, 57.29], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 292}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000519432.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [104, 565, 263, 115, 444, 384], 'image_id': 519432, 'image': tensor([[[144., 134., 128.,  ..., 128., 128., 128.],
         [139., 131., 127.,  ..., 128., 128., 128.],
         [136., 129., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 125., 127.,  ..., 128., 128., 128.],
         [126., 124., 127.,  ..., 128., 128., 128.],
         [125., 123., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[122., 121., 126.,  ..., 128., 128., 128.],
         [122., 122., 127.,  ..., 128., 128., 128.],
         [125., 123., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[196.0075, 168.8609, 251.9388, 234.8637]])), gt_classes: tensor([292])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000188311.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [127, 409, 782, 685], 'neg_category_ids': [712, 1099, 502, 481, 396, 84, 1194, 1082, 331, 243, 1158, 404, 248, 916, 386, 145, 756], 'image_id': 188311, 'annotations': [{'bbox': [263.85, 269.14, 156.43, 210.86], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 292}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000188311.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [127, 409, 782, 685], 'neg_category_ids': [712, 1099, 502, 481, 396, 84, 1194, 1082, 331, 243, 1158, 404, 248, 916, 386, 145, 756], 'image_id': 188311, 'image': tensor([[[179., 189., 197.,  ..., 233., 233., 234.],
         [183., 192., 198.,  ..., 230., 231., 232.],
         [187., 193., 198.,  ..., 226., 228., 229.],
         ...,
         [124., 123., 122.,  ..., 218., 217., 218.],
         [125., 124., 123.,  ..., 219., 218., 219.],
         [125., 124., 123.,  ..., 220., 219., 220.]],

        [[199., 214., 223.,  ..., 223., 222., 223.],
         [204., 216., 224.,  ..., 222., 222., 223.],
         [208., 218., 223.,  ..., 222., 223., 224.],
         ...,
         [117., 117., 117.,  ..., 220., 219., 220.],
         [116., 116., 116.,  ..., 222., 220., 221.],
         [116., 116., 116.,  ..., 224., 221., 222.]],

        [[208., 216., 222.,  ..., 234., 235., 237.],
         [210., 217., 222.,  ..., 233., 234., 236.],
         [212., 218., 221.,  ..., 230., 231., 233.],
         ...,
         [103., 103., 103.,  ..., 231., 229., 231.],
         [103., 103., 103.,  ..., 230., 230., 233.],
         [104., 103., 103.,  ..., 230., 231., 235.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  427.8374,  333.9253, 1024.0000]])), gt_classes: tensor([292])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000573963.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [45], 'neg_category_ids': [711, 392, 715, 593, 309, 1065, 429, 580], 'image_id': 573963, 'annotations': [{'bbox': [0.0, 284.44, 176.67, 117.82], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 645}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000573963.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [45], 'neg_category_ids': [711, 392, 715, 593, 309, 1065, 429, 580], 'image_id': 573963, 'image': tensor([[[ 40.,  40.,  39.,  ..., 128., 128., 128.],
         [ 39.,  39.,  40.,  ..., 128., 128., 128.],
         [ 39.,  39.,  40.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 26.,  26.,  25.,  ..., 128., 128., 128.],
         [ 25.,  25.,  26.,  ..., 128., 128., 128.],
         [ 25.,  25.,  26.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 45.,  45.,  44.,  ..., 128., 128., 128.],
         [ 44.,  44.,  45.,  ..., 128., 128., 128.],
         [ 44.,  44.,  45.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 345.8683, 215.0405, 489.1331]])), gt_classes: tensor([645])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000517451.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 1072, 761, 855, 839, 616, 530], 'image_id': 517451, 'annotations': [{'bbox': [62.55, 420.37, 81.41, 79.03], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 645}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000517451.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 1072, 761, 855, 839, 616, 530], 'image_id': 517451, 'image': tensor([[[183., 184., 190.,  ..., 255., 255., 255.],
         [188., 184., 187.,  ..., 255., 255., 255.],
         [180., 174., 176.,  ..., 255., 255., 255.],
         ...,
         [193., 184., 173.,  ..., 253., 254., 254.],
         [196., 195., 194.,  ..., 252., 253., 253.],
         [194., 194., 193.,  ..., 254., 255., 255.]],

        [[142., 141., 144.,  ..., 211., 213., 213.],
         [140., 134., 135.,  ..., 213., 214., 214.],
         [139., 132., 132.,  ..., 213., 214., 214.],
         ...,
         [178., 173., 168.,  ..., 212., 211., 211.],
         [181., 186., 187.,  ..., 213., 212., 212.],
         [181., 183., 186.,  ..., 217., 216., 218.]],

        [[122., 114., 121.,  ..., 194., 194., 194.],
         [127., 119., 122.,  ..., 194., 195., 193.],
         [128., 120., 122.,  ..., 194., 193., 193.],
         ...,
         [174., 167., 158.,  ..., 184., 185., 185.],
         [179., 180., 179.,  ..., 187., 190., 190.],
         [179., 179., 180.,  ..., 193., 196., 196.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 149.6764,  891.3972,  347.0861, 1024.0000]])), gt_classes: tensor([645])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000069293.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [366, 1002, 1095, 303, 416, 588, 5, 203, 440, 1135, 381, 995, 41, 449, 98, 342], 'image_id': 69293, 'annotations': [{'bbox': [395.33, 416.71, 125.83, 63.29], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 645}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000069293.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [366, 1002, 1095, 303, 416, 588, 5, 203, 440, 1135, 381, 995, 41, 449, 98, 342], 'image_id': 69293, 'image': tensor([[[164., 161., 156.,  ..., 128., 128., 128.],
         [155., 153., 152.,  ..., 128., 128., 128.],
         [152., 152., 153.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[195., 192., 190.,  ..., 128., 128., 128.],
         [194., 192., 192.,  ..., 128., 128., 128.],
         [192., 190., 190.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[132., 129., 219.,  ..., 128., 128., 128.],
         [134., 132., 130.,  ..., 128., 128., 128.],
         [135., 134., 134.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[139.4513, 488.7661, 287.1050, 563.0000]])), gt_classes: tensor([645])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000373765.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [745, 1160, 879, 471], 'image_id': 373765, 'annotations': [{'bbox': [161.7, 191.39, 75.47, 42.98], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 645}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000373765.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [745, 1160, 879, 471], 'image_id': 373765, 'image': tensor([[[211., 210., 215.,  ..., 128., 128., 128.],
         [218., 219., 223.,  ..., 128., 128., 128.],
         [225., 129., 134.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[175., 171., 170.,  ..., 128., 128., 128.],
         [184., 182., 180.,  ..., 128., 128., 128.],
         [192., 193., 194.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[166., 161., 159.,  ..., 128., 128., 128.],
         [174., 171., 167.,  ..., 128., 128., 128.],
         [180., 181., 179.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[609.9098, 289.9984, 724.1761, 355.1227]])), gt_classes: tensor([645])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000560360.jpg', 'height': 514, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [480, 176, 1104, 1132, 1035, 335, 727, 14, 891, 779], 'image_id': 560360, 'annotations': [{'bbox': [10.59, 191.26, 44.31, 208.88], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 645}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000560360.jpg', 'height': 514, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [480, 176, 1104, 1132, 1035, 335, 727, 14, 891, 779], 'image_id': 560360, 'image': tensor([[[165., 174., 191.,  ..., 152., 163., 184.],
         [164., 175., 193.,  ..., 156., 166., 185.],
         [163., 176., 196.,  ..., 163., 172., 187.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[167., 177., 194.,  ..., 159., 168., 188.],
         [167., 178., 196.,  ..., 163., 172., 190.],
         [168., 180., 200.,  ..., 172., 179., 193.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[176., 184., 200.,  ..., 166., 176., 195.],
         [174., 184., 202.,  ..., 170., 179., 197.],
         [171., 184., 205.,  ..., 179., 186., 200.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 378.7990,  47.7706, 792.4952]])), gt_classes: tensor([645])])}, len instances: 1
not 0
entering support set: 2
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000450674.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [323, 926, 1174, 991, 570, 312, 113, 993, 334, 1038, 184, 243, 164, 1091, 496, 1120], 'image_id': 450674, 'image': tensor([[[ 16.,  14.,  14.,  ...,  33.,  30.,  27.],
         [ 16.,  15.,  14.,  ...,  28.,  28.,  29.],
         [ 17.,  16.,  14.,  ...,  26.,  28.,  31.],
         ...,
         [184., 180., 177.,  ..., 161., 165., 170.],
         [195., 189., 180.,  ..., 154., 165., 172.],
         [188., 183., 174.,  ..., 149., 158., 165.]],

        [[ 16.,  14.,  14.,  ...,  33.,  30.,  27.],
         [ 16.,  15.,  14.,  ...,  28.,  28.,  29.],
         [ 17.,  16.,  14.,  ...,  26.,  28.,  31.],
         ...,
         [184., 180., 177.,  ..., 161., 165., 170.],
         [195., 189., 180.,  ..., 154., 165., 172.],
         [188., 183., 174.,  ..., 149., 158., 165.]],

        [[ 16.,  14.,  14.,  ...,  33.,  30.,  27.],
         [ 16.,  15.,  14.,  ...,  28.,  28.,  29.],
         [ 17.,  16.,  14.,  ...,  26.,  28.,  31.],
         ...,
         [184., 180., 177.,  ..., 161., 165., 170.],
         [195., 189., 180.,  ..., 154., 165., 172.],
         [188., 183., 174.,  ..., 149., 158., 165.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[174.5355, 259.7162, 228.4284, 336.1863]])), gt_classes: tensor([292])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000519432.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [104, 565, 263, 115, 444, 384], 'image_id': 519432, 'image': tensor([[[144., 134., 128.,  ..., 128., 128., 128.],
         [139., 131., 127.,  ..., 128., 128., 128.],
         [136., 129., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 125., 127.,  ..., 128., 128., 128.],
         [126., 124., 127.,  ..., 128., 128., 128.],
         [125., 123., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[122., 121., 126.,  ..., 128., 128., 128.],
         [122., 122., 127.,  ..., 128., 128., 128.],
         [125., 123., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[196.0075, 168.8609, 251.9388, 234.8637]])), gt_classes: tensor([292])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000188311.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [127, 409, 782, 685], 'neg_category_ids': [712, 1099, 502, 481, 396, 84, 1194, 1082, 331, 243, 1158, 404, 248, 916, 386, 145, 756], 'image_id': 188311, 'image': tensor([[[179., 189., 197.,  ..., 233., 233., 234.],
         [183., 192., 198.,  ..., 230., 231., 232.],
         [187., 193., 198.,  ..., 226., 228., 229.],
         ...,
         [124., 123., 122.,  ..., 218., 217., 218.],
         [125., 124., 123.,  ..., 219., 218., 219.],
         [125., 124., 123.,  ..., 220., 219., 220.]],

        [[199., 214., 223.,  ..., 223., 222., 223.],
         [204., 216., 224.,  ..., 222., 222., 223.],
         [208., 218., 223.,  ..., 222., 223., 224.],
         ...,
         [117., 117., 117.,  ..., 220., 219., 220.],
         [116., 116., 116.,  ..., 222., 220., 221.],
         [116., 116., 116.,  ..., 224., 221., 222.]],

        [[208., 216., 222.,  ..., 234., 235., 237.],
         [210., 217., 222.,  ..., 233., 234., 236.],
         [212., 218., 221.,  ..., 230., 231., 233.],
         ...,
         [103., 103., 103.,  ..., 231., 229., 231.],
         [103., 103., 103.,  ..., 230., 230., 233.],
         [104., 103., 103.,  ..., 230., 231., 235.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  427.8374,  333.9253, 1024.0000]])), gt_classes: tensor([292])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000188311.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [127, 409, 782, 685], 'neg_category_ids': [712, 1099, 502, 481, 396, 84, 1194, 1082, 331, 243, 1158, 404, 248, 916, 386, 145, 756], 'image_id': 188311, 'image': tensor([[[179., 189., 197.,  ..., 233., 233., 234.],
         [183., 192., 198.,  ..., 230., 231., 232.],
         [187., 193., 198.,  ..., 226., 228., 229.],
         ...,
         [124., 123., 122.,  ..., 218., 217., 218.],
         [125., 124., 123.,  ..., 219., 218., 219.],
         [125., 124., 123.,  ..., 220., 219., 220.]],

        [[199., 214., 223.,  ..., 223., 222., 223.],
         [204., 216., 224.,  ..., 222., 222., 223.],
         [208., 218., 223.,  ..., 222., 223., 224.],
         ...,
         [117., 117., 117.,  ..., 220., 219., 220.],
         [116., 116., 116.,  ..., 222., 220., 221.],
         [116., 116., 116.,  ..., 224., 221., 222.]],

        [[208., 216., 222.,  ..., 234., 235., 237.],
         [210., 217., 222.,  ..., 233., 234., 236.],
         [212., 218., 221.,  ..., 230., 231., 233.],
         ...,
         [103., 103., 103.,  ..., 231., 229., 231.],
         [103., 103., 103.,  ..., 230., 230., 233.],
         [104., 103., 103.,  ..., 230., 231., 235.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  427.8374,  333.9253, 1024.0000]])), gt_classes: tensor([292])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000188311.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [127, 409, 782, 685], 'neg_category_ids': [712, 1099, 502, 481, 396, 84, 1194, 1082, 331, 243, 1158, 404, 248, 916, 386, 145, 756], 'image_id': 188311, 'image': tensor([[[179., 189., 197.,  ..., 233., 233., 234.],
         [183., 192., 198.,  ..., 230., 231., 232.],
         [187., 193., 198.,  ..., 226., 228., 229.],
         ...,
         [124., 123., 122.,  ..., 218., 217., 218.],
         [125., 124., 123.,  ..., 219., 218., 219.],
         [125., 124., 123.,  ..., 220., 219., 220.]],

        [[199., 214., 223.,  ..., 223., 222., 223.],
         [204., 216., 224.,  ..., 222., 222., 223.],
         [208., 218., 223.,  ..., 222., 223., 224.],
         ...,
         [117., 117., 117.,  ..., 220., 219., 220.],
         [116., 116., 116.,  ..., 222., 220., 221.],
         [116., 116., 116.,  ..., 224., 221., 222.]],

        [[208., 216., 222.,  ..., 234., 235., 237.],
         [210., 217., 222.,  ..., 233., 234., 236.],
         [212., 218., 221.,  ..., 230., 231., 233.],
         ...,
         [103., 103., 103.,  ..., 231., 229., 231.],
         [103., 103., 103.,  ..., 230., 230., 233.],
         [104., 103., 103.,  ..., 230., 231., 235.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  427.8374,  333.9253, 1024.0000]])), gt_classes: tensor([292])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000175188.jpg', 'height': 416, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1023, 631, 284, 955, 293, 362, 341], 'image_id': 175188, 'annotations_cat_set': {880, 409, 962, 948}, 'image': tensor([[[ 39.,  38.,  38.,  ..., 128., 128., 128.],
         [ 39.,  39.,  40.,  ..., 128., 128., 128.],
         [ 39.,  42.,  41.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 63.,  66.,  71.,  ..., 128., 128., 128.],
         [ 61.,  67.,  73.,  ..., 128., 128., 128.],
         [ 60.,  66.,  73.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[112., 116., 121.,  ..., 128., 128., 128.],
         [110., 114., 121.,  ..., 128., 128., 128.],
         [109., 115., 120.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=13, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[175.0879, 437.6070, 185.6860, 464.6959],
        [656.5549, 303.4387, 661.2368, 310.7711],
        [654.4836, 297.7656, 660.1443, 305.3817],
        [530.8679, 427.7642, 641.9418, 458.7959],
        [675.8925, 537.1837, 848.3699, 590.0000],
        [573.5723, 487.3599, 734.1889, 528.9861],
        [672.3598, 450.9245, 773.3039, 477.7014],
        [564.9037, 418.8149, 598.4713, 445.7762],
        [730.1029, 534.4606, 803.6509, 574.1154],
        [821.4562, 523.0861, 868.1757, 565.5065],
        [689.3990, 446.6697, 748.4758, 471.7164],
        [612.3183, 477.6022, 672.9273, 512.8887],
        [695.0740, 473.1062, 750.6465, 503.2728]])), gt_classes: tensor([620, 292, 292, 675, 675, 675, 675, 664, 664, 664, 664, 664, 664])])}], 'support_set_target': tensor(292)}
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000573963.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [45], 'neg_category_ids': [711, 392, 715, 593, 309, 1065, 429, 580], 'image_id': 573963, 'image': tensor([[[ 40.,  40.,  39.,  ..., 128., 128., 128.],
         [ 39.,  39.,  40.,  ..., 128., 128., 128.],
         [ 39.,  39.,  40.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 26.,  26.,  25.,  ..., 128., 128., 128.],
         [ 25.,  25.,  26.,  ..., 128., 128., 128.],
         [ 25.,  25.,  26.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 45.,  45.,  44.,  ..., 128., 128., 128.],
         [ 44.,  44.,  45.,  ..., 128., 128., 128.],
         [ 44.,  44.,  45.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 345.8683, 215.0405, 489.1331]])), gt_classes: tensor([645])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000517451.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 1072, 761, 855, 839, 616, 530], 'image_id': 517451, 'image': tensor([[[183., 184., 190.,  ..., 255., 255., 255.],
         [188., 184., 187.,  ..., 255., 255., 255.],
         [180., 174., 176.,  ..., 255., 255., 255.],
         ...,
         [193., 184., 173.,  ..., 253., 254., 254.],
         [196., 195., 194.,  ..., 252., 253., 253.],
         [194., 194., 193.,  ..., 254., 255., 255.]],

        [[142., 141., 144.,  ..., 211., 213., 213.],
         [140., 134., 135.,  ..., 213., 214., 214.],
         [139., 132., 132.,  ..., 213., 214., 214.],
         ...,
         [178., 173., 168.,  ..., 212., 211., 211.],
         [181., 186., 187.,  ..., 213., 212., 212.],
         [181., 183., 186.,  ..., 217., 216., 218.]],

        [[122., 114., 121.,  ..., 194., 194., 194.],
         [127., 119., 122.,  ..., 194., 195., 193.],
         [128., 120., 122.,  ..., 194., 193., 193.],
         ...,
         [174., 167., 158.,  ..., 184., 185., 185.],
         [179., 180., 179.,  ..., 187., 190., 190.],
         [179., 179., 180.,  ..., 193., 196., 196.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 149.6764,  891.3972,  347.0861, 1024.0000]])), gt_classes: tensor([645])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000069293.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [366, 1002, 1095, 303, 416, 588, 5, 203, 440, 1135, 381, 995, 41, 449, 98, 342], 'image_id': 69293, 'image': tensor([[[164., 161., 156.,  ..., 128., 128., 128.],
         [155., 153., 152.,  ..., 128., 128., 128.],
         [152., 152., 153.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[195., 192., 190.,  ..., 128., 128., 128.],
         [194., 192., 192.,  ..., 128., 128., 128.],
         [192., 190., 190.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[132., 129., 219.,  ..., 128., 128., 128.],
         [134., 132., 130.,  ..., 128., 128., 128.],
         [135., 134., 134.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[139.4513, 488.7661, 287.1050, 563.0000]])), gt_classes: tensor([645])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000373765.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [745, 1160, 879, 471], 'image_id': 373765, 'image': tensor([[[211., 210., 215.,  ..., 128., 128., 128.],
         [218., 219., 223.,  ..., 128., 128., 128.],
         [225., 129., 134.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[175., 171., 170.,  ..., 128., 128., 128.],
         [184., 182., 180.,  ..., 128., 128., 128.],
         [192., 193., 194.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[166., 161., 159.,  ..., 128., 128., 128.],
         [174., 171., 167.,  ..., 128., 128., 128.],
         [180., 181., 179.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[609.9098, 289.9984, 724.1761, 355.1227]])), gt_classes: tensor([645])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000560360.jpg', 'height': 514, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [480, 176, 1104, 1132, 1035, 335, 727, 14, 891, 779], 'image_id': 560360, 'image': tensor([[[165., 174., 191.,  ..., 152., 163., 184.],
         [164., 175., 193.,  ..., 156., 166., 185.],
         [163., 176., 196.,  ..., 163., 172., 187.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[167., 177., 194.,  ..., 159., 168., 188.],
         [167., 178., 196.,  ..., 163., 172., 190.],
         [168., 180., 200.,  ..., 172., 179., 193.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[176., 184., 200.,  ..., 166., 176., 195.],
         [174., 184., 202.,  ..., 170., 179., 197.],
         [171., 184., 205.,  ..., 179., 186., 200.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 378.7990,  47.7706, 792.4952]])), gt_classes: tensor([645])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000410302.jpg', 'height': 500, 'width': 375, 'not_exhaustive_category_ids': [29, 12], 'neg_category_ids': [920, 456, 441, 658, 533, 387], 'image_id': 410302, 'annotations_cat_set': {544, 615, 12, 15, 61, 950, 919, 29}, 'image': tensor([[[106., 123., 157.,  ..., 128., 128., 128.],
         [102., 105., 120.,  ..., 128., 128., 128.],
         [ 99.,  94.,  93.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[102., 120., 156.,  ..., 128., 128., 128.],
         [ 98., 102., 117.,  ..., 128., 128., 128.],
         [ 95.,  90.,  89.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 98., 117., 154.,  ..., 128., 128., 128.],
         [ 95.,  99., 115.,  ..., 128., 128., 128.],
         [ 92.,  87.,  86.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=173, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[8.4640e-02, 1.0590e+00, 6.9772e+01, 8.1727e+01],
        [4.0486e+00, 7.9425e+01, 5.2773e+02, 1.2411e+02],
        [3.7955e+02, 2.9638e+01, 4.5191e+02, 6.1380e+01],
        [0.0000e+00, 1.8284e+02, 4.6552e+01, 2.4975e+02],
        [2.2967e+02, 6.2481e+01, 2.6949e+02, 9.8261e+01],
        [1.1243e+01, 1.4016e+02, 2.5745e+01, 1.5169e+02],
        [1.9326e+01, 1.2777e+02, 3.1232e+01, 1.3366e+02],
        [3.8528e+02, 1.4278e+02, 3.9628e+02, 1.5059e+02],
        [3.4424e+02, 3.0865e+02, 4.9689e+02, 4.0587e+02],
        [6.8826e+01, 2.9330e+02, 9.1214e+01, 3.1171e+02],
        [2.0748e+02, 3.2712e+02, 2.3098e+02, 3.5210e+02],
        [1.3641e+02, 3.0786e+02, 1.5338e+02, 3.2003e+02],
        [1.3640e+02, 2.0665e+02, 1.4832e+02, 2.1810e+02],
        [1.9849e+02, 3.5098e+02, 2.1713e+02, 3.6616e+02],
        [6.6922e+01, 2.8152e+02, 8.5359e+01, 2.9764e+02],
        [1.1802e+02, 5.7131e+02, 1.5459e+02, 6.0662e+02],
        [1.0217e+02, 5.1562e+02, 1.3424e+02, 5.4791e+02],
        [1.3427e+02, 3.6003e+02, 1.6048e+02, 3.8596e+02],
        [1.4662e+02, 5.4619e+02, 1.8102e+02, 5.8083e+02],
        [7.7319e+01, 6.6975e+02, 1.1147e+02, 7.0577e+02],
        [2.2263e+02, 3.1951e+02, 2.4162e+02, 3.3188e+02],
        [2.1784e+02, 6.2924e+02, 2.4948e+02, 6.6093e+02],
        [6.6245e+01, 6.1519e+02, 1.0177e+02, 6.5151e+02],
        [2.1456e+02, 3.3243e+02, 2.4564e+02, 3.6091e+02],
        [3.0456e+01, 6.9072e+02, 4.2010e+01, 7.0484e+02],
        [5.0840e+01, 3.1403e+02, 8.0394e+01, 3.4444e+02],
        [5.6060e+01, 6.3664e+02, 9.9113e+01, 6.7701e+02],
        [1.7966e+02, 3.2494e+02, 1.9450e+02, 3.3689e+02],
        [8.7038e+00, 5.8283e+02, 4.9317e+01, 6.2182e+02],
        [9.7223e+01, 6.4754e+02, 1.1905e+02, 6.6840e+02],
        [2.7494e+01, 6.5114e+02, 5.7795e+01, 6.9010e+02],
        [1.9672e+02, 3.1507e+02, 2.2026e+02, 3.3793e+02],
        [7.0928e+01, 2.3587e+02, 8.5938e+01, 2.5199e+02],
        [8.8660e+01, 3.5608e+02, 1.1876e+02, 3.8320e+02],
        [8.5952e+01, 2.3504e+02, 9.9424e+01, 2.4716e+02],
        [1.7687e+02, 5.5956e+02, 1.9644e+02, 5.8273e+02],
        [2.6774e+01, 3.3408e+02, 5.6398e+01, 3.5793e+02],
        [9.2187e+01, 2.5444e+02, 1.1479e+02, 2.7236e+02],
        [9.9381e+01, 3.3784e+02, 1.1728e+02, 3.5962e+02],
        [5.6384e+01, 3.5828e+02, 8.7842e+01, 3.8508e+02],
        [1.0405e+02, 5.4128e+02, 1.3518e+02, 5.7553e+02],
        [1.7619e+01, 5.4742e+02, 5.5058e+01, 5.7675e+02],
        [1.3462e+02, 5.5747e+02, 1.5060e+02, 5.7515e+02],
        [6.2535e+01, 5.3753e+02, 9.7477e+01, 5.7288e+02],
        [5.7598e+01, 2.7991e+02, 7.5146e+01, 2.9765e+02],
        [1.1902e+02, 6.6186e+02, 1.5953e+02, 7.0380e+02],
        [1.2568e+02, 2.9727e+02, 1.4149e+02, 3.1126e+02],
        [3.7693e+01, 2.6522e+02, 5.8458e+01, 2.8641e+02],
        [1.8068e+02, 1.8088e+02, 1.9261e+02, 1.8958e+02],
        [3.7072e+01, 6.6637e+02, 8.0958e+01, 7.0525e+02],
        [2.8566e+01, 3.0430e+02, 5.1898e+01, 3.3020e+02],
        [9.4783e+01, 2.4960e+02, 1.0487e+02, 2.5615e+02],
        [1.7130e+02, 6.0630e+02, 2.0431e+02, 6.3934e+02],
        [1.4555e+02, 1.8249e+02, 1.5246e+02, 1.9240e+02],
        [2.0737e+00, 6.6491e+02, 1.5630e+01, 6.8917e+02],
        [1.0983e+02, 3.7347e+02, 1.4149e+02, 4.0304e+02],
        [1.1693e+02, 6.4174e+02, 1.4974e+02, 6.7022e+02],
        [1.0859e+02, 2.1687e+02, 1.2270e+02, 2.2918e+02],
        [1.3609e+02, 3.1499e+02, 1.4765e+02, 3.2367e+02],
        [8.3385e+01, 5.6640e+02, 1.1761e+02, 5.9188e+02],
        [2.0134e+02, 6.0083e+02, 2.3552e+02, 6.3431e+02],
        [1.2978e+02, 5.2334e+02, 1.4084e+02, 5.4208e+02],
        [1.4773e+02, 1.8669e+02, 1.6175e+02, 1.9839e+02],
        [2.4546e+01, 3.5337e+02, 5.6864e+01, 3.8292e+02],
        [2.8284e+01, 2.7840e+02, 4.8456e+01, 3.0102e+02],
        [9.7844e+01, 6.5549e+02, 1.2099e+02, 6.9043e+02],
        [1.1319e+02, 3.2873e+02, 1.3834e+02, 3.5604e+02],
        [1.5969e+02, 1.8312e+02, 1.7236e+02, 1.9483e+02],
        [5.5101e+01, 5.5157e+02, 8.4950e+01, 5.7795e+02],
        [1.3157e+02, 1.9808e+02, 1.3881e+02, 2.0713e+02],
        [1.8057e+01, 2.9241e+02, 3.2361e+01, 3.0430e+02],
        [1.6646e+00, 5.8406e+02, 1.5038e+01, 6.0878e+02],
        [9.2046e+01, 5.4771e+02, 1.0849e+02, 5.6973e+02],
        [2.3262e+01, 3.8092e+02, 5.4226e+01, 4.0766e+02],
        [6.0743e+01, 2.7136e+02, 8.2679e+01, 2.8326e+02],
        [6.3847e+01, 2.5909e+02, 8.2284e+01, 2.6832e+02],
        [1.2235e+02, 3.4996e+02, 1.4984e+02, 3.7675e+02],
        [0.0000e+00, 6.2091e+02, 3.8243e+01, 6.5894e+02],
        [8.1269e+01, 3.8035e+02, 1.1172e+02, 4.0836e+02],
        [1.8384e+02, 6.3380e+02, 2.2056e+02, 6.6748e+02],
        [1.1308e+02, 3.1176e+02, 1.3750e+02, 3.2715e+02],
        [9.1129e+00, 3.1534e+02, 3.8779e+01, 3.3435e+02],
        [1.8787e+02, 3.3786e+02, 2.0487e+02, 3.5270e+02],
        [7.6218e+01, 2.1035e+02, 8.7969e+01, 2.2157e+02],
        [9.0522e+01, 3.2050e+02, 1.1044e+02, 3.3899e+02],
        [1.0367e+02, 2.9076e+02, 1.1895e+02, 3.0220e+02],
        [1.3998e+02, 1.9463e+02, 1.4830e+02, 2.0621e+02],
        [1.4277e+02, 1.9696e+02, 1.5507e+02, 2.1018e+02],
        [1.9367e+02, 5.6425e+02, 2.1460e+02, 5.8879e+02],
        [6.3565e+01, 2.2862e+02, 7.7841e+01, 2.4111e+02],
        [1.6017e+02, 5.7699e+02, 1.9621e+02, 6.1233e+02],
        [1.4794e+02, 2.1965e+02, 1.5486e+02, 2.3009e+02],
        [8.4795e+01, 5.3033e+02, 1.0824e+02, 5.5348e+02],
        [1.7316e+02, 1.8356e+02, 1.8509e+02, 1.9298e+02],
        [8.4569e+01, 3.1171e+02, 9.5968e+01, 3.2236e+02],
        [2.0295e+02, 5.6264e+02, 2.2960e+02, 5.8525e+02],
        [1.0143e+02, 2.9600e+02, 1.1995e+02, 3.1513e+02],
        [1.9988e+02, 3.2150e+02, 2.2375e+02, 3.4413e+02],
        [1.5122e+01, 5.6662e+02, 5.1348e+01, 5.9616e+02],
        [1.1521e+02, 2.9235e+02, 1.2585e+02, 3.0759e+02],
        [2.3118e+02, 3.2324e+02, 2.5626e+02, 3.4275e+02],
        [1.5239e+02, 1.7564e+02, 1.6423e+02, 1.8681e+02],
        [1.5046e+02, 1.7215e+02, 1.6420e+02, 1.8609e+02],
        [1.2585e+02, 2.6457e+02, 1.4603e+02, 2.8326e+02],
        [9.8013e+01, 2.1029e+02, 1.1013e+02, 2.2150e+02],
        [7.9153e+01, 2.4596e+02, 9.3640e+01, 2.5581e+02],
        [1.9202e+02, 5.8229e+02, 2.2483e+02, 6.1695e+02],
        [9.9381e+01, 3.0554e+02, 1.1587e+02, 3.2243e+02],
        [1.5673e+02, 2.1955e+02, 1.5980e+02, 2.2733e+02],
        [5.7047e+01, 2.5705e+02, 6.7712e+01, 2.7462e+02],
        [4.2800e+01, 6.9383e+02, 7.9618e+01, 7.0600e+02],
        [2.2840e+02, 3.4830e+02, 2.5788e+02, 3.6694e+02],
        [5.1687e+01, 3.8330e+02, 8.1127e+01, 4.1095e+02],
        [1.0794e+02, 2.2324e+02, 1.1989e+02, 2.3664e+02],
        [7.7784e+01, 3.2612e+02, 1.0340e+02, 3.5561e+02],
        [4.8781e+01, 5.2768e+02, 7.9153e+01, 5.5763e+02],
        [1.7008e+02, 5.3814e+02, 1.9668e+02, 5.6592e+02],
        [1.4849e+02, 6.3632e+02, 1.8267e+02, 6.7095e+02],
        [1.3170e+02, 5.3385e+02, 1.6018e+02, 5.6063e+02],
        [3.5619e+01, 6.2182e+02, 6.6908e+01, 6.5459e+02],
        [1.0210e+02, 6.1454e+02, 1.3389e+02, 6.4931e+02],
        [1.0244e+02, 2.3316e+02, 1.1521e+02, 2.4275e+02],
        [0.0000e+00, 3.7727e+02, 2.8961e+01, 4.0341e+02],
        [0.0000e+00, 6.0652e+02, 1.9213e+01, 6.2934e+02],
        [3.7637e+01, 3.2247e+02, 5.4522e+01, 3.3600e+02],
        [1.8310e+01, 2.9833e+02, 3.9005e+01, 3.1764e+02],
        [8.7334e+01, 3.0633e+02, 1.0632e+02, 3.2226e+02],
        [1.6537e+02, 1.7632e+02, 1.7822e+02, 1.8917e+02],
        [4.5155e+01, 2.9018e+02, 6.5949e+01, 3.1082e+02],
        [5.2195e+00, 3.2233e+02, 3.7848e+01, 3.5083e+02],
        [1.9330e+02, 3.1342e+02, 2.1317e+02, 3.2996e+02],
        [8.5458e+01, 2.2346e+02, 9.5234e+01, 2.3305e+02],
        [5.6398e+01, 2.7428e+02, 6.1576e+01, 2.8092e+02],
        [1.4929e+02, 7.0025e+02, 1.7199e+02, 7.0512e+02],
        [5.8317e+01, 2.3805e+02, 7.1253e+01, 2.5090e+02],
        [1.9044e+00, 3.5013e+02, 3.1021e+01, 3.7802e+02],
        [1.1292e+02, 6.9129e+02, 1.4935e+02, 7.0600e+02],
        [4.2334e+01, 3.1078e+02, 6.6217e+01, 3.2652e+02],
        [5.8839e+01, 3.0252e+02, 8.3201e+01, 3.2072e+02],
        [5.0361e+01, 5.7041e+02, 8.1819e+01, 5.9503e+02],
        [9.9593e+01, 2.8577e+02, 1.0701e+02, 2.9103e+02],
        [2.6803e+00, 5.6422e+02, 1.9763e+01, 5.8876e+02],
        [1.8954e+02, 5.3439e+02, 2.1657e+02, 5.6589e+02],
        [1.0756e+02, 6.8941e+02, 1.2307e+02, 7.0584e+02],
        [6.5610e+01, 2.4868e+02, 7.7446e+01, 2.5780e+02],
        [8.7969e+01, 2.1198e+02, 9.8098e+01, 2.2103e+02],
        [4.7300e+01, 5.8735e+02, 8.4019e+01, 6.2369e+02],
        [1.2925e+02, 5.8477e+02, 1.6684e+02, 6.1624e+02],
        [5.3704e+01, 3.3853e+02, 8.3342e+01, 3.6298e+02],
        [6.6301e-01, 6.8445e+02, 2.8876e+01, 7.0582e+02],
        [7.1662e+01, 2.2582e+02, 8.1226e+01, 2.3517e+02],
        [7.6712e+01, 2.3249e+02, 8.6657e+01, 2.3883e+02],
        [6.6019e+01, 2.0931e+02, 7.6077e+01, 2.1749e+02],
        [1.1089e+02, 2.5597e+02, 1.2482e+02, 2.6791e+02],
        [1.5310e+02, 2.2859e+02, 1.6292e+02, 2.3758e+02],
        [1.3133e+02, 6.0390e+02, 1.6461e+02, 6.4029e+02],
        [2.1647e+02, 5.8450e+02, 2.3684e+02, 6.1508e+02],
        [8.3385e+01, 2.8555e+02, 1.0502e+02, 3.0760e+02],
        [1.3379e+02, 1.7836e+02, 1.4359e+02, 1.8934e+02],
        [9.4091e+01, 2.2239e+02, 1.0703e+02, 2.3668e+02],
        [8.4753e+01, 5.8471e+02, 1.1909e+02, 6.1974e+02],
        [1.0433e+02, 5.9159e+02, 1.3201e+02, 6.2128e+02],
        [1.2194e+02, 2.2489e+02, 1.2844e+02, 2.3330e+02],
        [1.1419e+02, 2.2900e+02, 1.2703e+02, 2.4166e+02],
        [5.4593e+01, 2.5607e+02, 7.0463e+01, 2.6997e+02],
        [1.5483e+02, 6.7440e+02, 1.7591e+02, 7.0398e+02],
        [1.7148e+02, 6.7794e+02, 2.1579e+02, 7.0582e+02],
        [1.0395e+02, 2.7215e+02, 1.2521e+02, 2.9121e+02],
        [2.8460e+02, 3.3243e+02, 2.9909e+02, 3.6153e+02],
        [1.7100e+02, 2.4377e+02, 2.4616e+02, 2.9262e+02],
        [3.2062e+02, 1.7492e+02, 3.4559e+02, 1.9990e+02],
        [5.3887e+00, 3.5978e+02, 1.9462e+02, 4.2731e+02],
        [1.5036e+02, 1.9008e+02, 2.3627e+02, 2.4728e+02]])), gt_classes: tensor([ 23,  23,  23, 666, 387, 387, 387, 387,  12,  11,  11,  11,  11,  11,
         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,
         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,
         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,
         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,
         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,
         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,
         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,
         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,
         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,
         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,
         11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,  11,
        435, 645,  46,  46,  46])])}], 'support_set_target': tensor(645)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000348059.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [105, 349, 1032, 839, 599, 553, 93], 'image_id': 348059, 'annotations': [{'bbox': [176.33, 417.97, 15.95, 11.31], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 296}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000348059.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [105, 349, 1032, 839, 599, 553, 93], 'image_id': 348059, 'image': tensor([[[ 90.,  90.,  90.,  ...,  80.,  80.,  80.],
         [ 90.,  90.,  90.,  ...,  80.,  80.,  80.],
         [ 90.,  90.,  90.,  ...,  80.,  80.,  80.],
         ...,
         [113., 113., 113.,  ...,  96.,  96.,  97.],
         [112., 112., 112.,  ...,  97.,  97.,  97.],
         [112., 112., 112.,  ...,  97.,  97.,  97.]],

        [[ 91.,  91.,  91.,  ...,  80.,  80.,  80.],
         [ 91.,  91.,  91.,  ...,  80.,  80.,  80.],
         [ 91.,  91.,  91.,  ...,  80.,  80.,  80.],
         ...,
         [112., 112., 112.,  ...,  95.,  95.,  96.],
         [112., 112., 112.,  ...,  96.,  96.,  96.],
         [112., 112., 112.,  ...,  97.,  97.,  97.]],

        [[ 93.,  93.,  93.,  ...,  80.,  80.,  80.],
         [ 93.,  93.,  93.,  ...,  80.,  80.,  80.],
         [ 93.,  93.,  93.,  ...,  80.,  80.,  80.],
         ...,
         [113., 113., 113.,  ...,  98.,  99., 100.],
         [113., 113., 113.,  ...,  99.,  99., 100.],
         [113., 113., 113.,  ..., 100., 100., 100.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[280.1934, 660.5814, 324.9863, 692.3378]])), gt_classes: tensor([296])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000295159.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [941, 1095, 694, 1148, 8, 227, 1134, 39, 730], 'image_id': 295159, 'annotations': [{'bbox': [190.79, 191.8, 123.1, 109.01], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 296}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000295159.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [941, 1095, 694, 1148, 8, 227, 1134, 39, 730], 'image_id': 295159, 'image': tensor([[[ 12.,  12.,  12.,  ..., 134., 135., 135.],
         [ 12.,  11.,  11.,  ..., 133., 134., 134.],
         [ 11.,  11.,  11.,  ..., 133., 134., 134.],
         ...,
         [142., 143., 150.,  ..., 108., 106., 105.],
         [140., 142., 149.,  ..., 108., 106., 105.],
         [138., 139., 148.,  ..., 108., 106., 105.]],

        [[ 17.,  16.,  14.,  ..., 120., 121., 121.],
         [ 15.,  14.,  14.,  ..., 119., 120., 120.],
         [ 14.,  13.,  13.,  ..., 119., 120., 120.],
         ...,
         [129., 131., 140.,  ...,  93.,  93.,  92.],
         [128., 130., 140.,  ...,  93.,  92.,  91.],
         [127., 130., 140.,  ...,  93.,  92.,  91.]],

        [[ 17.,  15.,  14.,  ..., 107., 108., 108.],
         [ 15.,  14.,  14.,  ..., 106., 107., 107.],
         [ 14.,  13.,  13.,  ..., 106., 107., 107.],
         ...,
         [ 98., 101., 111.,  ...,  61.,  60.,  60.],
         [ 97., 100., 112.,  ...,  62.,  61.,  60.],
         [ 97., 100., 114.,  ...,  62.,  61.,  60.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[364.7147, 442.1067, 668.4254, 710.9980]])), gt_classes: tensor([296])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000486626.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [433, 789, 857, 421, 352, 1038, 13, 1160, 1065], 'image_id': 486626, 'annotations': [{'bbox': [213.63, 535.14, 44.2, 21.34], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 296}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000486626.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [433, 789, 857, 421, 352, 1038, 13, 1160, 1065], 'image_id': 486626, 'image': tensor([[[254., 248., 252.,  ..., 128., 128., 128.],
         [252., 254., 253.,  ..., 128., 128., 128.],
         [251., 253., 251.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[253., 233., 246.,  ..., 128., 128., 128.],
         [249., 241., 246.,  ..., 128., 128., 128.],
         [247., 246., 243.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[249., 218., 249.,  ..., 128., 128., 128.],
         [245., 225., 245.,  ..., 128., 128., 128.],
         [242., 234., 239.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[233.2785, 561.8970, 279.6885, 584.3040]])), gt_classes: tensor([296])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000503464.jpg', 'height': 478, 'width': 640, 'not_exhaustive_category_ids': [816, 150], 'neg_category_ids': [1095, 635, 239, 134, 676, 61, 598, 679, 825], 'image_id': 503464, 'annotations': [{'bbox': [156.08, 234.23, 58.44, 35.22], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 296}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000503464.jpg', 'height': 478, 'width': 640, 'not_exhaustive_category_ids': [816, 150], 'neg_category_ids': [1095, 635, 239, 134, 676, 61, 598, 679, 825], 'image_id': 503464, 'image': tensor([[[110., 110., 110.,  ..., 106., 106., 106.],
         [109., 110., 110.,  ..., 106., 106., 106.],
         [109., 110., 110.,  ..., 106., 106., 106.],
         ...,
         [106., 106., 106.,  ..., 106., 106., 106.],
         [106., 106., 106.,  ..., 106., 106., 106.],
         [106., 106., 106.,  ..., 106., 106., 106.]],

        [[109., 110., 110.,  ..., 106., 106., 106.],
         [109., 110., 110.,  ..., 106., 106., 106.],
         [109., 109., 110.,  ..., 106., 106., 106.],
         ...,
         [106., 106., 106.,  ..., 106., 106., 106.],
         [106., 106., 106.,  ..., 106., 106., 106.],
         [106., 106., 106.,  ..., 106., 106., 106.]],

        [[111., 111., 111.,  ..., 106., 106., 106.],
         [110., 111., 111.,  ..., 106., 106., 106.],
         [110., 111., 111.,  ..., 106., 106., 106.],
         ...,
         [106., 106., 106.,  ..., 106., 106., 106.],
         [106., 106., 106.,  ..., 106., 106., 106.],
         [106., 106., 106.,  ..., 106., 106., 106.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[582.3757, 320.9637, 662.3655, 369.2254]])), gt_classes: tensor([296])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000301221.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [417, 150], 'neg_category_ids': [193, 855, 1030, 1191, 1195, 88, 912, 213, 914, 1162, 1118, 364], 'image_id': 301221, 'annotations': [{'bbox': [231.4, 370.5, 90.19, 33.42], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 296}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000301221.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [417, 150], 'neg_category_ids': [193, 855, 1030, 1191, 1195, 88, 912, 213, 914, 1162, 1118, 364], 'image_id': 301221, 'image': tensor([[[  5.,   5.,   5.,  ..., 128., 128., 128.],
         [  5.,   5.,   5.,  ..., 128., 128., 128.],
         [  4.,   4.,   4.,  ..., 128., 128., 128.],
         ...,
         [223., 222., 220.,  ..., 128., 128., 128.],
         [228., 227., 225.,  ..., 128., 128., 128.],
         [233., 232., 230.,  ..., 128., 128., 128.]],

        [[ 21.,  21.,  21.,  ..., 128., 128., 128.],
         [ 21.,  21.,  21.,  ..., 128., 128., 128.],
         [ 21.,  21.,  21.,  ..., 128., 128., 128.],
         ...,
         [201., 200., 198.,  ..., 128., 128., 128.],
         [205., 204., 202.,  ..., 128., 128., 128.],
         [209., 208., 206.,  ..., 128., 128., 128.]],

        [[ 34.,  34.,  34.,  ..., 128., 128., 128.],
         [ 34.,  34.,  34.,  ..., 128., 128., 128.],
         [ 34.,  34.,  34.,  ..., 128., 128., 128.],
         ...,
         [199., 198., 196.,  ..., 128., 128., 128.],
         [203., 202., 200.,  ..., 128., 128., 128.],
         [206., 205., 203.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[232.3490, 643.9414, 433.0535, 718.3531]])), gt_classes: tensor([296])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000348059.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [105, 349, 1032, 839, 599, 553, 93], 'image_id': 348059, 'image': tensor([[[ 90.,  90.,  90.,  ...,  80.,  80.,  80.],
         [ 90.,  90.,  90.,  ...,  80.,  80.,  80.],
         [ 90.,  90.,  90.,  ...,  80.,  80.,  80.],
         ...,
         [113., 113., 113.,  ...,  96.,  96.,  97.],
         [112., 112., 112.,  ...,  97.,  97.,  97.],
         [112., 112., 112.,  ...,  97.,  97.,  97.]],

        [[ 91.,  91.,  91.,  ...,  80.,  80.,  80.],
         [ 91.,  91.,  91.,  ...,  80.,  80.,  80.],
         [ 91.,  91.,  91.,  ...,  80.,  80.,  80.],
         ...,
         [112., 112., 112.,  ...,  95.,  95.,  96.],
         [112., 112., 112.,  ...,  96.,  96.,  96.],
         [112., 112., 112.,  ...,  97.,  97.,  97.]],

        [[ 93.,  93.,  93.,  ...,  80.,  80.,  80.],
         [ 93.,  93.,  93.,  ...,  80.,  80.,  80.],
         [ 93.,  93.,  93.,  ...,  80.,  80.,  80.],
         ...,
         [113., 113., 113.,  ...,  98.,  99., 100.],
         [113., 113., 113.,  ...,  99.,  99., 100.],
         [113., 113., 113.,  ..., 100., 100., 100.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[280.1934, 660.5814, 324.9863, 692.3378]])), gt_classes: tensor([296])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000295159.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [941, 1095, 694, 1148, 8, 227, 1134, 39, 730], 'image_id': 295159, 'image': tensor([[[ 12.,  12.,  12.,  ..., 134., 135., 135.],
         [ 12.,  11.,  11.,  ..., 133., 134., 134.],
         [ 11.,  11.,  11.,  ..., 133., 134., 134.],
         ...,
         [142., 143., 150.,  ..., 108., 106., 105.],
         [140., 142., 149.,  ..., 108., 106., 105.],
         [138., 139., 148.,  ..., 108., 106., 105.]],

        [[ 17.,  16.,  14.,  ..., 120., 121., 121.],
         [ 15.,  14.,  14.,  ..., 119., 120., 120.],
         [ 14.,  13.,  13.,  ..., 119., 120., 120.],
         ...,
         [129., 131., 140.,  ...,  93.,  93.,  92.],
         [128., 130., 140.,  ...,  93.,  92.,  91.],
         [127., 130., 140.,  ...,  93.,  92.,  91.]],

        [[ 17.,  15.,  14.,  ..., 107., 108., 108.],
         [ 15.,  14.,  14.,  ..., 106., 107., 107.],
         [ 14.,  13.,  13.,  ..., 106., 107., 107.],
         ...,
         [ 98., 101., 111.,  ...,  61.,  60.,  60.],
         [ 97., 100., 112.,  ...,  62.,  61.,  60.],
         [ 97., 100., 114.,  ...,  62.,  61.,  60.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[364.7147, 442.1067, 668.4254, 710.9980]])), gt_classes: tensor([296])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000486626.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [433, 789, 857, 421, 352, 1038, 13, 1160, 1065], 'image_id': 486626, 'image': tensor([[[254., 248., 252.,  ..., 128., 128., 128.],
         [252., 254., 253.,  ..., 128., 128., 128.],
         [251., 253., 251.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[253., 233., 246.,  ..., 128., 128., 128.],
         [249., 241., 246.,  ..., 128., 128., 128.],
         [247., 246., 243.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[249., 218., 249.,  ..., 128., 128., 128.],
         [245., 225., 245.,  ..., 128., 128., 128.],
         [242., 234., 239.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[233.2785, 561.8970, 279.6885, 584.3040]])), gt_classes: tensor([296])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000503464.jpg', 'height': 478, 'width': 640, 'not_exhaustive_category_ids': [816, 150], 'neg_category_ids': [1095, 635, 239, 134, 676, 61, 598, 679, 825], 'image_id': 503464, 'image': tensor([[[110., 110., 110.,  ..., 106., 106., 106.],
         [109., 110., 110.,  ..., 106., 106., 106.],
         [109., 110., 110.,  ..., 106., 106., 106.],
         ...,
         [106., 106., 106.,  ..., 106., 106., 106.],
         [106., 106., 106.,  ..., 106., 106., 106.],
         [106., 106., 106.,  ..., 106., 106., 106.]],

        [[109., 110., 110.,  ..., 106., 106., 106.],
         [109., 110., 110.,  ..., 106., 106., 106.],
         [109., 109., 110.,  ..., 106., 106., 106.],
         ...,
         [106., 106., 106.,  ..., 106., 106., 106.],
         [106., 106., 106.,  ..., 106., 106., 106.],
         [106., 106., 106.,  ..., 106., 106., 106.]],

        [[111., 111., 111.,  ..., 106., 106., 106.],
         [110., 111., 111.,  ..., 106., 106., 106.],
         [110., 111., 111.,  ..., 106., 106., 106.],
         ...,
         [106., 106., 106.,  ..., 106., 106., 106.],
         [106., 106., 106.,  ..., 106., 106., 106.],
         [106., 106., 106.,  ..., 106., 106., 106.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[582.3757, 320.9637, 662.3655, 369.2254]])), gt_classes: tensor([296])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000301221.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [417, 150], 'neg_category_ids': [193, 855, 1030, 1191, 1195, 88, 912, 213, 914, 1162, 1118, 364], 'image_id': 301221, 'image': tensor([[[  5.,   5.,   5.,  ..., 128., 128., 128.],
         [  5.,   5.,   5.,  ..., 128., 128., 128.],
         [  4.,   4.,   4.,  ..., 128., 128., 128.],
         ...,
         [223., 222., 220.,  ..., 128., 128., 128.],
         [228., 227., 225.,  ..., 128., 128., 128.],
         [233., 232., 230.,  ..., 128., 128., 128.]],

        [[ 21.,  21.,  21.,  ..., 128., 128., 128.],
         [ 21.,  21.,  21.,  ..., 128., 128., 128.],
         [ 21.,  21.,  21.,  ..., 128., 128., 128.],
         ...,
         [201., 200., 198.,  ..., 128., 128., 128.],
         [205., 204., 202.,  ..., 128., 128., 128.],
         [209., 208., 206.,  ..., 128., 128., 128.]],

        [[ 34.,  34.,  34.,  ..., 128., 128., 128.],
         [ 34.,  34.,  34.,  ..., 128., 128., 128.],
         [ 34.,  34.,  34.,  ..., 128., 128., 128.],
         ...,
         [199., 198., 196.,  ..., 128., 128., 128.],
         [203., 202., 200.,  ..., 128., 128., 128.],
         [206., 205., 203.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[232.3490, 643.9414, 433.0535, 718.3531]])), gt_classes: tensor([296])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000272100.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [415, 417, 150], 'neg_category_ids': [667, 476, 1186, 654, 115, 383, 1063, 1092, 1020], 'image_id': 272100, 'annotations_cat_set': {417, 713, 816, 498, 150, 415}, 'image': tensor([[[120., 116., 120.,  ..., 128., 128., 128.],
         [118., 114., 116.,  ..., 128., 128., 128.],
         [117., 111., 111.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[112., 111., 115.,  ..., 128., 128., 128.],
         [112., 109., 111.,  ..., 128., 128., 128.],
         [112., 106., 106.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[113., 110., 113.,  ..., 128., 128., 128.],
         [112., 107., 109.,  ..., 128., 128., 128.],
         [111., 104., 103.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=12, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[7.3042e+02, 4.2184e+02, 7.8160e+02, 4.8542e+02],
        [3.1571e+02, 2.3958e+02, 4.4071e+02, 3.2231e+02],
        [3.5714e+02, 1.0964e+02, 5.3514e+02, 2.2346e+02],
        [4.8655e+02, 2.7920e+02, 5.2960e+02, 3.0490e+02],
        [3.2773e+02, 3.7941e+02, 4.5762e+02, 4.1890e+02],
        [1.7153e+02, 1.9444e+02, 2.4678e+02, 2.9143e+02],
        [1.2341e+00, 2.6895e-01, 1.5592e+02, 1.1540e+02],
        [1.1102e+02, 2.7651e+02, 7.8200e+02, 5.1618e+02],
        [2.8159e+02, 2.3456e+02, 5.0135e+02, 3.9205e+02],
        [2.8543e+01, 1.6947e+02, 4.0103e+02, 4.0970e+02],
        [2.2486e+02, 8.9901e+01, 5.9828e+02, 2.2661e+02],
        [2.8714e+00, 6.4303e+00, 7.8006e+02, 5.1557e+02]])), gt_classes: tensor([503, 296, 296, 296, 296, 296, 355, 114, 295, 295, 295, 575])])}], 'support_set_target': tensor(296)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000207620.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [943, 500, 502, 988, 796, 65, 164, 1019], 'image_id': 207620, 'annotations': [{'bbox': [250.11, 564.72, 34.6, 44.28], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 544}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000207620.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [943, 500, 502, 988, 796, 65, 164, 1019], 'image_id': 207620, 'image': tensor([[[ 47.,  47.,  49.,  ..., 128., 128., 128.],
         [ 28.,  31.,  35.,  ..., 128., 128., 128.],
         [  8.,  12.,  18.,  ..., 128., 128., 128.],
         ...,
         [ 96., 100., 107.,  ..., 128., 128., 128.],
         [100., 103., 110.,  ..., 128., 128., 128.],
         [107., 108., 113.,  ..., 128., 128., 128.]],

        [[ 47.,  47.,  49.,  ..., 128., 128., 128.],
         [ 28.,  31.,  35.,  ..., 128., 128., 128.],
         [  8.,  12.,  18.,  ..., 128., 128., 128.],
         ...,
         [ 96., 100., 107.,  ..., 128., 128., 128.],
         [100., 103., 110.,  ..., 128., 128., 128.],
         [107., 108., 113.,  ..., 128., 128., 128.]],

        [[ 47.,  47.,  49.,  ..., 128., 128., 128.],
         [ 28.,  31.,  35.,  ..., 128., 128., 128.],
         [  8.,  12.,  18.,  ..., 128., 128., 128.],
         ...,
         [ 96., 100., 107.,  ..., 128., 128., 128.],
         [100., 103., 110.,  ..., 128., 128., 128.],
         [107., 108., 113.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000419854.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 1002, 828, 455, 811, 416, 225, 508, 485, 288, 69], 'image_id': 419854, 'annotations': [{'bbox': [173.21, 144.0, 68.2, 184.23], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 544}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000419854.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 1002, 828, 455, 811, 416, 225, 508, 485, 288, 69], 'image_id': 419854, 'image': tensor([[[248., 248., 248.,  ..., 128., 128., 128.],
         [249., 249., 249.,  ..., 128., 128., 128.],
         [250., 250., 249.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[244., 244., 244.,  ..., 128., 128., 128.],
         [245., 245., 245.,  ..., 128., 128., 128.],
         [246., 246., 245.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[239., 239., 239.,  ..., 128., 128., 128.],
         [240., 240., 240.,  ..., 128., 128., 128.],
         [241., 241., 240.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[204.6043, 170.2430, 285.1656, 388.0476]])), gt_classes: tensor([544])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000540285.jpg', 'height': 640, 'width': 498, 'not_exhaustive_category_ids': [], 'neg_category_ids': [343, 455, 972, 309, 909, 94, 1000], 'image_id': 540285, 'annotations': [{'bbox': [325.06, 241.93, 105.59, 183.05], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 544}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000540285.jpg', 'height': 640, 'width': 498, 'not_exhaustive_category_ids': [], 'neg_category_ids': [343, 455, 972, 309, 909, 94, 1000], 'image_id': 540285, 'image': tensor([[[21., 22., 22.,  ..., 20., 20., 20.],
         [22., 22., 23.,  ..., 20., 20., 20.],
         [22., 22., 22.,  ..., 20., 20., 20.],
         ...,
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.]],

        [[18., 18., 18.,  ..., 20., 20., 20.],
         [18., 18., 19.,  ..., 20., 20., 20.],
         [19., 19., 19.,  ..., 20., 20., 20.],
         ...,
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.]],

        [[20., 20., 21.,  ..., 20., 20., 20.],
         [20., 21., 21.,  ..., 20., 20., 20.],
         [21., 21., 21.,  ..., 20., 20., 20.],
         ...,
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 57.4774, 206.3965, 147.5894, 362.5610]])), gt_classes: tensor([544])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000492973.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [787, 172, 80, 672, 463, 1016, 143, 684, 1164], 'image_id': 492973, 'annotations': [{'bbox': [6.4, 153.25, 103.23, 88.47], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 544}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000492973.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [787, 172, 80, 672, 463, 1016, 143, 684, 1164], 'image_id': 492973, 'image': tensor([[[106., 106., 106.,  ...,  82.,  82.,  82.],
         [106., 106., 106.,  ...,  83.,  83.,  83.],
         [106., 106., 106.,  ...,  83.,  83.,  83.],
         ...,
         [  0.,   0.,   0.,  ...,   7.,   5.,  10.],
         [  0.,   0.,   0.,  ...,   5.,   2.,   9.],
         [  0.,   0.,   0.,  ...,   7.,   3.,  10.]],

        [[ 75.,  73.,  73.,  ...,  43.,  42.,  42.],
         [ 73.,  73.,  73.,  ...,  43.,  43.,  43.],
         [ 73.,  73.,  73.,  ...,  43.,  43.,  43.],
         ...,
         [  0.,   0.,   0.,  ...,  83.,  82.,  85.],
         [  0.,   0.,   0.,  ...,  85.,  80.,  83.],
         [  0.,   0.,   0.,  ...,  87.,  82.,  87.]],

        [[ 47.,  47.,  47.,  ...,   5.,   3.,   3.],
         [ 47.,  47.,  47.,  ...,   5.,   5.,   5.],
         [ 47.,  47.,  47.,  ...,   5.,   5.,   5.],
         ...,
         [  0.,   0.,   0.,  ..., 162., 158., 163.],
         [  0.,   0.,   0.,  ..., 162., 157., 162.],
         [  0.,   3.,   0.,  ..., 163., 158., 163.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000110045.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [632, 173, 1031, 489, 573, 916, 450], 'image_id': 110045, 'annotations': [{'bbox': [135.06, 114.89, 184.85, 213.7], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 544}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000110045.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [632, 173, 1031, 489, 573, 916, 450], 'image_id': 110045, 'image': tensor([[[  5.,   5.,   5.,  ..., 141., 135., 130.],
         [  5.,   3.,   3.,  ..., 144., 137., 131.],
         [  3.,   1.,   1.,  ..., 146., 141., 135.],
         ...,
         [255., 255., 255.,  ..., 221., 219., 223.],
         [255., 255., 255.,  ..., 221., 221., 223.],
         [255., 255., 255.,  ..., 221., 221., 225.]],

        [[  5.,   5.,   5.,  ..., 117., 111., 106.],
         [  5.,   5.,   5.,  ..., 119., 113., 109.],
         [  5.,   5.,   5.,  ..., 120., 115., 111.],
         ...,
         [254., 255., 255.,  ...,  93.,  91.,  91.],
         [255., 255., 255.,  ...,  89.,  87.,  89.],
         [255., 255., 255.,  ...,  87.,  86.,  87.]],

        [[  9.,   9.,   9.,  ..., 126., 120., 117.],
         [  7.,   7.,   7.,  ..., 126., 122., 119.],
         [  7.,   7.,   7.,  ..., 128., 122., 119.],
         ...,
         [255., 255., 255.,  ...,  29.,  32.,  34.],
         [255., 255., 255.,  ...,  31.,  32.,  36.],
         [255., 255., 255.,  ...,  31.,  34.,  38.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[366.3016, 194.2867, 934.7045, 851.4142]])), gt_classes: tensor([544])])}, len instances: 1
not 0
entering support set: 2
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000419854.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 1002, 828, 455, 811, 416, 225, 508, 485, 288, 69], 'image_id': 419854, 'image': tensor([[[248., 248., 248.,  ..., 128., 128., 128.],
         [249., 249., 249.,  ..., 128., 128., 128.],
         [250., 250., 249.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[244., 244., 244.,  ..., 128., 128., 128.],
         [245., 245., 245.,  ..., 128., 128., 128.],
         [246., 246., 245.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[239., 239., 239.,  ..., 128., 128., 128.],
         [240., 240., 240.,  ..., 128., 128., 128.],
         [241., 241., 240.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[204.6043, 170.2430, 285.1656, 388.0476]])), gt_classes: tensor([544])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000540285.jpg', 'height': 640, 'width': 498, 'not_exhaustive_category_ids': [], 'neg_category_ids': [343, 455, 972, 309, 909, 94, 1000], 'image_id': 540285, 'image': tensor([[[21., 22., 22.,  ..., 20., 20., 20.],
         [22., 22., 23.,  ..., 20., 20., 20.],
         [22., 22., 22.,  ..., 20., 20., 20.],
         ...,
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.]],

        [[18., 18., 18.,  ..., 20., 20., 20.],
         [18., 18., 19.,  ..., 20., 20., 20.],
         [19., 19., 19.,  ..., 20., 20., 20.],
         ...,
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.]],

        [[20., 20., 21.,  ..., 20., 20., 20.],
         [20., 21., 21.,  ..., 20., 20., 20.],
         [21., 21., 21.,  ..., 20., 20., 20.],
         ...,
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.],
         [20., 20., 20.,  ..., 20., 20., 20.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 57.4774, 206.3965, 147.5894, 362.5610]])), gt_classes: tensor([544])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000110045.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [632, 173, 1031, 489, 573, 916, 450], 'image_id': 110045, 'image': tensor([[[  5.,   5.,   5.,  ..., 141., 135., 130.],
         [  5.,   3.,   3.,  ..., 144., 137., 131.],
         [  3.,   1.,   1.,  ..., 146., 141., 135.],
         ...,
         [255., 255., 255.,  ..., 221., 219., 223.],
         [255., 255., 255.,  ..., 221., 221., 223.],
         [255., 255., 255.,  ..., 221., 221., 225.]],

        [[  5.,   5.,   5.,  ..., 117., 111., 106.],
         [  5.,   5.,   5.,  ..., 119., 113., 109.],
         [  5.,   5.,   5.,  ..., 120., 115., 111.],
         ...,
         [254., 255., 255.,  ...,  93.,  91.,  91.],
         [255., 255., 255.,  ...,  89.,  87.,  89.],
         [255., 255., 255.,  ...,  87.,  86.,  87.]],

        [[  9.,   9.,   9.,  ..., 126., 120., 117.],
         [  7.,   7.,   7.,  ..., 126., 122., 119.],
         [  7.,   7.,   7.,  ..., 128., 122., 119.],
         ...,
         [255., 255., 255.,  ...,  29.,  32.,  34.],
         [255., 255., 255.,  ...,  31.,  32.,  36.],
         [255., 255., 255.,  ...,  31.,  34.,  38.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[366.3016, 194.2867, 934.7045, 851.4142]])), gt_classes: tensor([544])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000419854.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 1002, 828, 455, 811, 416, 225, 508, 485, 288, 69], 'image_id': 419854, 'image': tensor([[[248., 248., 248.,  ..., 128., 128., 128.],
         [249., 249., 249.,  ..., 128., 128., 128.],
         [250., 250., 249.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[244., 244., 244.,  ..., 128., 128., 128.],
         [245., 245., 245.,  ..., 128., 128., 128.],
         [246., 246., 245.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[239., 239., 239.,  ..., 128., 128., 128.],
         [240., 240., 240.,  ..., 128., 128., 128.],
         [241., 241., 240.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[204.6043, 170.2430, 285.1656, 388.0476]])), gt_classes: tensor([544])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000419854.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 1002, 828, 455, 811, 416, 225, 508, 485, 288, 69], 'image_id': 419854, 'image': tensor([[[248., 248., 248.,  ..., 128., 128., 128.],
         [249., 249., 249.,  ..., 128., 128., 128.],
         [250., 250., 249.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[244., 244., 244.,  ..., 128., 128., 128.],
         [245., 245., 245.,  ..., 128., 128., 128.],
         [246., 246., 245.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[239., 239., 239.,  ..., 128., 128., 128.],
         [240., 240., 240.,  ..., 128., 128., 128.],
         [241., 241., 240.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[204.6043, 170.2430, 285.1656, 388.0476]])), gt_classes: tensor([544])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000478717.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [], 'neg_category_ids': [757, 943, 175, 1177, 599, 751, 118], 'image_id': 478717, 'annotations_cat_set': {351, 232, 767, 127, 1023}, 'image': tensor([[[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=12, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1.5090e+02, 2.8103e+02, 3.9000e+02, 4.1983e+02],
        [2.7753e+02, 1.4997e+02, 3.9000e+02, 2.9116e+02],
        [3.1821e-01, 1.4412e+02, 2.4352e+02, 3.6225e+02],
        [9.1707e+00, 1.4401e+02, 2.4290e+02, 5.1052e+02],
        [2.9049e+02, 1.4956e+02, 3.9000e+02, 2.9057e+02],
        [2.2747e+01, 1.9777e+02, 2.9343e+02, 3.8356e+02],
        [9.3657e+01, 1.3733e+02, 1.1776e+02, 1.4536e+02],
        [6.4334e+01, 1.2649e+02, 8.5621e+01, 1.4536e+02],
        [1.2802e+02, 1.0651e+02, 1.4801e+02, 1.1433e+02],
        [2.9084e+02, 2.0251e+02, 3.0824e+02, 2.2018e+02],
        [9.9222e+01, 4.8466e+02, 1.0767e+02, 5.2200e+02],
        [9.1380e-01, 2.3018e+02, 2.8140e+01, 2.5717e+02]])), gt_classes: tensor([ 98, 178, 178, 255, 255, 544, 544, 544, 544, 718, 718, 718])])}], 'support_set_target': tensor(544)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000514901.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [510], 'neg_category_ids': [343, 602, 1022, 584, 103, 415, 564, 640, 951, 267, 974, 533], 'image_id': 514901, 'annotations': [{'bbox': [1.51, 59.42, 124.31, 166.71], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 114}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000514901.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [510], 'neg_category_ids': [343, 602, 1022, 584, 103, 415, 564, 640, 951, 267, 974, 533], 'image_id': 514901, 'image': tensor([[[ 94.,  94.,  94.,  ..., 121., 121., 121.],
         [ 94.,  94.,  94.,  ..., 121., 121., 121.],
         [ 94.,  94.,  94.,  ..., 121., 121., 121.],
         ...,
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.]],

        [[103., 103., 104.,  ..., 121., 121., 121.],
         [101., 102., 103.,  ..., 121., 121., 121.],
         [101., 101., 102.,  ..., 121., 121., 121.],
         ...,
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.]],

        [[133., 133., 133.,  ..., 121., 121., 121.],
         [132., 132., 132.,  ..., 121., 121., 121.],
         [130., 131., 131.,  ..., 121., 121., 121.],
         ...,
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[677.2715,  78.2062, 841.0110, 297.6231]])), gt_classes: tensor([114])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000196281.jpg', 'height': 414, 'width': 640, 'not_exhaustive_category_ids': [169, 150, 139], 'neg_category_ids': [1074, 814, 132, 772, 618, 1017], 'image_id': 196281, 'annotations': [{'bbox': [26.25, 210.36, 37.82, 37.28], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 114}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000196281.jpg', 'height': 414, 'width': 640, 'not_exhaustive_category_ids': [169, 150, 139], 'neg_category_ids': [1074, 814, 132, 772, 618, 1017], 'image_id': 196281, 'image': tensor([[[192., 199., 198.,  ..., 128., 128., 128.],
         [200., 198., 207.,  ..., 128., 128., 128.],
         [208., 208., 208.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[179., 184., 180.,  ..., 128., 128., 128.],
         [179., 177., 185.,  ..., 128., 128., 128.],
         [181., 182., 184.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[153., 158., 157.,  ..., 128., 128., 128.],
         [154., 152., 162.,  ..., 128., 128., 128.],
         [154., 156., 157.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 29.0391, 232.7171,  70.8774, 273.9592]])), gt_classes: tensor([114])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000302065.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [789], 'neg_category_ids': [920, 1022, 103, 265, 379, 486, 400, 64, 318], 'image_id': 302065, 'annotations': [{'bbox': [265.41, 42.72, 122.51, 98.21], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 114}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000302065.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [789], 'neg_category_ids': [920, 1022, 103, 265, 379, 486, 400, 64, 318], 'image_id': 302065, 'image': tensor([[[175., 173., 172.,  ..., 153., 153., 154.],
         [170., 170., 170.,  ..., 153., 153., 153.],
         [166., 166., 167.,  ..., 153., 154., 154.],
         ...,
         [185., 184., 188.,  ...,  77.,  69.,  63.],
         [186., 189., 194.,  ...,  74.,  66.,  60.],
         [188., 191., 196.,  ...,  60.,  57.,  56.]],

        [[126., 125., 124.,  ...,  69.,  69.,  69.],
         [115., 114., 114.,  ...,  70.,  70.,  70.],
         [107., 104., 106.,  ...,  70.,  71.,  72.],
         ...,
         [ 83.,  82.,  82.,  ...,  84.,  76.,  67.],
         [ 84.,  84.,  86.,  ...,  80.,  72.,  63.],
         [ 85.,  87.,  88.,  ...,  68.,  64.,  61.]],

        [[ 98.,  97.,  97.,  ...,  48.,  48.,  49.],
         [ 91.,  90.,  92.,  ...,  51.,  51.,  51.],
         [ 87.,  84.,  86.,  ...,  53.,  53.,  54.],
         ...,
         [ 53.,  51.,  55.,  ..., 134., 129., 123.],
         [ 55.,  56.,  59.,  ..., 137., 132., 123.],
         [ 56.,  57.,  59.,  ..., 121., 121., 121.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 745.6918,  115.6593, 1024.0000,  406.8393]])), gt_classes: tensor([114])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000145728.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [430, 300, 782, 808, 322, 174, 502, 416, 817, 821, 384, 275, 18], 'image_id': 145728, 'annotations': [{'bbox': [35.94, 230.87, 174.74, 275.78], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 114}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000145728.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [430, 300, 782, 808, 322, 174, 502, 416, 817, 821, 384, 275, 18], 'image_id': 145728, 'image': tensor([[[117., 122., 115.,  ..., 128., 128., 128.],
         [110., 108., 104.,  ..., 128., 128., 128.],
         [104., 101.,  99.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[122., 130., 123.,  ..., 128., 128., 128.],
         [124., 123., 120.,  ..., 128., 128., 128.],
         [126., 123., 121.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[113., 120., 116.,  ..., 128., 128., 128.],
         [118., 116., 113.,  ..., 128., 128., 128.],
         [121., 118., 116.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[277.1752, 237.7240, 457.0117, 521.6912]])), gt_classes: tensor([114])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000379820.jpg', 'height': 383, 'width': 640, 'not_exhaustive_category_ids': [150], 'neg_category_ids': [1025, 520, 152, 311, 551, 116, 1137, 449], 'image_id': 379820, 'annotations': [{'bbox': [175.9, 227.08, 27.77, 12.95], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 114}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000379820.jpg', 'height': 383, 'width': 640, 'not_exhaustive_category_ids': [150], 'neg_category_ids': [1025, 520, 152, 311, 551, 116, 1137, 449], 'image_id': 379820, 'image': tensor([[[ 52.,  55.,  49.,  ..., 157., 173., 140.],
         [ 51.,  54.,  49.,  ..., 141., 153., 127.],
         [ 49.,  53.,  49.,  ..., 112., 115., 103.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]],

        [[ 60.,  62.,  61.,  ..., 182., 194., 179.],
         [ 61.,  64.,  61.,  ..., 172., 179., 169.],
         [ 62.,  67.,  62.,  ..., 152., 150., 149.],
         ...,
         [123., 123., 123.,  ..., 123., 123., 123.],
         [123., 123., 123.,  ..., 123., 123., 123.],
         [123., 123., 123.,  ..., 123., 123., 123.]],

        [[ 60.,  63.,  57.,  ..., 189., 201., 187.],
         [ 61.,  64.,  57.,  ..., 181., 189., 179.],
         [ 62.,  67.,  58.,  ..., 165., 165., 163.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[786.1617, 442.3020, 840.2698, 467.5258]])), gt_classes: tensor([114])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000514901.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [510], 'neg_category_ids': [343, 602, 1022, 584, 103, 415, 564, 640, 951, 267, 974, 533], 'image_id': 514901, 'image': tensor([[[ 94.,  94.,  94.,  ..., 121., 121., 121.],
         [ 94.,  94.,  94.,  ..., 121., 121., 121.],
         [ 94.,  94.,  94.,  ..., 121., 121., 121.],
         ...,
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.]],

        [[103., 103., 104.,  ..., 121., 121., 121.],
         [101., 102., 103.,  ..., 121., 121., 121.],
         [101., 101., 102.,  ..., 121., 121., 121.],
         ...,
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.]],

        [[133., 133., 133.,  ..., 121., 121., 121.],
         [132., 132., 132.,  ..., 121., 121., 121.],
         [130., 131., 131.,  ..., 121., 121., 121.],
         ...,
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[677.2715,  78.2062, 841.0110, 297.6231]])), gt_classes: tensor([114])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000196281.jpg', 'height': 414, 'width': 640, 'not_exhaustive_category_ids': [169, 150, 139], 'neg_category_ids': [1074, 814, 132, 772, 618, 1017], 'image_id': 196281, 'image': tensor([[[192., 199., 198.,  ..., 128., 128., 128.],
         [200., 198., 207.,  ..., 128., 128., 128.],
         [208., 208., 208.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[179., 184., 180.,  ..., 128., 128., 128.],
         [179., 177., 185.,  ..., 128., 128., 128.],
         [181., 182., 184.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[153., 158., 157.,  ..., 128., 128., 128.],
         [154., 152., 162.,  ..., 128., 128., 128.],
         [154., 156., 157.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 29.0391, 232.7171,  70.8774, 273.9592]])), gt_classes: tensor([114])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000302065.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [789], 'neg_category_ids': [920, 1022, 103, 265, 379, 486, 400, 64, 318], 'image_id': 302065, 'image': tensor([[[175., 173., 172.,  ..., 153., 153., 154.],
         [170., 170., 170.,  ..., 153., 153., 153.],
         [166., 166., 167.,  ..., 153., 154., 154.],
         ...,
         [185., 184., 188.,  ...,  77.,  69.,  63.],
         [186., 189., 194.,  ...,  74.,  66.,  60.],
         [188., 191., 196.,  ...,  60.,  57.,  56.]],

        [[126., 125., 124.,  ...,  69.,  69.,  69.],
         [115., 114., 114.,  ...,  70.,  70.,  70.],
         [107., 104., 106.,  ...,  70.,  71.,  72.],
         ...,
         [ 83.,  82.,  82.,  ...,  84.,  76.,  67.],
         [ 84.,  84.,  86.,  ...,  80.,  72.,  63.],
         [ 85.,  87.,  88.,  ...,  68.,  64.,  61.]],

        [[ 98.,  97.,  97.,  ...,  48.,  48.,  49.],
         [ 91.,  90.,  92.,  ...,  51.,  51.,  51.],
         [ 87.,  84.,  86.,  ...,  53.,  53.,  54.],
         ...,
         [ 53.,  51.,  55.,  ..., 134., 129., 123.],
         [ 55.,  56.,  59.,  ..., 137., 132., 123.],
         [ 56.,  57.,  59.,  ..., 121., 121., 121.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 745.6918,  115.6593, 1024.0000,  406.8393]])), gt_classes: tensor([114])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000145728.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [430, 300, 782, 808, 322, 174, 502, 416, 817, 821, 384, 275, 18], 'image_id': 145728, 'image': tensor([[[117., 122., 115.,  ..., 128., 128., 128.],
         [110., 108., 104.,  ..., 128., 128., 128.],
         [104., 101.,  99.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[122., 130., 123.,  ..., 128., 128., 128.],
         [124., 123., 120.,  ..., 128., 128., 128.],
         [126., 123., 121.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[113., 120., 116.,  ..., 128., 128., 128.],
         [118., 116., 113.,  ..., 128., 128., 128.],
         [121., 118., 116.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[277.1752, 237.7240, 457.0117, 521.6912]])), gt_classes: tensor([114])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000379820.jpg', 'height': 383, 'width': 640, 'not_exhaustive_category_ids': [150], 'neg_category_ids': [1025, 520, 152, 311, 551, 116, 1137, 449], 'image_id': 379820, 'image': tensor([[[ 52.,  55.,  49.,  ..., 157., 173., 140.],
         [ 51.,  54.,  49.,  ..., 141., 153., 127.],
         [ 49.,  53.,  49.,  ..., 112., 115., 103.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]],

        [[ 60.,  62.,  61.,  ..., 182., 194., 179.],
         [ 61.,  64.,  61.,  ..., 172., 179., 169.],
         [ 62.,  67.,  62.,  ..., 152., 150., 149.],
         ...,
         [123., 123., 123.,  ..., 123., 123., 123.],
         [123., 123., 123.,  ..., 123., 123., 123.],
         [123., 123., 123.,  ..., 123., 123., 123.]],

        [[ 60.,  63.,  57.,  ..., 189., 201., 187.],
         [ 61.,  64.,  57.,  ..., 181., 189., 179.],
         [ 62.,  67.,  58.,  ..., 165., 165., 163.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[786.1617, 442.3020, 840.2698, 467.5258]])), gt_classes: tensor([114])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000579312.jpg', 'height': 640, 'width': 429, 'not_exhaustive_category_ids': [133, 143], 'neg_category_ids': [830, 879, 90, 188, 1091, 45], 'image_id': 579312, 'annotations_cat_set': {143, 133, 150, 183}, 'image': tensor([[[ 81.,  80.,  78.,  ..., 128., 128., 128.],
         [ 94.,  90.,  82.,  ..., 128., 128., 128.],
         [109., 100.,  92.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[110., 110., 109.,  ..., 128., 128., 128.],
         [122., 118., 111.,  ..., 128., 128., 128.],
         [136., 127., 117.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[141., 141., 142.,  ..., 128., 128., 128.],
         [151., 148., 143.,  ..., 128., 128., 128.],
         [161., 153., 146.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=101, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[4.6590e+02, 1.5243e+02, 5.0893e+02, 1.9176e+02],
        [6.3230e+02, 1.8897e+02, 6.5088e+02, 2.3313e+02],
        [3.9943e+02, 4.9697e+02, 4.3427e+02, 5.1281e+02],
        [5.1945e+02, 3.1679e+02, 5.5661e+02, 3.6649e+02],
        [5.2414e+02, 3.0354e+02, 5.5585e+02, 3.2501e+02],
        [3.6752e+02, 2.3142e+02, 4.1412e+02, 2.5290e+02],
        [4.6097e+02, 3.0999e+02, 4.9192e+02, 3.3562e+02],
        [5.7174e+02, 2.1752e+02, 5.9138e+02, 3.1199e+02],
        [3.3700e+02, 3.1295e+02, 3.6656e+02, 3.6296e+02],
        [3.7637e+02, 4.0410e+02, 4.0963e+02, 4.2660e+02],
        [4.8698e+02, 3.1547e+02, 5.2191e+02, 3.6629e+02],
        [6.1501e+02, 2.2832e+02, 6.3925e+02, 3.1348e+02],
        [4.2846e+02, 3.1733e+02, 4.6358e+02, 3.6481e+02],
        [3.8146e+02, 5.3434e+02, 4.0615e+02, 5.4968e+02],
        [3.7916e+02, 1.5321e+02, 4.2338e+02, 1.9164e+02],
        [5.6720e+02, 2.2213e+02, 5.8479e+02, 3.1413e+02],
        [3.6414e+02, 3.1691e+02, 3.9972e+02, 3.6355e+02],
        [5.9044e+02, 2.1981e+02, 6.1044e+02, 3.1339e+02],
        [4.5978e+02, 2.2655e+02, 5.0532e+02, 2.5231e+02],
        [5.0406e+02, 2.2591e+02, 5.5450e+02, 2.5263e+02],
        [3.4621e+02, 5.5743e+02, 4.0181e+02, 5.8198e+02],
        [4.9057e+02, 3.0500e+02, 5.2147e+02, 3.2582e+02],
        [3.8379e+02, 4.2334e+02, 4.1277e+02, 4.3941e+02],
        [5.8564e+02, 2.1476e+02, 6.1344e+02, 3.1450e+02],
        [4.6233e+02, 3.2412e+02, 4.8825e+02, 3.6546e+02],
        [4.1655e+02, 5.1545e+02, 4.3688e+02, 5.2778e+02],
        [3.1398e+02, 5.2560e+02, 3.6104e+02, 5.4327e+02],
        [6.0654e+02, 2.1942e+02, 6.2311e+02, 3.1325e+02],
        [3.5259e+02, 4.2070e+02, 3.7013e+02, 4.3481e+02],
        [5.0770e+02, 1.5145e+02, 5.5291e+02, 1.8857e+02],
        [2.4560e+02, 5.2715e+02, 2.9336e+02, 5.4447e+02],
        [5.8426e+02, 2.2134e+02, 5.9384e+02, 2.5959e+02],
        [3.3099e+02, 6.3191e+02, 3.4186e+02, 6.4168e+02],
        [4.2285e+02, 1.5302e+02, 4.6711e+02, 1.9138e+02],
        [3.2468e+02, 6.0751e+02, 3.5036e+02, 6.2428e+02],
        [3.3196e+02, 5.0947e+02, 4.0163e+02, 5.3727e+02],
        [5.7540e+02, 4.2182e+02, 6.2258e+02, 4.3938e+02],
        [1.7865e+02, 4.1372e+02, 2.0242e+02, 4.2443e+02],
        [2.5084e+02, 5.3337e+02, 3.4872e+02, 5.5735e+02],
        [2.5917e+02, 5.8943e+02, 3.2111e+02, 6.0596e+02],
        [2.9545e+02, 4.1657e+02, 3.3256e+02, 4.2935e+02],
        [3.5720e+02, 5.3548e+02, 4.0011e+02, 5.5673e+02],
        [3.9555e+02, 3.1577e+02, 4.3421e+02, 3.6467e+02],
        [3.2448e+02, 3.1577e+02, 3.3769e+02, 3.6147e+02],
        [2.4858e+02, 5.6192e+02, 3.6007e+02, 5.8199e+02],
        [2.6120e+02, 6.0053e+02, 3.3380e+02, 6.2431e+02],
        [4.1849e+02, 5.2921e+02, 4.3485e+02, 5.4382e+02],
        [4.1248e+02, 2.3031e+02, 4.6084e+02, 2.5422e+02],
        [5.1749e+02, 2.8946e+02, 5.4572e+02, 3.1614e+02],
        [2.4802e+02, 5.6843e+02, 3.3535e+02, 5.9138e+02],
        [3.6159e+02, 5.5335e+02, 4.0225e+02, 5.6005e+02],
        [2.3324e+02, 3.5338e+02, 2.4559e+02, 3.8972e+02],
        [1.0043e+02, 3.4771e+02, 1.1325e+02, 3.8596e+02],
        [1.9400e+02, 3.5759e+02, 2.0132e+02, 3.8782e+02],
        [1.4011e+02, 3.5363e+02, 1.5333e+02, 3.8754e+02],
        [2.5089e+02, 3.4745e+02, 2.6343e+02, 3.9054e+02],
        [1.6665e+02, 3.5856e+02, 1.7216e+02, 3.7793e+02],
        [2.4447e+02, 3.5669e+02, 2.5413e+02, 3.8970e+02],
        [1.5372e+02, 3.5457e+02, 1.6660e+02, 3.8697e+02],
        [7.4979e+01, 3.4836e+02, 8.7134e+01, 3.8585e+02],
        [2.1491e+02, 3.5678e+02, 2.3187e+02, 3.8919e+02],
        [1.2650e+02, 3.4863e+02, 1.3967e+02, 3.8634e+02],
        [1.6759e+02, 3.5458e+02, 1.7999e+02, 3.8761e+02],
        [2.0955e+02, 3.5810e+02, 2.1955e+02, 3.8869e+02],
        [1.1410e+02, 3.4863e+02, 1.2639e+02, 3.8594e+02],
        [1.7959e+02, 3.5772e+02, 1.8612e+02, 3.8782e+02],
        [1.0949e+02, 3.5229e+02, 1.1601e+02, 3.8581e+02],
        [1.8176e+02, 3.5501e+02, 1.9459e+02, 3.8793e+02],
        [8.7786e+01, 3.4863e+02, 1.0008e+02, 3.8600e+02],
        [1.9794e+02, 3.5404e+02, 2.0970e+02, 3.8889e+02],
        [6.0003e+02, 6.2027e+02, 6.2042e+02, 6.5316e+02],
        [6.0305e+02, 6.2074e+02, 6.2426e+02, 6.6588e+02],
        [2.9547e+02, 4.1701e+02, 3.3263e+02, 4.2932e+02],
        [5.9378e+02, 5.8471e+02, 6.2649e+02, 6.2849e+02],
        [5.9690e+02, 6.0559e+02, 6.1497e+02, 6.3446e+02],
        [5.9974e+02, 6.0216e+02, 6.2690e+02, 6.3987e+02],
        [7.8484e+01, 3.9690e+02, 1.1471e+02, 4.2100e+02],
        [3.5259e+02, 4.2073e+02, 3.7016e+02, 4.3472e+02],
        [3.3703e+01, 3.9935e+02, 5.8772e+01, 4.1927e+02],
        [4.4304e+02, 4.0614e+02, 4.9939e+02, 4.3131e+02],
        [4.9901e+02, 5.7636e+02, 5.9554e+02, 6.3255e+02],
        [5.0238e+02, 6.1792e+02, 6.0179e+02, 6.6931e+02],
        [0.0000e+00, 2.6276e+02, 4.7710e+01, 2.8977e+02],
        [2.2718e+02, 2.2979e+02, 2.7479e+02, 2.9342e+02],
        [0.0000e+00, 2.3777e+02, 2.5494e+01, 2.6352e+02],
        [2.0384e+02, 2.4028e+02, 2.4318e+02, 2.8795e+02],
        [4.2535e+01, 2.6147e+02, 1.1577e+02, 2.8880e+02],
        [1.9591e+01, 2.3489e+02, 9.4205e+01, 2.6563e+02],
        [1.1377e+02, 2.7403e+02, 1.3765e+02, 2.8811e+02],
        [0.0000e+00, 1.8285e+02, 4.6496e+01, 2.1113e+02],
        [2.0776e+02, 3.1570e+02, 2.3758e+02, 3.2559e+02],
        [9.0321e+01, 2.4779e+02, 1.1475e+02, 2.7026e+02],
        [2.5588e+02, 3.2525e+02, 2.7300e+02, 3.3730e+02],
        [1.8110e+02, 2.7312e+02, 2.0431e+02, 2.8790e+02],
        [2.1847e+02, 3.2533e+02, 2.4052e+02, 3.3727e+02],
        [4.4235e+01, 1.9990e+02, 7.3143e+01, 2.2435e+02],
        [1.5659e+02, 2.5914e+02, 1.8175e+02, 2.8848e+02],
        [6.7088e+01, 2.2348e+02, 9.5343e+01, 2.5047e+02],
        [4.7042e-01, 2.0793e+02, 7.0275e+01, 2.3979e+02],
        [1.7240e+02, 3.2509e+02, 1.9545e+02, 3.3726e+02],
        [4.2555e+02, 1.9819e+02, 4.9294e+02, 2.2240e+02]])), gt_classes: tensor([114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114,
        114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114,
        114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114,
        114, 114, 114, 114, 114, 114, 114, 114, 114, 102, 102, 102, 102, 102,
        102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102,
        138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 138, 109, 109,
        109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109,
        109, 109, 109])])}], 'support_set_target': tensor(114)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000326948.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1027, 118, 207, 1199], 'neg_category_ids': [1024, 564, 790, 1009, 487, 570, 1110], 'image_id': 326948, 'annotations': [{'bbox': [607.6, 288.67, 32.4, 27.68], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 861}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000326948.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1027, 118, 207, 1199], 'neg_category_ids': [1024, 564, 790, 1009, 487, 570, 1110], 'image_id': 326948, 'image': tensor([[[132., 130., 130.,  ..., 125., 125., 125.],
         [130., 131., 130.,  ..., 125., 125., 125.],
         [125., 126., 125.,  ..., 125., 125., 125.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]],

        [[133., 132., 131.,  ..., 125., 125., 125.],
         [131., 132., 131.,  ..., 125., 125., 125.],
         [125., 126., 126.,  ..., 125., 125., 125.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]],

        [[136., 135., 135.,  ..., 125., 125., 125.],
         [134., 134., 134.,  ..., 125., 125., 125.],
         [127., 127., 127.,  ..., 125., 125., 125.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 356.2742,  39.9938, 390.4366]])), gt_classes: tensor([861])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000457257.jpg', 'height': 469, 'width': 640, 'not_exhaustive_category_ids': [53], 'neg_category_ids': [876, 554, 789, 1105, 402, 357, 1015, 977, 624], 'image_id': 457257, 'annotations': [{'bbox': [538.63, 145.64, 61.62, 48.06], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 861}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000457257.jpg', 'height': 469, 'width': 640, 'not_exhaustive_category_ids': [53], 'neg_category_ids': [876, 554, 789, 1105, 402, 357, 1015, 977, 624], 'image_id': 457257, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 39.2531, 143.7768, 100.1029, 191.2220]])), gt_classes: tensor([861])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000326948.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1027, 118, 207, 1199], 'neg_category_ids': [1024, 564, 790, 1009, 487, 570, 1110], 'image_id': 326948, 'annotations': [{'bbox': [426.47, 318.07, 23.31, 26.88], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 861}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000326948.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1027, 118, 207, 1199], 'neg_category_ids': [1024, 564, 790, 1009, 487, 570, 1110], 'image_id': 326948, 'image': tensor([[[116., 115., 130.,  ..., 156., 157., 156.],
         [115., 114., 131.,  ..., 159., 158., 158.],
         [113., 114., 133.,  ..., 160., 158., 159.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]],

        [[101., 101., 120.,  ..., 165., 165., 165.],
         [100.,  99., 119.,  ..., 168., 165., 165.],
         [ 98.,  97., 118.,  ..., 169., 164., 163.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 99., 102., 124.,  ..., 184., 183., 183.],
         [ 96.,  96., 117.,  ..., 185., 182., 181.],
         [ 93.,  89., 108.,  ..., 184., 178., 176.],
         ...,
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[679.0128, 518.4467, 717.0009, 562.2604]])), gt_classes: tensor([861])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000457257.jpg', 'height': 469, 'width': 640, 'not_exhaustive_category_ids': [53], 'neg_category_ids': [876, 554, 789, 1105, 402, 357, 1015, 977, 624], 'image_id': 457257, 'annotations': [{'bbox': [137.56, 152.08, 174.04, 63.67], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 861}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000457257.jpg', 'height': 469, 'width': 640, 'not_exhaustive_category_ids': [53], 'neg_category_ids': [876, 554, 789, 1105, 402, 357, 1015, 977, 624], 'image_id': 457257, 'image': tensor([[[195., 196., 197.,  ..., 128., 128., 128.],
         [198., 198., 197.,  ..., 128., 128., 128.],
         [198., 198., 197.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[148., 149., 150.,  ..., 128., 128., 128.],
         [151., 151., 150.,  ..., 128., 128., 128.],
         [151., 151., 150.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[116., 117., 118.,  ..., 128., 128., 128.],
         [119., 119., 118.,  ..., 128., 128., 128.],
         [119., 119., 118.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[140.9990, 155.9712, 319.3900, 221.2702]])), gt_classes: tensor([861])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000447228.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [676, 118], 'neg_category_ids': [49, 712, 472, 720, 1110, 524, 67, 647], 'image_id': 447228, 'annotations': [{'bbox': [573.93, 232.32, 16.77, 8.39], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 861}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000447228.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [676, 118], 'neg_category_ids': [49, 712, 472, 720, 1110, 524, 67, 647], 'image_id': 447228, 'image': tensor([[[48., 48., 48.,  ..., 53., 53., 53.],
         [50., 50., 50.,  ..., 53., 53., 53.],
         [52., 52., 52.,  ..., 53., 53., 53.],
         ...,
         [19., 19., 19.,  ..., 27., 27., 28.],
         [19., 19., 19.,  ..., 27., 27., 27.],
         [19., 19., 19.,  ..., 27., 27., 27.]],

        [[47., 46., 46.,  ..., 52., 52., 52.],
         [49., 48., 48.,  ..., 52., 52., 52.],
         [50., 50., 50.,  ..., 52., 52., 52.],
         ...,
         [16., 17., 17.,  ..., 24., 25., 25.],
         [16., 17., 17.,  ..., 24., 24., 25.],
         [17., 17., 17.,  ..., 24., 24., 24.]],

        [[43., 42., 42.,  ..., 48., 48., 48.],
         [45., 44., 44.,  ..., 48., 48., 48.],
         [47., 46., 46.,  ..., 48., 48., 48.],
         ...,
         [13., 13., 14.,  ..., 20., 20., 21.],
         [13., 13., 14.,  ..., 20., 20., 21.],
         [13., 13., 14.,  ..., 20., 20., 21.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000448607.jpg', 'height': 479, 'width': 640, 'not_exhaustive_category_ids': [1133, 1045, 358], 'neg_category_ids': [711, 437, 265, 1085, 576, 360, 601], 'image_id': 448607, 'annotations': [{'bbox': [488.75, 308.37, 102.51, 32.11], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 735}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000448607.jpg', 'height': 479, 'width': 640, 'not_exhaustive_category_ids': [1133, 1045, 358], 'neg_category_ids': [711, 437, 265, 1085, 576, 360, 601], 'image_id': 448607, 'image': tensor([[[ 22., 231., 230.,  ...,   0.,   0.,   0.],
         [ 22., 231., 230.,  ...,   0.,   0.,   0.],
         [232., 231., 230.,  ...,   0.,   0.,   0.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  1.,   0.,   2.,  ..., 223., 223., 224.],
         [  1.,   0.,   2.,  ..., 223., 223., 224.],
         [  1.,   1.,   2.,  ..., 224., 224., 223.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  1.,   0.,   2.,  ...,  32.,  33.,  34.],
         [  1.,   0.,   2.,  ...,  32.,  33.,  34.],
         [  0.,   0.,   1.,  ...,  31.,  32.,  33.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 990.6484,  657.2980, 1024.0000,  725.7413]])), gt_classes: tensor([735])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000493454.jpg', 'height': 433, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1024, 854, 56, 700, 721, 1015], 'image_id': 493454, 'annotations': [{'bbox': [377.04, 141.05, 37.1, 39.47], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 735}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000493454.jpg', 'height': 433, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1024, 854, 56, 700, 721, 1015], 'image_id': 493454, 'image': tensor([[[203., 204., 206.,  ..., 243., 242., 241.],
         [203., 204., 204.,  ..., 244., 244., 243.],
         [204., 203., 203.,  ..., 244., 244., 244.],
         ...,
         [146., 147., 146.,  ..., 207., 207., 207.],
         [155., 153., 152.,  ..., 203., 202., 202.],
         [163., 160., 157.,  ..., 199., 198., 197.]],

        [[203., 204., 206.,  ..., 243., 242., 241.],
         [203., 204., 204.,  ..., 244., 244., 243.],
         [204., 203., 203.,  ..., 244., 244., 244.],
         ...,
         [145., 146., 145.,  ..., 207., 207., 207.],
         [154., 153., 151.,  ..., 203., 202., 202.],
         [163., 160., 156.,  ..., 199., 198., 197.]],

        [[202., 203., 205.,  ..., 243., 242., 241.],
         [202., 203., 203.,  ..., 244., 244., 243.],
         [203., 202., 202.,  ..., 244., 244., 244.],
         ...,
         [144., 145., 144.,  ..., 205., 205., 205.],
         [153., 151., 150.,  ..., 202., 201., 201.],
         [161., 158., 155.,  ..., 198., 197., 196.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[348.1066, 320.4148, 463.9282, 443.6560]])), gt_classes: tensor([735])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000090519.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [1045, 207], 'neg_category_ids': [498, 516, 51, 1191, 566, 462, 528, 404, 554, 362, 580], 'image_id': 90519, 'annotations': [{'bbox': [301.39, 387.75, 41.18, 42.53], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 735}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000090519.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [1045, 207], 'neg_category_ids': [498, 516, 51, 1191, 566, 462, 528, 404, 554, 362, 580], 'image_id': 90519, 'image': tensor([[[250., 248., 244.,  ..., 128., 128., 128.],
         [243., 244., 244.,  ..., 128., 128., 128.],
         [241., 243., 245.,  ..., 128., 128., 128.],
         ...,
         [162., 160., 156.,  ..., 128., 128., 128.],
         [162., 159., 154.,  ..., 128., 128., 128.],
         [164., 160., 154.,  ..., 128., 128., 128.]],

        [[252., 253., 253.,  ..., 128., 128., 128.],
         [250., 251., 253.,  ..., 128., 128., 128.],
         [248., 250., 253.,  ..., 128., 128., 128.],
         ...,
         [167., 165., 161.,  ..., 128., 128., 128.],
         [167., 164., 159.,  ..., 128., 128., 128.],
         [167., 163., 157.,  ..., 128., 128., 128.]],

        [[255., 249., 239.,  ..., 128., 128., 128.],
         [255., 249., 238.,  ..., 128., 128., 128.],
         [255., 250., 240.,  ..., 128., 128., 128.],
         ...,
         [166., 164., 160.,  ..., 128., 128., 128.],
         [166., 163., 158.,  ..., 128., 128., 128.],
         [167., 163., 157.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[259.6854, 669.4840, 337.4984, 749.8258]])), gt_classes: tensor([735])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000341981.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1108, 1045, 358], 'neg_category_ids': [559, 857, 107, 791, 446, 211, 143, 873, 166], 'image_id': 341981, 'annotations': [{'bbox': [192.08, 294.9, 5.82, 2.77], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 735}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000341981.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1108, 1045, 358], 'neg_category_ids': [559, 857, 107, 791, 446, 211, 143, 873, 166], 'image_id': 341981, 'image': tensor([[[ 30.,  30.,  31.,  ..., 254., 254., 253.],
         [ 35.,  35.,  35.,  ..., 253., 252., 252.],
         [ 41.,  41.,  40.,  ..., 251., 249., 248.],
         ...,
         [ 54.,  54.,  54.,  ...,  54.,  54.,  54.],
         [ 54.,  54.,  54.,  ...,  54.,  54.,  54.],
         [ 54.,  54.,  54.,  ...,  54.,  54.,  54.]],

        [[ 31.,  32.,  32.,  ..., 253., 253., 253.],
         [ 36.,  36.,  36.,  ..., 252., 252., 251.],
         [ 45.,  45.,  44.,  ..., 251., 249., 248.],
         ...,
         [ 59.,  59.,  59.,  ...,  59.,  59.,  59.],
         [ 59.,  59.,  59.,  ...,  59.,  59.,  59.],
         [ 59.,  59.,  59.,  ...,  59.,  59.,  59.]],

        [[ 34.,  34.,  34.,  ..., 252., 252., 252.],
         [ 38.,  38.,  38.,  ..., 252., 251., 251.],
         [ 45.,  45.,  44.,  ..., 250., 249., 248.],
         ...,
         [ 59.,  59.,  59.,  ...,  59.,  59.,  59.],
         [ 59.,  59.,  59.,  ...,  59.,  59.,  59.],
         [ 59.,  59.,  59.,  ...,  59.,  59.,  59.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[716.7018, 484.7419, 726.2685, 489.2950]])), gt_classes: tensor([735])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000234416.jpg', 'height': 409, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [559, 237, 879, 899, 792, 544, 334, 994], 'image_id': 234416, 'annotations': [{'bbox': [302.35, 197.46, 23.64, 34.96], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 735}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000234416.jpg', 'height': 409, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [559, 237, 879, 899, 792, 544, 334, 994], 'image_id': 234416, 'image': tensor([[[224., 227., 230.,  ..., 128., 128., 128.],
         [229., 227., 228.,  ..., 128., 128., 128.],
         [230., 223., 224.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 58.,  61.,  61.,  ..., 128., 128., 128.],
         [ 63.,  61.,  59.,  ..., 128., 128., 128.],
         [ 64.,  57.,  55.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[347.3736, 218.2199, 373.5253, 256.8554]])), gt_classes: tensor([735])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000448607.jpg', 'height': 479, 'width': 640, 'not_exhaustive_category_ids': [1133, 1045, 358], 'neg_category_ids': [711, 437, 265, 1085, 576, 360, 601], 'image_id': 448607, 'image': tensor([[[ 22., 231., 230.,  ...,   0.,   0.,   0.],
         [ 22., 231., 230.,  ...,   0.,   0.,   0.],
         [232., 231., 230.,  ...,   0.,   0.,   0.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  1.,   0.,   2.,  ..., 223., 223., 224.],
         [  1.,   0.,   2.,  ..., 223., 223., 224.],
         [  1.,   1.,   2.,  ..., 224., 224., 223.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  1.,   0.,   2.,  ...,  32.,  33.,  34.],
         [  1.,   0.,   2.,  ...,  32.,  33.,  34.],
         [  0.,   0.,   1.,  ...,  31.,  32.,  33.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 990.6484,  657.2980, 1024.0000,  725.7413]])), gt_classes: tensor([735])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000493454.jpg', 'height': 433, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1024, 854, 56, 700, 721, 1015], 'image_id': 493454, 'image': tensor([[[203., 204., 206.,  ..., 243., 242., 241.],
         [203., 204., 204.,  ..., 244., 244., 243.],
         [204., 203., 203.,  ..., 244., 244., 244.],
         ...,
         [146., 147., 146.,  ..., 207., 207., 207.],
         [155., 153., 152.,  ..., 203., 202., 202.],
         [163., 160., 157.,  ..., 199., 198., 197.]],

        [[203., 204., 206.,  ..., 243., 242., 241.],
         [203., 204., 204.,  ..., 244., 244., 243.],
         [204., 203., 203.,  ..., 244., 244., 244.],
         ...,
         [145., 146., 145.,  ..., 207., 207., 207.],
         [154., 153., 151.,  ..., 203., 202., 202.],
         [163., 160., 156.,  ..., 199., 198., 197.]],

        [[202., 203., 205.,  ..., 243., 242., 241.],
         [202., 203., 203.,  ..., 244., 244., 243.],
         [203., 202., 202.,  ..., 244., 244., 244.],
         ...,
         [144., 145., 144.,  ..., 205., 205., 205.],
         [153., 151., 150.,  ..., 202., 201., 201.],
         [161., 158., 155.,  ..., 198., 197., 196.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[348.1066, 320.4148, 463.9282, 443.6560]])), gt_classes: tensor([735])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000090519.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [1045, 207], 'neg_category_ids': [498, 516, 51, 1191, 566, 462, 528, 404, 554, 362, 580], 'image_id': 90519, 'image': tensor([[[250., 248., 244.,  ..., 128., 128., 128.],
         [243., 244., 244.,  ..., 128., 128., 128.],
         [241., 243., 245.,  ..., 128., 128., 128.],
         ...,
         [162., 160., 156.,  ..., 128., 128., 128.],
         [162., 159., 154.,  ..., 128., 128., 128.],
         [164., 160., 154.,  ..., 128., 128., 128.]],

        [[252., 253., 253.,  ..., 128., 128., 128.],
         [250., 251., 253.,  ..., 128., 128., 128.],
         [248., 250., 253.,  ..., 128., 128., 128.],
         ...,
         [167., 165., 161.,  ..., 128., 128., 128.],
         [167., 164., 159.,  ..., 128., 128., 128.],
         [167., 163., 157.,  ..., 128., 128., 128.]],

        [[255., 249., 239.,  ..., 128., 128., 128.],
         [255., 249., 238.,  ..., 128., 128., 128.],
         [255., 250., 240.,  ..., 128., 128., 128.],
         ...,
         [166., 164., 160.,  ..., 128., 128., 128.],
         [166., 163., 158.,  ..., 128., 128., 128.],
         [167., 163., 157.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[259.6854, 669.4840, 337.4984, 749.8258]])), gt_classes: tensor([735])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000341981.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1108, 1045, 358], 'neg_category_ids': [559, 857, 107, 791, 446, 211, 143, 873, 166], 'image_id': 341981, 'image': tensor([[[ 30.,  30.,  31.,  ..., 254., 254., 253.],
         [ 35.,  35.,  35.,  ..., 253., 252., 252.],
         [ 41.,  41.,  40.,  ..., 251., 249., 248.],
         ...,
         [ 54.,  54.,  54.,  ...,  54.,  54.,  54.],
         [ 54.,  54.,  54.,  ...,  54.,  54.,  54.],
         [ 54.,  54.,  54.,  ...,  54.,  54.,  54.]],

        [[ 31.,  32.,  32.,  ..., 253., 253., 253.],
         [ 36.,  36.,  36.,  ..., 252., 252., 251.],
         [ 45.,  45.,  44.,  ..., 251., 249., 248.],
         ...,
         [ 59.,  59.,  59.,  ...,  59.,  59.,  59.],
         [ 59.,  59.,  59.,  ...,  59.,  59.,  59.],
         [ 59.,  59.,  59.,  ...,  59.,  59.,  59.]],

        [[ 34.,  34.,  34.,  ..., 252., 252., 252.],
         [ 38.,  38.,  38.,  ..., 252., 251., 251.],
         [ 45.,  45.,  44.,  ..., 250., 249., 248.],
         ...,
         [ 59.,  59.,  59.,  ...,  59.,  59.,  59.],
         [ 59.,  59.,  59.,  ...,  59.,  59.,  59.],
         [ 59.,  59.,  59.,  ...,  59.,  59.,  59.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[716.7018, 484.7419, 726.2685, 489.2950]])), gt_classes: tensor([735])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000234416.jpg', 'height': 409, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [559, 237, 879, 899, 792, 544, 334, 994], 'image_id': 234416, 'image': tensor([[[224., 227., 230.,  ..., 128., 128., 128.],
         [229., 227., 228.,  ..., 128., 128., 128.],
         [230., 223., 224.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 58.,  61.,  61.,  ..., 128., 128., 128.],
         [ 63.,  61.,  59.,  ..., 128., 128., 128.],
         [ 64.,  57.,  55.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[347.3736, 218.2199, 373.5253, 256.8554]])), gt_classes: tensor([735])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000074176.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [193, 412, 1051, 971, 64, 527, 1113, 145, 1141, 1183], 'image_id': 74176, 'annotations_cat_set': {1037, 1045, 1023}, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=3, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[278.5456, 233.9505, 350.7035, 286.3350],
        [311.4619, 579.4897, 592.8712, 656.8853],
        [386.4677, 536.7285, 437.3841, 572.5912]])), gt_classes: tensor([735, 727, 718])])}], 'support_set_target': tensor(735)}
0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000326948.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1027, 118, 207, 1199], 'neg_category_ids': [1024, 564, 790, 1009, 487, 570, 1110], 'image_id': 326948, 'image': tensor([[[132., 130., 130.,  ..., 125., 125., 125.],
         [130., 131., 130.,  ..., 125., 125., 125.],
         [125., 126., 125.,  ..., 125., 125., 125.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]],

        [[133., 132., 131.,  ..., 125., 125., 125.],
         [131., 132., 131.,  ..., 125., 125., 125.],
         [125., 126., 126.,  ..., 125., 125., 125.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]],

        [[136., 135., 135.,  ..., 125., 125., 125.],
         [134., 134., 134.,  ..., 125., 125., 125.],
         [127., 127., 127.,  ..., 125., 125., 125.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 356.2742,  39.9938, 390.4366]])), gt_classes: tensor([861])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000457257.jpg', 'height': 469, 'width': 640, 'not_exhaustive_category_ids': [53], 'neg_category_ids': [876, 554, 789, 1105, 402, 357, 1015, 977, 624], 'image_id': 457257, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 39.2531, 143.7768, 100.1029, 191.2220]])), gt_classes: tensor([861])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000326948.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1027, 118, 207, 1199], 'neg_category_ids': [1024, 564, 790, 1009, 487, 570, 1110], 'image_id': 326948, 'image': tensor([[[116., 115., 130.,  ..., 156., 157., 156.],
         [115., 114., 131.,  ..., 159., 158., 158.],
         [113., 114., 133.,  ..., 160., 158., 159.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]],

        [[101., 101., 120.,  ..., 165., 165., 165.],
         [100.,  99., 119.,  ..., 168., 165., 165.],
         [ 98.,  97., 118.,  ..., 169., 164., 163.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 99., 102., 124.,  ..., 184., 183., 183.],
         [ 96.,  96., 117.,  ..., 185., 182., 181.],
         [ 93.,  89., 108.,  ..., 184., 178., 176.],
         ...,
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[679.0128, 518.4467, 717.0009, 562.2604]])), gt_classes: tensor([861])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000457257.jpg', 'height': 469, 'width': 640, 'not_exhaustive_category_ids': [53], 'neg_category_ids': [876, 554, 789, 1105, 402, 357, 1015, 977, 624], 'image_id': 457257, 'image': tensor([[[195., 196., 197.,  ..., 128., 128., 128.],
         [198., 198., 197.,  ..., 128., 128., 128.],
         [198., 198., 197.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[148., 149., 150.,  ..., 128., 128., 128.],
         [151., 151., 150.,  ..., 128., 128., 128.],
         [151., 151., 150.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[116., 117., 118.,  ..., 128., 128., 128.],
         [119., 119., 118.,  ..., 128., 128., 128.],
         [119., 119., 118.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[140.9990, 155.9712, 319.3900, 221.2702]])), gt_classes: tensor([861])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000326948.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1027, 118, 207, 1199], 'neg_category_ids': [1024, 564, 790, 1009, 487, 570, 1110], 'image_id': 326948, 'image': tensor([[[116., 115., 130.,  ..., 156., 157., 156.],
         [115., 114., 131.,  ..., 159., 158., 158.],
         [113., 114., 133.,  ..., 160., 158., 159.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]],

        [[101., 101., 120.,  ..., 165., 165., 165.],
         [100.,  99., 119.,  ..., 168., 165., 165.],
         [ 98.,  97., 118.,  ..., 169., 164., 163.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 99., 102., 124.,  ..., 184., 183., 183.],
         [ 96.,  96., 117.,  ..., 185., 182., 181.],
         [ 93.,  89., 108.,  ..., 184., 178., 176.],
         ...,
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[679.0128, 518.4467, 717.0009, 562.2604]])), gt_classes: tensor([861])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000006004.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1199], 'neg_category_ids': [20, 983, 85, 866, 64, 679, 91], 'image_id': 6004, 'annotations_cat_set': {451, 643, 1199, 336, 1173, 118}, 'image': tensor([[[137., 137., 134.,  ..., 128., 128., 128.],
         [140., 144., 142.,  ..., 128., 128., 128.],
         [136., 135., 139.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[111., 116., 113.,  ..., 128., 128., 128.],
         [111., 111., 114.,  ..., 128., 128., 128.],
         [107., 110., 113.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 75.,  72.,  73.,  ..., 128., 128., 128.],
         [ 69.,  86.,  83.,  ..., 128., 128., 128.],
         [ 76.,  72.,  78.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=13, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[0.0000e+00, 1.1208e+02, 1.5476e+02, 2.3440e+02],
        [3.5117e+02, 3.0025e+02, 4.1500e+02, 3.3342e+02],
        [0.0000e+00, 2.5396e+02, 1.4122e+02, 2.8990e+02],
        [1.8968e+02, 6.4293e+01, 4.6383e+02, 2.8328e+02],
        [5.4776e+02, 2.2812e+02, 5.8560e+02, 2.6105e+02],
        [4.5429e+02, 2.4890e+02, 4.8640e+02, 2.6316e+02],
        [5.0633e+02, 4.1615e+01, 5.1487e+02, 6.2205e+01],
        [2.3797e+02, 1.6570e+02, 2.4188e+02, 1.7642e+02],
        [1.9006e+02, 6.3819e+01, 4.6311e+02, 2.8362e+02],
        [5.4751e+02, 2.2819e+02, 5.8526e+02, 2.6053e+02],
        [1.9025e+02, 6.3868e+01, 4.6235e+02, 2.8403e+02],
        [1.7409e-01, 1.1225e+02, 1.5443e+02, 2.3462e+02],
        [1.2425e+02, 2.7050e+02, 1.3014e+02, 2.7752e+02]])), gt_classes: tensor([ 92,  92,  92,  92,  92,  92, 836, 320, 861, 861, 242, 242, 453])])}], 'support_set_target': tensor(861)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000110857.jpg', 'height': 369, 'width': 640, 'not_exhaustive_category_ids': [312], 'neg_category_ids': [921, 123, 171, 477, 437, 1052, 904, 55, 592, 34, 677, 1156, 954, 37, 142, 705], 'image_id': 110857, 'annotations': [{'bbox': [425.9, 71.4, 69.61, 39.39], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 226}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000110857.jpg', 'height': 369, 'width': 640, 'not_exhaustive_category_ids': [312], 'neg_category_ids': [921, 123, 171, 477, 437, 1052, 904, 55, 592, 34, 677, 1156, 954, 37, 142, 705], 'image_id': 110857, 'image': tensor([[[107., 107., 107.,  ...,  93.,  93.,  93.],
         [107., 108., 108.,  ...,  93.,  93.,  93.],
         [107., 108., 108.,  ...,  92.,  92.,  92.],
         ...,
         [ 20.,  20.,  20.,  ...,   6.,   7.,   6.],
         [ 21.,  21.,  21.,  ...,   7.,   7.,   6.],
         [ 24.,  24.,  25.,  ...,   6.,   6.,   5.]],

        [[141., 141., 141.,  ..., 141., 141., 141.],
         [140., 141., 141.,  ..., 141., 141., 141.],
         [140., 141., 141.,  ..., 141., 141., 141.],
         ...,
         [ 52.,  52.,  53.,  ...,  17.,  17.,  16.],
         [ 53.,  53.,  53.,  ...,  18.,  18.,  17.],
         [ 56.,  56.,  57.,  ...,  17.,  17.,  16.]],

        [[178., 178., 178.,  ..., 185., 185., 185.],
         [178., 179., 179.,  ..., 185., 185., 185.],
         [179., 180., 180.,  ..., 185., 185., 185.],
         ...,
         [ 81.,  81.,  82.,  ...,  46.,  46.,  45.],
         [ 82.,  82.,  82.,  ...,  46.,  46.,  45.],
         [ 85.,  85.,  86.,  ...,  45.,  45.,  44.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[688.0992, 174.0081, 890.9471, 288.7622]])), gt_classes: tensor([226])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000146965.jpg', 'height': 399, 'width': 600, 'not_exhaustive_category_ids': [626], 'neg_category_ids': [343, 852, 22, 519, 607, 394, 477, 1172, 523, 508, 598, 334, 183, 997, 163], 'image_id': 146965, 'annotations': [{'bbox': [72.99, 57.11, 208.63, 75.36], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 226}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000146965.jpg', 'height': 399, 'width': 600, 'not_exhaustive_category_ids': [626], 'neg_category_ids': [343, 852, 22, 519, 607, 394, 477, 1172, 523, 508, 598, 334, 183, 997, 163], 'image_id': 146965, 'image': tensor([[[169., 169., 169.,  ..., 213., 213., 213.],
         [168., 168., 168.,  ..., 214., 214., 214.],
         [166., 166., 167.,  ..., 214., 214., 214.],
         ...,
         [205., 203., 201.,  ..., 162., 159., 161.],
         [204., 203., 201.,  ..., 153., 151., 153.],
         [203., 203., 202.,  ..., 145., 143., 144.]],

        [[168., 168., 168.,  ..., 209., 208., 208.],
         [167., 167., 167.,  ..., 209., 209., 209.],
         [167., 167., 167.,  ..., 209., 209., 209.],
         ...,
         [196., 194., 192.,  ..., 153., 151., 152.],
         [195., 194., 192.,  ..., 144., 142., 143.],
         [194., 193., 192.,  ..., 134., 133., 134.]],

        [[160., 160., 159.,  ..., 210., 209., 209.],
         [159., 159., 158.,  ..., 210., 210., 210.],
         [158., 158., 158.,  ..., 210., 210., 210.],
         ...,
         [186., 184., 182.,  ..., 161., 157., 159.],
         [184., 184., 182.,  ..., 150., 147., 148.],
         [183., 183., 182.,  ..., 139., 137., 138.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000,  63.6105, 323.2484, 286.1019]])), gt_classes: tensor([226])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000481725.jpg', 'height': 424, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [921, 964, 965, 127, 790, 1053, 655, 68, 143, 188], 'image_id': 481725, 'annotations': [{'bbox': [332.21, 32.75, 182.39, 40.39], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 226}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000481725.jpg', 'height': 424, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [921, 964, 965, 127, 790, 1053, 655, 68, 143, 188], 'image_id': 481725, 'image': tensor([[[ 65.,  63.,  59.,  ..., 128., 128., 128.],
         [ 62.,  60.,  56.,  ..., 128., 128., 128.],
         [ 59.,  57.,  54.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[122., 123., 124.,  ..., 128., 128., 128.],
         [121., 122., 123.,  ..., 128., 128., 128.],
         [121., 122., 123.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[137., 138., 137.,  ..., 128., 128., 128.],
         [136., 137., 136.,  ..., 128., 128., 128.],
         [135., 136., 135.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[481.7045,  47.5029, 746.1700, 106.0875]])), gt_classes: tensor([226])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000237110.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [876, 808, 813, 59, 678, 843, 1116, 450], 'image_id': 237110, 'annotations': [{'bbox': [244.1, 91.22, 210.1, 24.91], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 226}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000237110.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [876, 808, 813, 59, 678, 843, 1116, 450], 'image_id': 237110, 'image': tensor([[[133., 142., 151.,  ..., 127., 127., 127.],
         [136., 139., 141.,  ..., 127., 127., 127.],
         [141., 145., 144.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[102., 112., 123.,  ..., 127., 127., 127.],
         [105., 109., 112.,  ..., 127., 127., 127.],
         [110., 114., 115.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[105., 115., 126.,  ..., 127., 127., 127.],
         [108., 112., 115.,  ..., 127., 127., 127.],
         [113., 117., 118.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[165.1878,  81.1478, 351.9798, 103.3073]])), gt_classes: tensor([226])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000110857.jpg', 'height': 369, 'width': 640, 'not_exhaustive_category_ids': [312], 'neg_category_ids': [921, 123, 171, 477, 437, 1052, 904, 55, 592, 34, 677, 1156, 954, 37, 142, 705], 'image_id': 110857, 'annotations': [{'bbox': [294.54, 76.54, 61.31, 32.13], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 226}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000110857.jpg', 'height': 369, 'width': 640, 'not_exhaustive_category_ids': [312], 'neg_category_ids': [921, 123, 171, 477, 437, 1052, 904, 55, 592, 34, 677, 1156, 954, 37, 142, 705], 'image_id': 110857, 'image': tensor([[[105., 106., 106.,  ..., 108., 108., 108.],
         [105., 106., 106.,  ..., 108., 108., 108.],
         [106., 106., 106.,  ..., 108., 108., 108.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]],

        [[109., 109., 110.,  ..., 116., 116., 116.],
         [109., 109., 110.,  ..., 116., 116., 116.],
         [109., 109., 110.,  ..., 116., 116., 116.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]],

        [[114., 115., 115.,  ..., 124., 124., 124.],
         [114., 115., 115.,  ..., 124., 124., 124.],
         [115., 115., 115.,  ..., 124., 124., 124.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[625.8570, 173.2003, 764.6666, 245.9064]])), gt_classes: tensor([226])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000110857.jpg', 'height': 369, 'width': 640, 'not_exhaustive_category_ids': [312], 'neg_category_ids': [921, 123, 171, 477, 437, 1052, 904, 55, 592, 34, 677, 1156, 954, 37, 142, 705], 'image_id': 110857, 'image': tensor([[[107., 107., 107.,  ...,  93.,  93.,  93.],
         [107., 108., 108.,  ...,  93.,  93.,  93.],
         [107., 108., 108.,  ...,  92.,  92.,  92.],
         ...,
         [ 20.,  20.,  20.,  ...,   6.,   7.,   6.],
         [ 21.,  21.,  21.,  ...,   7.,   7.,   6.],
         [ 24.,  24.,  25.,  ...,   6.,   6.,   5.]],

        [[141., 141., 141.,  ..., 141., 141., 141.],
         [140., 141., 141.,  ..., 141., 141., 141.],
         [140., 141., 141.,  ..., 141., 141., 141.],
         ...,
         [ 52.,  52.,  53.,  ...,  17.,  17.,  16.],
         [ 53.,  53.,  53.,  ...,  18.,  18.,  17.],
         [ 56.,  56.,  57.,  ...,  17.,  17.,  16.]],

        [[178., 178., 178.,  ..., 185., 185., 185.],
         [178., 179., 179.,  ..., 185., 185., 185.],
         [179., 180., 180.,  ..., 185., 185., 185.],
         ...,
         [ 81.,  81.,  82.,  ...,  46.,  46.,  45.],
         [ 82.,  82.,  82.,  ...,  46.,  46.,  45.],
         [ 85.,  85.,  86.,  ...,  45.,  45.,  44.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[688.0992, 174.0081, 890.9471, 288.7622]])), gt_classes: tensor([226])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000146965.jpg', 'height': 399, 'width': 600, 'not_exhaustive_category_ids': [626], 'neg_category_ids': [343, 852, 22, 519, 607, 394, 477, 1172, 523, 508, 598, 334, 183, 997, 163], 'image_id': 146965, 'image': tensor([[[169., 169., 169.,  ..., 213., 213., 213.],
         [168., 168., 168.,  ..., 214., 214., 214.],
         [166., 166., 167.,  ..., 214., 214., 214.],
         ...,
         [205., 203., 201.,  ..., 162., 159., 161.],
         [204., 203., 201.,  ..., 153., 151., 153.],
         [203., 203., 202.,  ..., 145., 143., 144.]],

        [[168., 168., 168.,  ..., 209., 208., 208.],
         [167., 167., 167.,  ..., 209., 209., 209.],
         [167., 167., 167.,  ..., 209., 209., 209.],
         ...,
         [196., 194., 192.,  ..., 153., 151., 152.],
         [195., 194., 192.,  ..., 144., 142., 143.],
         [194., 193., 192.,  ..., 134., 133., 134.]],

        [[160., 160., 159.,  ..., 210., 209., 209.],
         [159., 159., 158.,  ..., 210., 210., 210.],
         [158., 158., 158.,  ..., 210., 210., 210.],
         ...,
         [186., 184., 182.,  ..., 161., 157., 159.],
         [184., 184., 182.,  ..., 150., 147., 148.],
         [183., 183., 182.,  ..., 139., 137., 138.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000,  63.6105, 323.2484, 286.1019]])), gt_classes: tensor([226])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000481725.jpg', 'height': 424, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [921, 964, 965, 127, 790, 1053, 655, 68, 143, 188], 'image_id': 481725, 'image': tensor([[[ 65.,  63.,  59.,  ..., 128., 128., 128.],
         [ 62.,  60.,  56.,  ..., 128., 128., 128.],
         [ 59.,  57.,  54.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[122., 123., 124.,  ..., 128., 128., 128.],
         [121., 122., 123.,  ..., 128., 128., 128.],
         [121., 122., 123.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[137., 138., 137.,  ..., 128., 128., 128.],
         [136., 137., 136.,  ..., 128., 128., 128.],
         [135., 136., 135.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[481.7045,  47.5029, 746.1700, 106.0875]])), gt_classes: tensor([226])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000237110.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [876, 808, 813, 59, 678, 843, 1116, 450], 'image_id': 237110, 'image': tensor([[[133., 142., 151.,  ..., 127., 127., 127.],
         [136., 139., 141.,  ..., 127., 127., 127.],
         [141., 145., 144.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[102., 112., 123.,  ..., 127., 127., 127.],
         [105., 109., 112.,  ..., 127., 127., 127.],
         [110., 114., 115.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[105., 115., 126.,  ..., 127., 127., 127.],
         [108., 112., 115.,  ..., 127., 127., 127.],
         [113., 117., 118.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[165.1878,  81.1478, 351.9798, 103.3073]])), gt_classes: tensor([226])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000110857.jpg', 'height': 369, 'width': 640, 'not_exhaustive_category_ids': [312], 'neg_category_ids': [921, 123, 171, 477, 437, 1052, 904, 55, 592, 34, 677, 1156, 954, 37, 142, 705], 'image_id': 110857, 'image': tensor([[[105., 106., 106.,  ..., 108., 108., 108.],
         [105., 106., 106.,  ..., 108., 108., 108.],
         [106., 106., 106.,  ..., 108., 108., 108.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]],

        [[109., 109., 110.,  ..., 116., 116., 116.],
         [109., 109., 110.,  ..., 116., 116., 116.],
         [109., 109., 110.,  ..., 116., 116., 116.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]],

        [[114., 115., 115.,  ..., 124., 124., 124.],
         [114., 115., 115.,  ..., 124., 124., 124.],
         [115., 115., 115.,  ..., 124., 124., 124.],
         ...,
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.],
         [112., 112., 112.,  ..., 112., 112., 112.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[625.8570, 173.2003, 764.6666, 245.9064]])), gt_classes: tensor([226])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000501966.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [854, 1075, 1192, 910, 525, 187, 1203], 'image_id': 501966, 'annotations_cat_set': {836, 421, 430, 687, 979, 372, 312, 284, 1021}, 'image': tensor([[[ 83.,  80.,  84.,  ..., 128., 128., 128.],
         [ 83.,  81.,  83.,  ..., 128., 128., 128.],
         [ 83.,  81.,  83.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 92.,  90.,  93.,  ..., 128., 128., 128.],
         [ 92.,  91.,  93.,  ..., 128., 128., 128.],
         [ 92.,  91.,  93.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 95.,  93.,  96.,  ..., 128., 128., 128.],
         [ 95.,  94.,  96.,  ..., 128., 128., 128.],
         [ 95.,  94.,  96.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=16, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[230.0110, 208.1934, 258.5027, 222.3037],
        [334.9916, 189.9831, 361.8921, 228.7930],
        [302.9405, 285.0502, 325.1929, 358.0000],
        [190.5396, 103.1660, 297.2539, 130.4478],
        [391.7909, 119.5904, 410.0065, 127.1948],
        [  0.0000, 151.4667, 136.9731, 358.0000],
        [343.9780, 232.7335, 535.4724, 357.3376],
        [400.8694,  41.6521, 435.9774,  75.0626],
        [395.0990,  32.0523, 469.9380,  61.3295],
        [417.4268,  29.5203, 528.2112,  47.5796],
        [374.3625,  54.3204, 404.6381,  81.6860],
        [299.9757, 196.9922, 315.3522, 208.2269],
        [371.9840,  71.4659, 390.5346,  87.9993],
        [203.3701, 194.8627, 214.9946, 222.8068],
        [214.8020, 201.2933, 224.5673, 221.9851],
        [305.3860, 263.5031, 353.7516, 358.0000]])), gt_classes: tensor([305, 209, 266, 226, 226, 299, 484, 589, 589, 589, 589, 589, 589, 688,
        688, 716])])}], 'support_set_target': tensor(226)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000537986.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [538, 853, 520, 903, 6, 1079, 311, 643, 935, 623], 'image_id': 537986, 'annotations': [{'bbox': [10.41, 291.86, 170.77, 134.14], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 730}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000537986.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [538, 853, 520, 903, 6, 1079, 311, 643, 935, 623], 'image_id': 537986, 'image': tensor([[[ 73.,  74.,  74.,  ...,  16.,   5.,   0.],
         [ 73.,  73.,  73.,  ...,  16.,   5.,   0.],
         [ 72.,  72.,  71.,  ...,  11.,   5.,   0.],
         ...,
         [177., 177., 177.,  ..., 177., 177., 177.],
         [177., 177., 177.,  ..., 177., 177., 177.],
         [177., 177., 177.,  ..., 177., 177., 177.]],

        [[ 83.,  85.,  85.,  ...,   5.,   2.,   1.],
         [ 83.,  83.,  83.,  ...,   5.,   2.,   1.],
         [ 82.,  80.,  79.,  ...,   2.,   1.,   1.],
         ...,
         [169., 169., 169.,  ..., 169., 169., 169.],
         [169., 169., 169.,  ..., 169., 169., 169.],
         [169., 169., 169.,  ..., 169., 169., 169.]],

        [[ 96.,  96.,  96.,  ...,   5.,   3.,   1.],
         [ 96.,  95.,  95.,  ...,   5.,   3.,   1.],
         [ 94.,  93.,  93.,  ...,   3.,   1.,   1.],
         ...,
         [157., 157., 157.,  ..., 157., 157., 157.],
         [157., 157., 157.,  ..., 157., 157., 157.],
         [157., 157., 157.,  ..., 157., 157., 157.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 662.7684,  606.3289, 1017.3830,  885.0000]])), gt_classes: tensor([730])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000034378.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [29], 'neg_category_ids': [856, 152, 1190, 886, 132, 847, 207, 641, 213, 780], 'image_id': 34378, 'annotations': [{'bbox': [324.66, 360.23, 72.31, 66.34], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 730}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000034378.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [29], 'neg_category_ids': [856, 152, 1190, 886, 132, 847, 207, 641, 213, 780], 'image_id': 34378, 'image': tensor([[[198., 199., 199.,  ..., 128., 128., 128.],
         [199., 199., 199.,  ..., 128., 128., 128.],
         [199., 199., 199.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[215., 216., 216.,  ..., 128., 128., 128.],
         [216., 216., 216.,  ..., 128., 128., 128.],
         [216., 216., 216.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[218., 219., 219.,  ..., 128., 128., 128.],
         [219., 219., 219.,  ..., 128., 128., 128.],
         [219., 219., 219.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[308.7241, 457.8625, 400.5804, 542.1824]])), gt_classes: tensor([730])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000072002.jpg', 'height': 214, 'width': 640, 'not_exhaustive_category_ids': [793], 'neg_category_ids': [1070, 560, 1129, 208, 1138, 1180], 'image_id': 72002, 'annotations': [{'bbox': [250.37, 126.48, 52.01, 57.56], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 730}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000072002.jpg', 'height': 214, 'width': 640, 'not_exhaustive_category_ids': [793], 'neg_category_ids': [1070, 560, 1129, 208, 1138, 1180], 'image_id': 72002, 'image': tensor([[[  2.,   2.,   3.,  ..., 128., 128., 128.],
         [  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  2.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  2.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[341.8402, 128.2531, 394.5004, 186.6200]])), gt_classes: tensor([730])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000090293.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [236, 157, 44, 347, 1164], 'image_id': 90293, 'annotations': [{'bbox': [350.79, 214.64, 94.88, 193.52], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 730}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000090293.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [236, 157, 44, 347, 1164], 'image_id': 90293, 'image': tensor([[[ 68., 198., 221.,  ..., 128., 128., 128.],
         [184., 221., 169.,  ..., 128., 128., 128.],
         [195., 159., 141.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[132., 155., 170.,  ..., 128., 128., 128.],
         [164., 170., 153.,  ..., 128., 128., 128.],
         [166., 162., 146.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[157., 149., 153.,  ..., 128., 128., 128.],
         [155., 166., 153.,  ..., 128., 128., 128.],
         [150., 157., 146.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[209.5120, 231.2281, 311.8045, 439.7040]])), gt_classes: tensor([730])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000165341.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [589], 'neg_category_ids': [649, 999, 715, 379, 1085, 867, 554, 626, 627], 'image_id': 165341, 'annotations': [{'bbox': [489.7, 347.74, 17.44, 28.55], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 730}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000165341.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [589], 'neg_category_ids': [649, 999, 715, 379, 1085, 867, 554, 626, 627], 'image_id': 165341, 'image': tensor([[[44., 44., 44.,  ..., 50., 50., 50.],
         [44., 44., 44.,  ..., 51., 50., 50.],
         [44., 44., 44.,  ..., 50., 50., 50.],
         ...,
         [25., 24., 23.,  ..., 26., 25., 25.],
         [24., 23., 23.,  ..., 26., 25., 25.],
         [23., 23., 23.,  ..., 26., 26., 25.]],

        [[37., 37., 37.,  ..., 46., 46., 46.],
         [38., 37., 37.,  ..., 46., 46., 46.],
         [38., 37., 37.,  ..., 46., 46., 46.],
         ...,
         [29., 29., 29.,  ..., 30., 29., 29.],
         [29., 29., 28.,  ..., 30., 29., 29.],
         [28., 28., 28.,  ..., 30., 29., 29.]],

        [[31., 31., 31.,  ..., 42., 42., 42.],
         [31., 31., 31.,  ..., 42., 42., 42.],
         [31., 31., 31.,  ..., 42., 42., 42.],
         ...,
         [33., 33., 32.,  ..., 33., 33., 32.],
         [33., 32., 32.,  ..., 33., 33., 32.],
         [32., 31., 31.,  ..., 33., 32., 32.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1009.1064,  873.0333, 1024.0000,  947.6663]])), gt_classes: tensor([730])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000551341.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [726, 11], 'neg_category_ids': [896, 235, 982, 590, 992, 10, 357, 620, 892, 1021], 'image_id': 551341, 'annotations': [{'bbox': [82.39, 165.64, 6.78, 47.9], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 10}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000551341.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [726, 11], 'neg_category_ids': [896, 235, 982, 590, 992, 10, 357, 620, 892, 1021], 'image_id': 551341, 'image': tensor([[[174., 174., 173.,  ..., 230.,  91.,  91.],
         [174., 174., 173.,  ..., 230.,  91.,  91.],
         [174., 174., 174.,  ..., 230.,  91.,  91.],
         ...,
         [ 91.,  91.,  91.,  ...,  91.,  91.,  91.],
         [ 91.,  91.,  91.,  ...,  91.,  91.,  91.],
         [ 91.,  91.,  91.,  ...,  91.,  91.,  91.]],

        [[167., 167., 167.,  ..., 228.,  89.,  89.],
         [167., 167., 167.,  ..., 228.,  89.,  89.],
         [167., 167., 167.,  ..., 228.,  89.,  89.],
         ...,
         [ 89.,  89.,  89.,  ...,  89.,  89.,  89.],
         [ 89.,  89.,  89.,  ...,  89.,  89.,  89.],
         [ 89.,  89.,  89.,  ...,  89.,  89.,  89.]],

        [[ 72.,  72.,  72.,  ..., 225.,  75.,  75.],
         [ 72.,  72.,  72.,  ..., 225.,  75.,  75.],
         [ 69.,  72.,  75.,  ..., 225.,  75.,  75.],
         ...,
         [ 75.,  75.,  75.,  ...,  75.,  75.,  75.],
         [ 75.,  75.,  75.,  ...,  75.,  75.,  75.],
         [ 75.,  75.,  75.,  ...,  75.,  75.,  75.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[131.5665, 264.6789, 142.3933, 341.2191]])), gt_classes: tensor([10])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038751.jpg', 'height': 456, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [537, 586, 286, 660, 554, 937, 731], 'image_id': 38751, 'annotations': [{'bbox': [135.32, 0.0, 35.28, 153.25], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 10}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038751.jpg', 'height': 456, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [537, 586, 286, 660, 554, 937, 731], 'image_id': 38751, 'image': tensor([[[145., 145., 145.,  ..., 144., 144., 144.],
         [145., 145., 145.,  ..., 144., 144., 144.],
         [145., 145., 145.,  ..., 144., 144., 144.],
         ...,
         [109., 107., 105.,  ...,  81.,  80.,  80.],
         [112., 108., 107.,  ...,  81.,  80.,  80.],
         [115., 111., 111.,  ...,  82.,  81.,  80.]],

        [[145., 145., 145.,  ..., 145., 145., 145.],
         [145., 145., 145.,  ..., 145., 145., 144.],
         [145., 145., 145.,  ..., 145., 145., 144.],
         ...,
         [116., 112., 108.,  ...,  80.,  80.,  80.],
         [118., 113., 111.,  ...,  80.,  80.,  80.],
         [123., 116., 116.,  ...,  80.,  80.,  80.]],

        [[145., 145., 145.,  ..., 144., 144., 144.],
         [145., 145., 145.,  ..., 144., 144., 144.],
         [145., 145., 145.,  ..., 144., 144., 144.],
         ...,
         [115., 111., 107.,  ...,  80.,  80.,  80.],
         [118., 114., 111.,  ...,  81.,  80.,  80.],
         [123., 117., 118.,  ...,  80.,  80.,  80.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[232.4023,   0.0000, 317.2397, 355.3377]])), gt_classes: tensor([10])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000324785.jpg', 'height': 640, 'width': 463, 'not_exhaustive_category_ids': [324], 'neg_category_ids': [558, 49, 631, 272, 76, 520, 521, 223, 179, 1083, 444, 426, 622], 'image_id': 324785, 'annotations': [{'bbox': [419.76, 0.52, 2.07, 48.48], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 10}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000324785.jpg', 'height': 640, 'width': 463, 'not_exhaustive_category_ids': [324], 'neg_category_ids': [558, 49, 631, 272, 76, 520, 521, 223, 179, 1083, 444, 426, 622], 'image_id': 324785, 'image': tensor([[[ 37.,  35.,  34.,  ..., 128., 128., 128.],
         [ 36.,  34.,  32.,  ..., 128., 128., 128.],
         [ 35.,  32.,  30.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 29.,  30.,  29.,  ..., 129., 129., 129.],
         [ 30.,  29.,  27.,  ..., 129., 129., 129.],
         [ 29.,  27.,  25.,  ..., 129., 129., 129.],
         ...,
         [129., 129., 129.,  ..., 129., 129., 129.],
         [129., 129., 129.,  ..., 129., 129., 129.],
         [129., 129., 129.,  ..., 129., 129., 129.]],

        [[ 22.,  21.,  20.,  ..., 128., 128., 128.],
         [ 23.,  21.,  18.,  ..., 128., 128., 128.],
         [ 21.,  18.,  16.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[47.9279,  0.6053, 50.3377, 57.0391]])), gt_classes: tensor([10])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000168260.jpg', 'height': 640, 'width': 586, 'not_exhaustive_category_ids': [], 'neg_category_ids': [851, 711, 693, 905, 699, 1017, 1041], 'image_id': 168260, 'annotations': [{'bbox': [307.03, 150.11, 6.32, 100.03], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 10}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000168260.jpg', 'height': 640, 'width': 586, 'not_exhaustive_category_ids': [], 'neg_category_ids': [851, 711, 693, 905, 699, 1017, 1041], 'image_id': 168260, 'image': tensor([[[ 86.,  86.,  87.,  ...,  74.,  76.,  76.],
         [ 86.,  87.,  88.,  ...,  75.,  76.,  76.],
         [ 86.,  87.,  89.,  ...,  77.,  77.,  76.],
         ...,
         [143., 144., 147.,  ..., 159., 160., 160.],
         [146., 148., 152.,  ..., 160., 161., 161.],
         [147., 150., 154.,  ..., 160., 161., 161.]],

        [[ 80.,  81.,  82.,  ...,  67.,  69.,  70.],
         [ 81.,  82.,  83.,  ...,  67.,  68.,  69.],
         [ 81.,  82.,  83.,  ...,  68.,  68.,  68.],
         ...,
         [129., 131., 135.,  ...,  70.,  71.,  71.],
         [133., 135., 140.,  ...,  71.,  72.,  72.],
         [135., 137., 142.,  ...,  71.,  72.,  72.]],

        [[ 77.,  77.,  77.,  ...,  60.,  61.,  62.],
         [ 78.,  78.,  78.,  ...,  61.,  62.,  62.],
         [ 78.,  78.,  79.,  ...,  64.,  63.,  63.],
         ...,
         [123., 125., 128.,  ...,  33.,  34.,  34.],
         [126., 129., 132.,  ...,  34.,  35.,  35.],
         [128., 131., 134.,  ...,  34.,  35.,  35.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[545.0768, 221.4621, 559.9601, 457.0015]])), gt_classes: tensor([10])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000570037.jpg', 'height': 334, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1024, 222, 846, 1193, 983], 'image_id': 570037, 'annotations': [{'bbox': [120.54, 128.6, 4.2, 17.57], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 10}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000570037.jpg', 'height': 334, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1024, 222, 846, 1193, 983], 'image_id': 570037, 'image': tensor([[[ 26.,  31.,  34.,  ..., 218., 218., 219.],
         [ 26.,  31.,  34.,  ..., 218., 218., 219.],
         [ 27.,  32.,  35.,  ..., 218., 219., 220.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]],

        [[ 20.,  24.,  28.,  ..., 176., 176., 176.],
         [ 20.,  24.,  28.,  ..., 176., 176., 176.],
         [ 20.,  24.,  27.,  ..., 176., 176., 177.],
         ...,
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.]],

        [[ 21.,  26.,  29.,  ..., 120., 121., 122.],
         [ 21.,  26.,  29.,  ..., 120., 121., 122.],
         [ 22.,  26.,  29.,  ..., 121., 122., 123.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[850.7613, 376.5593, 863.0589, 428.0068]])), gt_classes: tensor([10])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000487942.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 853, 807, 1027, 504, 483, 1160, 361], 'image_id': 487942, 'annotations': [{'bbox': [0.33, 0.16, 118.85, 385.85], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 595}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000487942.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 853, 807, 1027, 504, 483, 1160, 361], 'image_id': 487942, 'image': tensor([[[136., 136., 136.,  ..., 126., 126., 126.],
         [136., 136., 136.,  ..., 126., 126., 126.],
         [136., 136., 137.,  ..., 126., 126., 126.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]],

        [[132., 132., 132.,  ..., 126., 126., 126.],
         [132., 132., 132.,  ..., 126., 126., 126.],
         [132., 132., 132.,  ..., 126., 126., 126.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]],

        [[128., 128., 129.,  ..., 126., 126., 126.],
         [128., 128., 129.,  ..., 126., 126., 126.],
         [128., 128., 129.,  ..., 126., 126., 126.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[5.5581e+02, 1.7089e-01, 6.8265e+02, 4.1229e+02]])), gt_classes: tensor([595])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000145791.jpg', 'height': 359, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [687, 604, 422, 821, 957, 1179, 781, 580], 'image_id': 145791, 'annotations': [{'bbox': [199.33, 206.31, 73.83, 88.49], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 595}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000145791.jpg', 'height': 359, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [687, 604, 422, 821, 957, 1179, 781, 580], 'image_id': 145791, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[330.6826, 559.7380, 530.9465, 799.8195]])), gt_classes: tensor([595])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000204671.jpg', 'height': 417, 'width': 640, 'not_exhaustive_category_ids': [330], 'neg_category_ids': [1069, 734, 1024, 455, 1107, 1177, 890, 513], 'image_id': 204671, 'annotations': [{'bbox': [525.43, 73.67, 78.84, 64.9], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 595}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000204671.jpg', 'height': 417, 'width': 640, 'not_exhaustive_category_ids': [330], 'neg_category_ids': [1069, 734, 1024, 455, 1107, 1177, 890, 513], 'image_id': 204671, 'image': tensor([[[109.,  99.,  83.,  ...,  87.,  89.,  83.],
         [112., 105.,  91.,  ...,  84.,  88.,  84.],
         [121., 117., 110.,  ...,  78.,  84.,  86.],
         ...,
         [131., 131., 131.,  ..., 131., 131., 131.],
         [131., 131., 131.,  ..., 131., 131., 131.],
         [131., 131., 131.,  ..., 131., 131., 131.]],

        [[108.,  99.,  83.,  ...,  84.,  87.,  82.],
         [112., 105.,  91.,  ...,  82.,  86.,  83.],
         [120., 116., 109.,  ...,  76.,  82.,  84.],
         ...,
         [129., 129., 129.,  ..., 129., 129., 129.],
         [129., 129., 129.,  ..., 129., 129., 129.],
         [129., 129., 129.,  ..., 129., 129., 129.]],

        [[109., 100.,  85.,  ...,  86.,  88.,  84.],
         [113., 105.,  92.,  ...,  84.,  87.,  85.],
         [121., 117., 110.,  ...,  78.,  84.,  86.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 922.6929,  162.8867, 1024.0000,  306.3826]])), gt_classes: tensor([595])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000277329.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [150, 76, 1170, 608, 696, 197, 91, 683, 1019, 780], 'image_id': 277329, 'annotations': [{'bbox': [87.08, 356.49, 14.25, 9.26], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 595}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000277329.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [150, 76, 1170, 608, 696, 197, 91, 683, 1019, 780], 'image_id': 277329, 'image': tensor([[[250., 250., 249.,  ..., 215., 215., 215.],
         [251., 251., 250.,  ..., 214., 214., 214.],
         [251., 251., 251.,  ..., 214., 214., 214.],
         ...,
         [ 63.,  63.,  63.,  ...,  50.,  50.,  63.],
         [ 63.,  63.,  63.,  ...,  47.,  42.,  55.],
         [ 62.,  62.,  62.,  ...,  44.,  41.,  49.]],

        [[249., 249., 248.,  ..., 206., 206., 206.],
         [250., 250., 249.,  ..., 205., 205., 205.],
         [250., 250., 250.,  ..., 205., 205., 205.],
         ...,
         [ 94.,  94.,  93.,  ..., 127., 127., 138.],
         [ 94.,  94.,  93.,  ..., 122., 117., 128.],
         [ 93.,  93.,  92.,  ..., 118., 113., 119.]],

        [[251., 251., 250.,  ..., 197., 197., 197.],
         [252., 252., 251.,  ..., 196., 196., 196.],
         [252., 252., 252.,  ..., 195., 195., 195.],
         ...,
         [149., 149., 150.,  ..., 115., 116., 129.],
         [149., 149., 150.,  ..., 111., 108., 121.],
         [148., 148., 149.,  ..., 109., 105., 113.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000289751.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [412, 1073, 126, 83, 569, 991, 548, 1019], 'image_id': 289751, 'annotations': [{'bbox': [109.96, 73.58, 58.59, 48.87], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 595}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000289751.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [412, 1073, 126, 83, 569, 991, 548, 1019], 'image_id': 289751, 'image': tensor([[[255., 248., 255.,  ..., 219., 226., 236.],
         [255., 237., 255.,  ..., 219., 225., 232.],
         [255., 255., 243.,  ..., 223., 225., 226.],
         ...,
         [255., 255., 255.,  ..., 223., 217., 215.],
         [255., 255., 255.,  ..., 223., 221., 221.],
         [255., 255., 255.,  ..., 232., 232., 232.]],

        [[255., 237., 255.,  ..., 241., 237., 230.],
         [255., 255., 248.,  ..., 245., 237., 228.],
         [255., 255., 241.,  ..., 247., 239., 226.],
         ...,
         [255., 255., 255.,  ..., 237., 234., 232.],
         [255., 255., 255.,  ..., 237., 232., 230.],
         [255., 255., 255.,  ..., 241., 234., 230.]],

        [[252., 255., 255.,  ..., 223., 225., 228.],
         [255., 255., 255.,  ..., 226., 226., 226.],
         [255., 255., 255.,  ..., 232., 228., 223.],
         ...,
         [255., 255., 255.,  ..., 239., 230., 219.],
         [255., 255., 255.,  ..., 239., 234., 225.],
         [255., 255., 255.,  ..., 250., 243., 232.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000537986.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [538, 853, 520, 903, 6, 1079, 311, 643, 935, 623], 'image_id': 537986, 'image': tensor([[[ 73.,  74.,  74.,  ...,  16.,   5.,   0.],
         [ 73.,  73.,  73.,  ...,  16.,   5.,   0.],
         [ 72.,  72.,  71.,  ...,  11.,   5.,   0.],
         ...,
         [177., 177., 177.,  ..., 177., 177., 177.],
         [177., 177., 177.,  ..., 177., 177., 177.],
         [177., 177., 177.,  ..., 177., 177., 177.]],

        [[ 83.,  85.,  85.,  ...,   5.,   2.,   1.],
         [ 83.,  83.,  83.,  ...,   5.,   2.,   1.],
         [ 82.,  80.,  79.,  ...,   2.,   1.,   1.],
         ...,
         [169., 169., 169.,  ..., 169., 169., 169.],
         [169., 169., 169.,  ..., 169., 169., 169.],
         [169., 169., 169.,  ..., 169., 169., 169.]],

        [[ 96.,  96.,  96.,  ...,   5.,   3.,   1.],
         [ 96.,  95.,  95.,  ...,   5.,   3.,   1.],
         [ 94.,  93.,  93.,  ...,   3.,   1.,   1.],
         ...,
         [157., 157., 157.,  ..., 157., 157., 157.],
         [157., 157., 157.,  ..., 157., 157., 157.],
         [157., 157., 157.,  ..., 157., 157., 157.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 662.7684,  606.3289, 1017.3830,  885.0000]])), gt_classes: tensor([730])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000034378.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [29], 'neg_category_ids': [856, 152, 1190, 886, 132, 847, 207, 641, 213, 780], 'image_id': 34378, 'image': tensor([[[198., 199., 199.,  ..., 128., 128., 128.],
         [199., 199., 199.,  ..., 128., 128., 128.],
         [199., 199., 199.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[215., 216., 216.,  ..., 128., 128., 128.],
         [216., 216., 216.,  ..., 128., 128., 128.],
         [216., 216., 216.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[218., 219., 219.,  ..., 128., 128., 128.],
         [219., 219., 219.,  ..., 128., 128., 128.],
         [219., 219., 219.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[308.7241, 457.8625, 400.5804, 542.1824]])), gt_classes: tensor([730])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000072002.jpg', 'height': 214, 'width': 640, 'not_exhaustive_category_ids': [793], 'neg_category_ids': [1070, 560, 1129, 208, 1138, 1180], 'image_id': 72002, 'image': tensor([[[  2.,   2.,   3.,  ..., 128., 128., 128.],
         [  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  2.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  2.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[341.8402, 128.2531, 394.5004, 186.6200]])), gt_classes: tensor([730])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000090293.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [236, 157, 44, 347, 1164], 'image_id': 90293, 'image': tensor([[[ 68., 198., 221.,  ..., 128., 128., 128.],
         [184., 221., 169.,  ..., 128., 128., 128.],
         [195., 159., 141.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[132., 155., 170.,  ..., 128., 128., 128.],
         [164., 170., 153.,  ..., 128., 128., 128.],
         [166., 162., 146.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[157., 149., 153.,  ..., 128., 128., 128.],
         [155., 166., 153.,  ..., 128., 128., 128.],
         [150., 157., 146.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[209.5120, 231.2281, 311.8045, 439.7040]])), gt_classes: tensor([730])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000165341.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [589], 'neg_category_ids': [649, 999, 715, 379, 1085, 867, 554, 626, 627], 'image_id': 165341, 'image': tensor([[[44., 44., 44.,  ..., 50., 50., 50.],
         [44., 44., 44.,  ..., 51., 50., 50.],
         [44., 44., 44.,  ..., 50., 50., 50.],
         ...,
         [25., 24., 23.,  ..., 26., 25., 25.],
         [24., 23., 23.,  ..., 26., 25., 25.],
         [23., 23., 23.,  ..., 26., 26., 25.]],

        [[37., 37., 37.,  ..., 46., 46., 46.],
         [38., 37., 37.,  ..., 46., 46., 46.],
         [38., 37., 37.,  ..., 46., 46., 46.],
         ...,
         [29., 29., 29.,  ..., 30., 29., 29.],
         [29., 29., 28.,  ..., 30., 29., 29.],
         [28., 28., 28.,  ..., 30., 29., 29.]],

        [[31., 31., 31.,  ..., 42., 42., 42.],
         [31., 31., 31.,  ..., 42., 42., 42.],
         [31., 31., 31.,  ..., 42., 42., 42.],
         ...,
         [33., 33., 32.,  ..., 33., 33., 32.],
         [33., 32., 32.,  ..., 33., 33., 32.],
         [32., 31., 31.,  ..., 33., 32., 32.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1009.1064,  873.0333, 1024.0000,  947.6663]])), gt_classes: tensor([730])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000297866.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [330], 'neg_category_ids': [1143, 1071, 199, 156, 9, 725], 'image_id': 297866, 'annotations_cat_set': {1040, 474, 1043, 330}, 'image': tensor([[[232., 232., 232.,  ..., 128., 128., 128.],
         [232., 232., 232.,  ..., 128., 128., 128.],
         [231., 231., 231.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[227., 227., 227.,  ..., 128., 128., 128.],
         [227., 227., 227.,  ..., 128., 128., 128.],
         [226., 226., 226.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[224., 224., 224.,  ..., 128., 128., 128.],
         [224., 224., 224.,  ..., 128., 128., 128.],
         [223., 223., 223.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=13, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[445.1845, 298.4231, 512.3570, 372.0477],
        [619.9967, 211.7675, 790.3378, 340.1523],
        [  0.0000, 405.7160, 233.5275, 421.5804],
        [745.3086, 379.9572, 970.0000, 391.8517],
        [  1.0912, 310.1964, 229.6929, 325.8183],
        [238.4078, 391.6850, 603.5673, 411.2466],
        [474.9514, 296.9078, 569.5567, 306.2416],
        [742.5350, 286.2861, 867.5740, 296.3624],
        [872.2422, 320.3786, 913.3611, 403.0037],
        [595.8528, 348.4709, 739.5644, 585.6941],
        [692.3223, 349.2133, 744.3992, 421.0500],
        [717.8758, 328.8184, 742.4895, 407.9585],
        [466.4639, 104.6867, 531.3023, 168.7200]])), gt_classes: tensor([733, 733, 238, 238, 238, 238, 238, 238, 730, 730, 730, 730, 340])])}], 'support_set_target': tensor(730)}
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000551341.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [726, 11], 'neg_category_ids': [896, 235, 982, 590, 992, 10, 357, 620, 892, 1021], 'image_id': 551341, 'image': tensor([[[174., 174., 173.,  ..., 230.,  91.,  91.],
         [174., 174., 173.,  ..., 230.,  91.,  91.],
         [174., 174., 174.,  ..., 230.,  91.,  91.],
         ...,
         [ 91.,  91.,  91.,  ...,  91.,  91.,  91.],
         [ 91.,  91.,  91.,  ...,  91.,  91.,  91.],
         [ 91.,  91.,  91.,  ...,  91.,  91.,  91.]],

        [[167., 167., 167.,  ..., 228.,  89.,  89.],
         [167., 167., 167.,  ..., 228.,  89.,  89.],
         [167., 167., 167.,  ..., 228.,  89.,  89.],
         ...,
         [ 89.,  89.,  89.,  ...,  89.,  89.,  89.],
         [ 89.,  89.,  89.,  ...,  89.,  89.,  89.],
         [ 89.,  89.,  89.,  ...,  89.,  89.,  89.]],

        [[ 72.,  72.,  72.,  ..., 225.,  75.,  75.],
         [ 72.,  72.,  72.,  ..., 225.,  75.,  75.],
         [ 69.,  72.,  75.,  ..., 225.,  75.,  75.],
         ...,
         [ 75.,  75.,  75.,  ...,  75.,  75.,  75.],
         [ 75.,  75.,  75.,  ...,  75.,  75.,  75.],
         [ 75.,  75.,  75.,  ...,  75.,  75.,  75.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[131.5665, 264.6789, 142.3933, 341.2191]])), gt_classes: tensor([10])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038751.jpg', 'height': 456, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [537, 586, 286, 660, 554, 937, 731], 'image_id': 38751, 'image': tensor([[[145., 145., 145.,  ..., 144., 144., 144.],
         [145., 145., 145.,  ..., 144., 144., 144.],
         [145., 145., 145.,  ..., 144., 144., 144.],
         ...,
         [109., 107., 105.,  ...,  81.,  80.,  80.],
         [112., 108., 107.,  ...,  81.,  80.,  80.],
         [115., 111., 111.,  ...,  82.,  81.,  80.]],

        [[145., 145., 145.,  ..., 145., 145., 145.],
         [145., 145., 145.,  ..., 145., 145., 144.],
         [145., 145., 145.,  ..., 145., 145., 144.],
         ...,
         [116., 112., 108.,  ...,  80.,  80.,  80.],
         [118., 113., 111.,  ...,  80.,  80.,  80.],
         [123., 116., 116.,  ...,  80.,  80.,  80.]],

        [[145., 145., 145.,  ..., 144., 144., 144.],
         [145., 145., 145.,  ..., 144., 144., 144.],
         [145., 145., 145.,  ..., 144., 144., 144.],
         ...,
         [115., 111., 107.,  ...,  80.,  80.,  80.],
         [118., 114., 111.,  ...,  81.,  80.,  80.],
         [123., 117., 118.,  ...,  80.,  80.,  80.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[232.4023,   0.0000, 317.2397, 355.3377]])), gt_classes: tensor([10])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000324785.jpg', 'height': 640, 'width': 463, 'not_exhaustive_category_ids': [324], 'neg_category_ids': [558, 49, 631, 272, 76, 520, 521, 223, 179, 1083, 444, 426, 622], 'image_id': 324785, 'image': tensor([[[ 37.,  35.,  34.,  ..., 128., 128., 128.],
         [ 36.,  34.,  32.,  ..., 128., 128., 128.],
         [ 35.,  32.,  30.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 29.,  30.,  29.,  ..., 129., 129., 129.],
         [ 30.,  29.,  27.,  ..., 129., 129., 129.],
         [ 29.,  27.,  25.,  ..., 129., 129., 129.],
         ...,
         [129., 129., 129.,  ..., 129., 129., 129.],
         [129., 129., 129.,  ..., 129., 129., 129.],
         [129., 129., 129.,  ..., 129., 129., 129.]],

        [[ 22.,  21.,  20.,  ..., 128., 128., 128.],
         [ 23.,  21.,  18.,  ..., 128., 128., 128.],
         [ 21.,  18.,  16.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[47.9279,  0.6053, 50.3377, 57.0391]])), gt_classes: tensor([10])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000168260.jpg', 'height': 640, 'width': 586, 'not_exhaustive_category_ids': [], 'neg_category_ids': [851, 711, 693, 905, 699, 1017, 1041], 'image_id': 168260, 'image': tensor([[[ 86.,  86.,  87.,  ...,  74.,  76.,  76.],
         [ 86.,  87.,  88.,  ...,  75.,  76.,  76.],
         [ 86.,  87.,  89.,  ...,  77.,  77.,  76.],
         ...,
         [143., 144., 147.,  ..., 159., 160., 160.],
         [146., 148., 152.,  ..., 160., 161., 161.],
         [147., 150., 154.,  ..., 160., 161., 161.]],

        [[ 80.,  81.,  82.,  ...,  67.,  69.,  70.],
         [ 81.,  82.,  83.,  ...,  67.,  68.,  69.],
         [ 81.,  82.,  83.,  ...,  68.,  68.,  68.],
         ...,
         [129., 131., 135.,  ...,  70.,  71.,  71.],
         [133., 135., 140.,  ...,  71.,  72.,  72.],
         [135., 137., 142.,  ...,  71.,  72.,  72.]],

        [[ 77.,  77.,  77.,  ...,  60.,  61.,  62.],
         [ 78.,  78.,  78.,  ...,  61.,  62.,  62.],
         [ 78.,  78.,  79.,  ...,  64.,  63.,  63.],
         ...,
         [123., 125., 128.,  ...,  33.,  34.,  34.],
         [126., 129., 132.,  ...,  34.,  35.,  35.],
         [128., 131., 134.,  ...,  34.,  35.,  35.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[545.0768, 221.4621, 559.9601, 457.0015]])), gt_classes: tensor([10])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000570037.jpg', 'height': 334, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1024, 222, 846, 1193, 983], 'image_id': 570037, 'image': tensor([[[ 26.,  31.,  34.,  ..., 218., 218., 219.],
         [ 26.,  31.,  34.,  ..., 218., 218., 219.],
         [ 27.,  32.,  35.,  ..., 218., 219., 220.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]],

        [[ 20.,  24.,  28.,  ..., 176., 176., 176.],
         [ 20.,  24.,  28.,  ..., 176., 176., 176.],
         [ 20.,  24.,  27.,  ..., 176., 176., 177.],
         ...,
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.],
         [124., 124., 124.,  ..., 124., 124., 124.]],

        [[ 21.,  26.,  29.,  ..., 120., 121., 122.],
         [ 21.,  26.,  29.,  ..., 120., 121., 122.],
         [ 22.,  26.,  29.,  ..., 121., 122., 123.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[850.7613, 376.5593, 863.0589, 428.0068]])), gt_classes: tensor([10])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000076414.jpg', 'height': 457, 'width': 640, 'not_exhaustive_category_ids': [118], 'neg_category_ids': [299, 810, 105, 373, 565, 768, 703, 754], 'image_id': 76414, 'annotations_cat_set': {1059, 643, 451, 11, 118, 570}, 'image': tensor([[[41., 21., 17.,  ..., 22., 22., 22.],
         [42., 30., 23.,  ..., 22., 22., 22.],
         [40., 37., 30.,  ..., 22., 22., 22.],
         ...,
         [22., 22., 22.,  ..., 22., 22., 22.],
         [22., 22., 22.,  ..., 22., 22., 22.],
         [22., 22., 22.,  ..., 22., 22., 22.]],

        [[41., 22., 17.,  ..., 22., 22., 22.],
         [41., 30., 23.,  ..., 22., 22., 22.],
         [39., 37., 30.,  ..., 22., 22., 22.],
         ...,
         [22., 22., 22.,  ..., 22., 22., 22.],
         [22., 22., 22.,  ..., 22., 22., 22.],
         [22., 22., 22.,  ..., 22., 22., 22.]],

        [[40., 21., 17.,  ..., 22., 22., 22.],
         [41., 29., 23.,  ..., 22., 22., 22.],
         [39., 36., 29.,  ..., 22., 22., 22.],
         ...,
         [22., 22., 22.,  ..., 22., 22., 22.],
         [22., 22., 22.,  ..., 22., 22., 22.],
         [22., 22., 22.,  ..., 22., 22., 22.]]]), 'instances': Instances(num_instances=12, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[2.8246e-01, 0.0000e+00, 4.9115e+02, 5.9672e+02],
        [0.0000e+00, 3.0021e+02, 6.2934e+01, 3.3490e+02],
        [1.0936e+02, 2.9699e+02, 1.7369e+02, 3.2404e+02],
        [4.1467e+02, 3.2517e+02, 4.5426e+02, 3.6025e+02],
        [2.8026e+02, 1.1976e+02, 3.1783e+02, 1.4912e+02],
        [6.6009e+02, 2.2844e+02, 6.6987e+02, 2.5573e+02],
        [6.6575e+02, 2.7067e+02, 6.7785e+02, 2.8227e+02],
        [6.8795e+02, 2.5251e+02, 6.9524e+02, 2.5909e+02],
        [6.6815e+02, 2.8228e+02, 6.7794e+02, 2.9217e+02],
        [0.0000e+00, 5.0663e+02, 5.7404e+01, 5.5164e+02],
        [2.4002e+02, 3.0696e+02, 2.7333e+02, 3.4203e+02],
        [6.2027e+02, 3.2738e+02, 6.2618e+02, 3.4300e+02]])), gt_classes: tensor([ 92,  92,  92, 742,  10,  10, 320, 320, 320, 406, 453, 453])])}], 'support_set_target': tensor(10)}
0
entering support set: 2
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000487942.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 853, 807, 1027, 504, 483, 1160, 361], 'image_id': 487942, 'image': tensor([[[136., 136., 136.,  ..., 126., 126., 126.],
         [136., 136., 136.,  ..., 126., 126., 126.],
         [136., 136., 137.,  ..., 126., 126., 126.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]],

        [[132., 132., 132.,  ..., 126., 126., 126.],
         [132., 132., 132.,  ..., 126., 126., 126.],
         [132., 132., 132.,  ..., 126., 126., 126.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]],

        [[128., 128., 129.,  ..., 126., 126., 126.],
         [128., 128., 129.,  ..., 126., 126., 126.],
         [128., 128., 129.,  ..., 126., 126., 126.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[5.5581e+02, 1.7089e-01, 6.8265e+02, 4.1229e+02]])), gt_classes: tensor([595])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000145791.jpg', 'height': 359, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [687, 604, 422, 821, 957, 1179, 781, 580], 'image_id': 145791, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[330.6826, 559.7380, 530.9465, 799.8195]])), gt_classes: tensor([595])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000204671.jpg', 'height': 417, 'width': 640, 'not_exhaustive_category_ids': [330], 'neg_category_ids': [1069, 734, 1024, 455, 1107, 1177, 890, 513], 'image_id': 204671, 'image': tensor([[[109.,  99.,  83.,  ...,  87.,  89.,  83.],
         [112., 105.,  91.,  ...,  84.,  88.,  84.],
         [121., 117., 110.,  ...,  78.,  84.,  86.],
         ...,
         [131., 131., 131.,  ..., 131., 131., 131.],
         [131., 131., 131.,  ..., 131., 131., 131.],
         [131., 131., 131.,  ..., 131., 131., 131.]],

        [[108.,  99.,  83.,  ...,  84.,  87.,  82.],
         [112., 105.,  91.,  ...,  82.,  86.,  83.],
         [120., 116., 109.,  ...,  76.,  82.,  84.],
         ...,
         [129., 129., 129.,  ..., 129., 129., 129.],
         [129., 129., 129.,  ..., 129., 129., 129.],
         [129., 129., 129.,  ..., 129., 129., 129.]],

        [[109., 100.,  85.,  ...,  86.,  88.,  84.],
         [113., 105.,  92.,  ...,  84.,  87.,  85.],
         [121., 117., 110.,  ...,  78.,  84.,  86.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 922.6929,  162.8867, 1024.0000,  306.3826]])), gt_classes: tensor([595])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000204671.jpg', 'height': 417, 'width': 640, 'not_exhaustive_category_ids': [330], 'neg_category_ids': [1069, 734, 1024, 455, 1107, 1177, 890, 513], 'image_id': 204671, 'image': tensor([[[109.,  99.,  83.,  ...,  87.,  89.,  83.],
         [112., 105.,  91.,  ...,  84.,  88.,  84.],
         [121., 117., 110.,  ...,  78.,  84.,  86.],
         ...,
         [131., 131., 131.,  ..., 131., 131., 131.],
         [131., 131., 131.,  ..., 131., 131., 131.],
         [131., 131., 131.,  ..., 131., 131., 131.]],

        [[108.,  99.,  83.,  ...,  84.,  87.,  82.],
         [112., 105.,  91.,  ...,  82.,  86.,  83.],
         [120., 116., 109.,  ...,  76.,  82.,  84.],
         ...,
         [129., 129., 129.,  ..., 129., 129., 129.],
         [129., 129., 129.,  ..., 129., 129., 129.],
         [129., 129., 129.,  ..., 129., 129., 129.]],

        [[109., 100.,  85.,  ...,  86.,  88.,  84.],
         [113., 105.,  92.,  ...,  84.,  87.,  85.],
         [121., 117., 110.,  ...,  78.,  84.,  86.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 922.6929,  162.8867, 1024.0000,  306.3826]])), gt_classes: tensor([595])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000487942.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 853, 807, 1027, 504, 483, 1160, 361], 'image_id': 487942, 'image': tensor([[[136., 136., 136.,  ..., 126., 126., 126.],
         [136., 136., 136.,  ..., 126., 126., 126.],
         [136., 136., 137.,  ..., 126., 126., 126.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]],

        [[132., 132., 132.,  ..., 126., 126., 126.],
         [132., 132., 132.,  ..., 126., 126., 126.],
         [132., 132., 132.,  ..., 126., 126., 126.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]],

        [[128., 128., 129.,  ..., 126., 126., 126.],
         [128., 128., 129.,  ..., 126., 126., 126.],
         [128., 128., 129.,  ..., 126., 126., 126.],
         ...,
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.],
         [126., 126., 126.,  ..., 126., 126., 126.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[5.5581e+02, 1.7089e-01, 6.8265e+02, 4.1229e+02]])), gt_classes: tensor([595])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000289751.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [412, 1073, 126, 83, 569, 991, 548, 1019], 'image_id': 289751, 'annotations_cat_set': {842, 540}, 'image': tensor([[[158., 161., 165.,  ..., 128., 128., 126.],
         [148., 153., 159.,  ..., 130., 130., 128.],
         [161., 164., 168.,  ..., 128., 128., 126.],
         ...,
         [212., 213., 214.,  ..., 147., 147., 140.],
         [203., 205., 209.,  ..., 145., 145., 140.],
         [193., 198., 203.,  ..., 143., 143., 141.]],

        [[155., 162., 168.,  ..., 133., 134., 131.],
         [150., 157., 164.,  ..., 135., 135., 132.],
         [164., 167., 171.,  ..., 134., 134., 131.],
         ...,
         [213., 212., 212.,  ..., 150., 148., 140.],
         [206., 207., 209.,  ..., 153., 151., 146.],
         [200., 202., 206.,  ..., 156., 154., 152.]],

        [[160., 164., 167.,  ..., 133., 137., 134.],
         [161., 166., 171.,  ..., 135., 138., 135.],
         [171., 175., 179.,  ..., 133., 135., 132.],
         ...,
         [128., 129., 131.,  ..., 154., 159., 146.],
         [215., 218., 221.,  ..., 156., 161., 152.],
         [204., 208., 214.,  ..., 158., 163., 158.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[403.4468, 660.6542, 427.7438, 687.4156]])), gt_classes: tensor([386])])}], 'support_set_target': tensor(595)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000091442.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [661], 'neg_category_ids': [22, 964, 787, 520, 856, 697, 355, 1092], 'image_id': 91442, 'annotations': [{'bbox': [235.99, 262.72, 12.16, 11.52], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 25}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000091442.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [661], 'neg_category_ids': [22, 964, 787, 520, 856, 697, 355, 1092], 'image_id': 91442, 'image': tensor([[[ 23.,  23.,  22.,  ...,   4.,   5.,   5.],
         [ 22.,  22.,  22.,  ...,   8.,   7.,   9.],
         [ 21.,  21.,  22.,  ...,  11.,   9.,  14.],
         ...,
         [ 66.,  67.,  69.,  ...,  75.,  73.,  72.],
         [ 75.,  74.,  75.,  ...,  74.,  73.,  70.],
         [ 83.,  81.,  81.,  ...,  73.,  72.,  68.]],

        [[204., 204., 204.,  ..., 219.,  35.,  35.],
         [205., 205., 205.,  ..., 217., 219., 218.],
         [206., 206., 205.,  ..., 215., 217., 215.],
         ...,
         [ 66.,  67.,  69.,  ...,  75.,  73.,  72.],
         [ 75.,  74.,  75.,  ...,  72.,  70.,  68.],
         [ 83.,  81.,  81.,  ...,  69.,  68.,  65.]],

        [[197., 197., 197.,  ..., 208., 209., 210.],
         [198., 198., 198.,  ..., 206., 208., 207.],
         [199., 199., 198.,  ..., 203., 206., 204.],
         ...,
         [ 66.,  67.,  69.,  ...,  75.,  73.,  72.],
         [ 75.,  74.,  75.,  ...,  72.,  71.,  68.],
         [ 83.,  81.,  81.,  ...,  70.,  69.,  65.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[609.3787, 548.3387, 638.4677, 575.8906]])), gt_classes: tensor([25])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000544832.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [122, 453, 101, 123, 832, 770, 442, 641, 142, 494], 'image_id': 544832, 'annotations': [{'bbox': [321.65, 280.81, 59.93, 63.69], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 25}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000544832.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [122, 453, 101, 123, 832, 770, 442, 641, 142, 494], 'image_id': 544832, 'image': tensor([[[169., 168., 167.,  ..., 127., 127., 127.],
         [167., 167., 167.,  ..., 127., 127., 127.],
         [165., 166., 168.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[159., 157., 155.,  ..., 127., 127., 127.],
         [157., 156., 156.,  ..., 127., 127., 127.],
         [154., 154., 156.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[171., 169., 166.,  ..., 127., 127., 127.],
         [169., 168., 166.,  ..., 127., 127., 127.],
         [166., 166., 167.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[390.5032, 341.0671, 463.2620, 418.4240]])), gt_classes: tensor([25])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000207223.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [50], 'neg_category_ids': [1022, 368, 559, 809, 813, 80, 356, 1014, 643, 14], 'image_id': 207223, 'annotations': [{'bbox': [181.28, 124.15, 20.07, 11.79], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 25}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000207223.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [50], 'neg_category_ids': [1022, 368, 559, 809, 813, 80, 356, 1014, 643, 14], 'image_id': 207223, 'image': tensor([[[128., 137., 148.,  ..., 215., 213., 212.],
         [103., 106., 111.,  ..., 215., 212., 212.],
         [ 81.,  76.,  72.,  ..., 214., 212., 211.],
         ...,
         [253., 255., 255.,  ..., 255., 255., 254.],
         [253., 253., 253.,  ..., 254., 254., 254.],
         [252., 252., 252.,  ..., 253., 253., 254.]],

        [[125., 133., 140.,  ..., 191., 189., 188.],
         [102., 103., 106.,  ..., 191., 188., 188.],
         [ 81.,  74.,  68.,  ..., 190., 188., 187.],
         ...,
         [187., 188., 191.,  ..., 167., 168., 170.],
         [188., 190., 193.,  ..., 167., 168., 170.],
         [190., 190., 192.,  ..., 167., 168., 169.]],

        [[ 68.,  74.,  80.,  ..., 173., 171., 170.],
         [ 57.,  58.,  58.,  ..., 173., 170., 170.],
         [ 53.,  47.,  40.,  ..., 172., 170., 169.],
         ...,
         [101., 101., 103.,  ...,  69.,  68.,  67.],
         [102., 103., 104.,  ...,  68.,  67.,  66.],
         [104., 105., 105.,  ...,  67.,  67.,  67.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[635.7801, 369.3769, 701.4893, 407.9688]])), gt_classes: tensor([25])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000519565.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [90], 'neg_category_ids': [279, 305, 129, 505, 312, 1011, 992], 'image_id': 519565, 'annotations': [{'bbox': [500.43, 1.01, 53.03, 38.68], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 25}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000519565.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [90], 'neg_category_ids': [279, 305, 129, 505, 312, 1011, 992], 'image_id': 519565, 'image': tensor([[[225., 223., 219.,  ..., 104., 104., 104.],
         [223., 223., 221.,  ..., 104., 104., 104.],
         [221., 222., 223.,  ..., 104., 104., 104.],
         ...,
         [104., 104., 104.,  ..., 104., 104., 104.],
         [104., 104., 104.,  ..., 104., 104., 104.],
         [104., 104., 104.,  ..., 104., 104., 104.]],

        [[246., 233., 223.,  ..., 104., 104., 104.],
         [233., 233., 230.,  ..., 104., 104., 104.],
         [226., 234., 245.,  ..., 104., 104., 104.],
         ...,
         [104., 104., 104.,  ..., 104., 104., 104.],
         [104., 104., 104.,  ..., 104., 104., 104.],
         [104., 104., 104.,  ..., 104., 104., 104.]],

        [[239., 236., 225.,  ...,  99.,  99.,  99.],
         [228., 236., 237.,  ...,  99.,  99.,  99.],
         [224., 237., 246.,  ...,  99.,  99.,  99.],
         ...,
         [ 99.,  99.,  99.,  ...,  99.,  99.,  99.],
         [ 99.,  99.,  99.,  ...,  99.,  99.,  99.],
         [ 99.,  99.,  99.,  ...,  99.,  99.,  99.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[755.3365,   1.5255, 835.3786,  59.9484]])), gt_classes: tensor([25])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000273321.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 687, 1014, 808, 371, 26, 283, 173, 858, 419, 1128, 742, 88, 1038, 780, 1141], 'image_id': 273321, 'annotations': [{'bbox': [361.19, 0.0, 84.54, 20.54], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 25}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000273321.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 687, 1014, 808, 371, 26, 283, 173, 858, 419, 1128, 742, 88, 1038, 780, 1141], 'image_id': 273321, 'image': tensor([[[240., 216., 227.,  ..., 127., 127., 127.],
         [235., 239., 233.,  ..., 127., 127., 127.],
         [232., 238., 231.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[243., 233., 241.,  ..., 127., 127., 127.],
         [247., 248., 247.,  ..., 127., 127., 127.],
         [248., 243., 246.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[243., 230., 239.,  ..., 127., 127., 127.],
         [245., 247., 245.,  ..., 127., 127., 127.],
         [245., 241., 244.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[345.9523,   0.0000, 426.9258,  19.6721]])), gt_classes: tensor([25])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000091442.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [661], 'neg_category_ids': [22, 964, 787, 520, 856, 697, 355, 1092], 'image_id': 91442, 'image': tensor([[[ 23.,  23.,  22.,  ...,   4.,   5.,   5.],
         [ 22.,  22.,  22.,  ...,   8.,   7.,   9.],
         [ 21.,  21.,  22.,  ...,  11.,   9.,  14.],
         ...,
         [ 66.,  67.,  69.,  ...,  75.,  73.,  72.],
         [ 75.,  74.,  75.,  ...,  74.,  73.,  70.],
         [ 83.,  81.,  81.,  ...,  73.,  72.,  68.]],

        [[204., 204., 204.,  ..., 219.,  35.,  35.],
         [205., 205., 205.,  ..., 217., 219., 218.],
         [206., 206., 205.,  ..., 215., 217., 215.],
         ...,
         [ 66.,  67.,  69.,  ...,  75.,  73.,  72.],
         [ 75.,  74.,  75.,  ...,  72.,  70.,  68.],
         [ 83.,  81.,  81.,  ...,  69.,  68.,  65.]],

        [[197., 197., 197.,  ..., 208., 209., 210.],
         [198., 198., 198.,  ..., 206., 208., 207.],
         [199., 199., 198.,  ..., 203., 206., 204.],
         ...,
         [ 66.,  67.,  69.,  ...,  75.,  73.,  72.],
         [ 75.,  74.,  75.,  ...,  72.,  71.,  68.],
         [ 83.,  81.,  81.,  ...,  70.,  69.,  65.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[609.3787, 548.3387, 638.4677, 575.8906]])), gt_classes: tensor([25])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000544832.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [122, 453, 101, 123, 832, 770, 442, 641, 142, 494], 'image_id': 544832, 'image': tensor([[[169., 168., 167.,  ..., 127., 127., 127.],
         [167., 167., 167.,  ..., 127., 127., 127.],
         [165., 166., 168.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[159., 157., 155.,  ..., 127., 127., 127.],
         [157., 156., 156.,  ..., 127., 127., 127.],
         [154., 154., 156.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[171., 169., 166.,  ..., 127., 127., 127.],
         [169., 168., 166.,  ..., 127., 127., 127.],
         [166., 166., 167.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[390.5032, 341.0671, 463.2620, 418.4240]])), gt_classes: tensor([25])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000207223.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [50], 'neg_category_ids': [1022, 368, 559, 809, 813, 80, 356, 1014, 643, 14], 'image_id': 207223, 'image': tensor([[[128., 137., 148.,  ..., 215., 213., 212.],
         [103., 106., 111.,  ..., 215., 212., 212.],
         [ 81.,  76.,  72.,  ..., 214., 212., 211.],
         ...,
         [253., 255., 255.,  ..., 255., 255., 254.],
         [253., 253., 253.,  ..., 254., 254., 254.],
         [252., 252., 252.,  ..., 253., 253., 254.]],

        [[125., 133., 140.,  ..., 191., 189., 188.],
         [102., 103., 106.,  ..., 191., 188., 188.],
         [ 81.,  74.,  68.,  ..., 190., 188., 187.],
         ...,
         [187., 188., 191.,  ..., 167., 168., 170.],
         [188., 190., 193.,  ..., 167., 168., 170.],
         [190., 190., 192.,  ..., 167., 168., 169.]],

        [[ 68.,  74.,  80.,  ..., 173., 171., 170.],
         [ 57.,  58.,  58.,  ..., 173., 170., 170.],
         [ 53.,  47.,  40.,  ..., 172., 170., 169.],
         ...,
         [101., 101., 103.,  ...,  69.,  68.,  67.],
         [102., 103., 104.,  ...,  68.,  67.,  66.],
         [104., 105., 105.,  ...,  67.,  67.,  67.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[635.7801, 369.3769, 701.4893, 407.9688]])), gt_classes: tensor([25])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000519565.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [90], 'neg_category_ids': [279, 305, 129, 505, 312, 1011, 992], 'image_id': 519565, 'image': tensor([[[225., 223., 219.,  ..., 104., 104., 104.],
         [223., 223., 221.,  ..., 104., 104., 104.],
         [221., 222., 223.,  ..., 104., 104., 104.],
         ...,
         [104., 104., 104.,  ..., 104., 104., 104.],
         [104., 104., 104.,  ..., 104., 104., 104.],
         [104., 104., 104.,  ..., 104., 104., 104.]],

        [[246., 233., 223.,  ..., 104., 104., 104.],
         [233., 233., 230.,  ..., 104., 104., 104.],
         [226., 234., 245.,  ..., 104., 104., 104.],
         ...,
         [104., 104., 104.,  ..., 104., 104., 104.],
         [104., 104., 104.,  ..., 104., 104., 104.],
         [104., 104., 104.,  ..., 104., 104., 104.]],

        [[239., 236., 225.,  ...,  99.,  99.,  99.],
         [228., 236., 237.,  ...,  99.,  99.,  99.],
         [224., 237., 246.,  ...,  99.,  99.,  99.],
         ...,
         [ 99.,  99.,  99.,  ...,  99.,  99.,  99.],
         [ 99.,  99.,  99.,  ...,  99.,  99.,  99.],
         [ 99.,  99.,  99.,  ...,  99.,  99.,  99.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[755.3365,   1.5255, 835.3786,  59.9484]])), gt_classes: tensor([25])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000273321.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1121, 687, 1014, 808, 371, 26, 283, 173, 858, 419, 1128, 742, 88, 1038, 780, 1141], 'image_id': 273321, 'image': tensor([[[240., 216., 227.,  ..., 127., 127., 127.],
         [235., 239., 233.,  ..., 127., 127., 127.],
         [232., 238., 231.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[243., 233., 241.,  ..., 127., 127., 127.],
         [247., 248., 247.,  ..., 127., 127., 127.],
         [248., 243., 246.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[243., 230., 239.,  ..., 127., 127., 127.],
         [245., 247., 245.,  ..., 127., 127., 127.],
         [245., 241., 244.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[345.9523,   0.0000, 426.9258,  19.6721]])), gt_classes: tensor([25])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000207223.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [50], 'neg_category_ids': [1022, 368, 559, 809, 813, 80, 356, 1014, 643, 14], 'image_id': 207223, 'annotations_cat_set': {33, 50, 62}, 'image': tensor([[[150., 151., 150.,  ..., 128., 128., 128.],
         [148., 147., 145.,  ..., 128., 128., 128.],
         [146., 144., 143.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[163., 164., 163.,  ..., 128., 128., 128.],
         [161., 160., 158.,  ..., 128., 128., 128.],
         [159., 157., 156.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[177., 178., 177.,  ..., 128., 128., 128.],
         [175., 174., 172.,  ..., 128., 128., 128.],
         [173., 171., 170.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=43, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[470.1663, 225.9789, 500.5965, 243.4131],
        [205.9503, 205.8940, 228.8085, 221.6699],
        [  0.0000, 239.3593,  73.4382, 276.3822],
        [ 93.1342, 203.9238, 118.8284, 226.0356],
        [115.8364, 140.0692, 147.9116, 150.4589],
        [603.4299, 104.5912, 671.3380, 128.5314],
        [443.2243, 111.9760, 458.8506, 119.1623],
        [653.7405,  66.4769, 709.0000,  86.4908],
        [ 57.5708, 136.8942,  93.4462, 147.5531],
        [204.1495, 222.3645, 231.0347, 231.6344],
        [456.7946,  78.9360, 510.9054, 130.1756],
        [457.1064, 131.4796, 491.6489, 141.9402],
        [552.7080, 233.4061, 659.7812, 263.1861],
        [205.1988, 186.7022, 268.6401, 201.2024],
        [408.2989, 219.3454, 419.8131, 232.0596],
        [205.8369, 122.4649, 324.0130, 129.9630],
        [299.9921, 142.8757, 336.7325, 151.3235],
        [369.8286, 138.5951, 398.0752, 147.1846],
        [531.1261,  81.8133, 634.7393, 109.7790],
        [520.8739, 230.6422, 560.0391, 254.6957],
        [654.5630, 243.4981, 709.0000, 280.6912],
        [367.5314, 202.8750, 395.7071, 219.8840],
        [161.0848, 142.1528, 189.7993, 151.6637],
        [342.3761, 218.9626, 369.6868, 229.7634],
        [ 16.7891, 134.9523,  55.3304, 145.8522],
        [130.7254, 119.3749, 172.8967, 128.6023],
        [155.9658, 224.0086, 170.4861, 233.7180],
        [526.2907, 119.0205, 576.3319, 136.3130],
        [360.0869, 116.8802, 400.8686, 126.4053],
        [  6.9766,  84.1521,  69.1700, 133.7617],
        [213.0829, 142.8898, 251.5816, 153.4354],
        [184.1557, 123.5563, 195.4146, 130.4591],
        [ 84.7822, 115.7038, 130.5836, 125.6399],
        [512.6070, 127.2274, 526.7019, 138.1699],
        [ 67.2983, 114.5982,  85.1509, 122.2523],
        [400.3014, 112.8973, 443.5504, 123.6130],
        [163.2969, 206.4610, 185.8714, 223.3566],
        [277.7862, 187.2408, 300.9705, 204.2215],
        [411.7021, 170.5295, 442.3593, 179.8419],
        [250.1636, 204.3491, 269.0797, 219.3595],
        [257.0550, 175.9724, 285.5143, 192.6837],
        [171.6205,   0.0000, 425.1590,  95.3213],
        [360.7392,  23.0614, 387.6386,  56.5975]])), gt_classes: tensor([37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
        37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37,
        37, 37, 37, 37, 25, 25, 47])])}], 'support_set_target': tensor(25)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000148531.jpg', 'height': 512, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [410, 453, 877, 692, 588, 740, 697, 462, 888, 62, 772, 773, 618, 425, 600, 145, 601], 'image_id': 148531, 'annotations': [{'bbox': [227.7, 144.63, 29.47, 212.53], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 601}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000148531.jpg', 'height': 512, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [410, 453, 877, 692, 588, 740, 697, 462, 888, 62, 772, 773, 618, 425, 600, 145, 601], 'image_id': 148531, 'image': tensor([[[241., 241., 241.,  ..., 243., 243., 243.],
         [241., 243., 243.,  ..., 243., 243., 243.],
         [237., 241., 243.,  ..., 243., 243., 243.],
         ...,
         [102., 102., 101.,  ...,  94.,  93.,  92.],
         [ 96.,  98.,  99.,  ...,  92.,  93.,  93.],
         [ 93.,  95.,  98.,  ...,  96.,  98.,  98.]],

        [[217., 220., 220.,  ..., 243., 243., 243.],
         [217., 220., 220.,  ..., 243., 243., 243.],
         [213., 217., 220.,  ..., 243., 243., 243.],
         ...,
         [116., 116., 116.,  ..., 114., 114., 113.],
         [113., 114., 114.,  ..., 113., 114., 114.],
         [112., 113., 114.,  ..., 115., 116., 116.]],

        [[215., 215., 215.,  ..., 241., 241., 241.],
         [212., 215., 215.,  ..., 241., 241., 241.],
         [210., 212., 215.,  ..., 242., 242., 242.],
         ...,
         [125., 125., 125.,  ..., 127., 126., 126.],
         [123., 124., 124.,  ..., 126., 126., 127.],
         [122., 123., 124.,  ..., 128., 128., 129.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 961.2663,  324.9973, 1024.0000,  967.1534]])), gt_classes: tensor([601])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000096154.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [668, 1147, 857, 794, 399, 245, 1038, 68, 756], 'image_id': 96154, 'annotations': [{'bbox': [350.89, 180.55, 28.56, 18.47], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 601}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000096154.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [668, 1147, 857, 794, 399, 245, 1038, 68, 756], 'image_id': 96154, 'image': tensor([[[ 97.,  80.,  51.,  ...,   3.,   3.,   3.],
         [ 97.,  80.,  80.,  ...,   3.,   3.,   3.],
         [ 97.,  80.,  80.,  ...,   3.,   3.,   3.],
         ...,
         [  3.,   3.,   3.,  ...,   3.,   3.,   3.],
         [  3.,   3.,   3.,  ...,   3.,   3.,   3.],
         [  3.,   3.,   3.,  ...,   3.,   3.,   3.]],

        [[ 54.,  80.,  80.,  ...,   3.,   3.,   3.],
         [ 54.,  80.,  94.,  ...,   3.,   3.,   3.],
         [ 54.,  80.,  94.,  ...,   3.,   3.,   3.],
         ...,
         [  3.,   3.,   3.,  ...,   3.,   3.,   3.],
         [  3.,   3.,   3.,  ...,   3.,   3.,   3.],
         [  3.,   3.,   3.,  ...,   3.,   3.,   3.]],

        [[ 15., 171., 156.,  ..., 148., 148., 148.],
         [ 15., 183., 161.,  ..., 148., 148., 148.],
         [224., 183., 161.,  ..., 148., 148., 148.],
         ...,
         [148., 148., 148.,  ..., 148., 148., 148.],
         [148., 148., 148.,  ..., 148., 148., 148.],
         [148., 148., 148.,  ..., 148., 148., 148.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[445.1917, 229.1759, 481.4272, 252.6202]])), gt_classes: tensor([601])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000149052.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [192, 24, 542, 504, 130, 396, 83, 862, 460, 379, 1109, 157, 465, 679, 65, 1040, 473], 'image_id': 149052, 'annotations': [{'bbox': [295.84, 210.19, 30.26, 62.57], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 601}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000149052.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [192, 24, 542, 504, 130, 396, 83, 862, 460, 379, 1109, 157, 465, 679, 65, 1040, 473], 'image_id': 149052, 'image': tensor([[[227., 226., 226.,  ..., 128., 128., 128.],
         [228., 228., 227.,  ..., 128., 128., 128.],
         [230., 230., 230.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[216., 215., 215.,  ..., 128., 128., 128.],
         [217., 217., 216.,  ..., 128., 128., 128.],
         [218., 218., 218.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[208., 207., 207.,  ..., 128., 128., 128.],
         [209., 209., 208.,  ..., 128., 128., 128.],
         [208., 208., 208.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[311.9381, 208.7133, 342.0090, 270.8437]])), gt_classes: tensor([601])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000098179.jpg', 'height': 392, 'width': 640, 'not_exhaustive_category_ids': [3], 'neg_category_ids': [475, 123, 1028, 768, 64, 231, 621, 627], 'image_id': 98179, 'annotations': [{'bbox': [543.43, 198.68, 33.03, 54.46], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 601}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000098179.jpg', 'height': 392, 'width': 640, 'not_exhaustive_category_ids': [3], 'neg_category_ids': [475, 123, 1028, 768, 64, 231, 621, 627], 'image_id': 98179, 'image': tensor([[[168., 168., 167.,  ..., 171., 167., 166.],
         [168., 168., 167.,  ..., 171., 168., 167.],
         [169., 169., 168.,  ..., 172., 170., 170.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[163., 163., 162.,  ..., 161., 157., 156.],
         [163., 163., 162.,  ..., 161., 158., 157.],
         [164., 164., 163.,  ..., 162., 160., 159.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[162., 162., 161.,  ..., 157., 153., 152.],
         [162., 162., 161.,  ..., 157., 154., 153.],
         [163., 163., 162.,  ..., 158., 156., 155.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000249441.jpg', 'height': 404, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [784, 585, 520, 1049, 547, 243, 489, 866, 1064], 'image_id': 249441, 'annotations': [{'bbox': [257.15, 169.09, 45.37, 72.46], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 601}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000249441.jpg', 'height': 404, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [784, 585, 520, 1049, 547, 243, 489, 866, 1064], 'image_id': 249441, 'image': tensor([[[250., 250., 250.,  ..., 244., 244., 245.],
         [250., 250., 250.,  ..., 244., 243., 245.],
         [250., 249., 249.,  ..., 246., 246., 246.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[251., 251., 251.,  ..., 244., 244., 245.],
         [251., 251., 251.,  ..., 244., 243., 245.],
         [251., 250., 250.,  ..., 246., 246., 246.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[248., 248., 248.,  ..., 244., 244., 245.],
         [248., 248., 248.,  ..., 244., 243., 245.],
         [248., 247., 247.,  ..., 246., 246., 246.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[599.4793, 405.9834, 708.4382, 579.9591]])), gt_classes: tensor([601])])}, len instances: 1
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000148531.jpg', 'height': 512, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [410, 453, 877, 692, 588, 740, 697, 462, 888, 62, 772, 773, 618, 425, 600, 145, 601], 'image_id': 148531, 'image': tensor([[[241., 241., 241.,  ..., 243., 243., 243.],
         [241., 243., 243.,  ..., 243., 243., 243.],
         [237., 241., 243.,  ..., 243., 243., 243.],
         ...,
         [102., 102., 101.,  ...,  94.,  93.,  92.],
         [ 96.,  98.,  99.,  ...,  92.,  93.,  93.],
         [ 93.,  95.,  98.,  ...,  96.,  98.,  98.]],

        [[217., 220., 220.,  ..., 243., 243., 243.],
         [217., 220., 220.,  ..., 243., 243., 243.],
         [213., 217., 220.,  ..., 243., 243., 243.],
         ...,
         [116., 116., 116.,  ..., 114., 114., 113.],
         [113., 114., 114.,  ..., 113., 114., 114.],
         [112., 113., 114.,  ..., 115., 116., 116.]],

        [[215., 215., 215.,  ..., 241., 241., 241.],
         [212., 215., 215.,  ..., 241., 241., 241.],
         [210., 212., 215.,  ..., 242., 242., 242.],
         ...,
         [125., 125., 125.,  ..., 127., 126., 126.],
         [123., 124., 124.,  ..., 126., 126., 127.],
         [122., 123., 124.,  ..., 128., 128., 129.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 961.2663,  324.9973, 1024.0000,  967.1534]])), gt_classes: tensor([601])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000096154.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [668, 1147, 857, 794, 399, 245, 1038, 68, 756], 'image_id': 96154, 'image': tensor([[[ 97.,  80.,  51.,  ...,   3.,   3.,   3.],
         [ 97.,  80.,  80.,  ...,   3.,   3.,   3.],
         [ 97.,  80.,  80.,  ...,   3.,   3.,   3.],
         ...,
         [  3.,   3.,   3.,  ...,   3.,   3.,   3.],
         [  3.,   3.,   3.,  ...,   3.,   3.,   3.],
         [  3.,   3.,   3.,  ...,   3.,   3.,   3.]],

        [[ 54.,  80.,  80.,  ...,   3.,   3.,   3.],
         [ 54.,  80.,  94.,  ...,   3.,   3.,   3.],
         [ 54.,  80.,  94.,  ...,   3.,   3.,   3.],
         ...,
         [  3.,   3.,   3.,  ...,   3.,   3.,   3.],
         [  3.,   3.,   3.,  ...,   3.,   3.,   3.],
         [  3.,   3.,   3.,  ...,   3.,   3.,   3.]],

        [[ 15., 171., 156.,  ..., 148., 148., 148.],
         [ 15., 183., 161.,  ..., 148., 148., 148.],
         [224., 183., 161.,  ..., 148., 148., 148.],
         ...,
         [148., 148., 148.,  ..., 148., 148., 148.],
         [148., 148., 148.,  ..., 148., 148., 148.],
         [148., 148., 148.,  ..., 148., 148., 148.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[445.1917, 229.1759, 481.4272, 252.6202]])), gt_classes: tensor([601])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000149052.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [192, 24, 542, 504, 130, 396, 83, 862, 460, 379, 1109, 157, 465, 679, 65, 1040, 473], 'image_id': 149052, 'image': tensor([[[227., 226., 226.,  ..., 128., 128., 128.],
         [228., 228., 227.,  ..., 128., 128., 128.],
         [230., 230., 230.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[216., 215., 215.,  ..., 128., 128., 128.],
         [217., 217., 216.,  ..., 128., 128., 128.],
         [218., 218., 218.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[208., 207., 207.,  ..., 128., 128., 128.],
         [209., 209., 208.,  ..., 128., 128., 128.],
         [208., 208., 208.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[311.9381, 208.7133, 342.0090, 270.8437]])), gt_classes: tensor([601])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000249441.jpg', 'height': 404, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [784, 585, 520, 1049, 547, 243, 489, 866, 1064], 'image_id': 249441, 'image': tensor([[[250., 250., 250.,  ..., 244., 244., 245.],
         [250., 250., 250.,  ..., 244., 243., 245.],
         [250., 249., 249.,  ..., 246., 246., 246.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[251., 251., 251.,  ..., 244., 244., 245.],
         [251., 251., 251.,  ..., 244., 243., 245.],
         [251., 250., 250.,  ..., 246., 246., 246.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[248., 248., 248.,  ..., 244., 244., 245.],
         [248., 248., 248.,  ..., 244., 243., 245.],
         [248., 247., 247.,  ..., 246., 246., 246.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[599.4793, 405.9834, 708.4382, 579.9591]])), gt_classes: tensor([601])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000249441.jpg', 'height': 404, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [784, 585, 520, 1049, 547, 243, 489, 866, 1064], 'image_id': 249441, 'image': tensor([[[250., 250., 250.,  ..., 244., 244., 245.],
         [250., 250., 250.,  ..., 244., 243., 245.],
         [250., 249., 249.,  ..., 246., 246., 246.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[251., 251., 251.,  ..., 244., 244., 245.],
         [251., 251., 251.,  ..., 244., 243., 245.],
         [251., 250., 250.,  ..., 246., 246., 246.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[248., 248., 248.,  ..., 244., 244., 245.],
         [248., 248., 248.,  ..., 244., 243., 245.],
         [248., 247., 247.,  ..., 246., 246., 246.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[599.4793, 405.9834, 708.4382, 579.9591]])), gt_classes: tensor([601])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000160974.jpg', 'height': 478, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1071, 194, 53, 54, 523, 931, 487, 243, 1016], 'image_id': 160974, 'annotations_cat_set': {848, 1186, 99}, 'image': tensor([[[244., 244., 242.,  ..., 224., 221., 221.],
         [242., 242., 244.,  ..., 224., 224., 224.],
         [244., 244., 246.,  ..., 224., 224., 224.],
         ...,
         [ 72.,  73.,  75.,  ...,  14.,  20.,  18.],
         [ 77.,  77.,  77.,  ...,   9.,   8.,  11.],
         [ 87.,  84.,  82.,  ...,   4.,   1.,   5.]],

        [[248., 248., 247.,  ..., 219., 217., 215.],
         [247., 247., 245.,  ..., 217., 219., 217.],
         [247., 247., 247.,  ..., 217., 219., 217.],
         ...,
         [ 82.,  82.,  81.,  ...,  28.,  33.,  31.],
         [ 86.,  85.,  85.,  ...,  22.,  20.,  22.],
         [ 91.,  89.,  88.,  ...,  15.,   9.,  12.]],

        [[247., 245., 243.,  ..., 225., 223., 225.],
         [245., 245., 243.,  ..., 225., 225., 227.],
         [245., 245., 245.,  ..., 227., 225., 227.],
         ...,
         [ 64.,  64.,  64.,  ...,  40.,  43.,  41.],
         [ 70.,  70.,  70.,  ...,  36.,  34.,  36.],
         [ 80.,  77.,  75.,  ...,  33.,  26.,  30.]]]), 'instances': Instances(num_instances=4, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 34.5152, 430.0136,  52.8362, 432.3528],
        [150.8438, 351.1447, 188.5939, 397.3383],
        [246.5858, 308.6939, 320.7070, 499.2054],
        [660.9753, 291.5314, 765.3360, 399.0127]])), gt_classes: tensor([849, 601, 601,  77])])}], 'support_set_target': tensor(601)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000144907.jpg', 'height': 340, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [896, 562, 224, 698, 1174, 67, 682], 'image_id': 144907, 'annotations': [{'bbox': [280.9, 240.77, 34.65, 31.48], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 130}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000144907.jpg', 'height': 340, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [896, 562, 224, 698, 1174, 67, 682], 'image_id': 144907, 'image': tensor([[[ 93.,  74.,  46.,  ..., 128., 128., 128.],
         [ 69.,  63.,  56.,  ..., 128., 128., 128.],
         [ 35.,  48.,  70.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 72.,  64.,  51.,  ..., 128., 128., 128.],
         [ 59.,  59.,  59.,  ..., 128., 128., 128.],
         [ 40.,  53.,  70.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 55.,  48.,  35.,  ..., 128., 128., 128.],
         [ 38.,  40.,  42.,  ..., 128., 128., 128.],
         [ 12.,  28.,  49.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[462.3614, 396.5623, 519.3953, 448.4118]])), gt_classes: tensor([130])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000354734.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1056, 1027, 173], 'neg_category_ids': [99, 666, 650, 1045, 285, 107, 611, 841], 'image_id': 354734, 'annotations': [{'bbox': [114.61, 244.59, 38.57, 31.92], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 130}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000354734.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1056, 1027, 173], 'neg_category_ids': [99, 666, 650, 1045, 285, 107, 611, 841], 'image_id': 354734, 'image': tensor([[[181., 181., 181.,  ..., 255., 255., 245.],
         [181., 181., 181.,  ..., 255., 255., 245.],
         [181., 181., 181.,  ..., 255., 255., 245.],
         ...,
         [110., 110., 110.,  ..., 110., 110., 110.],
         [110., 110., 110.,  ..., 110., 110., 110.],
         [110., 110., 110.,  ..., 110., 110., 110.]],

        [[172., 172., 172.,  ..., 247., 247., 249.],
         [172., 172., 171.,  ..., 247., 247., 249.],
         [171., 171., 171.,  ..., 247., 247., 249.],
         ...,
         [ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 96.,  96.,  96.,  ...,  96.,  96.,  96.]],

        [[146., 147., 147.,  ..., 239., 241., 242.],
         [146., 146., 146.,  ..., 239., 241., 242.],
         [146., 146., 146.,  ..., 241., 241., 242.],
         ...,
         [ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 96.,  96.,  96.,  ...,  96.,  96.,  96.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[803.7645, 421.9178, 870.2977, 476.9798]])), gt_classes: tensor([130])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000224790.jpg', 'height': 498, 'width': 640, 'not_exhaustive_category_ids': [1011], 'neg_category_ids': [666, 709, 101, 195, 1003, 1009, 32, 110, 268, 1157, 190], 'image_id': 224790, 'annotations': [{'bbox': [532.97, 192.73, 26.44, 172.55], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 130}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000224790.jpg', 'height': 498, 'width': 640, 'not_exhaustive_category_ids': [1011], 'neg_category_ids': [666, 709, 101, 195, 1003, 1009, 32, 110, 268, 1157, 190], 'image_id': 224790, 'image': tensor([[[145., 139., 127.,  ..., 232., 232., 232.],
         [145., 143., 130.,  ..., 232., 232., 232.],
         [145., 147., 136.,  ..., 232., 232., 232.],
         ...,
         [232., 232., 232.,  ..., 232., 232., 232.],
         [232., 232., 232.,  ..., 232., 232., 232.],
         [232., 232., 232.,  ..., 232., 232., 232.]],

        [[139., 137., 132.,  ..., 232., 232., 232.],
         [143., 145., 136.,  ..., 232., 232., 232.],
         [150., 150., 137.,  ..., 232., 232., 232.],
         ...,
         [232., 232., 232.,  ..., 232., 232., 232.],
         [232., 232., 232.,  ..., 232., 232., 232.],
         [232., 232., 232.,  ..., 232., 232., 232.]],

        [[132., 130., 123.,  ..., 232., 232., 232.],
         [132., 134., 127.,  ..., 232., 232., 232.],
         [137., 141., 132.,  ..., 232., 232., 232.],
         ...,
         [232., 232., 232.,  ..., 232., 232., 232.],
         [232., 232., 232.,  ..., 232., 232., 232.],
         [232., 232., 232.,  ..., 232., 232., 232.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 72.6569, 173.7666,  96.4943, 329.3388]])), gt_classes: tensor([130])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000276585.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [168, 649, 1045, 325, 278, 861, 314, 781], 'image_id': 276585, 'annotations': [{'bbox': [40.22, 119.51, 554.7, 219.02], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 130}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000276585.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [168, 649, 1045, 325, 278, 861, 314, 781], 'image_id': 276585, 'image': tensor([[[128., 105.,  73.,  ...,  95.,  95.,  95.],
         [101.,  94.,  81.,  ..., 110., 111., 112.],
         [ 74.,  82.,  89.,  ..., 124., 128., 129.],
         ...,
         [171., 188., 186.,  ..., 180., 180., 180.],
         [167., 186., 184.,  ..., 178., 176., 174.],
         [160., 170., 170.,  ..., 170., 171., 172.]],

        [[186., 166., 133.,  ...,  99.,  97.,  95.],
         [158., 151., 136.,  ..., 113., 112., 111.],
         [129., 135., 138.,  ..., 127., 128., 127.],
         ...,
         [240., 253., 253.,  ..., 181., 181., 181.],
         [231., 246., 245.,  ..., 179., 177., 175.],
         [210., 217., 216.,  ..., 171., 172., 173.]],

        [[160., 138., 104.,  ...,  75.,  73.,  71.],
         [130., 122., 107.,  ...,  87.,  86.,  85.],
         [100., 105., 109.,  ...,  99., 100., 100.],
         ...,
         [241., 254., 254.,  ..., 185., 185., 185.],
         [233., 248., 248.,  ..., 183., 181., 179.],
         [218., 224., 224.,  ..., 175., 176., 177.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  254.0199, 1024.0000,  803.8514]])), gt_classes: tensor([130])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000331198.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [173], 'neg_category_ids': [711, 811, 327, 81, 697, 1083, 1156, 248, 682, 871], 'image_id': 331198, 'annotations': [{'bbox': [416.36, 77.35, 42.63, 33.27], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 130}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000331198.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [173], 'neg_category_ids': [711, 811, 327, 81, 697, 1083, 1156, 248, 682, 871], 'image_id': 331198, 'image': tensor([[[157., 157., 154.,  ..., 128., 128., 128.],
         [159., 154., 152.,  ..., 128., 128., 128.],
         [160., 157., 152.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[131., 128., 132.,  ..., 128., 128., 128.],
         [129., 127., 128.,  ..., 128., 128., 128.],
         [129., 129., 125.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[119., 123., 119.,  ..., 128., 128., 128.],
         [118., 124., 128.,  ..., 128., 128., 128.],
         [114., 114., 113.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[402.6982,  74.8020, 443.9294, 106.9760]])), gt_classes: tensor([130])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000144907.jpg', 'height': 340, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [896, 562, 224, 698, 1174, 67, 682], 'image_id': 144907, 'image': tensor([[[ 93.,  74.,  46.,  ..., 128., 128., 128.],
         [ 69.,  63.,  56.,  ..., 128., 128., 128.],
         [ 35.,  48.,  70.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 72.,  64.,  51.,  ..., 128., 128., 128.],
         [ 59.,  59.,  59.,  ..., 128., 128., 128.],
         [ 40.,  53.,  70.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 55.,  48.,  35.,  ..., 128., 128., 128.],
         [ 38.,  40.,  42.,  ..., 128., 128., 128.],
         [ 12.,  28.,  49.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[462.3614, 396.5623, 519.3953, 448.4118]])), gt_classes: tensor([130])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000354734.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1056, 1027, 173], 'neg_category_ids': [99, 666, 650, 1045, 285, 107, 611, 841], 'image_id': 354734, 'image': tensor([[[181., 181., 181.,  ..., 255., 255., 245.],
         [181., 181., 181.,  ..., 255., 255., 245.],
         [181., 181., 181.,  ..., 255., 255., 245.],
         ...,
         [110., 110., 110.,  ..., 110., 110., 110.],
         [110., 110., 110.,  ..., 110., 110., 110.],
         [110., 110., 110.,  ..., 110., 110., 110.]],

        [[172., 172., 172.,  ..., 247., 247., 249.],
         [172., 172., 171.,  ..., 247., 247., 249.],
         [171., 171., 171.,  ..., 247., 247., 249.],
         ...,
         [ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 96.,  96.,  96.,  ...,  96.,  96.,  96.]],

        [[146., 147., 147.,  ..., 239., 241., 242.],
         [146., 146., 146.,  ..., 239., 241., 242.],
         [146., 146., 146.,  ..., 241., 241., 242.],
         ...,
         [ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 96.,  96.,  96.,  ...,  96.,  96.,  96.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[803.7645, 421.9178, 870.2977, 476.9798]])), gt_classes: tensor([130])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000224790.jpg', 'height': 498, 'width': 640, 'not_exhaustive_category_ids': [1011], 'neg_category_ids': [666, 709, 101, 195, 1003, 1009, 32, 110, 268, 1157, 190], 'image_id': 224790, 'image': tensor([[[145., 139., 127.,  ..., 232., 232., 232.],
         [145., 143., 130.,  ..., 232., 232., 232.],
         [145., 147., 136.,  ..., 232., 232., 232.],
         ...,
         [232., 232., 232.,  ..., 232., 232., 232.],
         [232., 232., 232.,  ..., 232., 232., 232.],
         [232., 232., 232.,  ..., 232., 232., 232.]],

        [[139., 137., 132.,  ..., 232., 232., 232.],
         [143., 145., 136.,  ..., 232., 232., 232.],
         [150., 150., 137.,  ..., 232., 232., 232.],
         ...,
         [232., 232., 232.,  ..., 232., 232., 232.],
         [232., 232., 232.,  ..., 232., 232., 232.],
         [232., 232., 232.,  ..., 232., 232., 232.]],

        [[132., 130., 123.,  ..., 232., 232., 232.],
         [132., 134., 127.,  ..., 232., 232., 232.],
         [137., 141., 132.,  ..., 232., 232., 232.],
         ...,
         [232., 232., 232.,  ..., 232., 232., 232.],
         [232., 232., 232.,  ..., 232., 232., 232.],
         [232., 232., 232.,  ..., 232., 232., 232.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 72.6569, 173.7666,  96.4943, 329.3388]])), gt_classes: tensor([130])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000276585.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [168, 649, 1045, 325, 278, 861, 314, 781], 'image_id': 276585, 'image': tensor([[[128., 105.,  73.,  ...,  95.,  95.,  95.],
         [101.,  94.,  81.,  ..., 110., 111., 112.],
         [ 74.,  82.,  89.,  ..., 124., 128., 129.],
         ...,
         [171., 188., 186.,  ..., 180., 180., 180.],
         [167., 186., 184.,  ..., 178., 176., 174.],
         [160., 170., 170.,  ..., 170., 171., 172.]],

        [[186., 166., 133.,  ...,  99.,  97.,  95.],
         [158., 151., 136.,  ..., 113., 112., 111.],
         [129., 135., 138.,  ..., 127., 128., 127.],
         ...,
         [240., 253., 253.,  ..., 181., 181., 181.],
         [231., 246., 245.,  ..., 179., 177., 175.],
         [210., 217., 216.,  ..., 171., 172., 173.]],

        [[160., 138., 104.,  ...,  75.,  73.,  71.],
         [130., 122., 107.,  ...,  87.,  86.,  85.],
         [100., 105., 109.,  ...,  99., 100., 100.],
         ...,
         [241., 254., 254.,  ..., 185., 185., 185.],
         [233., 248., 248.,  ..., 183., 181., 179.],
         [218., 224., 224.,  ..., 175., 176., 177.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  254.0199, 1024.0000,  803.8514]])), gt_classes: tensor([130])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000331198.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [173], 'neg_category_ids': [711, 811, 327, 81, 697, 1083, 1156, 248, 682, 871], 'image_id': 331198, 'image': tensor([[[157., 157., 154.,  ..., 128., 128., 128.],
         [159., 154., 152.,  ..., 128., 128., 128.],
         [160., 157., 152.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[131., 128., 132.,  ..., 128., 128., 128.],
         [129., 127., 128.,  ..., 128., 128., 128.],
         [129., 129., 125.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[119., 123., 119.,  ..., 128., 128., 128.],
         [118., 124., 128.,  ..., 128., 128., 128.],
         [114., 114., 113.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[402.6982,  74.8020, 443.9294, 106.9760]])), gt_classes: tensor([130])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000001366.jpg', 'height': 374, 'width': 500, 'not_exhaustive_category_ids': [207], 'neg_category_ids': [1083, 401, 1079, 1073, 1120], 'image_id': 1366, 'annotations_cat_set': {207, 173, 271}, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [251., 200., 150.,  ..., 207., 196., 184.],
         [255., 241., 180.,  ..., 200., 187., 178.],
         [255., 255., 226.,  ..., 198., 187., 178.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [250., 198., 146.,  ..., 234., 221., 207.],
         [255., 241., 178.,  ..., 228., 212., 200.],
         [255., 255., 223.,  ..., 225., 212., 203.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [223., 171., 121.,  ..., 251., 239., 225.],
         [255., 212., 151.,  ..., 244., 230., 217.],
         [255., 253., 196.,  ..., 242., 230., 221.]]]), 'instances': Instances(num_instances=2, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[208.0412, 602.3095, 260.2155, 675.5811],
        [302.0932, 596.7382, 356.6880, 670.4325]])), gt_classes: tensor([199, 199])])}], 'support_set_target': tensor(130)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000409259.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [], 'neg_category_ids': [732, 237, 436, 78, 833, 108, 62, 641, 425, 186, 70, 515], 'image_id': 409259, 'annotations': [{'bbox': [506.84, 1.11, 105.16, 109.36], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 159}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000409259.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [], 'neg_category_ids': [732, 237, 436, 78, 833, 108, 62, 641, 425, 186, 70, 515], 'image_id': 409259, 'image': tensor([[[ 76.,  70.,  66.,  ..., 134., 134., 134.],
         [ 79.,  77.,  76.,  ..., 134., 134., 134.],
         [ 86.,  86.,  85.,  ..., 134., 134., 134.],
         ...,
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.]],

        [[138., 132., 127.,  ..., 128., 128., 128.],
         [141., 140., 137.,  ..., 128., 128., 128.],
         [148., 148., 146.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[197., 190., 185.,  ..., 107., 107., 107.],
         [200., 197., 195.,  ..., 107., 107., 107.],
         [206., 204., 203.,  ..., 107., 107., 107.],
         ...,
         [107., 107., 107.,  ..., 107., 107., 107.],
         [107., 107., 107.,  ..., 107., 107., 107.],
         [107., 107., 107.,  ..., 107., 107., 107.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[713.0543,   1.5616, 861.0000, 155.4161]])), gt_classes: tensor([159])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000466374.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [], 'neg_category_ids': [828, 879, 413, 900, 1074, 565, 1110, 1156, 63, 933, 847, 145, 120], 'image_id': 466374, 'annotations': [{'bbox': [67.57, 398.38, 182.61, 169.54], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 159}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000466374.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [], 'neg_category_ids': [828, 879, 413, 900, 1074, 565, 1110, 1156, 63, 933, 847, 145, 120], 'image_id': 466374, 'image': tensor([[[  0.,   0.,   0.,  ..., 151., 151., 151.],
         [  0.,   0.,   0.,  ..., 151., 151., 151.],
         [  0.,   0.,   0.,  ..., 151., 151., 151.],
         ...,
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.]],

        [[  0.,   0.,   0.,  ..., 151., 151., 151.],
         [  0.,   0.,   0.,  ..., 151., 151., 151.],
         [  0.,   0.,   0.,  ..., 151., 151., 151.],
         ...,
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.]],

        [[  0.,   0.,   0.,  ..., 151., 151., 151.],
         [  0.,   0.,   0.,  ..., 151., 151., 151.],
         [  0.,   0.,   0.,  ..., 151., 151., 151.],
         ...,
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[343.4925, 378.2006, 516.8527, 539.1528]])), gt_classes: tensor([159])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000100542.jpg', 'height': 424, 'width': 640, 'not_exhaustive_category_ids': [735, 12], 'neg_category_ids': [1122, 1166, 149, 23, 1125, 586, 859, 952], 'image_id': 100542, 'annotations': [{'bbox': [380.66, 223.12, 140.41, 156.63], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 159}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000100542.jpg', 'height': 424, 'width': 640, 'not_exhaustive_category_ids': [735, 12], 'neg_category_ids': [1122, 1166, 149, 23, 1125, 586, 859, 952], 'image_id': 100542, 'image': tensor([[[250., 248., 247.,  ..., 127., 127., 127.],
         [248., 245., 242.,  ..., 127., 127., 127.],
         [244., 242., 242.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[237., 235., 234.,  ..., 127., 127., 127.],
         [235., 232., 229.,  ..., 127., 127., 127.],
         [231., 229., 229.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[239., 237., 236.,  ..., 127., 127., 127.],
         [237., 234., 231.,  ..., 127., 127., 127.],
         [233., 231., 231.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[124.3190, 233.1183, 271.0913, 396.7671]])), gt_classes: tensor([159])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000301029.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [192, 1069, 499, 811, 25, 1051, 951, 1155, 890, 867], 'image_id': 301029, 'annotations': [{'bbox': [200.18, 98.82, 181.24, 38.22], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 159}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000301029.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [192, 1069, 499, 811, 25, 1051, 951, 1155, 890, 867], 'image_id': 301029, 'image': tensor([[[ 29.,  22.,  16.,  ..., 128., 128., 128.],
         [ 26.,  23.,  18.,  ..., 128., 128., 128.],
         [ 20.,  20.,  18.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 14.,  13.,  13.,  ..., 128., 128., 128.],
         [ 13.,  15.,  15.,  ..., 128., 128., 128.],
         [ 12.,  14.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 11.,  12.,  12.,  ..., 128., 128., 128.],
         [ 10.,  13.,  14.,  ..., 128., 128., 128.],
         [  8.,  13.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[132.4669, 132.7894, 376.0081, 184.1475]])), gt_classes: tensor([159])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000382251.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [206], 'neg_category_ids': [1029, 1051, 986, 1134, 137, 292, 992, 142, 339], 'image_id': 382251, 'annotations': [{'bbox': [23.64, 212.61, 258.43, 187.95], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 159}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000382251.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [206], 'neg_category_ids': [1029, 1051, 986, 1134, 137, 292, 992, 142, 339], 'image_id': 382251, 'image': tensor([[[ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         ...,
         [ 95.,  95.,  95.,  ..., 169., 169., 169.],
         [ 95.,  95.,  95.,  ..., 169., 169., 169.],
         [ 95.,  95.,  95.,  ..., 169., 169., 169.]],

        [[ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         ...,
         [ 95.,  95.,  95.,  ..., 161., 161., 161.],
         [ 95.,  95.,  95.,  ..., 161., 161., 161.],
         [ 95.,  95.,  95.,  ..., 161., 161., 161.]],

        [[ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         ...,
         [ 95.,  95.,  95.,  ..., 163., 163., 163.],
         [ 95.,  95.,  95.,  ..., 163., 163., 163.],
         [ 95.,  95.,  95.,  ..., 163., 163., 163.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   6.2331,  511.6970,  697.4911, 1014.4326]])), gt_classes: tensor([159])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000409259.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [], 'neg_category_ids': [732, 237, 436, 78, 833, 108, 62, 641, 425, 186, 70, 515], 'image_id': 409259, 'image': tensor([[[ 76.,  70.,  66.,  ..., 134., 134., 134.],
         [ 79.,  77.,  76.,  ..., 134., 134., 134.],
         [ 86.,  86.,  85.,  ..., 134., 134., 134.],
         ...,
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.]],

        [[138., 132., 127.,  ..., 128., 128., 128.],
         [141., 140., 137.,  ..., 128., 128., 128.],
         [148., 148., 146.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[197., 190., 185.,  ..., 107., 107., 107.],
         [200., 197., 195.,  ..., 107., 107., 107.],
         [206., 204., 203.,  ..., 107., 107., 107.],
         ...,
         [107., 107., 107.,  ..., 107., 107., 107.],
         [107., 107., 107.,  ..., 107., 107., 107.],
         [107., 107., 107.,  ..., 107., 107., 107.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[713.0543,   1.5616, 861.0000, 155.4161]])), gt_classes: tensor([159])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000466374.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [], 'neg_category_ids': [828, 879, 413, 900, 1074, 565, 1110, 1156, 63, 933, 847, 145, 120], 'image_id': 466374, 'image': tensor([[[  0.,   0.,   0.,  ..., 151., 151., 151.],
         [  0.,   0.,   0.,  ..., 151., 151., 151.],
         [  0.,   0.,   0.,  ..., 151., 151., 151.],
         ...,
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.]],

        [[  0.,   0.,   0.,  ..., 151., 151., 151.],
         [  0.,   0.,   0.,  ..., 151., 151., 151.],
         [  0.,   0.,   0.,  ..., 151., 151., 151.],
         ...,
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.]],

        [[  0.,   0.,   0.,  ..., 151., 151., 151.],
         [  0.,   0.,   0.,  ..., 151., 151., 151.],
         [  0.,   0.,   0.,  ..., 151., 151., 151.],
         ...,
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.],
         [151., 151., 151.,  ..., 151., 151., 151.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[343.4925, 378.2006, 516.8527, 539.1528]])), gt_classes: tensor([159])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000100542.jpg', 'height': 424, 'width': 640, 'not_exhaustive_category_ids': [735, 12], 'neg_category_ids': [1122, 1166, 149, 23, 1125, 586, 859, 952], 'image_id': 100542, 'image': tensor([[[250., 248., 247.,  ..., 127., 127., 127.],
         [248., 245., 242.,  ..., 127., 127., 127.],
         [244., 242., 242.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[237., 235., 234.,  ..., 127., 127., 127.],
         [235., 232., 229.,  ..., 127., 127., 127.],
         [231., 229., 229.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[239., 237., 236.,  ..., 127., 127., 127.],
         [237., 234., 231.,  ..., 127., 127., 127.],
         [233., 231., 231.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[124.3190, 233.1183, 271.0913, 396.7671]])), gt_classes: tensor([159])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000301029.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [192, 1069, 499, 811, 25, 1051, 951, 1155, 890, 867], 'image_id': 301029, 'image': tensor([[[ 29.,  22.,  16.,  ..., 128., 128., 128.],
         [ 26.,  23.,  18.,  ..., 128., 128., 128.],
         [ 20.,  20.,  18.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 14.,  13.,  13.,  ..., 128., 128., 128.],
         [ 13.,  15.,  15.,  ..., 128., 128., 128.],
         [ 12.,  14.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 11.,  12.,  12.,  ..., 128., 128., 128.],
         [ 10.,  13.,  14.,  ..., 128., 128., 128.],
         [  8.,  13.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[132.4669, 132.7894, 376.0081, 184.1475]])), gt_classes: tensor([159])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000382251.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [206], 'neg_category_ids': [1029, 1051, 986, 1134, 137, 292, 992, 142, 339], 'image_id': 382251, 'image': tensor([[[ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         ...,
         [ 95.,  95.,  95.,  ..., 169., 169., 169.],
         [ 95.,  95.,  95.,  ..., 169., 169., 169.],
         [ 95.,  95.,  95.,  ..., 169., 169., 169.]],

        [[ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         ...,
         [ 95.,  95.,  95.,  ..., 161., 161., 161.],
         [ 95.,  95.,  95.,  ..., 161., 161., 161.],
         [ 95.,  95.,  95.,  ..., 161., 161., 161.]],

        [[ 96.,  96.,  96.,  ...,  96.,  96.,  96.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         ...,
         [ 95.,  95.,  95.,  ..., 163., 163., 163.],
         [ 95.,  95.,  95.,  ..., 163., 163., 163.],
         [ 95.,  95.,  95.,  ..., 163., 163., 163.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   6.2331,  511.6970,  697.4911, 1014.4326]])), gt_classes: tensor([159])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000553039.jpg', 'height': 640, 'width': 508, 'not_exhaustive_category_ids': [1052, 641], 'neg_category_ids': [711, 924, 788, 929, 398, 681, 661, 683], 'image_id': 553039, 'annotations_cat_set': {641, 1025, 708, 1099, 206, 818, 469, 27, 1052}, 'image': tensor([[[ 86.,  87.,  88.,  ...,  26.,  27.,  27.],
         [ 86.,  87.,  88.,  ...,  27.,  27.,  27.],
         [ 85.,  86.,  87.,  ...,  27.,  27.,  27.],
         ...,
         [134., 133., 133.,  ..., 107., 110., 114.],
         [133., 133., 133.,  ..., 107., 110., 112.],
         [133., 133., 132.,  ..., 107., 110., 111.]],

        [[108., 109., 110.,  ...,  36.,  36.,  36.],
         [108., 109., 110.,  ...,  36.,  36.,  36.],
         [108., 109., 110.,  ...,  36.,  35.,  35.],
         ...,
         [146., 145., 144.,  ..., 134., 137., 140.],
         [146., 145., 144.,  ..., 133., 135., 138.],
         [146., 146., 145.,  ..., 132., 134., 136.]],

        [[120., 121., 122.,  ...,  69.,  70.,  70.],
         [120., 121., 122.,  ...,  69.,  70.,  70.],
         [120., 121., 122.,  ...,  69.,  69.,  68.],
         ...,
         [158., 158., 158.,  ..., 152., 154., 156.],
         [158., 158., 158.,  ..., 151., 153., 154.],
         [158., 158., 159.,  ..., 151., 152., 153.]]]), 'instances': Instances(num_instances=28, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 882.7756,  474.2842,  973.8993,  555.5259],
        [ 195.7964,  389.0958,  383.5683,  621.2843],
        [ 548.6351,  894.2759,  658.2142, 1002.4160],
        [ 802.8527,  752.3154,  938.3241,  827.5763],
        [ 384.1147,  391.6157,  491.2047,  483.7867],
        [ 340.0099,  858.2089,  488.4425, 1024.0000],
        [ 681.4050,  355.1540,  903.2648,  580.0259],
        [ 574.4363, 1021.5423,  700.9228, 1024.0000],
        [ 231.5842,  835.1357,  367.5716,  977.6427],
        [ 991.7780,  877.1227, 1024.0000,  973.8174],
        [ 486.6213,  355.6094,  559.3199,  468.1213],
        [ 979.6363,  802.3780, 1024.0000,  902.3514],
        [ 506.7158,  328.2860,  575.9540,  370.1516],
        [ 857.0655,  539.3748, 1024.0000,  723.3829],
        [ 397.1367,  781.8854,  567.2424,  905.8124],
        [ 948.3714,  763.1840, 1024.0000,  845.0632],
        [ 694.2449,  569.5519,  867.0521,  755.4120],
        [ 413.8012,  993.0956,  551.0938, 1024.0000],
        [ 609.4045,  872.8420,  886.6913, 1024.0000],
        [ 541.6233,  576.8381,  643.3103,  800.4957],
        [   0.0000,  281.5629, 1024.0000, 1024.0000],
        [   0.0000,    0.0000, 1024.0000, 1024.0000],
        [1006.6820,    0.0000, 1024.0000,  704.6207],
        [ 625.3102,  663.4534,  831.9929,  852.5620],
        [ 456.6615,  584.6709,  729.1827,  887.4753],
        [ 589.1885,  921.3260,  733.6448, 1024.0000],
        [ 765.2133,  496.2037, 1024.0000,  775.2367],
        [   0.0000,  573.4379,  361.8043, 1024.0000]])), gt_classes: tensor([451, 451, 451, 451, 451, 451, 451, 451, 451, 451, 451, 451, 779, 779,
        779, 779, 779, 779, 779, 779, 577, 739, 500,  21,  21,  21,  21, 335])])}], 'support_set_target': tensor(159)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349338.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [300, 50, 128, 522, 954, 86, 1196], 'image_id': 349338, 'annotations': [{'bbox': [305.05, 44.78, 49.27, 138.78], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 62}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349338.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [300, 50, 128, 522, 954, 86, 1196], 'image_id': 349338, 'image': tensor([[[  2.,   3.,   3.,  ...,  15.,  14.,  13.],
         [  4.,   5.,   5.,  ...,  19.,  17.,  14.],
         [  4.,   5.,   5.,  ...,  15.,  13.,  12.],
         ...,
         [  3.,   2.,   2.,  ...,   6.,   6.,   4.],
         [  3.,   2.,   2.,  ...,   6.,   6.,   3.],
         [  3.,   2.,   3.,  ...,   5.,   5.,   4.]],

        [[ 89.,  88.,  88.,  ...,  61.,  62.,  64.],
         [ 91.,  90.,  90.,  ...,  68.,  67.,  67.],
         [ 91.,  89.,  89.,  ...,  68.,  67.,  67.],
         ...,
         [ 50.,  49.,  44.,  ...,  69.,  64.,  66.],
         [ 50.,  49.,  44.,  ...,  70.,  63.,  63.],
         [ 48.,  47.,  44.,  ...,  71.,  64.,  62.]],

        [[184., 185., 186.,  ..., 103., 104., 106.],
         [187., 188., 188.,  ..., 110., 109., 109.],
         [187., 187., 187.,  ..., 109., 108., 109.],
         ...,
         [146., 144., 139.,  ..., 155., 150., 149.],
         [146., 143., 139.,  ..., 155., 149., 145.],
         [144., 142., 138.,  ..., 154., 147., 144.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[679.4753,  88.9238, 801.4955, 432.6934]])), gt_classes: tensor([62])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000008776.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [338, 81], 'neg_category_ids': [1142, 101, 391, 967, 457, 1113, 208, 211], 'image_id': 8776, 'annotations': [{'bbox': [184.24, 207.53, 156.79, 61.1], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 62}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000008776.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [338, 81], 'neg_category_ids': [1142, 101, 391, 967, 457, 1113, 208, 211], 'image_id': 8776, 'image': tensor([[[227., 227., 228.,  ...,   5.,   2.,   2.],
         [228., 227., 228.,  ...,   5.,   3.,   3.],
         [229., 228., 227.,  ...,   6.,   4.,   4.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[206., 206., 203.,  ...,   7.,   6.,   7.],
         [205., 205., 202.,  ...,   7.,   6.,   7.],
         [203., 202., 200.,  ...,   7.,   6.,   6.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[176., 178., 180.,  ...,   7.,   5.,   6.],
         [175., 177., 179.,  ...,   7.,   5.,   6.],
         [174., 175., 176.,  ...,   8.,   6.,   6.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[206.7530, 391.7129, 502.6941, 507.0391]])), gt_classes: tensor([62])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000279957.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [811, 713, 130, 654, 816, 600, 623, 365], 'image_id': 279957, 'annotations': [{'bbox': [147.71, 99.87, 46.51, 111.58], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 62}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000279957.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [811, 713, 130, 654, 816, 600, 623, 365], 'image_id': 279957, 'image': tensor([[[  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[143.7865,  97.1652, 189.0610, 205.7232]])), gt_classes: tensor([62])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000511208.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [81, 217], 'neg_category_ids': [302, 418, 377, 1111, 334, 272, 494], 'image_id': 511208, 'annotations': [{'bbox': [374.72, 213.23, 39.82, 44.2], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 62}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000511208.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [81, 217], 'neg_category_ids': [302, 418, 377, 1111, 334, 272, 494], 'image_id': 511208, 'image': tensor([[[ 15.,  15.,  15.,  ..., 128., 128., 128.],
         [ 16.,  16.,  15.,  ..., 128., 128., 128.],
         [ 16.,  16.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 15.,  15.,  15.,  ..., 128., 128., 128.],
         [ 15.,  15.,  15.,  ..., 128., 128., 128.],
         [ 14.,  14.,  14.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 14.,  14.,  14.,  ..., 128., 128., 128.],
         [ 15.,  15.,  14.,  ..., 128., 128., 128.],
         [ 15.,  15.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[417.5801, 237.6190, 461.9547, 286.8746]])), gt_classes: tensor([62])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000076207.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [217], 'neg_category_ids': [1142, 1045, 370, 1189, 108, 639, 677, 725, 754, 165, 145], 'image_id': 76207, 'annotations': [{'bbox': [31.35, 165.01, 100.71, 121.15], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 62}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000076207.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [217], 'neg_category_ids': [1142, 1045, 370, 1189, 108, 639, 677, 725, 754, 165, 145], 'image_id': 76207, 'image': tensor([[[199., 200., 199.,  ..., 225., 225., 224.],
         [200., 201., 201.,  ..., 227., 227., 226.],
         [201., 202., 203.,  ..., 229., 228., 228.],
         ...,
         [  6.,   7.,   6.,  ...,  21.,  15.,  21.],
         [  7.,   7.,   6.,  ...,  23.,  16.,  21.],
         [  8.,   8.,   6.,  ...,  25.,  22.,  25.]],

        [[195., 195., 194.,  ..., 222., 222., 222.],
         [194., 194., 195.,  ..., 223., 223., 223.],
         [193., 194., 195.,  ..., 224., 223., 223.],
         ...,
         [ 12.,  11.,  10.,  ...,  36.,  33.,  41.],
         [ 13.,  11.,  10.,  ...,  38.,  32.,  41.],
         [ 13.,  12.,  10.,  ...,  40.,  38.,  44.]],

        [[183., 184., 183.,  ..., 224., 223., 223.],
         [182., 183., 184.,  ..., 225., 224., 224.],
         [182., 182., 184.,  ..., 226., 225., 225.],
         ...,
         [  9.,   9.,   8.,  ...,  73.,  73.,  80.],
         [  8.,   8.,   6.,  ...,  76.,  74.,  81.],
         [  9.,   9.,   8.,  ...,  80.,  81.,  87.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349338.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [300, 50, 128, 522, 954, 86, 1196], 'image_id': 349338, 'image': tensor([[[  2.,   3.,   3.,  ...,  15.,  14.,  13.],
         [  4.,   5.,   5.,  ...,  19.,  17.,  14.],
         [  4.,   5.,   5.,  ...,  15.,  13.,  12.],
         ...,
         [  3.,   2.,   2.,  ...,   6.,   6.,   4.],
         [  3.,   2.,   2.,  ...,   6.,   6.,   3.],
         [  3.,   2.,   3.,  ...,   5.,   5.,   4.]],

        [[ 89.,  88.,  88.,  ...,  61.,  62.,  64.],
         [ 91.,  90.,  90.,  ...,  68.,  67.,  67.],
         [ 91.,  89.,  89.,  ...,  68.,  67.,  67.],
         ...,
         [ 50.,  49.,  44.,  ...,  69.,  64.,  66.],
         [ 50.,  49.,  44.,  ...,  70.,  63.,  63.],
         [ 48.,  47.,  44.,  ...,  71.,  64.,  62.]],

        [[184., 185., 186.,  ..., 103., 104., 106.],
         [187., 188., 188.,  ..., 110., 109., 109.],
         [187., 187., 187.,  ..., 109., 108., 109.],
         ...,
         [146., 144., 139.,  ..., 155., 150., 149.],
         [146., 143., 139.,  ..., 155., 149., 145.],
         [144., 142., 138.,  ..., 154., 147., 144.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[679.4753,  88.9238, 801.4955, 432.6934]])), gt_classes: tensor([62])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000008776.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [338, 81], 'neg_category_ids': [1142, 101, 391, 967, 457, 1113, 208, 211], 'image_id': 8776, 'image': tensor([[[227., 227., 228.,  ...,   5.,   2.,   2.],
         [228., 227., 228.,  ...,   5.,   3.,   3.],
         [229., 228., 227.,  ...,   6.,   4.,   4.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[206., 206., 203.,  ...,   7.,   6.,   7.],
         [205., 205., 202.,  ...,   7.,   6.,   7.],
         [203., 202., 200.,  ...,   7.,   6.,   6.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[176., 178., 180.,  ...,   7.,   5.,   6.],
         [175., 177., 179.,  ...,   7.,   5.,   6.],
         [174., 175., 176.,  ...,   8.,   6.,   6.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[206.7530, 391.7129, 502.6941, 507.0391]])), gt_classes: tensor([62])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000279957.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [811, 713, 130, 654, 816, 600, 623, 365], 'image_id': 279957, 'image': tensor([[[  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[143.7865,  97.1652, 189.0610, 205.7232]])), gt_classes: tensor([62])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000511208.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [81, 217], 'neg_category_ids': [302, 418, 377, 1111, 334, 272, 494], 'image_id': 511208, 'image': tensor([[[ 15.,  15.,  15.,  ..., 128., 128., 128.],
         [ 16.,  16.,  15.,  ..., 128., 128., 128.],
         [ 16.,  16.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 15.,  15.,  15.,  ..., 128., 128., 128.],
         [ 15.,  15.,  15.,  ..., 128., 128., 128.],
         [ 14.,  14.,  14.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 14.,  14.,  14.,  ..., 128., 128., 128.],
         [ 15.,  15.,  14.,  ..., 128., 128., 128.],
         [ 15.,  15.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[417.5801, 237.6190, 461.9547, 286.8746]])), gt_classes: tensor([62])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000279957.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [811, 713, 130, 654, 816, 600, 623, 365], 'image_id': 279957, 'image': tensor([[[  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[143.7865,  97.1652, 189.0610, 205.7232]])), gt_classes: tensor([62])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000054244.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [170, 373, 395, 881, 817, 1106, 1192, 888], 'image_id': 54244, 'annotations_cat_set': {81, 169, 139}, 'image': tensor([[[ 62.,  63.,  65.,  ..., 125., 126., 126.],
         [ 65.,  66.,  67.,  ..., 124., 125., 125.],
         [ 66.,  66.,  67.,  ..., 124., 125., 125.],
         ...,
         [162., 162., 163.,  ..., 161., 160., 160.],
         [163., 164., 165.,  ..., 161., 161., 161.],
         [164., 165., 165.,  ..., 161., 161., 161.]],

        [[ 83.,  84.,  85.,  ..., 129., 129., 130.],
         [ 85.,  86.,  87.,  ..., 128., 128., 129.],
         [ 86.,  86.,  87.,  ..., 128., 128., 129.],
         ...,
         [154., 156., 157.,  ..., 157., 156., 155.],
         [155., 158., 160.,  ..., 158., 157., 156.],
         [156., 159., 160.,  ..., 159., 158., 157.]],

        [[129., 130., 131.,  ..., 134., 133., 133.],
         [132., 133., 134.,  ..., 131., 130., 130.],
         [133., 133., 134.,  ..., 129., 128., 128.],
         ...,
         [127., 128., 129.,  ..., 138., 137., 136.],
         [129., 131., 132.,  ..., 138., 138., 137.],
         [130., 132., 133.,  ..., 139., 139., 138.]]]), 'instances': Instances(num_instances=14, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 769.0186,  330.4794,  861.9806,  386.7948],
        [ 897.3914,  334.1794,  942.6735,  374.8336],
        [ 736.3550,  281.4710,  767.0164,  296.0851],
        [ 933.8964,  393.1245,  980.3658,  449.3003],
        [ 295.6642,  235.7206,  351.8419,  266.2286],
        [   0.0000,  201.0470, 1024.0000,  490.3267],
        [ 644.0449,  265.6003,  727.4150,  335.0405],
        [ 550.6405,  222.4795,  593.4780,  248.2402],
        [ 980.5287,  447.9506, 1024.0000,  479.2498],
        [ 148.3870,  224.3877,  203.2842,  256.1058],
        [ 692.2836,  323.4981,  775.7935,  364.6642],
        [   0.0000,  391.8679,  951.5670,  526.3500],
        [   0.0000,  426.1691, 1024.0000,  814.5360],
        [ 927.9131,  206.7484, 1024.0000,  271.8602]])), gt_classes: tensor([ 62,  62,  62,  62,  62,  62,  62,  62,  62,  62,  62, 127, 107, 107])])}], 'support_set_target': tensor(62)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000264923.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [343, 1097, 405, 464, 1082, 1016, 871, 1018], 'image_id': 264923, 'annotations': [{'bbox': [333.96, 320.26, 29.12, 9.82], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 692}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000264923.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [343, 1097, 405, 464, 1082, 1016, 871, 1018], 'image_id': 264923, 'image': tensor([[[158., 158., 160.,  ..., 142., 142., 142.],
         [160., 160., 162.,  ..., 142., 142., 142.],
         [162., 162., 163.,  ..., 142., 142., 142.],
         ...,
         [ 48.,  48.,  48.,  ..., 142., 142., 142.],
         [ 50.,  45.,  40.,  ..., 142., 142., 142.],
         [ 50.,  43.,  32.,  ..., 142., 142., 142.]],

        [[ 96.,  96.,  98.,  ..., 142., 142., 142.],
         [ 98.,  98., 100.,  ..., 142., 142., 142.],
         [100., 100., 101.,  ..., 142., 142., 142.],
         ...,
         [ 77.,  77.,  77.,  ..., 142., 142., 142.],
         [ 78.,  73.,  68.,  ..., 142., 142., 142.],
         [ 78.,  71.,  61.,  ..., 142., 142., 142.]],

        [[ 71.,  71.,  73.,  ..., 142., 142., 142.],
         [ 73.,  73.,  75.,  ..., 142., 142., 142.],
         [ 75.,  75.,  77.,  ..., 142., 142., 142.],
         ...,
         [100., 100., 100.,  ..., 142., 142., 142.],
         [101.,  96.,  91.,  ..., 142., 142., 142.],
         [101.,  94.,  84.,  ..., 142., 142., 142.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[546.6933, 505.4258, 594.3628, 521.5060]])), gt_classes: tensor([692])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000542453.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [967, 1005, 1153, 34, 1196, 1116, 848, 387], 'image_id': 542453, 'annotations': [{'bbox': [415.52, 180.65, 27.18, 11.41], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 692}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000542453.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [967, 1005, 1153, 34, 1196, 1116, 848, 387], 'image_id': 542453, 'image': tensor([[[  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[600.8419, 261.0995, 640.1442, 277.5907]])), gt_classes: tensor([692])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000554075.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [454, 712, 946, 523, 868, 870, 873, 450, 191], 'image_id': 554075, 'annotations': [{'bbox': [3.78, 357.92, 6.91, 4.87], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 692}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000554075.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [454, 712, 946, 523, 868, 870, 873, 450, 191], 'image_id': 554075, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[568.3456, 322.8737, 574.5862, 327.2668]])), gt_classes: tensor([692])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000102968.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [984, 330], 'neg_category_ids': [710, 789, 902, 485, 135, 1059, 248, 96], 'image_id': 102968, 'annotations': [{'bbox': [230.92, 150.22, 11.01, 10.61], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 692}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000102968.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [984, 330], 'neg_category_ids': [710, 789, 902, 485, 135, 1059, 248, 96], 'image_id': 102968, 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[497.3670, 332.4869, 521.7431, 355.9704]])), gt_classes: tensor([692])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000554075.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [454, 712, 946, 523, 868, 870, 873, 450, 191], 'image_id': 554075, 'annotations': [{'bbox': [104.98, 376.86, 8.86, 7.14], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 692}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000554075.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [454, 712, 946, 523, 868, 870, 873, 450, 191], 'image_id': 554075, 'image': tensor([[[ 77.,  80.,  80.,  ..., 127., 127., 127.],
         [ 77.,  78.,  78.,  ..., 127., 127., 127.],
         [ 78.,  76.,  75.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[133., 134., 135.,  ..., 127., 127., 127.],
         [136., 134., 133.,  ..., 127., 127., 127.],
         [136., 133., 131.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[182., 181., 180.,  ..., 127., 127., 127.],
         [175., 175., 178.,  ..., 127., 127., 127.],
         [178., 178., 180.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[526.1600, 376.8600, 535.0200, 384.0000]])), gt_classes: tensor([692])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000264923.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [343, 1097, 405, 464, 1082, 1016, 871, 1018], 'image_id': 264923, 'image': tensor([[[158., 158., 160.,  ..., 142., 142., 142.],
         [160., 160., 162.,  ..., 142., 142., 142.],
         [162., 162., 163.,  ..., 142., 142., 142.],
         ...,
         [ 48.,  48.,  48.,  ..., 142., 142., 142.],
         [ 50.,  45.,  40.,  ..., 142., 142., 142.],
         [ 50.,  43.,  32.,  ..., 142., 142., 142.]],

        [[ 96.,  96.,  98.,  ..., 142., 142., 142.],
         [ 98.,  98., 100.,  ..., 142., 142., 142.],
         [100., 100., 101.,  ..., 142., 142., 142.],
         ...,
         [ 77.,  77.,  77.,  ..., 142., 142., 142.],
         [ 78.,  73.,  68.,  ..., 142., 142., 142.],
         [ 78.,  71.,  61.,  ..., 142., 142., 142.]],

        [[ 71.,  71.,  73.,  ..., 142., 142., 142.],
         [ 73.,  73.,  75.,  ..., 142., 142., 142.],
         [ 75.,  75.,  77.,  ..., 142., 142., 142.],
         ...,
         [100., 100., 100.,  ..., 142., 142., 142.],
         [101.,  96.,  91.,  ..., 142., 142., 142.],
         [101.,  94.,  84.,  ..., 142., 142., 142.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[546.6933, 505.4258, 594.3628, 521.5060]])), gt_classes: tensor([692])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000542453.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [967, 1005, 1153, 34, 1196, 1116, 848, 387], 'image_id': 542453, 'image': tensor([[[  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         [  0.,   0.,   0.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[600.8419, 261.0995, 640.1442, 277.5907]])), gt_classes: tensor([692])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000554075.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [454, 712, 946, 523, 868, 870, 873, 450, 191], 'image_id': 554075, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[568.3456, 322.8737, 574.5862, 327.2668]])), gt_classes: tensor([692])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000102968.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [984, 330], 'neg_category_ids': [710, 789, 902, 485, 135, 1059, 248, 96], 'image_id': 102968, 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[497.3670, 332.4869, 521.7431, 355.9704]])), gt_classes: tensor([692])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000554075.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [454, 712, 946, 523, 868, 870, 873, 450, 191], 'image_id': 554075, 'image': tensor([[[ 77.,  80.,  80.,  ..., 127., 127., 127.],
         [ 77.,  78.,  78.,  ..., 127., 127., 127.],
         [ 78.,  76.,  75.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[133., 134., 135.,  ..., 127., 127., 127.],
         [136., 134., 133.,  ..., 127., 127., 127.],
         [136., 133., 131.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[182., 181., 180.,  ..., 127., 127., 127.],
         [175., 175., 178.,  ..., 127., 127., 127.],
         [178., 178., 180.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[526.1600, 376.8600, 535.0200, 384.0000]])), gt_classes: tensor([692])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000560389.jpg', 'height': 500, 'width': 375, 'not_exhaustive_category_ids': [], 'neg_category_ids': [328, 224, 111, 290, 1082, 1113, 89, 246], 'image_id': 560389, 'annotations_cat_set': {984, 207}, 'image': tensor([[[253., 253., 253.,  ..., 128., 128., 128.],
         [253., 253., 253.,  ..., 128., 128., 128.],
         [253., 253., 253.,  ..., 128., 128., 128.],
         ...,
         [156., 156., 155.,  ..., 128., 128., 128.],
         [154., 154., 154.,  ..., 128., 128., 128.],
         [153., 153., 154.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [147., 147., 146.,  ..., 128., 128., 128.],
         [144., 144., 144.,  ..., 128., 128., 128.],
         [143., 143., 144.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [138., 138., 138.,  ..., 128., 128., 128.],
         [136., 136., 137.,  ..., 128., 128., 128.],
         [135., 135., 136.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=8, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[278.1632, 312.2240, 473.8272, 460.0864],
        [ 64.4224, 548.9920, 109.4912, 595.8528],
        [142.3744, 536.8288, 150.9088, 580.6432],
        [468.5184, 590.5888, 840.0000, 903.4720],
        [797.2832, 727.3184, 840.0000, 976.0256],
        [193.3344, 545.0048, 204.4896, 579.9040],
        [ 53.4464, 542.2720,  90.7200, 591.2832],
        [200.8832, 532.3264, 278.9920, 598.6528]])), gt_classes: tensor([692, 160, 160, 160, 160, 160, 160, 160])])}], 'support_set_target': tensor(692)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000199720.jpg', 'height': 349, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [923, 763, 1008, 130, 131, 1108, 936], 'image_id': 199720, 'annotations': [{'bbox': [464.82, 289.66, 15.59, 37.77], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 434}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000199720.jpg', 'height': 349, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [923, 763, 1008, 130, 131, 1108, 936], 'image_id': 199720, 'image': tensor([[[ 13.,  12.,  10.,  ..., 128., 128., 128.],
         [ 14.,  12.,   9.,  ..., 128., 128., 128.],
         [ 16.,  15.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 86.,  85.,  83.,  ..., 128., 128., 128.],
         [ 87.,  84.,  82.,  ..., 128., 128., 128.],
         [ 88.,  87.,  88.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 60.,  61.,  60.,  ..., 128., 128., 128.],
         [ 61.,  61.,  59.,  ..., 128., 128., 128.],
         [ 64.,  65.,  66.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 23.7431, 351.0779,  42.6381, 396.8564]])), gt_classes: tensor([434])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000146626.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [738, 984, 503, 549, 271, 1089, 534], 'image_id': 146626, 'annotations': [{'bbox': [142.21, 387.47, 14.45, 23.51], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 434}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000146626.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [738, 984, 503, 549, 271, 1089, 534], 'image_id': 146626, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[576.2319, 461.7351, 593.4590, 489.7512]])), gt_classes: tensor([434])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000317193.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [851, 500, 327, 1152, 647, 36, 804], 'image_id': 317193, 'annotations': [{'bbox': [290.2, 376.9, 26.8, 29.63], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 434}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000317193.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [851, 500, 327, 1152, 647, 36, 804], 'image_id': 317193, 'image': tensor([[[197., 198., 201.,  ..., 128., 128., 128.],
         [197., 197., 198.,  ..., 128., 128., 128.],
         [196., 196., 196.,  ..., 128., 128., 128.],
         ...,
         [ 73.,  74.,  78.,  ..., 128., 128., 128.],
         [ 68.,  66.,  68.,  ..., 128., 128., 128.],
         [ 70.,  70.,  70.,  ..., 128., 128., 128.]],

        [[207., 208., 211.,  ..., 128., 128., 128.],
         [207., 207., 208.,  ..., 128., 128., 128.],
         [206., 206., 206.,  ..., 128., 128., 128.],
         ...,
         [112., 112., 114.,  ..., 128., 128., 128.],
         [109., 109., 107.,  ..., 128., 128., 128.],
         [109., 108., 106.,  ..., 128., 128., 128.]],

        [[217., 218., 221.,  ..., 128., 128., 128.],
         [217., 217., 218.,  ..., 128., 128., 128.],
         [216., 216., 216.,  ..., 128., 128., 128.],
         ...,
         [195., 194., 196.,  ..., 128., 128., 128.],
         [192., 190., 189.,  ..., 128., 128., 128.],
         [195., 193., 190.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[530.1077, 687.0203, 579.0632, 741.1877]])), gt_classes: tensor([434])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000073927.jpg', 'height': 281, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [372, 882, 902, 590, 593, 1056, 268, 291, 958, 445, 162, 708], 'image_id': 73927, 'annotations': [{'bbox': [132.72, 120.12, 14.78, 20.33], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 434}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000073927.jpg', 'height': 281, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [372, 882, 902, 590, 593, 1056, 268, 291, 958, 445, 162, 708], 'image_id': 73927, 'image': tensor([[[156., 154., 154.,  ..., 133., 127., 124.],
         [154., 152., 152.,  ..., 133., 127., 124.],
         [148., 148., 148.,  ..., 129., 127., 125.],
         ...,
         [240., 240., 240.,  ..., 240., 240., 240.],
         [240., 240., 240.,  ..., 240., 240., 240.],
         [240., 240., 240.,  ..., 240., 240., 240.]],

        [[255., 255., 255.,  ..., 255., 255., 253.],
         [255., 255., 255.,  ..., 255., 255., 253.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [240., 240., 240.,  ..., 240., 240., 240.],
         [240., 240., 240.,  ..., 240., 240., 240.],
         [240., 240., 240.,  ..., 240., 240., 240.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [240., 240., 240.,  ..., 240., 240., 240.],
         [240., 240., 240.,  ..., 240., 240., 240.],
         [240., 240., 240.,  ..., 240., 240., 240.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000468841.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [88], 'neg_category_ids': [343, 784, 76, 197, 766, 771, 800, 937, 1118, 320], 'image_id': 468841, 'annotations': [{'bbox': [547.11, 438.08, 9.6, 30.76], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 434}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000468841.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [88], 'neg_category_ids': [343, 784, 76, 197, 766, 771, 800, 937, 1118, 320], 'image_id': 468841, 'image': tensor([[[ 87.,  85.,  85.,  ..., 128., 128., 128.],
         [ 81.,  81.,  82.,  ..., 128., 128., 128.],
         [ 74.,  77.,  78.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 97.,  95.,  96.,  ..., 128., 128., 128.],
         [ 94.,  94.,  97.,  ..., 128., 128., 128.],
         [ 90.,  93.,  97.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[145., 144., 146.,  ..., 128., 128., 128.],
         [142., 143., 146.,  ..., 128., 128., 128.],
         [139., 143., 147.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[119.0787, 626.0893, 132.8037, 670.0505]])), gt_classes: tensor([434])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000166948.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [94], 'neg_category_ids': [602, 255, 1145, 173, 1048, 673, 675, 160, 620, 600, 781, 1000], 'image_id': 166948, 'annotations': [{'bbox': [322.95, 238.35, 202.94, 231.08], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 732}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000166948.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [94], 'neg_category_ids': [602, 255, 1145, 173, 1048, 673, 675, 160, 620, 600, 781, 1000], 'image_id': 166948, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[109.2960, 228.4188, 303.6744, 449.8704]])), gt_classes: tensor([732])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000331875.jpg', 'height': 311, 'width': 640, 'not_exhaustive_category_ids': [392], 'neg_category_ids': [516, 877, 388, 1092, 788, 586, 1141, 715, 55, 81, 133, 546, 89, 619, 663, 827], 'image_id': 331875, 'annotations': [{'bbox': [381.17, 236.28, 89.75, 73.54], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 732}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000331875.jpg', 'height': 311, 'width': 640, 'not_exhaustive_category_ids': [392], 'neg_category_ids': [516, 877, 388, 1092, 788, 586, 1141, 715, 55, 81, 133, 546, 89, 619, 663, 827], 'image_id': 331875, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[414.1148, 641.2229, 657.8422, 840.7977]])), gt_classes: tensor([732])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000317728.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [629, 368, 1026, 763, 635, 595, 571, 974, 678], 'image_id': 317728, 'annotations': [{'bbox': [153.73, 150.73, 150.76, 121.97], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 732}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000317728.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [629, 368, 1026, 763, 635, 595, 571, 974, 678], 'image_id': 317728, 'image': tensor([[[  3.,   4.,   6.,  ..., 128., 128., 128.],
         [  5.,   6.,   7.,  ..., 128., 128., 128.],
         [  7.,   7.,   7.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  6.,   7.,   9.,  ..., 128., 128., 128.],
         [  8.,   9.,  10.,  ..., 128., 128., 128.],
         [ 10.,  10.,   9.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 11.,  12.,  14.,  ..., 128., 128., 128.],
         [ 13.,  14.,  15.,  ..., 128., 128., 128.],
         [ 16.,  16.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[477.5775, 214.4762, 692.1750, 388.0294]])), gt_classes: tensor([732])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000281557.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [257, 24, 259, 927, 134, 798, 891, 705], 'image_id': 281557, 'annotations': [{'bbox': [102.3, 127.2, 363.74, 311.26], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 732}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000281557.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [257, 24, 259, 927, 134, 798, 891, 705], 'image_id': 281557, 'image': tensor([[[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[210.1111, 153.7000, 649.4408, 529.8058]])), gt_classes: tensor([732])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000162645.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [709], 'neg_category_ids': [688, 633, 26, 882, 670, 1129, 1116, 1063], 'image_id': 162645, 'annotations': [{'bbox': [49.87, 192.16, 170.51, 102.4], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 732}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000162645.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [709], 'neg_category_ids': [688, 633, 26, 882, 670, 1129, 1116, 1063], 'image_id': 162645, 'image': tensor([[[ 25.,  23.,  16.,  ..., 176., 180., 178.],
         [ 27.,  23.,  16.,  ..., 180., 184., 182.],
         [ 25.,  21.,  16.,  ..., 184., 187., 185.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[ 83.,  84.,  84.,  ..., 124., 124., 122.],
         [ 81.,  83.,  83.,  ..., 126., 126., 124.],
         [ 79.,  81.,  81.,  ..., 128., 128., 126.],
         ...,
         [ 93.,  93.,  92.,  ...,   0.,   0.,   0.],
         [ 88.,  93.,  92.,  ...,   0.,   0.,   0.],
         [ 92.,  92.,  88.,  ...,   1.,   0.,   0.]],

        [[187., 191., 189.,  ...,  74.,  79.,  79.],
         [185., 187., 187.,  ...,  77.,  81.,  79.],
         [180., 182., 182.,  ...,  79.,  83.,  81.],
         ...,
         [146., 142., 137.,  ...,  77.,  74.,  75.],
         [139., 135., 130.,  ...,  79.,  74.,  74.],
         [135., 131., 124.,  ...,  84.,  81.,  79.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 110.1315, 168.5998, 322.2915]])), gt_classes: tensor([732])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000166948.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [94], 'neg_category_ids': [602, 255, 1145, 173, 1048, 673, 675, 160, 620, 600, 781, 1000], 'image_id': 166948, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[109.2960, 228.4188, 303.6744, 449.8704]])), gt_classes: tensor([732])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000331875.jpg', 'height': 311, 'width': 640, 'not_exhaustive_category_ids': [392], 'neg_category_ids': [516, 877, 388, 1092, 788, 586, 1141, 715, 55, 81, 133, 546, 89, 619, 663, 827], 'image_id': 331875, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[414.1148, 641.2229, 657.8422, 840.7977]])), gt_classes: tensor([732])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000317728.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [629, 368, 1026, 763, 635, 595, 571, 974, 678], 'image_id': 317728, 'image': tensor([[[  3.,   4.,   6.,  ..., 128., 128., 128.],
         [  5.,   6.,   7.,  ..., 128., 128., 128.],
         [  7.,   7.,   7.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  6.,   7.,   9.,  ..., 128., 128., 128.],
         [  8.,   9.,  10.,  ..., 128., 128., 128.],
         [ 10.,  10.,   9.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 11.,  12.,  14.,  ..., 128., 128., 128.],
         [ 13.,  14.,  15.,  ..., 128., 128., 128.],
         [ 16.,  16.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[477.5775, 214.4762, 692.1750, 388.0294]])), gt_classes: tensor([732])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000281557.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [257, 24, 259, 927, 134, 798, 891, 705], 'image_id': 281557, 'image': tensor([[[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         [255., 255., 255.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[210.1111, 153.7000, 649.4408, 529.8058]])), gt_classes: tensor([732])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000162645.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [709], 'neg_category_ids': [688, 633, 26, 882, 670, 1129, 1116, 1063], 'image_id': 162645, 'image': tensor([[[ 25.,  23.,  16.,  ..., 176., 180., 178.],
         [ 27.,  23.,  16.,  ..., 180., 184., 182.],
         [ 25.,  21.,  16.,  ..., 184., 187., 185.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[ 83.,  84.,  84.,  ..., 124., 124., 122.],
         [ 81.,  83.,  83.,  ..., 126., 126., 124.],
         [ 79.,  81.,  81.,  ..., 128., 128., 126.],
         ...,
         [ 93.,  93.,  92.,  ...,   0.,   0.,   0.],
         [ 88.,  93.,  92.,  ...,   0.,   0.,   0.],
         [ 92.,  92.,  88.,  ...,   1.,   0.,   0.]],

        [[187., 191., 189.,  ...,  74.,  79.,  79.],
         [185., 187., 187.,  ...,  77.,  81.,  79.],
         [180., 182., 182.,  ...,  79.,  83.,  81.],
         ...,
         [146., 142., 137.,  ...,  77.,  74.,  75.],
         [139., 135., 130.,  ...,  79.,  74.,  74.],
         [135., 131., 124.,  ...,  84.,  81.,  79.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 110.1315, 168.5998, 322.2915]])), gt_classes: tensor([732])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000429033.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [252], 'neg_category_ids': [829, 127, 902, 927, 418, 310, 1131, 1154, 648, 659, 957, 190, 756, 939, 167], 'image_id': 429033, 'annotations_cat_set': {715, 685, 559, 1042, 631, 440, 252}, 'image': tensor([[[148., 151., 151.,  ..., 139., 144., 148.],
         [148., 151., 148.,  ..., 139., 139., 139.],
         [151., 148., 144.,  ..., 128., 134., 139.],
         ...,
         [ 61.,  36.,  48.,  ...,  26.,  36.,  48.],
         [100.,  75.,  75.,  ...,  36.,  48.,  75.],
         [128., 111., 111.,  ...,  61.,  75., 100.]],

        [[126., 127., 127.,  ..., 128., 127., 127.],
         [126., 127., 127.,  ..., 128., 127., 125.],
         [127., 126., 126.,  ..., 127., 125., 124.],
         ...,
         [ 38.,  25.,  32.,  ...,   1.,   3.,   7.],
         [ 54.,  44.,  44.,  ...,   3.,   7.,  18.],
         [ 66.,  58.,  58.,  ...,  12.,  18.,  32.]],

        [[122., 123., 123.,  ..., 138., 137., 137.],
         [122., 123., 123.,  ..., 138., 136., 136.],
         [123., 122., 122.,  ..., 137., 137., 136.],
         ...,
         [ 41.,  36.,  41.,  ...,   1.,   2.,   6.],
         [ 47.,  44.,  46.,  ...,   2.,   4.,   9.],
         [ 52.,  49.,  49.,  ...,   6.,   9.,  16.]]]), 'instances': Instances(num_instances=12, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 716.4500,  180.4285,  801.5396,  213.5047],
        [ 368.1854,  280.2074,  394.5167,  300.9746],
        [ 908.2396,  491.6159, 1024.0000,  542.3420],
        [ 135.2604,  478.8254,  292.1021,  562.4902],
        [ 497.5271,  496.8420,  597.1000,  509.7012],
        [   0.0000,  803.0095,  251.8604, 1024.0000],
        [ 369.1250,  511.8100,  803.7396,  873.1734],
        [   0.0000,  287.1985,   25.0771,  387.7798],
        [  52.8521,  655.1863,  623.0646, 1024.0000],
        [ 722.1791,  579.7734,  835.1125,  768.2599],
        [ 365.0000,  318.3035,  388.0083,  378.9777],
        [ 490.0104,  497.2317,  604.3646,  514.1480]])), gt_classes: tensor([399, 311, 187, 187, 187, 732, 732, 732, 446, 446, 483, 504])])}], 'support_set_target': tensor(732)}
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000199720.jpg', 'height': 349, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [923, 763, 1008, 130, 131, 1108, 936], 'image_id': 199720, 'image': tensor([[[ 13.,  12.,  10.,  ..., 128., 128., 128.],
         [ 14.,  12.,   9.,  ..., 128., 128., 128.],
         [ 16.,  15.,  15.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 86.,  85.,  83.,  ..., 128., 128., 128.],
         [ 87.,  84.,  82.,  ..., 128., 128., 128.],
         [ 88.,  87.,  88.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 60.,  61.,  60.,  ..., 128., 128., 128.],
         [ 61.,  61.,  59.,  ..., 128., 128., 128.],
         [ 64.,  65.,  66.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 23.7431, 351.0779,  42.6381, 396.8564]])), gt_classes: tensor([434])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000146626.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [738, 984, 503, 549, 271, 1089, 534], 'image_id': 146626, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[576.2319, 461.7351, 593.4590, 489.7512]])), gt_classes: tensor([434])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000317193.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [851, 500, 327, 1152, 647, 36, 804], 'image_id': 317193, 'image': tensor([[[197., 198., 201.,  ..., 128., 128., 128.],
         [197., 197., 198.,  ..., 128., 128., 128.],
         [196., 196., 196.,  ..., 128., 128., 128.],
         ...,
         [ 73.,  74.,  78.,  ..., 128., 128., 128.],
         [ 68.,  66.,  68.,  ..., 128., 128., 128.],
         [ 70.,  70.,  70.,  ..., 128., 128., 128.]],

        [[207., 208., 211.,  ..., 128., 128., 128.],
         [207., 207., 208.,  ..., 128., 128., 128.],
         [206., 206., 206.,  ..., 128., 128., 128.],
         ...,
         [112., 112., 114.,  ..., 128., 128., 128.],
         [109., 109., 107.,  ..., 128., 128., 128.],
         [109., 108., 106.,  ..., 128., 128., 128.]],

        [[217., 218., 221.,  ..., 128., 128., 128.],
         [217., 217., 218.,  ..., 128., 128., 128.],
         [216., 216., 216.,  ..., 128., 128., 128.],
         ...,
         [195., 194., 196.,  ..., 128., 128., 128.],
         [192., 190., 189.,  ..., 128., 128., 128.],
         [195., 193., 190.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[530.1077, 687.0203, 579.0632, 741.1877]])), gt_classes: tensor([434])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000468841.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [88], 'neg_category_ids': [343, 784, 76, 197, 766, 771, 800, 937, 1118, 320], 'image_id': 468841, 'image': tensor([[[ 87.,  85.,  85.,  ..., 128., 128., 128.],
         [ 81.,  81.,  82.,  ..., 128., 128., 128.],
         [ 74.,  77.,  78.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 97.,  95.,  96.,  ..., 128., 128., 128.],
         [ 94.,  94.,  97.,  ..., 128., 128., 128.],
         [ 90.,  93.,  97.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[145., 144., 146.,  ..., 128., 128., 128.],
         [142., 143., 146.,  ..., 128., 128., 128.],
         [139., 143., 147.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[119.0787, 626.0893, 132.8037, 670.0505]])), gt_classes: tensor([434])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000317193.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [851, 500, 327, 1152, 647, 36, 804], 'image_id': 317193, 'image': tensor([[[197., 198., 201.,  ..., 128., 128., 128.],
         [197., 197., 198.,  ..., 128., 128., 128.],
         [196., 196., 196.,  ..., 128., 128., 128.],
         ...,
         [ 73.,  74.,  78.,  ..., 128., 128., 128.],
         [ 68.,  66.,  68.,  ..., 128., 128., 128.],
         [ 70.,  70.,  70.,  ..., 128., 128., 128.]],

        [[207., 208., 211.,  ..., 128., 128., 128.],
         [207., 207., 208.,  ..., 128., 128., 128.],
         [206., 206., 206.,  ..., 128., 128., 128.],
         ...,
         [112., 112., 114.,  ..., 128., 128., 128.],
         [109., 109., 107.,  ..., 128., 128., 128.],
         [109., 108., 106.,  ..., 128., 128., 128.]],

        [[217., 218., 221.,  ..., 128., 128., 128.],
         [217., 217., 218.,  ..., 128., 128., 128.],
         [216., 216., 216.,  ..., 128., 128., 128.],
         ...,
         [195., 194., 196.,  ..., 128., 128., 128.],
         [192., 190., 189.,  ..., 128., 128., 128.],
         [195., 193., 190.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[530.1077, 687.0203, 579.0632, 741.1877]])), gt_classes: tensor([434])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000239936.jpg', 'height': 357, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [193, 73, 303, 172, 881, 815, 991, 494, 118], 'image_id': 239936, 'annotations_cat_set': {58, 675, 614}, 'image': tensor([[[  1.,   1.,   1.,  ...,   2.,   2.,   3.],
         [  1.,   1.,   1.,  ...,   3.,   4.,   6.],
         [  1.,   1.,   1.,  ...,   9.,   9.,  11.],
         ...,
         [171., 168., 171.,  ...,  40.,  54.,  69.],
         [168., 166., 168.,  ...,  46.,  54.,  61.],
         [171., 171., 173.,  ...,  46.,  54.,  54.]],

        [[  1.,   1.,   1.,  ...,  28.,  32.,  37.],
         [  1.,   1.,   1.,  ...,  28.,  32.,  37.],
         [  1.,   1.,   1.,  ...,  32.,  32.,  37.],
         ...,
         [  9.,   9.,   9.,  ...,  42.,  57.,  75.],
         [  8.,   8.,   8.,  ...,  49.,  57.,  65.],
         [  9.,   9.,   9.,  ...,  65.,  65.,  57.]],

        [[  0.,   0.,   0.,  ...,   5.,   5.,   5.],
         [  0.,   0.,   0.,  ...,   5.,   5.,   5.],
         [  0.,   0.,   0.,  ...,   5.,   5.,   5.],
         ...,
         [153., 153., 153.,  ...,  77.,  83.,  83.],
         [147., 144., 144.,  ...,  83.,  77.,  71.],
         [153., 153., 153.,  ...,  77.,  66.,  60.]]]), 'instances': Instances(num_instances=5, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[458.9602, 267.3092, 474.7242, 301.4748],
        [347.2018, 176.1907, 360.8974, 206.5322],
        [463.9433, 335.4836, 478.8925, 356.7352],
        [649.2254, 251.6370, 660.5705, 322.6950],
        [ 75.7661,  71.8447,  95.8550, 141.9938]])), gt_classes: tensor([474, 474, 434,  43,  43])])}], 'support_set_target': tensor(434)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000207629.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [338, 249], 'neg_category_ids': [99, 733, 760, 127, 29, 130, 1198, 1015], 'image_id': 207629, 'annotations': [{'bbox': [0.44, 267.34, 367.54, 212.49], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 534}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000207629.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [338, 249], 'neg_category_ids': [99, 733, 760, 127, 29, 130, 1198, 1015], 'image_id': 207629, 'image': tensor([[[100., 100., 100.,  ..., 186., 173., 162.],
         [100., 100., 100.,  ..., 186., 174., 163.],
         [102., 102., 102.,  ..., 187., 176., 164.],
         ...,
         [190., 190., 190.,  ..., 190., 190., 190.],
         [190., 190., 190.,  ..., 190., 190., 190.],
         [190., 190., 190.,  ..., 190., 190., 190.]],

        [[ 91.,  91.,  91.,  ..., 203., 169., 162.],
         [ 91.,  91.,  91.,  ..., 203., 169., 162.],
         [ 89.,  91.,  92.,  ..., 202., 169., 163.],
         ...,
         [171., 171., 171.,  ..., 171., 171., 171.],
         [171., 171., 171.,  ..., 171., 171., 171.],
         [171., 171., 171.,  ..., 171., 171., 171.]],

        [[ 62.,  62.,  62.,  ..., 217., 197., 182.],
         [ 62.,  62.,  62.,  ..., 216., 197., 182.],
         [ 62.,  62.,  62.,  ..., 214., 196., 181.],
         ...,
         [145., 145., 145.,  ..., 145., 145., 145.],
         [145., 145., 145.,  ..., 145., 145., 145.],
         [145., 145., 145.,  ..., 145., 145., 145.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 474.8900,  535.2369, 1024.0000,  960.6597]])), gt_classes: tensor([534])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000084038.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [617], 'neg_category_ids': [1145, 928, 884, 60, 331, 468, 1018, 999], 'image_id': 84038, 'annotations': [{'bbox': [251.67, 0.0, 111.5, 64.4], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 534}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000084038.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [617], 'neg_category_ids': [1145, 928, 884, 60, 331, 468, 1018, 999], 'image_id': 84038, 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[261.8941,   0.0000, 377.9238,  67.0833]])), gt_classes: tensor([534])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000095595.jpg', 'height': 419, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [687, 148, 981, 1, 366, 566, 264, 971, 679, 424, 892, 142, 1139, 15, 44], 'image_id': 95595, 'annotations': [{'bbox': [19.38, 154.18, 229.26, 158.06], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 534}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000095595.jpg', 'height': 419, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [687, 148, 981, 1, 366, 566, 264, 971, 679, 424, 892, 142, 1139, 15, 44], 'image_id': 95595, 'image': tensor([[[ 25.,  24.,  22.,  ...,  28.,  29.,  28.],
         [ 24.,  23.,  22.,  ...,  27.,  27.,  27.],
         [ 22.,  22.,  22.,  ...,  24.,  24.,  25.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 27.,  29.,  28.,  ...,  23.,  24.,  24.],
         [ 25.,  26.,  25.,  ...,  24.,  24.,  24.],
         [ 20.,  21.,  20.,  ...,  25.,  24.,  23.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 27.,  28.,  27.,  ...,  24.,  25.,  26.],
         [ 24.,  25.,  24.,  ...,  25.,  25.,  25.],
         [ 19.,  20.,  19.,  ...,  27.,  25.,  24.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[548.4900, 303.5764, 999.8456, 614.7924]])), gt_classes: tensor([534])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000086676.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [812, 415, 903, 593, 398, 1130, 889, 993, 490, 600, 211], 'image_id': 86676, 'annotations': [{'bbox': [22.46, 218.35, 145.36, 97.76], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 534}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000086676.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [812, 415, 903, 593, 398, 1130, 889, 993, 490, 600, 211], 'image_id': 86676, 'image': tensor([[[250., 168., 167.,  ..., 168., 168., 168.],
         [250., 250., 168.,  ..., 168., 168., 168.],
         [250., 250., 250.,  ..., 168., 168., 168.],
         ...,
         [168., 168., 168.,  ..., 168., 168., 168.],
         [168., 168., 168.,  ..., 168., 168., 168.],
         [168., 168., 168.,  ..., 168., 168., 168.]],

        [[167., 166., 166.,  ..., 167., 167., 167.],
         [167., 166., 166.,  ..., 167., 167., 167.],
         [249., 166., 166.,  ..., 167., 167., 167.],
         ...,
         [167., 167., 167.,  ..., 167., 167., 167.],
         [167., 167., 167.,  ..., 167., 167., 167.],
         [167., 167., 167.,  ..., 167., 167., 167.]],

        [[155., 154., 152.,  ..., 155., 155., 155.],
         [154., 153., 152.,  ..., 155., 155., 155.],
         [153., 153., 153.,  ..., 155., 155., 155.],
         ...,
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 34.2164, 332.5289, 255.6633, 481.4092]])), gt_classes: tensor([534])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000087000.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [217], 'neg_category_ids': [452, 786, 229, 1060, 642, 644, 728], 'image_id': 87000, 'annotations': [{'bbox': [342.08, 175.01, 297.42, 204.45], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 534}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000087000.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [217], 'neg_category_ids': [452, 786, 229, 1060, 642, 644, 728], 'image_id': 87000, 'image': tensor([[[ 52.,  52.,  51.,  ...,  53.,  49.,  68.],
         [ 50.,  50.,  49.,  ...,  53.,  51.,  69.],
         [ 46.,  46.,  45.,  ...,  53.,  55.,  72.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 51.,  51.,  50.,  ...,  63.,  61.,  80.],
         [ 52.,  52.,  51.,  ...,  63.,  63.,  82.],
         [ 53.,  53.,  52.,  ...,  63.,  67.,  86.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 71.,  71.,  70.,  ...,  77.,  75.,  94.],
         [ 70.,  70.,  69.,  ...,  77.,  77.,  96.],
         [ 69.,  69.,  68.,  ...,  77.,  81., 100.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 480.7800,  339.0819, 1024.0000,  735.2037]])), gt_classes: tensor([534])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000207629.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [338, 249], 'neg_category_ids': [99, 733, 760, 127, 29, 130, 1198, 1015], 'image_id': 207629, 'image': tensor([[[100., 100., 100.,  ..., 186., 173., 162.],
         [100., 100., 100.,  ..., 186., 174., 163.],
         [102., 102., 102.,  ..., 187., 176., 164.],
         ...,
         [190., 190., 190.,  ..., 190., 190., 190.],
         [190., 190., 190.,  ..., 190., 190., 190.],
         [190., 190., 190.,  ..., 190., 190., 190.]],

        [[ 91.,  91.,  91.,  ..., 203., 169., 162.],
         [ 91.,  91.,  91.,  ..., 203., 169., 162.],
         [ 89.,  91.,  92.,  ..., 202., 169., 163.],
         ...,
         [171., 171., 171.,  ..., 171., 171., 171.],
         [171., 171., 171.,  ..., 171., 171., 171.],
         [171., 171., 171.,  ..., 171., 171., 171.]],

        [[ 62.,  62.,  62.,  ..., 217., 197., 182.],
         [ 62.,  62.,  62.,  ..., 216., 197., 182.],
         [ 62.,  62.,  62.,  ..., 214., 196., 181.],
         ...,
         [145., 145., 145.,  ..., 145., 145., 145.],
         [145., 145., 145.,  ..., 145., 145., 145.],
         [145., 145., 145.,  ..., 145., 145., 145.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 474.8900,  535.2369, 1024.0000,  960.6597]])), gt_classes: tensor([534])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000084038.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [617], 'neg_category_ids': [1145, 928, 884, 60, 331, 468, 1018, 999], 'image_id': 84038, 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[261.8941,   0.0000, 377.9238,  67.0833]])), gt_classes: tensor([534])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000095595.jpg', 'height': 419, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [687, 148, 981, 1, 366, 566, 264, 971, 679, 424, 892, 142, 1139, 15, 44], 'image_id': 95595, 'image': tensor([[[ 25.,  24.,  22.,  ...,  28.,  29.,  28.],
         [ 24.,  23.,  22.,  ...,  27.,  27.,  27.],
         [ 22.,  22.,  22.,  ...,  24.,  24.,  25.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 27.,  29.,  28.,  ...,  23.,  24.,  24.],
         [ 25.,  26.,  25.,  ...,  24.,  24.,  24.],
         [ 20.,  21.,  20.,  ...,  25.,  24.,  23.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 27.,  28.,  27.,  ...,  24.,  25.,  26.],
         [ 24.,  25.,  24.,  ...,  25.,  25.,  25.],
         [ 19.,  20.,  19.,  ...,  27.,  25.,  24.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[548.4900, 303.5764, 999.8456, 614.7924]])), gt_classes: tensor([534])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000086676.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [812, 415, 903, 593, 398, 1130, 889, 993, 490, 600, 211], 'image_id': 86676, 'image': tensor([[[250., 168., 167.,  ..., 168., 168., 168.],
         [250., 250., 168.,  ..., 168., 168., 168.],
         [250., 250., 250.,  ..., 168., 168., 168.],
         ...,
         [168., 168., 168.,  ..., 168., 168., 168.],
         [168., 168., 168.,  ..., 168., 168., 168.],
         [168., 168., 168.,  ..., 168., 168., 168.]],

        [[167., 166., 166.,  ..., 167., 167., 167.],
         [167., 166., 166.,  ..., 167., 167., 167.],
         [249., 166., 166.,  ..., 167., 167., 167.],
         ...,
         [167., 167., 167.,  ..., 167., 167., 167.],
         [167., 167., 167.,  ..., 167., 167., 167.],
         [167., 167., 167.,  ..., 167., 167., 167.]],

        [[155., 154., 152.,  ..., 155., 155., 155.],
         [154., 153., 152.,  ..., 155., 155., 155.],
         [153., 153., 153.,  ..., 155., 155., 155.],
         ...,
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.],
         [155., 155., 155.,  ..., 155., 155., 155.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 34.2164, 332.5289, 255.6633, 481.4092]])), gt_classes: tensor([534])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000087000.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [217], 'neg_category_ids': [452, 786, 229, 1060, 642, 644, 728], 'image_id': 87000, 'image': tensor([[[ 52.,  52.,  51.,  ...,  53.,  49.,  68.],
         [ 50.,  50.,  49.,  ...,  53.,  51.,  69.],
         [ 46.,  46.,  45.,  ...,  53.,  55.,  72.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 51.,  51.,  50.,  ...,  63.,  61.,  80.],
         [ 52.,  52.,  51.,  ...,  63.,  63.,  82.],
         [ 53.,  53.,  52.,  ...,  63.,  67.,  86.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 71.,  71.,  70.,  ...,  77.,  75.,  94.],
         [ 70.,  70.,  69.,  ...,  77.,  77.,  96.],
         [ 69.,  69.,  68.,  ...,  77.,  81., 100.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 480.7800,  339.0819, 1024.0000,  735.2037]])), gt_classes: tensor([534])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000441816.jpg', 'height': 640, 'width': 533, 'not_exhaustive_category_ids': [751, 338], 'neg_category_ids': [649, 735, 523, 230, 470, 870, 316, 939], 'image_id': 441816, 'annotations_cat_set': {993, 418, 739, 836, 751, 338, 248, 1117}, 'image': tensor([[[58., 58., 58.,  ..., 29., 29., 29.],
         [58., 58., 58.,  ..., 29., 29., 29.],
         [58., 58., 58.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]],

        [[58., 58., 58.,  ..., 29., 29., 29.],
         [58., 58., 58.,  ..., 29., 29., 29.],
         [58., 58., 58.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]],

        [[58., 58., 58.,  ..., 29., 29., 29.],
         [58., 58., 58.,  ..., 29., 29., 29.],
         [58., 58., 58.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]]]), 'instances': Instances(num_instances=75, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[364.6199, 432.2131, 617.3536, 591.5629],
        [219.5050, 425.0040, 342.8954, 602.5170],
        [ 44.8401, 614.0329, 489.5889, 831.5772],
        [ 33.7505, 448.0358, 164.9398, 590.7069],
        [137.5435, 200.6250, 374.4120, 250.6876],
        [ 89.1451, 532.6058, 132.2461, 554.9288],
        [ 86.3225, 502.4453, 121.4240, 527.9113],
        [126.4003, 524.7012, 147.2285, 545.0714],
        [107.2844, 497.5767, 145.7704, 529.8372],
        [364.3925, 314.1252, 680.2930, 627.7823],
        [390.3976,  86.0547, 664.8424, 187.9589],
        [ 27.1555, 391.6468, 343.1496, 605.8875],
        [296.1826, 247.2369, 309.5865, 259.5553],
        [146.3723, 180.4154, 157.3416, 190.9549],
        [285.5612, 361.0983, 293.0122, 369.4442],
        [350.3867, 250.6609, 357.5836, 257.0675],
        [206.0610, 198.3513, 213.5254, 204.0624],
        [205.4323, 219.1494, 251.4629, 239.0113],
        [235.4238, 278.5344, 245.0285, 292.1234],
        [109.4114, 258.4719, 122.1330, 270.7635],
        [123.3370, 281.5972, 137.1555, 290.8260],
        [122.3203, 257.7095, 139.5233, 269.2521],
        [249.6436, 308.6281, 261.8168, 322.4980],
        [182.1695, 309.3637, 193.0183, 324.5711],
        [153.0341, 284.8206, 171.0531, 300.4292],
        [181.9822, 276.1938, 197.6602, 285.5696],
        [183.6677, 192.2121, 193.4999, 199.2474],
        [ 54.9398, 259.6489,  84.5567, 281.5973],
        [193.7006, 201.4944, 207.3051, 210.0544],
        [236.6411, 320.2376, 253.7504, 334.4954],
        [199.6935, 179.5727, 213.5254, 189.4569],
        [109.6923, 268.2624, 124.8352, 281.8647],
        [146.6265, 311.9184, 196.4429, 359.2659],
        [230.2602, 292.6049, 237.1093, 301.4859],
        [273.1472, 213.0905, 312.9174, 241.6194],
        [338.2670, 256.3452, 348.9018, 266.9918],
        [225.1769, 310.1395, 240.3198, 322.6451],
        [130.8281, 196.1042, 180.6311, 216.2069],
        [192.3361, 354.4375, 202.4091, 364.0407],
        [198.1150, 330.0549, 216.7895, 347.0411],
        [215.0370, 358.2093, 221.8326, 363.0376],
        [ 57.0801, 294.0360, 148.4324, 331.0179],
        [310.6834, 287.9637, 317.7064, 294.1163],
        [260.6263, 340.3670, 283.7151, 361.4193],
        [283.0062, 345.5699, 290.9120, 353.4879],
        [346.8016, 276.5014, 365.2620, 293.0195],
        [305.3994, 264.7849, 316.1546, 275.7925],
        [220.8561, 202.1096, 230.1131, 209.3188],
        [305.1720, 338.6951, 322.5757, 355.4138],
        [192.3896, 269.6534, 207.0911, 279.7381],
        [321.9202, 191.2090, 339.0696, 200.0231],
        [243.8380, 198.2710, 257.2151, 209.6799],
        [321.1978, 246.7019, 340.0595, 267.9949],
        [291.8885, 268.4496, 298.9383, 275.0970],
        [159.8030, 163.7367, 165.7290, 170.9860],
        [320.7831, 282.8946, 322.8164, 285.1282],
        [226.9293, 346.1049, 239.1292, 357.4736],
        [204.6564, 314.6736, 224.8291, 329.4396],
        [154.0776, 256.6261, 160.8999, 264.3569],
        [219.9331, 367.3176, 224.4010, 372.9084],
        [352.9149, 625.4283, 668.4677, 789.2453],
        [440.6420, 154.1201, 687.9714, 261.7354],
        [413.4330,  79.0596, 588.7133, 151.7126],
        [ 29.6704, 353.1936, 232.1597, 483.1317],
        [364.7671, 434.1391, 625.8080, 592.9539],
        [ 24.6406,  35.3368, 382.4248, 419.7075],
        [399.0927, 163.1215, 686.9414, 324.9991],
        [164.8996, 768.4606, 322.8164, 830.7480],
        [276.4648, 442.4851, 322.7495, 594.5856],
        [116.1401,  38.0653, 380.7259, 415.6415],
        [ 30.1253, 352.3109, 232.1196, 482.0083],
        [414.0751,  80.0360, 588.9808, 152.3412],
        [217.4048, 440.7865, 343.0292, 598.9191],
        [364.7136, 434.1124, 624.1894, 597.2205],
        [352.0053, 625.3615, 668.7886, 788.8843]])), gt_classes: tensor([589, 589, 589, 589, 696, 185, 185, 185, 185, 523, 523, 523, 244, 244,
        244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244,
        244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244,
        244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244, 244,
        244, 244, 244, 244, 796, 796, 796, 796, 796, 796, 796, 297, 297, 534,
        534, 534, 534, 534, 534])])}], 'support_set_target': tensor(534)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000268711.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [943, 435, 1147, 418, 750, 842, 1179, 1200], 'image_id': 268711, 'annotations': [{'bbox': [121.65, 233.39, 50.57, 95.18], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 24}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000268711.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [943, 435, 1147, 418, 750, 842, 1179, 1200], 'image_id': 268711, 'image': tensor([[[112., 111., 109.,  ..., 128., 128., 128.],
         [112., 111., 110.,  ..., 128., 128., 128.],
         [112., 112., 112.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[113., 111., 109.,  ..., 128., 128., 128.],
         [113., 112., 110.,  ..., 128., 128., 128.],
         [113., 113., 112.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[127., 125., 123.,  ..., 128., 128., 128.],
         [127., 126., 124.,  ..., 128., 128., 128.],
         [127., 127., 126.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[744.7935, 371.2274, 825.3104, 522.6196]])), gt_classes: tensor([24])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000119561.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [255, 785, 760, 692, 173, 260, 1153, 973, 619, 253], 'image_id': 119561, 'annotations': [{'bbox': [0.0, 347.81, 125.35, 132.19], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 24}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000119561.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [255, 785, 760, 692, 173, 260, 1153, 973, 619, 253], 'image_id': 119561, 'image': tensor([[[243., 235., 226.,  ...,  64.,  66.,  67.],
         [244., 240., 234.,  ...,  98.,  88.,  78.],
         [246., 247., 248.,  ..., 151., 121.,  97.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[244., 237., 229.,  ...,  73.,  73.,  73.],
         [245., 242., 236.,  ..., 104.,  94.,  84.],
         [247., 248., 249.,  ..., 151., 124., 102.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[243., 236., 226.,  ...,  66.,  68.,  69.],
         [244., 241., 235.,  ...,  98.,  89.,  79.],
         [248., 248., 249.,  ..., 148., 120.,  97.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 812.6168,  605.7691, 1024.0000,  836.0000]])), gt_classes: tensor([24])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484636.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [959, 1071, 834, 32], 'neg_category_ids': [218, 1073, 925, 176, 396, 1108, 554, 1000], 'image_id': 484636, 'annotations': [{'bbox': [357.51, 206.86, 62.6, 48.15], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 24}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484636.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [959, 1071, 834, 32], 'neg_category_ids': [218, 1073, 925, 176, 396, 1108, 554, 1000], 'image_id': 484636, 'image': tensor([[[203., 203., 201.,  ..., 128., 128., 128.],
         [201., 202., 202.,  ..., 128., 128., 128.],
         [196., 195., 199.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[210., 212., 212.,  ..., 128., 128., 128.],
         [210., 211., 211.,  ..., 128., 128., 128.],
         [208., 204., 210.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[227., 226., 226.,  ..., 128., 128., 128.],
         [224., 225., 224.,  ..., 128., 128., 128.],
         [220., 217., 222.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 85.9616, 222.3900, 153.3192, 274.1549]])), gt_classes: tensor([24])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484636.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [959, 1071, 834, 32], 'neg_category_ids': [218, 1073, 925, 176, 396, 1108, 554, 1000], 'image_id': 484636, 'annotations': [{'bbox': [46.63, 190.01, 106.37, 72.06], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 24}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484636.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [959, 1071, 834, 32], 'neg_category_ids': [218, 1073, 925, 176, 396, 1108, 554, 1000], 'image_id': 484636, 'image': tensor([[[ 10.,  17.,  20.,  ..., 127., 127., 127.],
         [  9.,  17.,  20.,  ..., 127., 127., 127.],
         [  9.,  17.,  19.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  5.,   6.,  11.,  ..., 127., 127., 127.],
         [  4.,   6.,  11.,  ..., 127., 127., 127.],
         [  4.,   6.,  11.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  6.,   2.,   0.,  ..., 127., 127., 127.],
         [  5.,   2.,   0.,  ..., 127., 127., 127.],
         [  5.,   2.,   0.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 48.4019, 196.8572, 158.8140, 271.5140]])), gt_classes: tensor([24])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000234963.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1074], 'neg_category_ids': [367, 689, 688, 1101, 1032, 836, 614, 511], 'image_id': 234963, 'annotations': [{'bbox': [463.73, 335.06, 11.79, 21.34], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 24}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000234963.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1074], 'neg_category_ids': [367, 689, 688, 1101, 1032, 836, 614, 511], 'image_id': 234963, 'image': tensor([[[ 90.,  92.,  94.,  ...,  72.,  73.,  70.],
         [ 94.,  93.,  92.,  ...,  70.,  70.,  68.],
         [102.,  94.,  89.,  ...,  66.,  65.,  65.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[160., 162., 163.,  ...,  90.,  91.,  90.],
         [164., 163., 161.,  ...,  88.,  89.,  88.],
         [172., 164., 158.,  ...,  83.,  84.,  84.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[200., 203., 206.,  ...,  93.,  96.,  95.],
         [204., 203., 204.,  ...,  91.,  94.,  93.],
         [212., 204., 199.,  ...,  89.,  89.,  89.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[285.8580, 625.4453, 307.8537, 665.2800]])), gt_classes: tensor([24])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000351770.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [540, 170, 522, 570, 799, 94], 'image_id': 351770, 'annotations': [{'bbox': [180.36, 0.0, 339.89, 226.44], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 843}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000351770.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [540, 170, 522, 570, 799, 94], 'image_id': 351770, 'image': tensor([[[137., 135., 134.,  ..., 127., 126., 126.],
         [127., 126., 125.,  ..., 127., 126., 126.],
         [106., 105., 104.,  ..., 126., 127., 127.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[123., 124., 125.,  ..., 154., 153., 153.],
         [119., 120., 121.,  ..., 154., 153., 153.],
         [111., 112., 113.,  ..., 154., 154., 154.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[144., 145., 146.,  ..., 188., 187., 187.],
         [140., 141., 141.,  ..., 188., 187., 187.],
         [130., 131., 130.,  ..., 189., 188., 188.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[119.7848,   0.0000, 837.2713, 477.8828]])), gt_classes: tensor([843])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000527535.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [782, 758, 300, 1025, 1001, 240, 286, 1105, 264, 990, 379, 242, 821, 842, 705, 186, 1020], 'image_id': 527535, 'annotations': [{'bbox': [417.61, 161.76, 87.55, 80.49], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 843}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000527535.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [782, 758, 300, 1025, 1001, 240, 286, 1105, 264, 990, 379, 242, 821, 842, 705, 186, 1020], 'image_id': 527535, 'image': tensor([[[136., 139., 141.,  ..., 172., 172., 170.],
         [137., 140., 141.,  ..., 172., 173., 170.],
         [140., 142., 144.,  ..., 172., 173., 172.],
         ...,
         [ 93.,  93.,  93.,  ...,  15.,  15.,  15.],
         [ 93.,  95.,  90.,  ...,  18.,  18.,  18.],
         [106., 106., 104.,  ...,  20.,  20.,  18.]],

        [[128., 129., 130.,  ..., 123., 124., 121.],
         [128., 129., 130.,  ..., 121., 122., 120.],
         [129., 130., 130.,  ..., 118., 118., 119.],
         ...,
         [130., 129., 130.,  ...,  16.,  16.,  16.],
         [132., 131., 132.,  ...,  18.,  18.,  18.],
         [135., 134., 134.,  ...,  18.,  18.,  18.]],

        [[143., 144., 146.,  ...,  52.,  52.,  51.],
         [143., 144., 146.,  ...,  52.,  52.,  51.],
         [143., 144., 144.,  ...,  51.,  51.,  50.],
         ...,
         [ 69.,  68.,  68.,  ...,  22.,  22.,  22.],
         [ 71.,  70.,  70.,  ...,  24.,  23.,  23.],
         [ 74.,  72.,  70.,  ...,  26.,  26.,  26.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[321.2468, 451.3692, 575.2785, 684.9221]])), gt_classes: tensor([843])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000321079.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [753], 'neg_category_ids': [498, 1185, 584, 1027, 237, 1171, 459, 1104, 86, 268, 1198, 1015, 67, 962], 'image_id': 321079, 'annotations': [{'bbox': [370.36, 0.0, 175.85, 97.46], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 843}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000321079.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [753], 'neg_category_ids': [498, 1185, 584, 1027, 237, 1171, 459, 1104, 86, 268, 1198, 1015, 67, 962], 'image_id': 321079, 'image': tensor([[[149., 151., 152.,  ..., 196., 194., 190.],
         [149., 151., 152.,  ..., 193., 192., 188.],
         [148., 150., 152.,  ..., 189., 188., 185.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[164., 165., 166.,  ..., 194., 193., 189.],
         [164., 165., 166.,  ..., 192., 191., 188.],
         [163., 164., 165.,  ..., 189., 188., 186.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[190., 189., 189.,  ..., 192., 193., 191.],
         [190., 189., 189.,  ..., 191., 192., 190.],
         [189., 188., 188.,  ..., 188., 189., 189.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[627.8152,   0.0000, 934.4536, 169.9830]])), gt_classes: tensor([843])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000438905.jpg', 'height': 443, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [557, 389, 541, 634, 79, 1052, 970, 1192, 225, 991, 1036, 38, 136, 576, 554, 252, 166], 'image_id': 438905, 'annotations': [{'bbox': [106.89, 70.03, 58.2, 77.37], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 843}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000438905.jpg', 'height': 443, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [557, 389, 541, 634, 79, 1052, 970, 1192, 225, 991, 1036, 38, 136, 576, 554, 252, 166], 'image_id': 438905, 'image': tensor([[[220., 220., 220.,  ..., 220., 220., 220.],
         [220., 220., 220.,  ..., 220., 220., 220.],
         [220., 220., 220.,  ..., 220., 220., 220.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[218., 218., 218.,  ..., 218., 218., 218.],
         [218., 218., 218.,  ..., 218., 218., 218.],
         [218., 218., 218.,  ..., 218., 218., 218.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[217., 217., 217.,  ..., 217., 217., 217.],
         [217., 217., 217.,  ..., 217., 217., 217.],
         [217., 217., 217.,  ..., 217., 217., 217.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[750.2972, 133.5787, 861.2410, 281.1580]])), gt_classes: tensor([843])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000285512.jpg', 'height': 524, 'width': 640, 'not_exhaustive_category_ids': [1180], 'neg_category_ids': [235, 1004, 395, 287, 36, 185, 319, 780, 120], 'image_id': 285512, 'annotations': [{'bbox': [148.96, 450.56, 78.28, 49.65], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 843}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000285512.jpg', 'height': 524, 'width': 640, 'not_exhaustive_category_ids': [1180], 'neg_category_ids': [235, 1004, 395, 287, 36, 185, 319, 780, 120], 'image_id': 285512, 'image': tensor([[[144., 144., 145.,  ...,  87.,  87.,  87.],
         [144., 144., 145.,  ...,  87.,  87.,  87.],
         [144., 144., 145.,  ...,  87.,  87.,  87.],
         ...,
         [142., 142., 143.,  ..., 108., 108., 108.],
         [142., 142., 143.,  ..., 109., 109., 109.],
         [141., 141., 142.,  ..., 111., 111., 111.]],

        [[115., 116., 117.,  ...,  50.,  50.,  50.],
         [114., 114., 115.,  ...,  50.,  50.,  50.],
         [113., 113., 114.,  ...,  50.,  50.,  50.],
         ...,
         [112., 118., 123.,  ...,  66.,  65.,  65.],
         [122., 126., 129.,  ...,  67.,  66.,  66.],
         [129., 132., 133.,  ...,  68.,  67.,  67.]],

        [[ 51.,  52.,  53.,  ...,  28.,  28.,  28.],
         [ 48.,  49.,  50.,  ...,  28.,  28.,  28.],
         [ 46.,  47.,  48.,  ...,  28.,  28.,  28.],
         ...,
         [ 73.,  82.,  89.,  ...,  44.,  44.,  44.],
         [ 86.,  93.,  98.,  ...,  45.,  45.,  45.],
         [ 95., 100., 102.,  ...,  47.,  46.,  46.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038090.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [628, 626], 'neg_category_ids': [475, 688, 2, 541, 196, 812, 127, 901, 482, 486, 227, 1084, 448, 868, 1139], 'image_id': 38090, 'annotations': [{'bbox': [57.4, 297.28, 138.03, 77.72], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 334}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038090.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [628, 626], 'neg_category_ids': [475, 688, 2, 541, 196, 812, 127, 901, 482, 486, 227, 1084, 448, 868, 1139], 'image_id': 38090, 'image': tensor([[[193., 194., 194.,  ..., 134., 134., 134.],
         [193., 194., 194.,  ..., 134., 134., 134.],
         [193., 194., 194.,  ..., 134., 133., 134.],
         ...,
         [ 72.,  52.,  27.,  ...,  85.,  91.,  96.],
         [ 76.,  57.,  37.,  ...,  76.,  79.,  85.],
         [ 79.,  63.,  46.,  ...,  66.,  69.,  75.]],

        [[198., 199., 199.,  ..., 140., 140., 140.],
         [198., 199., 199.,  ..., 140., 140., 140.],
         [198., 199., 199.,  ..., 140., 139., 140.],
         ...,
         [ 80.,  59.,  33.,  ...,  92.,  98., 103.],
         [ 84.,  64.,  43.,  ...,  82.,  85.,  92.],
         [ 86.,  69.,  52.,  ...,  72.,  75.,  81.]],

        [[201., 202., 202.,  ..., 144., 144., 144.],
         [201., 202., 202.,  ..., 144., 144., 144.],
         [201., 202., 202.,  ..., 144., 143., 144.],
         ...,
         [ 81.,  62.,  37.,  ..., 101., 107., 111.],
         [ 86.,  68.,  48.,  ...,  91.,  95., 100.],
         [ 90.,  73.,  57.,  ...,  81.,  84.,  90.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 641.1057,  819.5187, 1024.0000, 1024.0000]])), gt_classes: tensor([334])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000198762.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [312], 'neg_category_ids': [323, 326, 415, 225, 1133, 820, 277], 'image_id': 198762, 'annotations': [{'bbox': [106.42, 357.69, 215.71, 122.08], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 334}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000198762.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [312], 'neg_category_ids': [323, 326, 415, 225, 1133, 820, 277], 'image_id': 198762, 'image': tensor([[[164., 164., 164.,  ...,  15.,  18.,  22.],
         [164., 164., 164.,  ...,  16.,  19.,  23.],
         [165., 164., 163.,  ...,  19.,  22.,  24.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[145., 145., 146.,  ..., 208., 205., 201.],
         [145., 145., 145.,  ..., 207., 204., 201.],
         [145., 144., 144.,  ..., 204., 202., 200.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[127., 127., 127.,  ..., 185., 182., 178.],
         [127., 127., 127.,  ..., 184., 181., 178.],
         [127., 126., 126.,  ..., 181., 179., 177.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 739.9712, 403.9098, 992.5242]])), gt_classes: tensor([334])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000337902.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [430, 1169, 586, 670, 1102, 616, 272, 661], 'image_id': 337902, 'annotations': [{'bbox': [26.95, 239.85, 127.26, 86.21], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 334}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000337902.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [430, 1169, 586, 670, 1102, 616, 272, 661], 'image_id': 337902, 'image': tensor([[[107., 106., 103.,  ..., 128., 128., 128.],
         [108., 106., 105.,  ..., 128., 128., 128.],
         [110., 108., 111.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[132., 135., 134.,  ..., 128., 128., 128.],
         [133., 134., 135.,  ..., 128., 128., 128.],
         [134., 135., 138.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[154., 157., 156.,  ..., 128., 128., 128.],
         [153., 155., 156.,  ..., 128., 128., 128.],
         [154., 156., 159.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 23.5391, 209.3691, 134.6928, 284.6232]])), gt_classes: tensor([334])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000469317.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [558, 1143, 788, 1053, 597, 620, 448, 849], 'image_id': 469317, 'annotations': [{'bbox': [80.83, 193.73, 29.05, 35.0], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 334}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000469317.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [558, 1143, 788, 1053, 597, 620, 448, 849], 'image_id': 469317, 'image': tensor([[[195., 193., 187.,  ..., 128., 128., 128.],
         [194., 193., 185.,  ..., 128., 128., 128.],
         [200., 192., 189.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[195., 192., 186.,  ..., 128., 128., 128.],
         [193., 192., 183.,  ..., 128., 128., 128.],
         [199., 190., 187.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[165., 166., 162.,  ..., 128., 128., 128.],
         [166., 167., 160.,  ..., 128., 128., 128.],
         [171., 166., 165.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[332.3369, 174.0543, 358.4214, 205.4996]])), gt_classes: tensor([334])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000546569.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [350], 'neg_category_ids': [733, 943, 736, 282, 610, 970, 1030, 663, 700, 771, 44, 138, 272, 161, 751, 363, 253], 'image_id': 546569, 'annotations': [{'bbox': [148.91, 388.12, 94.7, 86.01], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 334}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000546569.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [350], 'neg_category_ids': [733, 943, 736, 282, 610, 970, 1030, 663, 700, 771, 44, 138, 272, 161, 751, 363, 253], 'image_id': 546569, 'image': tensor([[[ 60.,  52.,  43.,  ..., 141., 143., 141.],
         [ 60.,  52.,  43.,  ..., 141., 144., 144.],
         [ 66.,  60.,  48.,  ..., 136., 138., 136.],
         ...,
         [ 19.,  19.,  19.,  ..., 161., 159., 161.],
         [ 25.,  25.,  24.,  ..., 169., 167., 169.],
         [ 25.,  24.,  21.,  ..., 177., 177., 177.]],

        [[ 59.,  59.,  59.,  ..., 118., 118., 125.],
         [ 53.,  53.,  53.,  ..., 116., 118., 125.],
         [ 59.,  59.,  62.,  ..., 118., 121., 125.],
         ...,
         [ 38.,  38.,  38.,  ..., 159., 160., 160.],
         [ 50.,  47.,  45.,  ..., 163., 162., 163.],
         [ 50.,  45.,  39.,  ..., 160., 159., 159.]],

        [[ 97.,  97.,  92.,  ..., 146., 148., 150.],
         [ 95.,  92.,  89.,  ..., 146., 150., 154.],
         [100., 100.,  97.,  ..., 150., 152., 154.],
         ...,
         [ 71.,  73.,  76.,  ...,  38.,  38.,  41.],
         [ 85.,  89.,  92.,  ...,  38.,  38.,  41.],
         [ 85.,  89.,  82.,  ...,  37.,  37.,  38.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 108.1019,  861.3163,  331.3867, 1024.0000]])), gt_classes: tensor([334])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000268711.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [943, 435, 1147, 418, 750, 842, 1179, 1200], 'image_id': 268711, 'image': tensor([[[112., 111., 109.,  ..., 128., 128., 128.],
         [112., 111., 110.,  ..., 128., 128., 128.],
         [112., 112., 112.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[113., 111., 109.,  ..., 128., 128., 128.],
         [113., 112., 110.,  ..., 128., 128., 128.],
         [113., 113., 112.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[127., 125., 123.,  ..., 128., 128., 128.],
         [127., 126., 124.,  ..., 128., 128., 128.],
         [127., 127., 126.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[744.7935, 371.2274, 825.3104, 522.6196]])), gt_classes: tensor([24])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000119561.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [255, 785, 760, 692, 173, 260, 1153, 973, 619, 253], 'image_id': 119561, 'image': tensor([[[243., 235., 226.,  ...,  64.,  66.,  67.],
         [244., 240., 234.,  ...,  98.,  88.,  78.],
         [246., 247., 248.,  ..., 151., 121.,  97.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[244., 237., 229.,  ...,  73.,  73.,  73.],
         [245., 242., 236.,  ..., 104.,  94.,  84.],
         [247., 248., 249.,  ..., 151., 124., 102.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[243., 236., 226.,  ...,  66.,  68.,  69.],
         [244., 241., 235.,  ...,  98.,  89.,  79.],
         [248., 248., 249.,  ..., 148., 120.,  97.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 812.6168,  605.7691, 1024.0000,  836.0000]])), gt_classes: tensor([24])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484636.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [959, 1071, 834, 32], 'neg_category_ids': [218, 1073, 925, 176, 396, 1108, 554, 1000], 'image_id': 484636, 'image': tensor([[[203., 203., 201.,  ..., 128., 128., 128.],
         [201., 202., 202.,  ..., 128., 128., 128.],
         [196., 195., 199.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[210., 212., 212.,  ..., 128., 128., 128.],
         [210., 211., 211.,  ..., 128., 128., 128.],
         [208., 204., 210.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[227., 226., 226.,  ..., 128., 128., 128.],
         [224., 225., 224.,  ..., 128., 128., 128.],
         [220., 217., 222.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 85.9616, 222.3900, 153.3192, 274.1549]])), gt_classes: tensor([24])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000484636.jpg', 'height': 333, 'width': 500, 'not_exhaustive_category_ids': [959, 1071, 834, 32], 'neg_category_ids': [218, 1073, 925, 176, 396, 1108, 554, 1000], 'image_id': 484636, 'image': tensor([[[ 10.,  17.,  20.,  ..., 127., 127., 127.],
         [  9.,  17.,  20.,  ..., 127., 127., 127.],
         [  9.,  17.,  19.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  5.,   6.,  11.,  ..., 127., 127., 127.],
         [  4.,   6.,  11.,  ..., 127., 127., 127.],
         [  4.,   6.,  11.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[  6.,   2.,   0.,  ..., 127., 127., 127.],
         [  5.,   2.,   0.,  ..., 127., 127., 127.],
         [  5.,   2.,   0.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 48.4019, 196.8572, 158.8140, 271.5140]])), gt_classes: tensor([24])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000234963.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1074], 'neg_category_ids': [367, 689, 688, 1101, 1032, 836, 614, 511], 'image_id': 234963, 'image': tensor([[[ 90.,  92.,  94.,  ...,  72.,  73.,  70.],
         [ 94.,  93.,  92.,  ...,  70.,  70.,  68.],
         [102.,  94.,  89.,  ...,  66.,  65.,  65.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[160., 162., 163.,  ...,  90.,  91.,  90.],
         [164., 163., 161.,  ...,  88.,  89.,  88.],
         [172., 164., 158.,  ...,  83.,  84.,  84.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[200., 203., 206.,  ...,  93.,  96.,  95.],
         [204., 203., 204.,  ...,  91.,  94.,  93.],
         [212., 204., 199.,  ...,  89.,  89.,  89.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[285.8580, 625.4453, 307.8537, 665.2800]])), gt_classes: tensor([24])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000203928.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [35, 1035, 32], 'neg_category_ids': [1069, 370, 501, 372, 478, 175, 522, 1106, 131, 441, 466, 229, 250, 729, 495, 191], 'image_id': 203928, 'annotations_cat_set': {32, 35, 611, 392, 1035, 655}, 'image': tensor([[[224., 224., 224.,  ..., 128., 128., 128.],
         [225., 225., 225.,  ..., 128., 128., 128.],
         [224., 225., 225.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[193., 193., 193.,  ..., 129., 129., 129.],
         [194., 194., 194.,  ..., 129., 129., 129.],
         [193., 194., 194.,  ..., 129., 129., 129.],
         ...,
         [129., 129., 129.,  ..., 129., 129., 129.],
         [129., 129., 129.,  ..., 129., 129., 129.],
         [129., 129., 129.,  ..., 129., 129., 129.]],

        [[169., 169., 169.,  ..., 128., 128., 128.],
         [170., 170., 170.,  ..., 128., 128., 128.],
         [169., 170., 170.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=67, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[145.0520, 562.2138, 150.0501, 577.3908],
        [439.3193, 595.6503, 450.9530, 608.9865],
        [184.9298, 585.6857, 194.8190, 600.5417],
        [ 86.2306, 579.6492,  90.9933, 584.2194],
        [233.3376, 604.8229, 242.1672, 610.2815],
        [430.6503, 574.5972, 438.0886, 587.7407],
        [ 60.9084, 575.4000,  78.0753, 594.7298],
        [ 69.0744, 613.0750, 116.1658, 660.4256],
        [ 49.8526, 574.6401,  62.5672, 594.3552],
        [ 34.6228, 530.1793,  42.2431, 537.6501],
        [390.4621, 556.1558, 397.8148, 576.6416],
        [271.4494, 575.6675, 279.4550, 587.8584],
        [125.7767, 561.1541, 131.8772, 573.5804],
        [377.0625, 564.5042, 387.5296, 577.8617],
        [168.5014, 591.6580, 187.5841, 641.8450],
        [398.2000, 557.1726, 403.9152, 571.3221],
        [337.9338, 578.8679, 352.0291, 605.5507],
        [257.7501, 570.0806, 263.9790, 587.3554],
        [416.9402, 565.1357, 424.6675, 581.8647],
        [414.1362, 563.1342, 418.3316, 577.3480],
        [117.6855, 579.1675, 123.4114, 587.7407],
        [447.9991, 563.0807, 453.9605, 565.4354],
        [418.7383, 562.1495, 421.8528, 563.2841],
        [391.3718, 552.5916, 393.7585, 553.5442],
        [205.6286, 548.7064, 207.6514, 549.7981],
        [245.2923, 271.4205, 314.1955, 299.5376],
        [317.7488, 505.3695, 342.3433, 512.9794],
        [206.2601, 494.6021, 250.1085, 501.3022],
        [186.3211, 417.1329, 241.2361, 437.4260],
        [246.1593, 124.1991, 293.2934, 151.0532],
        [179.6535, 549.4449, 192.9996, 554.9677],
        [360.9872, 584.4656, 378.3896, 593.0815],
        [380.5087, 587.0771, 411.8672, 607.1776],
        [361.6187, 306.2699, 398.8957, 320.6335],
        [323.1215,   2.6009, 382.6599,  35.2668],
        [309.7754, 262.2480, 390.6119, 287.1113],
        [197.9548, 479.7141, 220.4517, 489.7215],
        [137.5174, 424.0899, 145.9082, 428.2749],
        [213.0134, 516.3187, 226.4558, 530.8000],
        [ 94.1613, 531.9239, 113.5972, 540.1439],
        [ 54.9042, 382.7759,  64.8576, 389.1656],
        [194.9902, 483.1177, 209.5992, 487.8806],
        [148.9157, 494.7520, 157.5312, 502.0087],
        [368.0402, 567.3834, 376.0457, 577.1768],
        [175.4045, 492.0441, 189.1145, 497.0103],
        [ 91.1859, 483.8134, 102.3380, 489.9142],
        [ 95.1673, 594.7834, 106.3515, 597.3414],
        [253.2122, 544.2218, 258.1783, 550.6972],
        [  0.0000, 206.2171,  22.0259, 218.5578],
        [264.0754, 623.9814, 304.5418, 627.3530],
        [198.2438, 497.8130, 238.5604, 514.4885],
        [149.0976, 133.1041, 176.0467, 148.8055],
        [369.0676, 447.3264, 384.9824, 456.0923],
        [328.8045, 419.9478, 375.5534, 438.5391],
        [ 94.4502, 503.1860, 106.6298, 513.5681],
        [170.4813, 368.1019, 179.3431, 372.7149],
        [101.8136, 488.0625, 116.6367, 494.7627],
        [100.5293, 516.0084, 112.0667, 526.0157],
        [158.8690, 259.8612, 192.3360, 271.3884],
        [277.5178, 498.7335, 317.7595, 518.3738],
        [117.0434, 541.8885, 124.8134, 548.6101],
        [232.1710, 120.0248, 268.0139, 145.6481],
        [ 59.3244, 225.1188, 115.6841, 262.5049],
        [109.0485, 517.3035, 129.4262, 529.2589],
        [221.9714, 566.5271, 232.6526, 572.4138],
        [219.7667, 358.7152, 263.5616, 383.2147],
        [ 59.1424, 425.1174, 105.1207, 451.6826]])), gt_classes: tensor([ 27,  27,  27,  27,  27,  24,  24,  24,  24, 462, 280, 280, 280, 280,
        280, 280, 280, 280, 280, 280, 280, 725, 725, 725, 725, 431, 431, 431,
        431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431,
        431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431,
        431, 431, 431, 431, 431, 431, 431, 431, 431, 431, 431])])}], 'support_set_target': tensor(24)}
0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000351770.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [540, 170, 522, 570, 799, 94], 'image_id': 351770, 'image': tensor([[[137., 135., 134.,  ..., 127., 126., 126.],
         [127., 126., 125.,  ..., 127., 126., 126.],
         [106., 105., 104.,  ..., 126., 127., 127.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[123., 124., 125.,  ..., 154., 153., 153.],
         [119., 120., 121.,  ..., 154., 153., 153.],
         [111., 112., 113.,  ..., 154., 154., 154.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[144., 145., 146.,  ..., 188., 187., 187.],
         [140., 141., 141.,  ..., 188., 187., 187.],
         [130., 131., 130.,  ..., 189., 188., 188.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[119.7848,   0.0000, 837.2713, 477.8828]])), gt_classes: tensor([843])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000527535.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [782, 758, 300, 1025, 1001, 240, 286, 1105, 264, 990, 379, 242, 821, 842, 705, 186, 1020], 'image_id': 527535, 'image': tensor([[[136., 139., 141.,  ..., 172., 172., 170.],
         [137., 140., 141.,  ..., 172., 173., 170.],
         [140., 142., 144.,  ..., 172., 173., 172.],
         ...,
         [ 93.,  93.,  93.,  ...,  15.,  15.,  15.],
         [ 93.,  95.,  90.,  ...,  18.,  18.,  18.],
         [106., 106., 104.,  ...,  20.,  20.,  18.]],

        [[128., 129., 130.,  ..., 123., 124., 121.],
         [128., 129., 130.,  ..., 121., 122., 120.],
         [129., 130., 130.,  ..., 118., 118., 119.],
         ...,
         [130., 129., 130.,  ...,  16.,  16.,  16.],
         [132., 131., 132.,  ...,  18.,  18.,  18.],
         [135., 134., 134.,  ...,  18.,  18.,  18.]],

        [[143., 144., 146.,  ...,  52.,  52.,  51.],
         [143., 144., 146.,  ...,  52.,  52.,  51.],
         [143., 144., 144.,  ...,  51.,  51.,  50.],
         ...,
         [ 69.,  68.,  68.,  ...,  22.,  22.,  22.],
         [ 71.,  70.,  70.,  ...,  24.,  23.,  23.],
         [ 74.,  72.,  70.,  ...,  26.,  26.,  26.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[321.2468, 451.3692, 575.2785, 684.9221]])), gt_classes: tensor([843])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000321079.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [753], 'neg_category_ids': [498, 1185, 584, 1027, 237, 1171, 459, 1104, 86, 268, 1198, 1015, 67, 962], 'image_id': 321079, 'image': tensor([[[149., 151., 152.,  ..., 196., 194., 190.],
         [149., 151., 152.,  ..., 193., 192., 188.],
         [148., 150., 152.,  ..., 189., 188., 185.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[164., 165., 166.,  ..., 194., 193., 189.],
         [164., 165., 166.,  ..., 192., 191., 188.],
         [163., 164., 165.,  ..., 189., 188., 186.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[190., 189., 189.,  ..., 192., 193., 191.],
         [190., 189., 189.,  ..., 191., 192., 190.],
         [189., 188., 188.,  ..., 188., 189., 189.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[627.8152,   0.0000, 934.4536, 169.9830]])), gt_classes: tensor([843])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000438905.jpg', 'height': 443, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [557, 389, 541, 634, 79, 1052, 970, 1192, 225, 991, 1036, 38, 136, 576, 554, 252, 166], 'image_id': 438905, 'image': tensor([[[220., 220., 220.,  ..., 220., 220., 220.],
         [220., 220., 220.,  ..., 220., 220., 220.],
         [220., 220., 220.,  ..., 220., 220., 220.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[218., 218., 218.,  ..., 218., 218., 218.],
         [218., 218., 218.,  ..., 218., 218., 218.],
         [218., 218., 218.,  ..., 218., 218., 218.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[217., 217., 217.,  ..., 217., 217., 217.],
         [217., 217., 217.,  ..., 217., 217., 217.],
         [217., 217., 217.,  ..., 217., 217., 217.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[750.2972, 133.5787, 861.2410, 281.1580]])), gt_classes: tensor([843])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000438905.jpg', 'height': 443, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [557, 389, 541, 634, 79, 1052, 970, 1192, 225, 991, 1036, 38, 136, 576, 554, 252, 166], 'image_id': 438905, 'image': tensor([[[220., 220., 220.,  ..., 220., 220., 220.],
         [220., 220., 220.,  ..., 220., 220., 220.],
         [220., 220., 220.,  ..., 220., 220., 220.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[218., 218., 218.,  ..., 218., 218., 218.],
         [218., 218., 218.,  ..., 218., 218., 218.],
         [218., 218., 218.,  ..., 218., 218., 218.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[217., 217., 217.,  ..., 217., 217., 217.],
         [217., 217., 217.,  ..., 217., 217., 217.],
         [217., 217., 217.,  ..., 217., 217., 217.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[750.2972, 133.5787, 861.2410, 281.1580]])), gt_classes: tensor([843])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000092799.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1185, 415, 201, 57, 972, 109, 250], 'image_id': 92799, 'annotations_cat_set': {1180, 469}, 'image': tensor([[[10., 10., 10.,  ..., 30., 30., 30.],
         [10., 10., 10.,  ..., 30., 30., 30.],
         [10., 10., 10.,  ..., 30., 30., 30.],
         ...,
         [30., 30., 30.,  ..., 30., 30., 30.],
         [30., 30., 30.,  ..., 30., 30., 30.],
         [30., 30., 30.,  ..., 30., 30., 30.]],

        [[ 6.,  6.,  6.,  ..., 30., 30., 30.],
         [ 6.,  6.,  6.,  ..., 30., 30., 30.],
         [ 6.,  6.,  6.,  ..., 30., 30., 30.],
         ...,
         [32., 32., 32.,  ..., 30., 30., 30.],
         [32., 32., 32.,  ..., 30., 30., 30.],
         [32., 32., 30.,  ..., 30., 30., 30.]],

        [[25., 25., 25.,  ..., 30., 30., 30.],
         [25., 25., 25.,  ..., 30., 30., 30.],
         [25., 25., 25.,  ..., 30., 30., 30.],
         ...,
         [36., 36., 36.,  ..., 30., 30., 30.],
         [34., 34., 34.,  ..., 30., 30., 30.],
         [34., 34., 34.,  ..., 30., 30., 30.]]]), 'instances': Instances(num_instances=7, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[348.6927,   0.0000, 624.1790, 424.5716],
        [434.2734, 238.4054, 499.3187, 319.5376],
        [218.0526, 290.9937, 252.1423, 306.2836],
        [237.0817, 371.3725, 260.3849, 408.3858],
        [206.1669, 492.6330, 705.8316, 668.9858],
        [ 99.7253, 563.1578, 174.5804, 599.1940],
        [145.7211, 278.4727, 174.5194, 299.5650]])), gt_classes: tensor([335, 843, 843, 843, 843, 843, 843])])}], 'support_set_target': tensor(843)}
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000038090.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [628, 626], 'neg_category_ids': [475, 688, 2, 541, 196, 812, 127, 901, 482, 486, 227, 1084, 448, 868, 1139], 'image_id': 38090, 'image': tensor([[[193., 194., 194.,  ..., 134., 134., 134.],
         [193., 194., 194.,  ..., 134., 134., 134.],
         [193., 194., 194.,  ..., 134., 133., 134.],
         ...,
         [ 72.,  52.,  27.,  ...,  85.,  91.,  96.],
         [ 76.,  57.,  37.,  ...,  76.,  79.,  85.],
         [ 79.,  63.,  46.,  ...,  66.,  69.,  75.]],

        [[198., 199., 199.,  ..., 140., 140., 140.],
         [198., 199., 199.,  ..., 140., 140., 140.],
         [198., 199., 199.,  ..., 140., 139., 140.],
         ...,
         [ 80.,  59.,  33.,  ...,  92.,  98., 103.],
         [ 84.,  64.,  43.,  ...,  82.,  85.,  92.],
         [ 86.,  69.,  52.,  ...,  72.,  75.,  81.]],

        [[201., 202., 202.,  ..., 144., 144., 144.],
         [201., 202., 202.,  ..., 144., 144., 144.],
         [201., 202., 202.,  ..., 144., 143., 144.],
         ...,
         [ 81.,  62.,  37.,  ..., 101., 107., 111.],
         [ 86.,  68.,  48.,  ...,  91.,  95., 100.],
         [ 90.,  73.,  57.,  ...,  81.,  84.,  90.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 641.1057,  819.5187, 1024.0000, 1024.0000]])), gt_classes: tensor([334])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000198762.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [312], 'neg_category_ids': [323, 326, 415, 225, 1133, 820, 277], 'image_id': 198762, 'image': tensor([[[164., 164., 164.,  ...,  15.,  18.,  22.],
         [164., 164., 164.,  ...,  16.,  19.,  23.],
         [165., 164., 163.,  ...,  19.,  22.,  24.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[145., 145., 146.,  ..., 208., 205., 201.],
         [145., 145., 145.,  ..., 207., 204., 201.],
         [145., 144., 144.,  ..., 204., 202., 200.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[127., 127., 127.,  ..., 185., 182., 178.],
         [127., 127., 127.,  ..., 184., 181., 178.],
         [127., 126., 126.,  ..., 181., 179., 177.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 739.9712, 403.9098, 992.5242]])), gt_classes: tensor([334])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000337902.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [430, 1169, 586, 670, 1102, 616, 272, 661], 'image_id': 337902, 'image': tensor([[[107., 106., 103.,  ..., 128., 128., 128.],
         [108., 106., 105.,  ..., 128., 128., 128.],
         [110., 108., 111.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[132., 135., 134.,  ..., 128., 128., 128.],
         [133., 134., 135.,  ..., 128., 128., 128.],
         [134., 135., 138.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[154., 157., 156.,  ..., 128., 128., 128.],
         [153., 155., 156.,  ..., 128., 128., 128.],
         [154., 156., 159.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 23.5391, 209.3691, 134.6928, 284.6232]])), gt_classes: tensor([334])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000469317.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [558, 1143, 788, 1053, 597, 620, 448, 849], 'image_id': 469317, 'image': tensor([[[195., 193., 187.,  ..., 128., 128., 128.],
         [194., 193., 185.,  ..., 128., 128., 128.],
         [200., 192., 189.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[195., 192., 186.,  ..., 128., 128., 128.],
         [193., 192., 183.,  ..., 128., 128., 128.],
         [199., 190., 187.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[165., 166., 162.,  ..., 128., 128., 128.],
         [166., 167., 160.,  ..., 128., 128., 128.],
         [171., 166., 165.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[332.3369, 174.0543, 358.4214, 205.4996]])), gt_classes: tensor([334])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000546569.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [350], 'neg_category_ids': [733, 943, 736, 282, 610, 970, 1030, 663, 700, 771, 44, 138, 272, 161, 751, 363, 253], 'image_id': 546569, 'image': tensor([[[ 60.,  52.,  43.,  ..., 141., 143., 141.],
         [ 60.,  52.,  43.,  ..., 141., 144., 144.],
         [ 66.,  60.,  48.,  ..., 136., 138., 136.],
         ...,
         [ 19.,  19.,  19.,  ..., 161., 159., 161.],
         [ 25.,  25.,  24.,  ..., 169., 167., 169.],
         [ 25.,  24.,  21.,  ..., 177., 177., 177.]],

        [[ 59.,  59.,  59.,  ..., 118., 118., 125.],
         [ 53.,  53.,  53.,  ..., 116., 118., 125.],
         [ 59.,  59.,  62.,  ..., 118., 121., 125.],
         ...,
         [ 38.,  38.,  38.,  ..., 159., 160., 160.],
         [ 50.,  47.,  45.,  ..., 163., 162., 163.],
         [ 50.,  45.,  39.,  ..., 160., 159., 159.]],

        [[ 97.,  97.,  92.,  ..., 146., 148., 150.],
         [ 95.,  92.,  89.,  ..., 146., 150., 154.],
         [100., 100.,  97.,  ..., 150., 152., 154.],
         ...,
         [ 71.,  73.,  76.,  ...,  38.,  38.,  41.],
         [ 85.,  89.,  92.,  ...,  38.,  38.,  41.],
         [ 85.,  89.,  82.,  ...,  37.,  37.,  38.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 108.1019,  861.3163,  331.3867, 1024.0000]])), gt_classes: tensor([334])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000212420.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [602, 371, 327, 177, 241, 37, 573, 248], 'image_id': 212420, 'annotations_cat_set': {804, 968, 299, 143, 19, 468, 1077}, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=11, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 949.9973,  592.2458, 1024.0000,  650.7941],
        [ 511.8148,  485.6294,  629.5276,  597.7654],
        [ 967.1179,  575.3730, 1024.0000,  619.5637],
        [ 875.8896,  445.8403, 1024.0000,  548.9984],
        [ 257.0323,  657.6411,  610.9745, 1024.0000],
        [   0.0000,  888.1312,  105.0084, 1024.0000],
        [   0.0000,  444.4779,   43.0248,  514.4843],
        [ 554.4066,  312.7792, 1024.0000,  808.2037],
        [   0.0000,  884.0789,  102.1782, 1024.0000],
        [   0.0000,  808.2386,   50.1177, 1024.0000],
        [ 191.7993,  793.7762,  303.3977,  935.2912]])), gt_classes: tensor([219, 219, 219, 109, 681, 334, 334,  15,  15, 569, 569])])}], 'support_set_target': tensor(334)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000538640.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [96], 'neg_category_ids': [628, 73, 562, 634, 699, 398, 907, 677, 357, 1015, 623, 45], 'image_id': 538640, 'annotations': [{'bbox': [194.66, 90.26, 19.55, 29.95], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 74}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000538640.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [96], 'neg_category_ids': [628, 73, 562, 634, 699, 398, 907, 677, 357, 1015, 623, 45], 'image_id': 538640, 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[297.4648, 138.0226, 327.3397, 183.8211]])), gt_classes: tensor([74])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000363902.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [59], 'neg_category_ids': [876, 1146, 967, 55, 396, 1128, 110, 1152, 310, 34, 38, 956, 841, 1040, 186, 875], 'image_id': 363902, 'annotations': [{'bbox': [59.51, 101.65, 116.07, 56.92], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 74}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000363902.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [59], 'neg_category_ids': [876, 1146, 967, 55, 396, 1128, 110, 1152, 310, 34, 38, 956, 841, 1040, 186, 875], 'image_id': 363902, 'image': tensor([[[ 23.,  17.,   8.,  ..., 134., 134., 134.],
         [ 21.,  16.,  10.,  ..., 134., 134., 134.],
         [ 19.,  17.,  12.,  ..., 134., 134., 134.],
         ...,
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.]],

        [[  7.,   3.,   0.,  ..., 134., 134., 134.],
         [  7.,   5.,   3.,  ..., 134., 134., 134.],
         [  8.,  10.,  10.,  ..., 134., 134., 134.],
         ...,
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.]],

        [[  0.,   0.,   0.,  ..., 134., 134., 134.],
         [  0.,   0.,   0.,  ..., 134., 134., 134.],
         [  0.,   0.,   0.,  ..., 134., 134., 134.],
         ...,
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 82.7561, 141.3125, 244.1659, 220.4420]])), gt_classes: tensor([74])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000250243.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [805, 1122, 233, 485, 569, 660, 728, 1182], 'image_id': 250243, 'annotations': [{'bbox': [447.51, 21.64, 133.07, 374.05], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 74}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000250243.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [805, 1122, 233, 485, 569, 660, 728, 1182], 'image_id': 250243, 'image': tensor([[[122., 121., 120.,  ..., 142., 130., 119.],
         [121., 120., 119.,  ..., 142., 130., 120.],
         [117., 117., 117.,  ..., 141., 132., 124.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[111., 110., 109.,  ..., 159., 154., 148.],
         [110., 109., 109.,  ..., 159., 154., 148.],
         [108., 107., 107.,  ..., 160., 155., 150.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[107., 106., 105.,  ..., 138., 131., 218.],
         [106., 105., 105.,  ..., 138., 131., 219.],
         [105., 104., 104.,  ..., 136., 132., 221.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[622.6638,  50.1563, 931.2199, 917.1133]])), gt_classes: tensor([74])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000295340.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [173], 'neg_category_ids': [920, 1070, 1166, 259, 984, 986, 987, 860, 619, 140, 69, 938, 514], 'image_id': 295340, 'annotations': [{'bbox': [0.0, 80.15, 43.03, 51.45], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 74}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000295340.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [173], 'neg_category_ids': [920, 1070, 1166, 259, 984, 986, 987, 860, 619, 140, 69, 938, 514], 'image_id': 295340, 'image': tensor([[[160.,  94.,  28.,  ...,  55.,  54.,  52.],
         [160.,  95.,  29.,  ...,  55.,  54.,  53.],
         [161.,  96.,  32.,  ...,  54.,  55.,  55.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 96.,  55.,  14.,  ...,  44.,  41.,  38.],
         [ 96.,  55.,  14.,  ...,  42.,  40.,  38.],
         [ 95.,  55.,  16.,  ...,  37.,  37.,  37.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 42.,  31.,  19.,  ...,  36.,  33.,  29.],
         [ 40.,  30.,  19.,  ...,  35.,  33.,  30.],
         [ 36.,  27.,  17.,  ...,  31.,  31.,  32.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 926.9050,  182.6369, 1024.0000,  299.8754]])), gt_classes: tensor([74])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000191651.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [96], 'neg_category_ids': [150, 105, 790, 929, 1152, 490, 338, 872], 'image_id': 191651, 'annotations': [{'bbox': [266.38, 190.82, 24.4, 14.65], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 74}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000191651.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [96], 'neg_category_ids': [150, 105, 790, 929, 1152, 490, 338, 872], 'image_id': 191651, 'image': tensor([[[247., 243., 247.,  ..., 241., 241., 242.],
         [245., 243., 246.,  ..., 241., 242., 243.],
         [242., 242., 245.,  ..., 242., 243., 244.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[220., 215., 218.,  ..., 194., 194., 195.],
         [219., 215., 218.,  ..., 194., 195., 196.],
         [218., 216., 218.,  ..., 195., 196., 197.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]],

        [[216., 211., 214.,  ..., 177., 177., 178.],
         [216., 212., 215.,  ..., 177., 178., 179.],
         [215., 213., 216.,  ..., 178., 179., 180.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[350.5978, 378.8572, 399.0166, 407.9436]])), gt_classes: tensor([74])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000369126.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [629, 453, 654, 1130, 569, 510, 446, 1117], 'image_id': 369126, 'annotations': [{'bbox': [70.3, 211.49, 39.95, 72.69], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 580}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000369126.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [629, 453, 654, 1130, 569, 510, 446, 1117], 'image_id': 369126, 'image': tensor([[[ 62.,  62.,  62.,  ..., 141., 139., 138.],
         [ 63.,  62.,  62.,  ..., 141., 142., 141.],
         [ 63.,  63.,  63.,  ..., 143., 145., 144.],
         ...,
         [224., 223., 222.,  ..., 214., 214., 216.],
         [224., 224., 223.,  ..., 214., 215., 217.],
         [223., 223., 223.,  ..., 213., 215., 218.]],

        [[ 50.,  50.,  50.,  ..., 138., 135., 134.],
         [ 50.,  50.,  50.,  ..., 141., 138., 136.],
         [ 50.,  50.,  50.,  ..., 142., 140., 138.],
         ...,
         [217., 216., 215.,  ..., 210., 210., 212.],
         [218., 217., 216.,  ..., 210., 211., 213.],
         [217., 217., 216.,  ..., 209., 211., 214.]],

        [[ 52.,  52.,  52.,  ..., 133., 130., 128.],
         [ 52.,  52.,  52.,  ..., 133., 130., 128.],
         [ 52.,  52.,  52.,  ..., 133., 130., 127.],
         ...,
         [220., 219., 218.,  ..., 216., 217., 219.],
         [220., 219., 219.,  ..., 216., 217., 219.],
         [219., 219., 219.,  ..., 215., 217., 219.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000513993.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [658, 591], 'neg_category_ids': [300, 733, 633, 565, 328, 1033, 290, 570, 213, 577, 1181, 1018, 189], 'image_id': 513993, 'annotations': [{'bbox': [573.3, 133.89, 20.49, 24.57], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 580}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000513993.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [658, 591], 'neg_category_ids': [300, 733, 633, 565, 328, 1033, 290, 570, 213, 577, 1181, 1018, 189], 'image_id': 513993, 'image': tensor([[[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0., 128.,  ...,   0.,   0.,   0.],
         [  0., 128., 128.,  ...,   0.,   0.,   0.],
         [  0., 128., 128.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000103027.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [898, 97], 'neg_category_ids': [966, 983, 813, 459, 697, 950, 83, 659, 1159, 726, 43], 'image_id': 103027, 'annotations': [{'bbox': [445.75, 407.61, 59.22, 16.75], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 580}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000103027.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [898, 97], 'neg_category_ids': [966, 983, 813, 459, 697, 950, 83, 659, 1159, 726, 43], 'image_id': 103027, 'image': tensor([[[107., 111., 116.,  ...,  88., 102.,  93.],
         [102., 102., 107.,  ..., 107., 116., 107.],
         [102., 107., 111.,  ...,  93.,  97.,  93.],
         ...,
         [ 27., 138., 189.,  ...,  27.,  45.,  21.],
         [ 53., 138., 188.,  ...,  12.,  21.,  16.],
         [ 67., 144., 187.,  ...,   6.,   6.,  12.]],

        [[127., 132., 137.,  ..., 117., 122., 122.],
         [125., 127., 129.,  ..., 123., 127., 127.],
         [125., 129., 134.,  ..., 118., 118., 120.],
         ...,
         [110., 139., 182.,  ..., 109., 110., 107.],
         [116., 148., 184.,  ..., 104., 104., 104.],
         [125., 160., 186.,  ...,  94.,  94., 102.]],

        [[122., 124., 126.,  ..., 117., 118., 118.],
         [121., 122., 123.,  ..., 120., 120., 120.],
         [121., 123., 125.,  ..., 118., 118., 118.],
         ...,
         [131., 156., 179.,  ..., 124., 124., 121.],
         [139., 163., 181.,  ..., 121., 120., 120.],
         [148., 168., 182.,  ..., 118., 118., 119.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 904.4055,  84.0340, 947.1180]])), gt_classes: tensor([580])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000246609.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [48, 541, 217, 1102, 337, 772, 1116, 167], 'image_id': 246609, 'annotations': [{'bbox': [436.63, 341.23, 17.97, 7.71], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 580}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000246609.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [48, 541, 217, 1102, 337, 772, 1116, 167], 'image_id': 246609, 'image': tensor([[[131., 131., 131.,  ..., 127., 127., 127.],
         [132., 132., 133.,  ..., 127., 127., 127.],
         [132., 132., 133.,  ..., 127., 127., 127.],
         ...,
         [192., 193., 193.,  ..., 127., 127., 127.],
         [190., 191., 194.,  ..., 127., 127., 127.],
         [182., 186., 193.,  ..., 127., 127., 127.]],

        [[ 87.,  87.,  87.,  ..., 127., 127., 127.],
         [ 86.,  86.,  86.,  ..., 127., 127., 127.],
         [ 87.,  87.,  86.,  ..., 127., 127., 127.],
         ...,
         [185., 181., 175.,  ..., 127., 127., 127.],
         [185., 181., 176.,  ..., 127., 127., 127.],
         [177., 177., 177.,  ..., 127., 127., 127.]],

        [[ 69.,  68.,  67.,  ..., 127., 127., 127.],
         [ 68.,  67.,  65.,  ..., 127., 127., 127.],
         [ 68.,  67.,  65.,  ..., 127., 127., 127.],
         ...,
         [185., 184., 181.,  ..., 127., 127., 127.],
         [183., 182., 180.,  ..., 127., 127., 127.],
         [174., 176., 179.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[808.6752, 480.8087, 841.9571, 495.0842]])), gt_classes: tensor([580])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000120388.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [174, 479, 27, 55, 200, 566, 951, 60, 657, 975, 361, 915, 94, 826, 46], 'image_id': 120388, 'annotations': [{'bbox': [218.69, 202.9, 82.69, 114.74], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 580}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000120388.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [174, 479, 27, 55, 200, 566, 951, 60, 657, 975, 361, 915, 94, 826, 46], 'image_id': 120388, 'image': tensor([[[220., 221., 222.,  ..., 213., 228., 244.],
         [229., 229., 230.,  ..., 208., 223., 241.],
         [239., 239., 239.,  ..., 214., 226., 241.],
         ...,
         [237., 239., 242.,  ...,   2., 247., 241.],
         [235., 237., 240.,  ..., 252., 246., 240.],
         [239., 241., 243.,  ..., 252., 246., 241.]],

        [[135., 132., 130.,  ..., 171., 180., 187.],
         [147., 142., 138.,  ..., 160., 171., 183.],
         [186., 175., 163.,  ..., 166., 176., 187.],
         ...,
         [143., 157., 172.,  ..., 213., 178., 136.],
         [145., 148., 153.,  ..., 214., 182., 147.],
         [160., 156., 153.,  ..., 217., 188., 156.]],

        [[121., 114., 109.,  ..., 174., 190., 207.],
         [131., 117., 104.,  ..., 167., 181., 200.],
         [178., 162., 146.,  ..., 175., 191., 209.],
         ...,
         [188., 195., 204.,  ..., 251., 228., 202.],
         [186., 186., 187.,  ..., 250., 229., 205.],
         [199., 193., 189.,  ..., 250., 233., 213.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[290.3010, 325.7766, 502.5818, 620.2759]])), gt_classes: tensor([580])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000538640.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [96], 'neg_category_ids': [628, 73, 562, 634, 699, 398, 907, 677, 357, 1015, 623, 45], 'image_id': 538640, 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[297.4648, 138.0226, 327.3397, 183.8211]])), gt_classes: tensor([74])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000363902.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [59], 'neg_category_ids': [876, 1146, 967, 55, 396, 1128, 110, 1152, 310, 34, 38, 956, 841, 1040, 186, 875], 'image_id': 363902, 'image': tensor([[[ 23.,  17.,   8.,  ..., 134., 134., 134.],
         [ 21.,  16.,  10.,  ..., 134., 134., 134.],
         [ 19.,  17.,  12.,  ..., 134., 134., 134.],
         ...,
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.]],

        [[  7.,   3.,   0.,  ..., 134., 134., 134.],
         [  7.,   5.,   3.,  ..., 134., 134., 134.],
         [  8.,  10.,  10.,  ..., 134., 134., 134.],
         ...,
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.]],

        [[  0.,   0.,   0.,  ..., 134., 134., 134.],
         [  0.,   0.,   0.,  ..., 134., 134., 134.],
         [  0.,   0.,   0.,  ..., 134., 134., 134.],
         ...,
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.],
         [134., 134., 134.,  ..., 134., 134., 134.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 82.7561, 141.3125, 244.1659, 220.4420]])), gt_classes: tensor([74])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000250243.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [805, 1122, 233, 485, 569, 660, 728, 1182], 'image_id': 250243, 'image': tensor([[[122., 121., 120.,  ..., 142., 130., 119.],
         [121., 120., 119.,  ..., 142., 130., 120.],
         [117., 117., 117.,  ..., 141., 132., 124.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[111., 110., 109.,  ..., 159., 154., 148.],
         [110., 109., 109.,  ..., 159., 154., 148.],
         [108., 107., 107.,  ..., 160., 155., 150.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[107., 106., 105.,  ..., 138., 131., 218.],
         [106., 105., 105.,  ..., 138., 131., 219.],
         [105., 104., 104.,  ..., 136., 132., 221.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[622.6638,  50.1563, 931.2199, 917.1133]])), gt_classes: tensor([74])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000295340.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [173], 'neg_category_ids': [920, 1070, 1166, 259, 984, 986, 987, 860, 619, 140, 69, 938, 514], 'image_id': 295340, 'image': tensor([[[160.,  94.,  28.,  ...,  55.,  54.,  52.],
         [160.,  95.,  29.,  ...,  55.,  54.,  53.],
         [161.,  96.,  32.,  ...,  54.,  55.,  55.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 96.,  55.,  14.,  ...,  44.,  41.,  38.],
         [ 96.,  55.,  14.,  ...,  42.,  40.,  38.],
         [ 95.,  55.,  16.,  ...,  37.,  37.,  37.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 42.,  31.,  19.,  ...,  36.,  33.,  29.],
         [ 40.,  30.,  19.,  ...,  35.,  33.,  30.],
         [ 36.,  27.,  17.,  ...,  31.,  31.,  32.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 926.9050,  182.6369, 1024.0000,  299.8754]])), gt_classes: tensor([74])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000191651.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [96], 'neg_category_ids': [150, 105, 790, 929, 1152, 490, 338, 872], 'image_id': 191651, 'image': tensor([[[247., 243., 247.,  ..., 241., 241., 242.],
         [245., 243., 246.,  ..., 241., 242., 243.],
         [242., 242., 245.,  ..., 242., 243., 244.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[220., 215., 218.,  ..., 194., 194., 195.],
         [219., 215., 218.,  ..., 194., 195., 196.],
         [218., 216., 218.,  ..., 195., 196., 197.],
         ...,
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.],
         [125., 125., 125.,  ..., 125., 125., 125.]],

        [[216., 211., 214.,  ..., 177., 177., 178.],
         [216., 212., 215.,  ..., 177., 178., 179.],
         [215., 213., 216.,  ..., 178., 179., 180.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[350.5978, 378.8572, 399.0166, 407.9436]])), gt_classes: tensor([74])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000538687.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [96], 'neg_category_ids': [1169, 858, 505, 747, 912, 66, 708, 46], 'image_id': 538687, 'annotations_cat_set': {96, 80, 556}, 'image': tensor([[[154., 154., 155.,  ..., 141., 141., 141.],
         [156., 156., 157.,  ..., 141., 141., 140.],
         [157., 157., 158.,  ..., 141., 141., 140.],
         ...,
         [ 56.,  54.,  53.,  ...,  48.,  49.,  50.],
         [ 53.,  51.,  50.,  ...,  45.,  47.,  48.],
         [ 51.,  49.,  48.,  ...,  42.,  44.,  46.]],

        [[144., 144., 145.,  ..., 131., 131., 131.],
         [146., 146., 147.,  ..., 131., 131., 130.],
         [147., 147., 148.,  ..., 131., 131., 130.],
         ...,
         [ 65.,  62.,  60.,  ...,  52.,  53.,  55.],
         [ 63.,  60.,  58.,  ...,  48.,  50.,  52.],
         [ 62.,  59.,  57.,  ...,  45.,  47.,  49.]],

        [[127., 127., 127.,  ..., 113., 113., 113.],
         [128., 128., 129.,  ..., 113., 113., 112.],
         [129., 129., 130.,  ..., 113., 113., 112.],
         ...,
         [ 63.,  61.,  59.,  ...,  50.,  51.,  53.],
         [ 61.,  59.,  57.,  ...,  46.,  48.,  50.],
         [ 60.,  58.,  56.,  ...,  43.,  45.,  47.]]]), 'instances': Instances(num_instances=4, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[517.5544,  92.2608, 662.1999, 158.9274],
        [465.6760,  12.8814, 572.0223,  68.8837],
        [239.6147, 170.3146, 381.5504, 245.2054],
        [  0.0000, 181.0693, 417.8322, 586.9433]])), gt_classes: tensor([74, 74, 74, 61])])}], 'support_set_target': tensor(74)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000010358.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [], 'neg_category_ids': [980, 200, 1152, 379, 1035, 1137], 'image_id': 10358, 'annotations': [{'bbox': [29.42, 154.62, 170.53, 119.12], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 191}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000010358.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [], 'neg_category_ids': [980, 200, 1152, 379, 1035, 1137], 'image_id': 10358, 'image': tensor([[[122.,  88.,  40.,  ..., 128., 128., 128.],
         [124.,  47.,  79.,  ..., 128., 128., 128.],
         [130.,  69., 108.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 76.,  70.,  54.,  ..., 128., 128., 128.],
         [105.,  67., 109.,  ..., 128., 128., 128.],
         [111.,  68., 101.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 76.,  99.,  81.,  ..., 128., 128., 128.],
         [ 89.,  83., 139.,  ..., 128., 128., 128.],
         [ 81.,  66., 122.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[261.1808, 145.1978, 421.3649, 257.0590]])), gt_classes: tensor([191])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000393607.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1166, 1127, 742, 951, 296, 35, 338, 708], 'image_id': 393607, 'annotations': [{'bbox': [12.09, 298.93, 59.25, 99.12], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 191}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000393607.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1166, 1127, 742, 951, 296, 35, 338, 708], 'image_id': 393607, 'image': tensor([[[17., 17., 16.,  ..., 16., 15., 14.],
         [17., 17., 16.,  ..., 15., 14., 13.],
         [17., 17., 17.,  ..., 16., 16., 15.],
         ...,
         [54., 56., 58.,  ..., 21., 21., 20.],
         [51., 53., 55.,  ..., 20., 19., 18.],
         [51., 51., 51.,  ..., 20., 19., 17.]],

        [[ 4.,  4.,  3.,  ..., 10.,  9.,  8.],
         [ 4.,  4.,  3.,  ...,  9.,  8.,  7.],
         [ 4.,  4.,  4.,  ..., 10.,  9.,  8.],
         ...,
         [65., 63., 61.,  ..., 17., 17., 18.],
         [62., 61., 59.,  ..., 16., 16., 16.],
         [60., 58., 54.,  ..., 17., 17., 16.]],

        [[ 2.,  2.,  1.,  ...,  7.,  6.,  5.],
         [ 2.,  2.,  1.,  ...,  6.,  5.,  4.],
         [ 2.,  2.,  2.,  ...,  7.,  6.,  5.],
         ...,
         [62., 60., 58.,  ..., 12., 13., 14.],
         [60., 59., 57.,  ..., 11., 11., 12.],
         [60., 58., 55.,  ..., 12., 11., 12.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000332038.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1044, 1185, 1168, 260, 417, 306, 566, 989, 866], 'image_id': 332038, 'annotations': [{'bbox': [269.24, 185.44, 18.95, 32.36], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 191}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000332038.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1044, 1185, 1168, 260, 417, 306, 566, 989, 866], 'image_id': 332038, 'image': tensor([[[  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         ...,
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.]],

        [[  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         ...,
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.]],

        [[  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         ...,
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[409.5288, 215.9603, 431.5878, 253.6463]])), gt_classes: tensor([191])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000574964.jpg', 'height': 479, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [943, 1026, 416, 327, 1153, 357, 750, 959, 474], 'image_id': 574964, 'annotations': [{'bbox': [579.01, 254.74, 27.91, 48.17], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 191}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000574964.jpg', 'height': 479, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [943, 1026, 416, 327, 1153, 357, 750, 959, 474], 'image_id': 574964, 'image': tensor([[[254., 254., 251.,  ..., 248., 248., 249.],
         [251., 253., 250.,  ..., 249., 249., 249.],
         [249., 254., 250.,  ..., 249., 249., 249.],
         ...,
         [212., 213., 214.,  ..., 177., 178., 179.],
         [212., 211., 213.,  ..., 177., 178., 179.],
         [214., 214., 214.,  ..., 177., 178., 179.]],

        [[251., 253., 253.,  ..., 196., 196., 197.],
         [247., 255., 252.,  ..., 197., 197., 197.],
         [243., 255., 252.,  ..., 198., 197., 197.],
         ...,
         [221., 222., 223.,  ..., 169., 169., 169.],
         [221., 220., 222.,  ..., 171., 170., 170.],
         [223., 223., 223.,  ..., 172., 171., 170.]],

        [[249., 252., 252.,  ..., 155., 156., 156.],
         [245., 251., 251.,  ..., 156., 157., 156.],
         [241., 253., 250.,  ..., 157., 157., 156.],
         ...,
         [225., 226., 227.,  ..., 166., 164., 160.],
         [225., 224., 225.,  ..., 168., 165., 161.],
         [227., 227., 228.,  ..., 169., 166., 162.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000089154.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [861, 794, 746, 64, 725, 316, 936, 917], 'image_id': 89154, 'annotations': [{'bbox': [280.46, 62.75, 28.82, 18.88], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 191}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000089154.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [861, 794, 746, 64, 725, 316, 936, 917], 'image_id': 89154, 'image': tensor([[[126., 129., 130.,  ..., 151., 151., 151.],
         [125., 128., 129.,  ..., 151., 151., 151.],
         [123., 122., 122.,  ..., 151., 151., 151.],
         ...,
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.]],

        [[114., 114., 114.,  ..., 148., 148., 148.],
         [118., 116., 116.,  ..., 148., 148., 148.],
         [129., 126., 126.,  ..., 148., 148., 148.],
         ...,
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.]],

        [[106., 106., 106.,  ..., 137., 137., 137.],
         [110., 108., 108.,  ..., 137., 137., 137.],
         [120., 118., 118.,  ..., 137., 137., 137.],
         ...,
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[587.1315, 143.4047, 653.0141, 186.5518]])), gt_classes: tensor([191])])}, len instances: 1
not 0
entering support set: 2
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000103027.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [898, 97], 'neg_category_ids': [966, 983, 813, 459, 697, 950, 83, 659, 1159, 726, 43], 'image_id': 103027, 'image': tensor([[[107., 111., 116.,  ...,  88., 102.,  93.],
         [102., 102., 107.,  ..., 107., 116., 107.],
         [102., 107., 111.,  ...,  93.,  97.,  93.],
         ...,
         [ 27., 138., 189.,  ...,  27.,  45.,  21.],
         [ 53., 138., 188.,  ...,  12.,  21.,  16.],
         [ 67., 144., 187.,  ...,   6.,   6.,  12.]],

        [[127., 132., 137.,  ..., 117., 122., 122.],
         [125., 127., 129.,  ..., 123., 127., 127.],
         [125., 129., 134.,  ..., 118., 118., 120.],
         ...,
         [110., 139., 182.,  ..., 109., 110., 107.],
         [116., 148., 184.,  ..., 104., 104., 104.],
         [125., 160., 186.,  ...,  94.,  94., 102.]],

        [[122., 124., 126.,  ..., 117., 118., 118.],
         [121., 122., 123.,  ..., 120., 120., 120.],
         [121., 123., 125.,  ..., 118., 118., 118.],
         ...,
         [131., 156., 179.,  ..., 124., 124., 121.],
         [139., 163., 181.,  ..., 121., 120., 120.],
         [148., 168., 182.,  ..., 118., 118., 119.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 904.4055,  84.0340, 947.1180]])), gt_classes: tensor([580])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000246609.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [48, 541, 217, 1102, 337, 772, 1116, 167], 'image_id': 246609, 'image': tensor([[[131., 131., 131.,  ..., 127., 127., 127.],
         [132., 132., 133.,  ..., 127., 127., 127.],
         [132., 132., 133.,  ..., 127., 127., 127.],
         ...,
         [192., 193., 193.,  ..., 127., 127., 127.],
         [190., 191., 194.,  ..., 127., 127., 127.],
         [182., 186., 193.,  ..., 127., 127., 127.]],

        [[ 87.,  87.,  87.,  ..., 127., 127., 127.],
         [ 86.,  86.,  86.,  ..., 127., 127., 127.],
         [ 87.,  87.,  86.,  ..., 127., 127., 127.],
         ...,
         [185., 181., 175.,  ..., 127., 127., 127.],
         [185., 181., 176.,  ..., 127., 127., 127.],
         [177., 177., 177.,  ..., 127., 127., 127.]],

        [[ 69.,  68.,  67.,  ..., 127., 127., 127.],
         [ 68.,  67.,  65.,  ..., 127., 127., 127.],
         [ 68.,  67.,  65.,  ..., 127., 127., 127.],
         ...,
         [185., 184., 181.,  ..., 127., 127., 127.],
         [183., 182., 180.,  ..., 127., 127., 127.],
         [174., 176., 179.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[808.6752, 480.8087, 841.9571, 495.0842]])), gt_classes: tensor([580])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000120388.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [174, 479, 27, 55, 200, 566, 951, 60, 657, 975, 361, 915, 94, 826, 46], 'image_id': 120388, 'image': tensor([[[220., 221., 222.,  ..., 213., 228., 244.],
         [229., 229., 230.,  ..., 208., 223., 241.],
         [239., 239., 239.,  ..., 214., 226., 241.],
         ...,
         [237., 239., 242.,  ...,   2., 247., 241.],
         [235., 237., 240.,  ..., 252., 246., 240.],
         [239., 241., 243.,  ..., 252., 246., 241.]],

        [[135., 132., 130.,  ..., 171., 180., 187.],
         [147., 142., 138.,  ..., 160., 171., 183.],
         [186., 175., 163.,  ..., 166., 176., 187.],
         ...,
         [143., 157., 172.,  ..., 213., 178., 136.],
         [145., 148., 153.,  ..., 214., 182., 147.],
         [160., 156., 153.,  ..., 217., 188., 156.]],

        [[121., 114., 109.,  ..., 174., 190., 207.],
         [131., 117., 104.,  ..., 167., 181., 200.],
         [178., 162., 146.,  ..., 175., 191., 209.],
         ...,
         [188., 195., 204.,  ..., 251., 228., 202.],
         [186., 186., 187.,  ..., 250., 229., 205.],
         [199., 193., 189.,  ..., 250., 233., 213.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[290.3010, 325.7766, 502.5818, 620.2759]])), gt_classes: tensor([580])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000246609.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [48, 541, 217, 1102, 337, 772, 1116, 167], 'image_id': 246609, 'image': tensor([[[131., 131., 131.,  ..., 127., 127., 127.],
         [132., 132., 133.,  ..., 127., 127., 127.],
         [132., 132., 133.,  ..., 127., 127., 127.],
         ...,
         [192., 193., 193.,  ..., 127., 127., 127.],
         [190., 191., 194.,  ..., 127., 127., 127.],
         [182., 186., 193.,  ..., 127., 127., 127.]],

        [[ 87.,  87.,  87.,  ..., 127., 127., 127.],
         [ 86.,  86.,  86.,  ..., 127., 127., 127.],
         [ 87.,  87.,  86.,  ..., 127., 127., 127.],
         ...,
         [185., 181., 175.,  ..., 127., 127., 127.],
         [185., 181., 176.,  ..., 127., 127., 127.],
         [177., 177., 177.,  ..., 127., 127., 127.]],

        [[ 69.,  68.,  67.,  ..., 127., 127., 127.],
         [ 68.,  67.,  65.,  ..., 127., 127., 127.],
         [ 68.,  67.,  65.,  ..., 127., 127., 127.],
         ...,
         [185., 184., 181.,  ..., 127., 127., 127.],
         [183., 182., 180.,  ..., 127., 127., 127.],
         [174., 176., 179.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[808.6752, 480.8087, 841.9571, 495.0842]])), gt_classes: tensor([580])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000246609.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [48, 541, 217, 1102, 337, 772, 1116, 167], 'image_id': 246609, 'image': tensor([[[131., 131., 131.,  ..., 127., 127., 127.],
         [132., 132., 133.,  ..., 127., 127., 127.],
         [132., 132., 133.,  ..., 127., 127., 127.],
         ...,
         [192., 193., 193.,  ..., 127., 127., 127.],
         [190., 191., 194.,  ..., 127., 127., 127.],
         [182., 186., 193.,  ..., 127., 127., 127.]],

        [[ 87.,  87.,  87.,  ..., 127., 127., 127.],
         [ 86.,  86.,  86.,  ..., 127., 127., 127.],
         [ 87.,  87.,  86.,  ..., 127., 127., 127.],
         ...,
         [185., 181., 175.,  ..., 127., 127., 127.],
         [185., 181., 176.,  ..., 127., 127., 127.],
         [177., 177., 177.,  ..., 127., 127., 127.]],

        [[ 69.,  68.,  67.,  ..., 127., 127., 127.],
         [ 68.,  67.,  65.,  ..., 127., 127., 127.],
         [ 68.,  67.,  65.,  ..., 127., 127., 127.],
         ...,
         [185., 184., 181.,  ..., 127., 127., 127.],
         [183., 182., 180.,  ..., 127., 127., 127.],
         [174., 176., 179.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[808.6752, 480.8087, 841.9571, 495.0842]])), gt_classes: tensor([580])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000438851.jpg', 'height': 640, 'width': 457, 'not_exhaustive_category_ids': [47], 'neg_category_ids': [279, 72, 943, 694, 1049, 715, 399, 228, 1111, 974, 617, 65, 66, 572, 615, 427, 534], 'image_id': 438851, 'annotations_cat_set': {230, 1133, 1102, 781, 47, 825, 605}, 'image': tensor([[[133., 132., 132.,  ..., 128., 129., 129.],
         [133., 132., 132.,  ..., 130., 131., 131.],
         [133., 132., 132.,  ..., 129., 129., 129.],
         ...,
         [172., 172., 173.,  ...,  23.,  21.,  20.],
         [171., 172., 173.,  ...,  24.,  22.,  20.],
         [172., 173., 174.,  ...,  25.,  23.,  20.]],

        [[154., 153., 153.,  ..., 161., 161., 161.],
         [154., 153., 153.,  ..., 161., 162., 162.],
         [154., 153., 153.,  ..., 160., 161., 161.],
         ...,
         [216., 216., 216.,  ...,  27.,  26.,  25.],
         [215., 215., 216.,  ...,  28.,  27.,  25.],
         [215., 215., 216.,  ...,  28.,  27.,  25.]],

        [[186., 185., 185.,  ..., 187., 188., 188.],
         [186., 185., 185.,  ..., 186., 187., 187.],
         [186., 185., 185.,  ..., 187., 188., 188.],
         ...,
         [237., 237., 237.,  ...,  38.,  38.,  38.],
         [237., 237., 237.,  ...,  40.,  40.,  40.],
         [237., 237., 237.,  ...,  42.,  42.,  41.]]]), 'instances': Instances(num_instances=3, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 925.1124,  747.7291, 1024.0000, 1024.0000],
        [ 222.0384,  936.4224,  294.3885, 1024.0000],
        [ 642.0881,  793.1241,  865.9277,  861.6594]])), gt_classes: tensor([807, 782,  35])])}], 'support_set_target': tensor(580)}
not 0
entering support set: 2
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000010358.jpg', 'height': 640, 'width': 478, 'not_exhaustive_category_ids': [], 'neg_category_ids': [980, 200, 1152, 379, 1035, 1137], 'image_id': 10358, 'image': tensor([[[122.,  88.,  40.,  ..., 128., 128., 128.],
         [124.,  47.,  79.,  ..., 128., 128., 128.],
         [130.,  69., 108.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 76.,  70.,  54.,  ..., 128., 128., 128.],
         [105.,  67., 109.,  ..., 128., 128., 128.],
         [111.,  68., 101.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 76.,  99.,  81.,  ..., 128., 128., 128.],
         [ 89.,  83., 139.,  ..., 128., 128., 128.],
         [ 81.,  66., 122.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[261.1808, 145.1978, 421.3649, 257.0590]])), gt_classes: tensor([191])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000332038.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1044, 1185, 1168, 260, 417, 306, 566, 989, 866], 'image_id': 332038, 'image': tensor([[[  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         ...,
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.]],

        [[  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         ...,
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.]],

        [[  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         ...,
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[409.5288, 215.9603, 431.5878, 253.6463]])), gt_classes: tensor([191])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000089154.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [861, 794, 746, 64, 725, 316, 936, 917], 'image_id': 89154, 'image': tensor([[[126., 129., 130.,  ..., 151., 151., 151.],
         [125., 128., 129.,  ..., 151., 151., 151.],
         [123., 122., 122.,  ..., 151., 151., 151.],
         ...,
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.]],

        [[114., 114., 114.,  ..., 148., 148., 148.],
         [118., 116., 116.,  ..., 148., 148., 148.],
         [129., 126., 126.,  ..., 148., 148., 148.],
         ...,
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.]],

        [[106., 106., 106.,  ..., 137., 137., 137.],
         [110., 108., 108.,  ..., 137., 137., 137.],
         [120., 118., 118.,  ..., 137., 137., 137.],
         ...,
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.],
         [121., 121., 121.,  ..., 121., 121., 121.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[587.1315, 143.4047, 653.0141, 186.5518]])), gt_classes: tensor([191])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000332038.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1044, 1185, 1168, 260, 417, 306, 566, 989, 866], 'image_id': 332038, 'image': tensor([[[  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         ...,
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.]],

        [[  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         ...,
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.]],

        [[  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         ...,
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[409.5288, 215.9603, 431.5878, 253.6463]])), gt_classes: tensor([191])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000332038.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1044, 1185, 1168, 260, 417, 306, 566, 989, 866], 'image_id': 332038, 'image': tensor([[[  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         ...,
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.]],

        [[  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         ...,
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.]],

        [[  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         [  0.,   0.,   0.,  ..., 138., 138., 138.],
         ...,
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.],
         [138., 138., 138.,  ..., 138., 138., 138.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[409.5288, 215.9603, 431.5878, 253.6463]])), gt_classes: tensor([191])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000452694.jpg', 'height': 566, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [831, 1149, 114, 38, 601, 995, 44, 979], 'image_id': 452694, 'annotations_cat_set': {256, 298, 621, 90}, 'image': tensor([[[161., 162., 162.,  ..., 144., 144., 144.],
         [161., 161., 162.,  ..., 144., 144., 144.],
         [161., 162., 162.,  ..., 144., 144., 144.],
         ...,
         [144., 144., 144.,  ..., 144., 144., 144.],
         [144., 144., 144.,  ..., 144., 144., 144.],
         [144., 144., 144.,  ..., 144., 144., 144.]],

        [[154., 154., 154.,  ..., 144., 144., 144.],
         [154., 153., 153.,  ..., 144., 144., 144.],
         [154., 154., 154.,  ..., 144., 144., 144.],
         ...,
         [144., 144., 144.,  ..., 144., 144., 144.],
         [144., 144., 144.,  ..., 144., 144., 144.],
         [144., 144., 144.,  ..., 144., 144., 144.]],

        [[150., 151., 152.,  ..., 144., 144., 144.],
         [150., 151., 151.,  ..., 144., 144., 144.],
         [151., 152., 152.,  ..., 144., 144., 144.],
         ...,
         [144., 144., 144.,  ..., 144., 144., 144.],
         [144., 144., 144.,  ..., 144., 144., 144.],
         [144., 144., 144.,  ..., 144., 144., 144.]]]), 'instances': Instances(num_instances=10, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[221.3951, 205.1437, 268.9364, 271.3600],
        [303.2422, 223.4708, 335.0329, 240.0520],
        [196.1362, 228.2561, 269.8683, 284.6214],
        [288.8034, 213.7917, 320.4493, 234.6878],
        [230.1796, 197.2014, 271.7681, 235.1491],
        [273.3965, 332.0039, 299.6958, 395.2984],
        [387.4053, 262.3412, 432.9382, 269.4785],
        [486.2152, 231.9288, 512.8583, 245.7510],
        [449.0778, 263.6529, 489.3997, 279.9174],
        [259.0754, 197.3823, 266.5843, 235.2848]])), gt_classes: tensor([191, 191, 191, 191, 191, 218,  69,  69,  69, 437])])}], 'support_set_target': tensor(191)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000121769.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 922, 1045, 283, 790, 792, 1059], 'image_id': 121769, 'annotations': [{'bbox': [544.0, 0.89, 17.69, 34.5], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 32}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000121769.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 922, 1045, 283, 790, 792, 1059], 'image_id': 121769, 'image': tensor([[[ 94.,  93.,  93.,  ..., 113., 113., 113.],
         [ 94.,  94.,  93.,  ..., 113., 113., 113.],
         [ 94.,  94.,  93.,  ..., 113., 113., 113.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]],

        [[103., 102., 102.,  ..., 113., 113., 113.],
         [103., 103., 102.,  ..., 113., 113., 113.],
         [104., 104., 103.,  ..., 113., 113., 113.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]],

        [[100.,  99.,  99.,  ..., 113., 113., 113.],
         [100.,  99.,  99.,  ..., 113., 113., 113.],
         [100., 100.,  99.,  ..., 113., 113., 113.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[111.4694,   1.2664, 136.6500,  50.3570]])), gt_classes: tensor([32])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000519181.jpg', 'height': 640, 'width': 425, 'not_exhaustive_category_ids': [], 'neg_category_ids': [650, 982, 206, 401, 359, 959, 213], 'image_id': 519181, 'annotations': [{'bbox': [263.71, 320.85, 11.67, 94.13], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 32}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000519181.jpg', 'height': 640, 'width': 425, 'not_exhaustive_category_ids': [], 'neg_category_ids': [650, 982, 206, 401, 359, 959, 213], 'image_id': 519181, 'image': tensor([[[238., 235., 225.,  ...,  46.,  96., 129.],
         [238., 235., 225.,  ...,  62.,  84., 107.],
         [238., 235., 225.,  ...,  77.,  70.,  70.],
         ...,
         [238., 235., 225.,  ..., 145., 174., 190.],
         [238., 235., 225.,  ..., 136., 171., 187.],
         [238., 235., 225.,  ..., 125., 165., 184.]],

        [[237., 233., 220.,  ...,  87.,  91.,  94.],
         [237., 233., 220.,  ..., 101.,  94.,  87.],
         [237., 233., 220.,  ..., 118., 101.,  81.],
         ...,
         [237., 233., 220.,  ..., 108., 146., 174.],
         [237., 233., 220.,  ..., 118., 149., 174.],
         [237., 233., 220.,  ..., 130., 154., 172.]],

        [[239., 233., 220.,  ...,  69.,  76.,  80.],
         [239., 233., 220.,  ...,  86.,  76.,  69.],
         [239., 233., 220.,  ..., 100.,  80.,  60.],
         ...,
         [239., 233., 220.,  ...,  96., 145., 178.],
         [239., 233., 220.,  ..., 109., 150., 178.],
         [239., 233., 220.,  ..., 130., 158., 180.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 752.3349,  814.0699,  787.6196, 1024.0000]])), gt_classes: tensor([32])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000432506.jpg', 'height': 423, 'width': 640, 'not_exhaustive_category_ids': [45], 'neg_category_ids': [453, 303, 104, 946, 899, 1062, 14], 'image_id': 432506, 'annotations': [{'bbox': [49.75, 144.27, 23.89, 111.88], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 32}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000432506.jpg', 'height': 423, 'width': 640, 'not_exhaustive_category_ids': [45], 'neg_category_ids': [453, 303, 104, 946, 899, 1062, 14], 'image_id': 432506, 'image': tensor([[[226., 227., 224.,  ...,  21.,  20.,  20.],
         [226., 228., 226.,  ...,  19.,  17.,  17.],
         [217., 222., 222.,  ...,  15.,  14.,  14.],
         ...,
         [ 16.,  15.,  14.,  ...,   2.,   1.,   1.],
         [ 14.,  11.,  10.,  ...,   4.,   4.,   3.],
         [ 12.,   7.,   5.,  ...,   6.,   6.,   5.]],

        [[206., 207., 205.,  ..., 213., 211., 210.],
         [205., 207., 206.,  ..., 218., 216., 216.],
         [196., 201., 202.,  ..., 223., 221., 221.],
         ...,
         [229.,  22.,  21.,  ..., 211., 207., 203.],
         [ 22.,  16.,  14.,  ..., 215., 213., 210.],
         [ 17.,  10.,   7.,  ..., 220., 220., 217.]],

        [[188., 189., 189.,  ..., 218., 219., 218.],
         [186., 189., 189.,  ..., 222., 224., 223.],
         [177., 182., 185.,  ..., 226., 227., 226.],
         ...,
         [209., 215., 217.,  ..., 219., 218., 215.],
         [215., 223., 227.,  ..., 222., 222., 220.],
         [221., 231.,  18.,  ..., 225., 227., 224.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000432506.jpg', 'height': 423, 'width': 640, 'not_exhaustive_category_ids': [45], 'neg_category_ids': [453, 303, 104, 946, 899, 1062, 14], 'image_id': 432506, 'annotations': [{'bbox': [170.3, 71.69, 50.15, 67.03], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 32}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000432506.jpg', 'height': 423, 'width': 640, 'not_exhaustive_category_ids': [45], 'neg_category_ids': [453, 303, 104, 946, 899, 1062, 14], 'image_id': 432506, 'image': tensor([[[ 36.,  36.,  35.,  ..., 102.,  93.,  85.],
         [ 38.,  37.,  33.,  ...,  85.,  77.,  70.],
         [ 50.,  46.,  42.,  ...,  70.,  65.,  59.],
         ...,
         [ 19.,  20.,  22.,  ...,  18.,  20.,  21.],
         [ 17.,  19.,  21.,  ...,  16.,  17.,  19.],
         [ 16.,  17.,  19.,  ...,  14.,  16.,  17.]],

        [[ 37.,  37.,  37.,  ..., 113., 104.,  95.],
         [ 39.,  38.,  35.,  ...,  96.,  87.,  79.],
         [ 51.,  47.,  43.,  ...,  81.,  75.,  69.],
         ...,
         [ 21.,  22.,  24.,  ...,  22.,  23.,  25.],
         [ 19.,  21.,  23.,  ...,  19.,  21.,  23.],
         [ 18.,  19.,  21.,  ...,  16.,  18.,  19.]],

        [[ 39.,  40.,  40.,  ..., 112., 102.,  92.],
         [ 41.,  40.,  37.,  ...,  94.,  85.,  76.],
         [ 53.,  50.,  46.,  ...,  79.,  73.,  66.],
         ...,
         [ 24.,  25.,  27.,  ...,  21.,  22.,  24.],
         [ 21.,  24.,  26.,  ...,  18.,  20.,  22.],
         [ 20.,  21.,  24.,  ...,  16.,  18.,  19.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[710.7733, 105.3253, 850.9583, 292.6289]])), gt_classes: tensor([32])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000016183.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [853, 197, 695, 742, 288, 180, 467, 291, 824], 'image_id': 16183, 'annotations': [{'bbox': [334.47, 59.51, 5.8, 5.3], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 32}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000016183.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [853, 197, 695, 742, 288, 180, 467, 291, 824], 'image_id': 16183, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[487.0719,  86.6614, 495.5182,  94.3796]])), gt_classes: tensor([32])])}, len instances: 1
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000121769.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 922, 1045, 283, 790, 792, 1059], 'image_id': 121769, 'image': tensor([[[ 94.,  93.,  93.,  ..., 113., 113., 113.],
         [ 94.,  94.,  93.,  ..., 113., 113., 113.],
         [ 94.,  94.,  93.,  ..., 113., 113., 113.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]],

        [[103., 102., 102.,  ..., 113., 113., 113.],
         [103., 103., 102.,  ..., 113., 113., 113.],
         [104., 104., 103.,  ..., 113., 113., 113.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]],

        [[100.,  99.,  99.,  ..., 113., 113., 113.],
         [100.,  99.,  99.,  ..., 113., 113., 113.],
         [100., 100.,  99.,  ..., 113., 113., 113.],
         ...,
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.],
         [113., 113., 113.,  ..., 113., 113., 113.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[111.4694,   1.2664, 136.6500,  50.3570]])), gt_classes: tensor([32])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000519181.jpg', 'height': 640, 'width': 425, 'not_exhaustive_category_ids': [], 'neg_category_ids': [650, 982, 206, 401, 359, 959, 213], 'image_id': 519181, 'image': tensor([[[238., 235., 225.,  ...,  46.,  96., 129.],
         [238., 235., 225.,  ...,  62.,  84., 107.],
         [238., 235., 225.,  ...,  77.,  70.,  70.],
         ...,
         [238., 235., 225.,  ..., 145., 174., 190.],
         [238., 235., 225.,  ..., 136., 171., 187.],
         [238., 235., 225.,  ..., 125., 165., 184.]],

        [[237., 233., 220.,  ...,  87.,  91.,  94.],
         [237., 233., 220.,  ..., 101.,  94.,  87.],
         [237., 233., 220.,  ..., 118., 101.,  81.],
         ...,
         [237., 233., 220.,  ..., 108., 146., 174.],
         [237., 233., 220.,  ..., 118., 149., 174.],
         [237., 233., 220.,  ..., 130., 154., 172.]],

        [[239., 233., 220.,  ...,  69.,  76.,  80.],
         [239., 233., 220.,  ...,  86.,  76.,  69.],
         [239., 233., 220.,  ..., 100.,  80.,  60.],
         ...,
         [239., 233., 220.,  ...,  96., 145., 178.],
         [239., 233., 220.,  ..., 109., 150., 178.],
         [239., 233., 220.,  ..., 130., 158., 180.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 752.3349,  814.0699,  787.6196, 1024.0000]])), gt_classes: tensor([32])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000432506.jpg', 'height': 423, 'width': 640, 'not_exhaustive_category_ids': [45], 'neg_category_ids': [453, 303, 104, 946, 899, 1062, 14], 'image_id': 432506, 'image': tensor([[[ 36.,  36.,  35.,  ..., 102.,  93.,  85.],
         [ 38.,  37.,  33.,  ...,  85.,  77.,  70.],
         [ 50.,  46.,  42.,  ...,  70.,  65.,  59.],
         ...,
         [ 19.,  20.,  22.,  ...,  18.,  20.,  21.],
         [ 17.,  19.,  21.,  ...,  16.,  17.,  19.],
         [ 16.,  17.,  19.,  ...,  14.,  16.,  17.]],

        [[ 37.,  37.,  37.,  ..., 113., 104.,  95.],
         [ 39.,  38.,  35.,  ...,  96.,  87.,  79.],
         [ 51.,  47.,  43.,  ...,  81.,  75.,  69.],
         ...,
         [ 21.,  22.,  24.,  ...,  22.,  23.,  25.],
         [ 19.,  21.,  23.,  ...,  19.,  21.,  23.],
         [ 18.,  19.,  21.,  ...,  16.,  18.,  19.]],

        [[ 39.,  40.,  40.,  ..., 112., 102.,  92.],
         [ 41.,  40.,  37.,  ...,  94.,  85.,  76.],
         [ 53.,  50.,  46.,  ...,  79.,  73.,  66.],
         ...,
         [ 24.,  25.,  27.,  ...,  21.,  22.,  24.],
         [ 21.,  24.,  26.,  ...,  18.,  20.,  22.],
         [ 20.,  21.,  24.,  ...,  16.,  18.,  19.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[710.7733, 105.3253, 850.9583, 292.6289]])), gt_classes: tensor([32])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000016183.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [853, 197, 695, 742, 288, 180, 467, 291, 824], 'image_id': 16183, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[487.0719,  86.6614, 495.5182,  94.3796]])), gt_classes: tensor([32])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000016183.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [853, 197, 695, 742, 288, 180, 467, 291, 824], 'image_id': 16183, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[487.0719,  86.6614, 495.5182,  94.3796]])), gt_classes: tensor([32])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000519181.jpg', 'height': 640, 'width': 425, 'not_exhaustive_category_ids': [], 'neg_category_ids': [650, 982, 206, 401, 359, 959, 213], 'image_id': 519181, 'annotations_cat_set': {1178, 44, 703}, 'image': tensor([[[68., 68., 68.,  ..., 88., 88., 88.],
         [68., 68., 68.,  ..., 88., 88., 88.],
         [68., 68., 68.,  ..., 88., 88., 88.],
         ...,
         [68., 68., 68.,  ..., 88., 88., 88.],
         [68., 68., 68.,  ..., 88., 88., 88.],
         [68., 68., 68.,  ..., 88., 88., 88.]],

        [[68., 68., 68.,  ..., 88., 88., 88.],
         [68., 68., 68.,  ..., 88., 88., 88.],
         [68., 68., 68.,  ..., 88., 88., 88.],
         ...,
         [68., 68., 68.,  ..., 88., 88., 88.],
         [68., 68., 68.,  ..., 88., 88., 88.],
         [68., 68., 68.,  ..., 88., 88., 88.]],

        [[68., 68., 68.,  ..., 88., 88., 88.],
         [68., 68., 68.,  ..., 88., 88., 88.],
         [68., 68., 68.,  ..., 88., 88., 88.],
         ...,
         [68., 68., 68.,  ..., 88., 88., 88.],
         [68., 68., 68.,  ..., 88., 88., 88.],
         [68., 68., 68.,  ..., 88., 88., 88.]]]), 'instances': Instances(num_instances=30, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[316.1484, 344.7661, 371.3665, 695.5564],
        [337.2654, 426.8474, 395.9079, 679.8182],
        [599.0519, 357.7385, 663.1519, 875.4750],
        [666.1304, 561.7104, 720.0465, 869.9077],
        [353.6025, 246.0010, 438.4272, 645.4333],
        [669.5548, 508.6609, 719.8681, 876.0281],
        [ 67.5066,  14.4248, 283.6703, 724.3205],
        [540.9088, 339.6271, 560.5098, 794.3216],
        [577.9705, 675.9640, 601.6736, 878.5976],
        [566.5024, 443.7811, 583.4460, 808.7571],
        [522.0569, 519.3137, 545.1179, 780.2072],
        [654.0380, 447.5105, 719.8503, 891.1240],
        [610.3238, 556.7499, 666.7190, 892.9083],
        [342.1523, 275.8357, 397.8519, 652.1782],
        [453.8904, 515.4773, 474.2227, 707.7258],
        [433.1123, 516.6728, 462.6832, 669.4510],
        [581.3414, 357.0248, 607.0956, 804.4568],
        [501.4215, 152.4997, 537.6271, 771.8384],
        [182.6513, 130.9623, 273.3259, 663.3127],
        [215.9854, 570.3468, 245.4672, 717.1473],
        [470.3345, 510.5167, 491.1483, 678.4800],
        [615.2106, 537.9961, 654.3948, 792.1625],
        [276.7146, 494.2432, 329.6141, 718.9139],
        [234.7481, 206.9232, 316.8083, 723.7139],
        [629.1935, 312.9329, 721.2415, 853.5627],
        [472.5283, 629.6415, 485.6907, 757.3136],
        [189.7854,  12.8188, 305.0727, 726.2833],
        [102.0357, 793.6792, 248.1425, 947.4567],
        [444.0810, 772.4630, 590.8298, 957.1815],
        [105.1034, 637.5999, 592.3279, 957.3599]])), gt_classes: tensor([ 32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,
         32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32, 841,
        841, 495])])}], 'support_set_target': tensor(32)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000095753.jpg', 'height': 640, 'width': 632, 'not_exhaustive_category_ids': [840], 'neg_category_ids': [147, 302, 585, 1028, 326, 373, 175, 836, 910, 823, 999], 'image_id': 95753, 'annotations': [{'bbox': [165.9, 546.92, 131.31, 49.44], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 785}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000095753.jpg', 'height': 640, 'width': 632, 'not_exhaustive_category_ids': [840], 'neg_category_ids': [147, 302, 585, 1028, 326, 373, 175, 836, 910, 823, 999], 'image_id': 95753, 'image': tensor([[[ 94.,  94.,  94.,  ..., 219., 223., 229.],
         [ 94.,  97.,  97.,  ..., 222., 227., 231.],
         [ 90.,  97.,  99.,  ..., 225., 230., 233.],
         ...,
         [157., 158., 158.,  ..., 158., 153., 148.],
         [158., 157., 155.,  ..., 150., 150., 151.],
         [158., 156., 152.,  ..., 143., 147., 152.]],

        [[ 94.,  94.,  94.,  ..., 219., 223., 229.],
         [ 94.,  97.,  97.,  ..., 222., 227., 231.],
         [ 90.,  97.,  99.,  ..., 225., 230., 233.],
         ...,
         [157., 158., 158.,  ..., 158., 153., 148.],
         [158., 157., 155.,  ..., 150., 150., 151.],
         [158., 156., 152.,  ..., 143., 147., 152.]],

        [[ 94.,  94.,  94.,  ..., 219., 223., 229.],
         [ 94.,  97.,  97.,  ..., 222., 227., 231.],
         [ 90.,  97.,  99.,  ..., 225., 230., 233.],
         ...,
         [157., 158., 158.,  ..., 158., 153., 148.],
         [158., 157., 155.,  ..., 150., 150., 151.],
         [158., 156., 152.,  ..., 143., 147., 152.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  89.6625,  966.0072,  395.7062, 1024.0000]])), gt_classes: tensor([785])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000210809.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [49, 1006, 1051, 57, 115, 510, 912, 892, 625], 'image_id': 210809, 'annotations': [{'bbox': [32.31, 280.09, 46.53, 22.44], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 785}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000210809.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [49, 1006, 1051, 57, 115, 510, 912, 892, 625], 'image_id': 210809, 'image': tensor([[[192., 192., 191.,  ..., 208., 206., 209.],
         [192., 192., 191.,  ..., 237., 235., 235.],
         [192., 192., 191.,  ..., 251., 250., 249.],
         ...,
         [ 98., 100., 102.,  ...,  70.,  68.,  66.],
         [103., 105., 106.,  ...,  70.,  68.,  66.],
         [110., 111., 111.,  ...,  70.,  68.,  67.]],

        [[198., 198., 197.,  ..., 212., 215., 220.],
         [198., 198., 197.,  ..., 240., 241., 243.],
         [198., 198., 197.,  ..., 254., 254., 254.],
         ...,
         [112., 114., 116.,  ...,  85.,  83.,  82.],
         [117., 118., 120.,  ...,  85.,  84.,  83.],
         [123., 124., 125.,  ...,  86.,  84.,  84.]],

        [[203., 203., 202.,  ..., 247., 249., 250.],
         [203., 203., 202.,  ..., 250., 252., 252.],
         [203., 203., 202.,  ..., 252., 254., 253.],
         ...,
         [124., 126., 128.,  ..., 103., 100.,  99.],
         [130., 131., 132.,  ..., 103., 101., 100.],
         [137., 137., 137.,  ..., 103., 101., 101.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 693.4401,  14.0565, 750.3585]])), gt_classes: tensor([785])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000489449.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [], 'neg_category_ids': [602, 922, 1145, 1150, 307, 1086, 825, 754, 253], 'image_id': 489449, 'annotations': [{'bbox': [316.19, 432.25, 26.1, 50.29], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 785}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000489449.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [], 'neg_category_ids': [602, 922, 1145, 1150, 307, 1086, 825, 754, 253], 'image_id': 489449, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[ 34.,  35.,  36.,  ..., 128., 128., 128.],
         [ 36.,  37.,  38.,  ..., 128., 128., 128.],
         [ 38.,  38.,  39.,  ..., 128., 128., 128.],
         ...,
         [ 68.,  69.,  70.,  ..., 128., 128., 128.],
         [ 69.,  69.,  70.,  ..., 128., 128., 128.],
         [ 69.,  69.,  70.,  ..., 128., 128., 128.]],

        [[127., 127., 128.,  ..., 128., 128., 128.],
         [129., 129., 130.,  ..., 128., 128., 128.],
         [130., 130., 131.,  ..., 128., 128., 128.],
         ...,
         [219., 220., 221.,  ..., 128., 128., 128.],
         [220., 220., 221.,  ..., 128., 128., 128.],
         [222., 222., 221.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 705.1185,  926.7824,  763.3228, 1024.0000]])), gt_classes: tensor([785])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000204826.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [711, 2, 175, 766, 35, 797, 511, 386, 1118], 'image_id': 204826, 'annotations': [{'bbox': [177.59, 315.42, 135.78, 80.23], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 785}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000204826.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [711, 2, 175, 766, 35, 797, 511, 386, 1118], 'image_id': 204826, 'image': tensor([[[251., 254., 255.,  ...,  71.,  67.,  71.],
         [245., 253., 254.,  ...,  63.,  67.,  71.],
         [244., 253., 254.,  ...,  67.,  71.,  71.],
         ...,
         [  2.,   3.,   3.,  ..., 239., 239., 238.],
         [  2.,   2.,   3.,  ..., 238., 237., 236.],
         [  2.,   2.,   3.,  ..., 237., 235., 234.]],

        [[252., 254., 255.,  ...,  53.,  50.,  53.],
         [252., 253., 255.,  ...,  46.,  50.,  53.],
         [252., 253., 255.,  ...,  50.,  53.,  53.],
         ...,
         [  4.,   5.,   6.,  ..., 236., 234., 233.],
         [  4.,   4.,   6.,  ..., 233., 232., 230.],
         [  4.,   4.,   5.,  ..., 230., 227., 225.]],

        [[252., 254., 255.,  ...,  18.,  18.,  18.],
         [252., 253., 255.,  ...,  17.,  18.,  18.],
         [252., 253., 254.,  ...,  18.,  18.,  18.],
         ...,
         [  7.,   9.,  10.,  ..., 237., 236., 236.],
         [  7.,   8.,  10.,  ..., 236., 235., 235.],
         [  7.,   8.,   9.,  ..., 235., 234., 233.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[263.1219, 701.0945, 576.6888, 886.2921]])), gt_classes: tensor([785])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000574147.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [432, 584, 1168, 609, 1078, 507, 1177, 822, 623, 320], 'image_id': 574147, 'annotations': [{'bbox': [306.46, 482.69, 52.6, 21.65], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 785}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000574147.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [432, 584, 1168, 609, 1078, 507, 1177, 822, 623, 320], 'image_id': 574147, 'image': tensor([[[ 44.,  44.,  40.,  ..., 144., 144., 144.],
         [ 44.,  44.,  40.,  ..., 144., 144., 144.],
         [ 44.,  44.,  40.,  ..., 144., 144., 144.],
         ...,
         [181., 183., 188.,  ..., 144., 144., 144.],
         [181., 186., 190.,  ..., 144., 144., 144.],
         [181., 186., 190.,  ..., 144., 144., 144.]],

        [[ 63.,  63.,  61.,  ..., 204., 204., 204.],
         [ 63.,  63.,  61.,  ..., 204., 204., 204.],
         [ 63.,  63.,  61.,  ..., 204., 204., 204.],
         ...,
         [211., 212., 214.,  ..., 204., 204., 204.],
         [211., 212., 214.,  ..., 204., 204., 204.],
         [211., 212., 214.,  ..., 204., 204., 204.]],

        [[ 39.,  39.,  37.,  ..., 215., 215., 215.],
         [ 39.,  39.,  37.,  ..., 215., 215., 215.],
         [ 42.,  42.,  39.,  ..., 215., 215., 215.],
         ...,
         [139., 139., 141.,  ..., 215., 215., 215.],
         [139., 141., 142.,  ..., 215., 215., 215.],
         [139., 141., 143.,  ..., 215., 215., 215.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[125.3787, 735.9597, 222.4485, 775.8769]])), gt_classes: tensor([785])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000095753.jpg', 'height': 640, 'width': 632, 'not_exhaustive_category_ids': [840], 'neg_category_ids': [147, 302, 585, 1028, 326, 373, 175, 836, 910, 823, 999], 'image_id': 95753, 'image': tensor([[[ 94.,  94.,  94.,  ..., 219., 223., 229.],
         [ 94.,  97.,  97.,  ..., 222., 227., 231.],
         [ 90.,  97.,  99.,  ..., 225., 230., 233.],
         ...,
         [157., 158., 158.,  ..., 158., 153., 148.],
         [158., 157., 155.,  ..., 150., 150., 151.],
         [158., 156., 152.,  ..., 143., 147., 152.]],

        [[ 94.,  94.,  94.,  ..., 219., 223., 229.],
         [ 94.,  97.,  97.,  ..., 222., 227., 231.],
         [ 90.,  97.,  99.,  ..., 225., 230., 233.],
         ...,
         [157., 158., 158.,  ..., 158., 153., 148.],
         [158., 157., 155.,  ..., 150., 150., 151.],
         [158., 156., 152.,  ..., 143., 147., 152.]],

        [[ 94.,  94.,  94.,  ..., 219., 223., 229.],
         [ 94.,  97.,  97.,  ..., 222., 227., 231.],
         [ 90.,  97.,  99.,  ..., 225., 230., 233.],
         ...,
         [157., 158., 158.,  ..., 158., 153., 148.],
         [158., 157., 155.,  ..., 150., 150., 151.],
         [158., 156., 152.,  ..., 143., 147., 152.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  89.6625,  966.0072,  395.7062, 1024.0000]])), gt_classes: tensor([785])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000210809.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [49, 1006, 1051, 57, 115, 510, 912, 892, 625], 'image_id': 210809, 'image': tensor([[[192., 192., 191.,  ..., 208., 206., 209.],
         [192., 192., 191.,  ..., 237., 235., 235.],
         [192., 192., 191.,  ..., 251., 250., 249.],
         ...,
         [ 98., 100., 102.,  ...,  70.,  68.,  66.],
         [103., 105., 106.,  ...,  70.,  68.,  66.],
         [110., 111., 111.,  ...,  70.,  68.,  67.]],

        [[198., 198., 197.,  ..., 212., 215., 220.],
         [198., 198., 197.,  ..., 240., 241., 243.],
         [198., 198., 197.,  ..., 254., 254., 254.],
         ...,
         [112., 114., 116.,  ...,  85.,  83.,  82.],
         [117., 118., 120.,  ...,  85.,  84.,  83.],
         [123., 124., 125.,  ...,  86.,  84.,  84.]],

        [[203., 203., 202.,  ..., 247., 249., 250.],
         [203., 203., 202.,  ..., 250., 252., 252.],
         [203., 203., 202.,  ..., 252., 254., 253.],
         ...,
         [124., 126., 128.,  ..., 103., 100.,  99.],
         [130., 131., 132.,  ..., 103., 101., 100.],
         [137., 137., 137.,  ..., 103., 101., 101.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 693.4401,  14.0565, 750.3585]])), gt_classes: tensor([785])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000489449.jpg', 'height': 640, 'width': 426, 'not_exhaustive_category_ids': [], 'neg_category_ids': [602, 922, 1145, 1150, 307, 1086, 825, 754, 253], 'image_id': 489449, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.]],

        [[ 34.,  35.,  36.,  ..., 128., 128., 128.],
         [ 36.,  37.,  38.,  ..., 128., 128., 128.],
         [ 38.,  38.,  39.,  ..., 128., 128., 128.],
         ...,
         [ 68.,  69.,  70.,  ..., 128., 128., 128.],
         [ 69.,  69.,  70.,  ..., 128., 128., 128.],
         [ 69.,  69.,  70.,  ..., 128., 128., 128.]],

        [[127., 127., 128.,  ..., 128., 128., 128.],
         [129., 129., 130.,  ..., 128., 128., 128.],
         [130., 130., 131.,  ..., 128., 128., 128.],
         ...,
         [219., 220., 221.,  ..., 128., 128., 128.],
         [220., 220., 221.,  ..., 128., 128., 128.],
         [222., 222., 221.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 705.1185,  926.7824,  763.3228, 1024.0000]])), gt_classes: tensor([785])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000204826.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [711, 2, 175, 766, 35, 797, 511, 386, 1118], 'image_id': 204826, 'image': tensor([[[251., 254., 255.,  ...,  71.,  67.,  71.],
         [245., 253., 254.,  ...,  63.,  67.,  71.],
         [244., 253., 254.,  ...,  67.,  71.,  71.],
         ...,
         [  2.,   3.,   3.,  ..., 239., 239., 238.],
         [  2.,   2.,   3.,  ..., 238., 237., 236.],
         [  2.,   2.,   3.,  ..., 237., 235., 234.]],

        [[252., 254., 255.,  ...,  53.,  50.,  53.],
         [252., 253., 255.,  ...,  46.,  50.,  53.],
         [252., 253., 255.,  ...,  50.,  53.,  53.],
         ...,
         [  4.,   5.,   6.,  ..., 236., 234., 233.],
         [  4.,   4.,   6.,  ..., 233., 232., 230.],
         [  4.,   4.,   5.,  ..., 230., 227., 225.]],

        [[252., 254., 255.,  ...,  18.,  18.,  18.],
         [252., 253., 255.,  ...,  17.,  18.,  18.],
         [252., 253., 254.,  ...,  18.,  18.,  18.],
         ...,
         [  7.,   9.,  10.,  ..., 237., 236., 236.],
         [  7.,   8.,  10.,  ..., 236., 235., 235.],
         [  7.,   8.,   9.,  ..., 235., 234., 233.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[263.1219, 701.0945, 576.6888, 886.2921]])), gt_classes: tensor([785])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000574147.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [432, 584, 1168, 609, 1078, 507, 1177, 822, 623, 320], 'image_id': 574147, 'image': tensor([[[ 44.,  44.,  40.,  ..., 144., 144., 144.],
         [ 44.,  44.,  40.,  ..., 144., 144., 144.],
         [ 44.,  44.,  40.,  ..., 144., 144., 144.],
         ...,
         [181., 183., 188.,  ..., 144., 144., 144.],
         [181., 186., 190.,  ..., 144., 144., 144.],
         [181., 186., 190.,  ..., 144., 144., 144.]],

        [[ 63.,  63.,  61.,  ..., 204., 204., 204.],
         [ 63.,  63.,  61.,  ..., 204., 204., 204.],
         [ 63.,  63.,  61.,  ..., 204., 204., 204.],
         ...,
         [211., 212., 214.,  ..., 204., 204., 204.],
         [211., 212., 214.,  ..., 204., 204., 204.],
         [211., 212., 214.,  ..., 204., 204., 204.]],

        [[ 39.,  39.,  37.,  ..., 215., 215., 215.],
         [ 39.,  39.,  37.,  ..., 215., 215., 215.],
         [ 42.,  42.,  39.,  ..., 215., 215., 215.],
         ...,
         [139., 139., 141.,  ..., 215., 215., 215.],
         [139., 141., 142.,  ..., 215., 215., 215.],
         [139., 141., 143.,  ..., 215., 215., 215.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[125.3787, 735.9597, 222.4485, 775.8769]])), gt_classes: tensor([785])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000492993.jpg', 'height': 300, 'width': 400, 'not_exhaustive_category_ids': [344], 'neg_category_ids': [788, 763, 950, 817, 34, 314, 1059, 138, 572, 118], 'image_id': 492993, 'annotations_cat_set': {1065, 1035, 1105, 344, 59}, 'image': tensor([[[20., 20., 20.,  ..., 36., 36., 36.],
         [20., 20., 20.,  ..., 36., 36., 36.],
         [20., 19., 19.,  ..., 36., 36., 35.],
         ...,
         [28., 28., 28.,  ..., 28., 28., 28.],
         [28., 28., 28.,  ..., 28., 28., 28.],
         [28., 28., 28.,  ..., 28., 28., 28.]],

        [[23., 23., 23.,  ..., 37., 37., 37.],
         [23., 23., 23.,  ..., 37., 37., 37.],
         [23., 22., 22.,  ..., 37., 37., 36.],
         ...,
         [28., 28., 28.,  ..., 28., 28., 28.],
         [28., 28., 28.,  ..., 28., 28., 28.],
         [28., 28., 28.,  ..., 28., 28., 28.]],

        [[27., 26., 26.,  ..., 37., 37., 37.],
         [27., 26., 26.,  ..., 37., 37., 37.],
         [26., 26., 26.,  ..., 37., 37., 37.],
         ...,
         [28., 28., 28.,  ..., 28., 28., 28.],
         [28., 28., 28.,  ..., 28., 28., 28.],
         [28., 28., 28.,  ..., 28., 28., 28.]]]), 'instances': Instances(num_instances=30, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  512.2086,   75.1871,  563.0776],
        [ 741.0950,  234.7405,  778.2671,  255.1598],
        [ 833.2114,  261.9663,  896.5212,  296.1938],
        [ 996.0266,  197.7122, 1024.0000,  219.0108],
        [ 871.1648,  301.1114,  944.8254,  333.9386],
        [ 771.4316,  276.1653,  819.9962,  294.0770],
        [ 931.9356,  187.8771,  984.2760,  208.6872],
        [ 903.4869,  283.1020,  974.3483,  313.4216],
        [ 909.8342,  201.1643,  959.4078,  218.9457],
        [ 797.1786,  285.9028,  863.6783,  315.9292],
        [ 979.6865,  205.1374, 1024.0000,  231.9398],
        [ 947.9502,  262.0314, 1017.0864,  288.0847],
        [ 696.4363,  600.4642,  783.5727,  653.3525],
        [ 915.7582,  170.2911,  966.8943,  190.8407],
        [ 314.0715,  100.1099,  555.6901,  445.4143],
        [   0.0000,  137.6593,  128.4714,  683.0208],
        [   0.0000,  511.7852,   77.4330,  665.5975],
        [ 901.8268,  282.5158,  974.9016,  370.4133],
        [ 996.2869,  197.9076, 1024.0000,  257.6675],
        [ 830.2494,  266.2976,  896.7816,  352.7296],
        [ 864.7524,  300.2321,  944.6952,  383.7982],
        [ 795.0303,  282.7764,  863.1249,  364.6490],
        [ 947.6572,  262.1942, 1016.5981,  370.9995],
        [ 932.7168,  188.1702,  984.6666,  254.8667],
        [ 911.1687,  201.4248,  961.4910,  256.2671],
        [ 915.1072,  171.3658,  965.7876,  200.1222],
        [ 683.6116,  294.2724,  732.0786,  335.8600],
        [ 970.5399,  206.9612, 1024.0000,  267.8282],
        [ 448.0799,    0.0000,  579.8422,   69.7904],
        [ 453.9063,   44.5512,  560.7679,  103.4317]])), gt_classes: tensor([785, 785, 785, 785, 785, 785, 785, 785, 785, 785, 785, 785, 785, 785,
        748, 748, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,
         44, 725])])}], 'support_set_target': tensor(785)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000301156.jpg', 'height': 355, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [167, 1097, 481, 974, 159, 1198, 599, 977, 120], 'image_id': 301156, 'annotations': [{'bbox': [237.35, 244.46, 47.77, 60.88], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 324}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000301156.jpg', 'height': 355, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [167, 1097, 481, 974, 159, 1198, 599, 977, 120], 'image_id': 301156, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[320.2963, 433.8304, 405.0880, 541.8710]])), gt_classes: tensor([324])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000397353.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [650, 124, 370, 712, 798, 892, 119, 895], 'image_id': 397353, 'annotations': [{'bbox': [259.58, 277.93, 73.82, 19.26], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 324}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000397353.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [650, 124, 370, 712, 798, 892, 119, 895], 'image_id': 397353, 'image': tensor([[[179., 178., 179.,  ..., 183., 184., 184.],
         [179., 178., 179.,  ..., 183., 184., 184.],
         [180., 180., 180.,  ..., 184., 184., 184.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[113., 112., 113.,  ..., 113., 114., 114.],
         [113., 112., 113.,  ..., 113., 114., 114.],
         [114., 114., 114.,  ..., 114., 114., 114.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 67.,  66.,  67.,  ...,  68.,  69.,  69.],
         [ 67.,  66.,  67.,  ...,  68.,  69.,  69.],
         [ 66.,  64.,  66.,  ...,  69.,  69.,  69.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[528.6591, 639.8248, 698.5604, 684.1634]])), gt_classes: tensor([324])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000237988.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [198, 54, 883, 379, 1011, 704, 803, 1140], 'image_id': 237988, 'annotations': [{'bbox': [64.71, 125.46, 244.65, 48.28], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 324}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000237988.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [198, 54, 883, 379, 1011, 704, 803, 1140], 'image_id': 237988, 'image': tensor([[[241., 241., 242.,  ...,   3.,   1.,   0.],
         [241., 241., 242.,  ...,   3.,   1.,   0.],
         [241., 242., 243.,  ...,   2.,   0.,   0.],
         ...,
         [  9.,   8.,   8.,  ...,  12.,  12.,  12.],
         [  9.,   9.,   9.,  ...,  12.,  12.,  12.],
         [ 10.,   9.,   9.,  ...,  12.,  12.,  12.]],

        [[202., 202., 203.,  ...,   3.,   2.,   1.],
         [202., 202., 203.,  ...,   3.,   2.,   1.],
         [203., 203., 204.,  ...,   2.,   2.,   2.],
         ...,
         [ 10.,   9.,   9.,  ...,  14.,  14.,  14.],
         [ 10.,   9.,   9.,  ...,  14.,  14.,  14.],
         [ 10.,   9.,   9.,  ...,  14.,  14.,  14.]],

        [[128., 129., 129.,  ...,   3.,   2.,   1.],
         [129., 130., 130.,  ...,   3.,   2.,   1.],
         [131., 131., 132.,  ...,   2.,   2.,   2.],
         ...,
         [ 10.,   9.,   9.,  ...,  14.,  14.,  14.],
         [ 10.,   9.,   9.,  ...,  14.,  14.,  14.],
         [ 10.,   9.,   9.,  ...,  14.,  14.,  14.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[241.3394, 177.4822, 950.4421, 317.3589]])), gt_classes: tensor([324])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000200922.jpg', 'height': 325, 'width': 640, 'not_exhaustive_category_ids': [204, 880], 'neg_category_ids': [501, 326, 929, 614, 675, 1133, 336, 1041, 533], 'image_id': 200922, 'annotations': [{'bbox': [256.29, 235.79, 14.3, 31.4], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 324}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000200922.jpg', 'height': 325, 'width': 640, 'not_exhaustive_category_ids': [204, 880], 'neg_category_ids': [501, 326, 929, 614, 675, 1133, 336, 1041, 533], 'image_id': 200922, 'image': tensor([[[ 78.,  77.,  77.,  ...,  74.,  74.,  74.],
         [ 78.,  77.,  77.,  ...,  74.,  74.,  74.],
         [ 77.,  76.,  76.,  ...,  75.,  75.,  74.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[131., 131., 130.,  ..., 126., 126., 126.],
         [131., 131., 130.,  ..., 126., 126., 126.],
         [130., 130., 129.,  ..., 127., 126., 126.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[182., 182., 183.,  ..., 173., 173., 173.],
         [182., 182., 183.,  ..., 173., 173., 173.],
         [180., 180., 181.,  ..., 174., 174., 174.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[224.4919, 562.2684, 258.6108, 637.1454]])), gt_classes: tensor([324])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000531684.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [100, 368, 411, 1166, 326, 34, 730, 979], 'image_id': 531684, 'annotations': [{'bbox': [435.18, 219.15, 67.87, 17.55], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 324}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000531684.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [100, 368, 411, 1166, 326, 34, 730, 979], 'image_id': 531684, 'image': tensor([[[25., 24., 25.,  ..., 16., 16., 16.],
         [24., 25., 25.,  ..., 16., 16., 16.],
         [25., 25., 25.,  ..., 16., 16., 16.],
         ...,
         [16., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.]],

        [[17., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.],
         [17., 17., 17.,  ..., 16., 16., 16.],
         ...,
         [16., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.]],

        [[11., 11., 11.,  ..., 16., 16., 16.],
         [10., 10., 11.,  ..., 16., 16., 16.],
         [10., 10., 10.,  ..., 16., 16., 16.],
         ...,
         [16., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[129.2466, 206.8035, 193.2989, 223.3648]])), gt_classes: tensor([324])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000301156.jpg', 'height': 355, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [167, 1097, 481, 974, 159, 1198, 599, 977, 120], 'image_id': 301156, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[320.2963, 433.8304, 405.0880, 541.8710]])), gt_classes: tensor([324])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000397353.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [650, 124, 370, 712, 798, 892, 119, 895], 'image_id': 397353, 'image': tensor([[[179., 178., 179.,  ..., 183., 184., 184.],
         [179., 178., 179.,  ..., 183., 184., 184.],
         [180., 180., 180.,  ..., 184., 184., 184.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[113., 112., 113.,  ..., 113., 114., 114.],
         [113., 112., 113.,  ..., 113., 114., 114.],
         [114., 114., 114.,  ..., 114., 114., 114.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 67.,  66.,  67.,  ...,  68.,  69.,  69.],
         [ 67.,  66.,  67.,  ...,  68.,  69.,  69.],
         [ 66.,  64.,  66.,  ...,  69.,  69.,  69.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[528.6591, 639.8248, 698.5604, 684.1634]])), gt_classes: tensor([324])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000237988.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [198, 54, 883, 379, 1011, 704, 803, 1140], 'image_id': 237988, 'image': tensor([[[241., 241., 242.,  ...,   3.,   1.,   0.],
         [241., 241., 242.,  ...,   3.,   1.,   0.],
         [241., 242., 243.,  ...,   2.,   0.,   0.],
         ...,
         [  9.,   8.,   8.,  ...,  12.,  12.,  12.],
         [  9.,   9.,   9.,  ...,  12.,  12.,  12.],
         [ 10.,   9.,   9.,  ...,  12.,  12.,  12.]],

        [[202., 202., 203.,  ...,   3.,   2.,   1.],
         [202., 202., 203.,  ...,   3.,   2.,   1.],
         [203., 203., 204.,  ...,   2.,   2.,   2.],
         ...,
         [ 10.,   9.,   9.,  ...,  14.,  14.,  14.],
         [ 10.,   9.,   9.,  ...,  14.,  14.,  14.],
         [ 10.,   9.,   9.,  ...,  14.,  14.,  14.]],

        [[128., 129., 129.,  ...,   3.,   2.,   1.],
         [129., 130., 130.,  ...,   3.,   2.,   1.],
         [131., 131., 132.,  ...,   2.,   2.,   2.],
         ...,
         [ 10.,   9.,   9.,  ...,  14.,  14.,  14.],
         [ 10.,   9.,   9.,  ...,  14.,  14.,  14.],
         [ 10.,   9.,   9.,  ...,  14.,  14.,  14.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[241.3394, 177.4822, 950.4421, 317.3589]])), gt_classes: tensor([324])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000200922.jpg', 'height': 325, 'width': 640, 'not_exhaustive_category_ids': [204, 880], 'neg_category_ids': [501, 326, 929, 614, 675, 1133, 336, 1041, 533], 'image_id': 200922, 'image': tensor([[[ 78.,  77.,  77.,  ...,  74.,  74.,  74.],
         [ 78.,  77.,  77.,  ...,  74.,  74.,  74.],
         [ 77.,  76.,  76.,  ...,  75.,  75.,  74.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[131., 131., 130.,  ..., 126., 126., 126.],
         [131., 131., 130.,  ..., 126., 126., 126.],
         [130., 130., 129.,  ..., 127., 126., 126.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[182., 182., 183.,  ..., 173., 173., 173.],
         [182., 182., 183.,  ..., 173., 173., 173.],
         [180., 180., 181.,  ..., 174., 174., 174.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[224.4919, 562.2684, 258.6108, 637.1454]])), gt_classes: tensor([324])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000531684.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [100, 368, 411, 1166, 326, 34, 730, 979], 'image_id': 531684, 'image': tensor([[[25., 24., 25.,  ..., 16., 16., 16.],
         [24., 25., 25.,  ..., 16., 16., 16.],
         [25., 25., 25.,  ..., 16., 16., 16.],
         ...,
         [16., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.]],

        [[17., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.],
         [17., 17., 17.,  ..., 16., 16., 16.],
         ...,
         [16., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.]],

        [[11., 11., 11.,  ..., 16., 16., 16.],
         [10., 10., 11.,  ..., 16., 16., 16.],
         [10., 10., 10.,  ..., 16., 16., 16.],
         ...,
         [16., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.],
         [16., 16., 16.,  ..., 16., 16., 16.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[129.2466, 206.8035, 193.2989, 223.3648]])), gt_classes: tensor([324])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000134447.jpg', 'height': 334, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1022, 691, 1187, 1169, 1151, 333, 183, 893, 554], 'image_id': 134447, 'annotations_cat_set': {962, 230, 455, 75, 207, 592, 921, 59}, 'image': tensor([[[213., 213., 213.,  ..., 204., 203., 204.],
         [213., 213., 213.,  ..., 204., 204., 205.],
         [215., 215., 215.,  ..., 204., 204., 206.],
         ...,
         [231., 220., 224.,  ..., 173., 172., 169.],
         [231., 222., 224.,  ..., 169., 169., 166.],
         [231., 222., 226.,  ..., 165., 165., 166.]],

        [[207., 207., 207.,  ..., 216., 216., 214.],
         [207., 207., 207.,  ..., 212., 212., 212.],
         [208., 208., 208.,  ..., 209., 211., 211.],
         ...,
         [233., 220., 225.,  ..., 115., 108., 108.],
         [236., 225., 228.,  ...,  93.,  85., 100.],
         [238., 228., 231.,  ...,  77.,  69., 100.]],

        [[200., 200., 200.,  ..., 231., 226., 226.],
         [200., 200., 200.,  ..., 223., 221., 223.],
         [200., 200., 200.,  ..., 218., 218., 220.],
         ...,
         [231., 221., 226.,  ..., 152., 155., 155.],
         [234., 226., 231.,  ..., 152., 155., 158.],
         [236., 228., 234.,  ..., 150., 155., 161.]]]), 'instances': Instances(num_instances=10, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 142.6777,  749.9392,  499.6689, 1024.0000],
        [ 725.4139,  795.8242, 1024.0000, 1024.0000],
        [   0.0000,  844.1821,   12.0990, 1024.0000],
        [ 779.3571,  673.7520, 1024.0000,  874.3272],
        [ 214.8376,    0.0000,  418.0866,   54.8344],
        [ 190.0253,   27.2406,  522.9501,  478.9076],
        [ 779.4357,  114.5752,  931.4897,  291.7564],
        [ 856.8957,  532.2504, 1024.0000,  613.5009],
        [ 691.3755,  553.7601,  770.1310,  621.9792],
        [ 676.4959,  297.1731,  768.6392,  365.7847]])), gt_classes: tensor([419, 419, 419, 675,  57, 646, 646, 324, 324, 324])])}], 'support_set_target': tensor(324)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000210804.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 1061, 1074, 564, 608, 654, 35, 113, 230, 384, 846, 318, 365], 'image_id': 210804, 'annotations': [{'bbox': [306.71, 441.92, 120.29, 48.55], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 307}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000210804.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 1061, 1074, 564, 608, 654, 35, 113, 230, 384, 846, 318, 365], 'image_id': 210804, 'image': tensor([[[223., 223., 223.,  ..., 220., 219., 219.],
         [223., 223., 223.,  ..., 220., 219., 219.],
         [223., 223., 223.,  ..., 219., 219., 219.],
         ...,
         [ 78.,  72.,  75.,  ..., 133., 135., 139.],
         [ 83.,  73.,  74.,  ..., 129., 131., 138.],
         [ 89.,  82.,  82.,  ..., 137., 142., 148.]],

        [[235., 235., 235.,  ..., 225., 224., 224.],
         [235., 235., 235.,  ..., 225., 224., 224.],
         [235., 235., 235.,  ..., 224., 224., 224.],
         ...,
         [100.,  95.,  96.,  ..., 153., 154., 157.],
         [106.,  96.,  96.,  ..., 148., 150., 155.],
         [112., 105., 104.,  ..., 155., 160., 165.]],

        [[237., 237., 237.,  ..., 226., 225., 225.],
         [237., 237., 237.,  ..., 226., 225., 225.],
         [237., 237., 237.,  ..., 225., 225., 225.],
         ...,
         [118., 112., 114.,  ..., 170., 171., 174.],
         [122., 112., 112.,  ..., 165., 167., 172.],
         [128., 121., 119.,  ..., 172., 176., 181.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  877.2360,  234.1798, 1022.2791]])), gt_classes: tensor([307])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000175469.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [666, 74, 1029, 107, 487, 37, 621], 'image_id': 175469, 'annotations': [{'bbox': [320.44, 117.61, 132.41, 122.02], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 307}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000175469.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [666, 74, 1029, 107, 487, 37, 621], 'image_id': 175469, 'image': tensor([[[ 60.,  66.,  67.,  ..., 127., 127., 127.],
         [ 65.,  67.,  66.,  ..., 127., 127., 127.],
         [ 62.,  60.,  59.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[105., 107., 109.,  ..., 127., 127., 127.],
         [110., 112., 112.,  ..., 127., 127., 127.],
         [115., 117., 118.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 78.,  85.,  89.,  ..., 127., 127., 127.],
         [ 83.,  84.,  85.,  ..., 127., 127., 127.],
         [ 89.,  86.,  85.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[249.4359, 156.8133, 425.9136, 319.5067]])), gt_classes: tensor([307])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000527163.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [602, 709, 807, 736, 1172, 521, 653, 1105, 860, 569, 158, 1156, 956, 46], 'image_id': 527163, 'annotations': [{'bbox': [393.91, 294.49, 141.17, 59.35], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 307}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000527163.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [602, 709, 807, 736, 1172, 521, 653, 1105, 860, 569, 158, 1156, 956, 46], 'image_id': 527163, 'image': tensor([[[166., 167., 168.,  ..., 239., 239., 239.],
         [166., 167., 168.,  ..., 239., 239., 239.],
         [167., 168., 169.,  ..., 238., 238., 238.],
         ...,
         [ 66.,  37.,   7.,  ..., 136., 140., 144.],
         [ 76.,  53.,  28.,  ..., 142., 134., 125.],
         [ 86.,  69.,  51.,  ..., 148., 127., 105.]],

        [[154., 154., 154.,  ..., 249., 249., 249.],
         [154., 154., 154.,  ..., 248., 248., 248.],
         [155., 155., 154.,  ..., 247., 247., 247.],
         ...,
         [ 75.,  41.,   7.,  ..., 178., 182., 186.],
         [100.,  73.,  44.,  ..., 183., 175., 166.],
         [125., 106.,  83.,  ..., 187., 166., 145.]],

        [[144., 146., 148.,  ..., 249., 249., 249.],
         [144., 147., 149.,  ..., 249., 249., 249.],
         [145., 148., 151.,  ..., 250., 250., 250.],
         ...,
         [ 83.,  53.,  23.,  ..., 213., 217., 221.],
         [111.,  83.,  53.,  ..., 219., 210., 201.],
         [140., 115.,  86.,  ..., 225., 203., 180.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[131.3975, 522.3856, 422.5606, 644.7950]])), gt_classes: tensor([307])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000040325.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [330], 'neg_category_ids': [518, 968, 396, 441, 400, 576, 577, 514], 'image_id': 40325, 'annotations': [{'bbox': [117.95, 94.5, 412.63, 256.84], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 307}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000040325.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [330], 'neg_category_ids': [518, 968, 396, 441, 400, 576, 577, 514], 'image_id': 40325, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 168., 173., 177.],
         [253., 255., 255.,  ..., 164., 171., 177.],
         [254., 255., 255.,  ..., 175., 176., 179.]],

        [[187., 188., 189.,  ..., 184., 185., 184.],
         [188., 188., 188.,  ..., 187., 188., 188.],
         [188., 186., 186.,  ..., 190., 190., 190.],
         ...,
         [240., 241., 241.,  ..., 104., 112., 120.],
         [238., 239., 241.,  ..., 100., 110., 122.],
         [241., 243., 243.,  ..., 108., 114., 119.]],

        [[ 99., 100.,  99.,  ..., 117., 119., 120.],
         [102., 102., 103.,  ..., 114., 115., 115.],
         [103., 103., 107.,  ..., 109., 109., 111.],
         ...,
         [207., 209., 211.,  ...,  46.,  48.,  51.],
         [205., 209., 215.,  ...,  42.,  43.,  46.],
         [209., 213., 215.,  ...,  54.,  50.,  48.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  123.9918, 1024.0000,  936.6167]])), gt_classes: tensor([307])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000210804.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 1061, 1074, 564, 608, 654, 35, 113, 230, 384, 846, 318, 365], 'image_id': 210804, 'annotations': [{'bbox': [118.55, 464.99, 254.4, 58.41], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 307}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000210804.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 1061, 1074, 564, 608, 654, 35, 113, 230, 384, 846, 318, 365], 'image_id': 210804, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 44.8843, 816.6127, 755.0594, 979.6130]])), gt_classes: tensor([307])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000320089.jpg', 'height': 478, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [898, 712, 108, 378, 597, 1061, 512, 213, 341, 167], 'image_id': 320089, 'annotations': [{'bbox': [305.39, 285.15, 331.72, 78.4], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 216}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000320089.jpg', 'height': 478, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [898, 712, 108, 378, 597, 1061, 512, 213, 341, 167], 'image_id': 320089, 'image': tensor([[[139., 150., 152.,  ..., 128., 128., 128.],
         [137., 144., 155.,  ..., 128., 128., 128.],
         [135., 144., 154.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[157., 168., 171.,  ..., 128., 128., 128.],
         [155., 162., 173.,  ..., 128., 128., 128.],
         [151., 162., 171.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[218., 227., 229.,  ..., 128., 128., 128.],
         [216., 222., 231.,  ..., 128., 128., 128.],
         [211., 220., 228.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[359.7876, 335.8566, 750.5952, 428.1980]])), gt_classes: tensor([216])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000526801.jpg', 'height': 483, 'width': 640, 'not_exhaustive_category_ids': [670, 781], 'neg_category_ids': [582, 1145, 1047, 926, 1103, 1127, 29, 1195, 889, 332, 186, 144], 'image_id': 526801, 'annotations': [{'bbox': [411.44, 314.86, 98.09, 48.17], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 216}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000526801.jpg', 'height': 483, 'width': 640, 'not_exhaustive_category_ids': [670, 781], 'neg_category_ids': [582, 1145, 1047, 926, 1103, 1127, 29, 1195, 889, 332, 186, 144], 'image_id': 526801, 'image': tensor([[[177., 174., 175.,  ..., 223., 206., 189.],
         [178., 175., 173.,  ..., 217., 208., 189.],
         [177., 176., 173.,  ..., 212., 209., 197.],
         ...,
         [ 74.,  79.,  88.,  ...,   7.,   9.,  11.],
         [ 80.,  81.,  86.,  ...,   8.,  10.,  12.],
         [ 86.,  84.,  84.,  ...,   9.,  11.,  13.]],

        [[151., 148., 148.,  ..., 202., 204., 205.],
         [150., 148., 148.,  ..., 196., 204., 207.],
         [146., 145., 145.,  ..., 198., 206., 207.],
         ...,
         [ 65.,  72.,  75.,  ...,   3.,   4.,   4.],
         [ 64.,  68.,  71.,  ...,   4.,   5.,   6.],
         [ 63.,  66.,  66.,  ...,   5.,   6.,   8.]],

        [[124., 118., 117.,  ..., 217., 207., 195.],
         [120., 113., 110.,  ..., 211., 205., 192.],
         [118., 113., 112.,  ..., 210., 206., 195.],
         ...,
         [ 62.,  72.,  76.,  ...,   2.,   2.,   2.],
         [ 63.,  71.,  72.,  ...,   2.,   2.,   3.],
         [ 64.,  72.,  70.,  ...,   2.,   3.,   4.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 59.7262, 723.8040, 318.8984, 851.0605]])), gt_classes: tensor([216])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000186442.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1044, 1049, 437, 509, 548, 992, 526, 749, 446], 'image_id': 186442, 'annotations': [{'bbox': [0.0, 408.6, 640.0, 71.4], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 216}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000186442.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1044, 1049, 437, 509, 548, 992, 526, 749, 446], 'image_id': 186442, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [ 38.,  27.,  14.,  ...,   1.,   5.,  12.],
         [ 53.,  34.,  18.,  ...,  12.,  12.,  12.],
         [ 73.,  47.,  22.,  ...,  31.,  27.,  16.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [163., 150., 139.,  ...,  69.,  73.,  84.],
         [172., 152., 132.,  ...,  88.,  86.,  88.],
         [185., 156., 125.,  ..., 112., 104.,  91.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [ 80.,  53.,  23.,  ...,  45.,  49.,  60.],
         [ 86.,  51.,  18.,  ...,  64.,  62.,  62.],
         [ 93.,  55.,  16.,  ...,  86.,  79.,  64.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  973.8962, 1024.0000, 1024.0000]])), gt_classes: tensor([216])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000321495.jpg', 'height': 335, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1043, 150, 391, 970, 110, 135, 797, 641, 749, 144, 184, 1161, 297, 363], 'image_id': 321495, 'annotations': [{'bbox': [159.66, 237.52, 60.31, 18.38], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 216}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000321495.jpg', 'height': 335, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1043, 150, 391, 970, 110, 135, 797, 641, 749, 144, 184, 1161, 297, 363], 'image_id': 321495, 'image': tensor([[[188., 188., 188.,  ..., 177., 177., 177.],
         [188., 188., 188.,  ..., 177., 177., 177.],
         [188., 188., 188.,  ..., 177., 177., 178.],
         ...,
         [168., 168., 169.,  ..., 189., 189., 189.],
         [168., 169., 169.,  ..., 188., 188., 189.],
         [168., 169., 169.,  ..., 187., 188., 189.]],

        [[189., 189., 189.,  ..., 176., 176., 176.],
         [189., 189., 189.,  ..., 176., 176., 176.],
         [189., 189., 189.,  ..., 176., 176., 176.],
         ...,
         [165., 166., 166.,  ..., 189., 190., 190.],
         [166., 166., 166.,  ..., 188., 189., 190.],
         [166., 166., 166.,  ..., 188., 189., 189.]],

        [[189., 189., 189.,  ..., 180., 180., 180.],
         [189., 189., 189.,  ..., 180., 180., 180.],
         [189., 189., 189.,  ..., 180., 180., 180.],
         ...,
         [164., 164., 164.,  ..., 189., 190., 190.],
         [164., 164., 165.,  ..., 188., 189., 190.],
         [164., 165., 165.,  ..., 188., 189., 189.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[264.7760, 782.0720, 481.8920, 848.2401]])), gt_classes: tensor([216])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000263434.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [127], 'neg_category_ids': [540, 436, 646, 865, 751, 622, 871, 978, 342], 'image_id': 263434, 'annotations': [{'bbox': [446.64, 328.64, 128.74, 65.09], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 216}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000263434.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [127], 'neg_category_ids': [540, 436, 646, 865, 751, 622, 871, 978, 342], 'image_id': 263434, 'image': tensor([[[ 96.,  96.,  97.,  ..., 106., 108., 107.],
         [ 97.,  98.,  98.,  ..., 107., 108., 107.],
         [ 99., 100.,  99.,  ..., 107., 108., 107.],
         ...,
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.]],

        [[ 96.,  96.,  97.,  ..., 109., 110., 110.],
         [ 97.,  98.,  98.,  ..., 110., 110., 110.],
         [ 99., 100.,  99.,  ..., 110., 110., 110.],
         ...,
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.]],

        [[101., 101., 100.,  ..., 110., 109., 111.],
         [102., 102., 101.,  ..., 110., 110., 111.],
         [103., 104., 103.,  ..., 111., 110., 111.],
         ...,
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 74.2482, 555.9493, 291.8992, 666.0599]])), gt_classes: tensor([216])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000311240.jpg', 'height': 500, 'width': 335, 'not_exhaustive_category_ids': [], 'neg_category_ids': [691, 1073, 653, 134, 228, 550, 444, 1179, 576], 'image_id': 311240, 'annotations': [{'bbox': [79.49, 73.31, 9.42, 7.61], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 57}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000311240.jpg', 'height': 500, 'width': 335, 'not_exhaustive_category_ids': [], 'neg_category_ids': [691, 1073, 653, 134, 228, 550, 444, 1179, 576], 'image_id': 311240, 'image': tensor([[[ 67.,  67.,  71.,  ..., 211., 212., 212.],
         [ 66.,  66.,  71.,  ..., 211., 212., 212.],
         [ 66.,  66.,  71.,  ..., 211., 212., 212.],
         ...,
         [125., 125., 125.,  ..., 109., 109., 108.],
         [129., 129., 129.,  ..., 108., 108., 108.],
         [131., 131., 131.,  ..., 106., 108., 109.]],

        [[ 41.,  42.,  45.,  ..., 185., 186., 187.],
         [ 40.,  41.,  45.,  ..., 185., 186., 187.],
         [ 40.,  41.,  45.,  ..., 185., 186., 187.],
         ...,
         [161., 161., 161.,  ..., 155., 155., 154.],
         [161., 162., 162.,  ..., 154., 155., 156.],
         [162., 162., 162.,  ..., 153., 156., 158.]],

        [[ 32.,  32.,  35.,  ..., 169., 170., 171.],
         [ 31.,  31.,  35.,  ..., 169., 170., 171.],
         [ 31.,  31.,  35.,  ..., 169., 170., 171.],
         ...,
         [173., 174., 174.,  ..., 176., 174., 174.],
         [172., 172., 172.,  ..., 175., 176., 176.],
         [171., 171., 171.,  ..., 175., 177., 178.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[867.1894, 184.7694, 901.0733, 212.1501]])), gt_classes: tensor([57])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000525360.jpg', 'height': 603, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1166, 1028, 545, 595, 958, 1118], 'image_id': 525360, 'annotations': [{'bbox': [298.13, 122.18, 46.3, 40.52], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 57}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000525360.jpg', 'height': 603, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1166, 1028, 545, 595, 958, 1118], 'image_id': 525360, 'image': tensor([[[151., 150., 150.,  ..., 132., 132., 132.],
         [151., 150., 150.,  ..., 132., 132., 132.],
         [150., 149., 150.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]],

        [[149., 147., 145.,  ..., 132., 132., 132.],
         [148., 147., 146.,  ..., 132., 132., 132.],
         [147., 146., 147.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]],

        [[149., 148., 146.,  ..., 132., 132., 132.],
         [148., 147., 146.,  ..., 132., 132., 132.],
         [147., 146., 147.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[251.2345, 103.9442, 290.5895, 138.4164]])), gt_classes: tensor([57])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000044600.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [75, 556, 967], 'neg_category_ids': [124, 737, 612, 930, 33, 723, 512, 97, 497], 'image_id': 44600, 'annotations': [{'bbox': [470.06, 234.01, 2.79, 2.3], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 57}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000044600.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [75, 556, 967], 'neg_category_ids': [124, 737, 612, 930, 33, 723, 512, 97, 497], 'image_id': 44600, 'image': tensor([[[180., 179., 178.,  ..., 144., 144., 143.],
         [181., 180., 180.,  ..., 145., 145., 144.],
         [181., 180., 180.,  ..., 145., 145., 144.],
         ...,
         [232., 234., 235.,  ..., 226., 226., 225.],
         [229., 231., 233.,  ..., 214., 214., 220.],
         [225., 228., 231.,  ..., 203., 202., 216.]],

        [[134., 133., 132.,  ...,  83.,  83.,  82.],
         [134., 133., 133.,  ...,  83.,  83.,  82.],
         [133., 133., 133.,  ...,  83.,  83.,  82.],
         ...,
         [227., 229., 230.,  ..., 221., 221., 220.],
         [224., 226., 228.,  ..., 209., 209., 215.],
         [220., 223., 226.,  ..., 198., 197., 211.]],

        [[107., 106., 105.,  ...,  43.,  43.,  42.],
         [107., 106., 106.,  ...,  43.,  43.,  42.],
         [107., 106., 106.,  ...,  43.,  43.,  42.],
         ...,
         [228., 230., 231.,  ..., 222., 222., 221.],
         [225., 227., 229.,  ..., 210., 210., 216.],
         [221., 224., 227.,  ..., 199., 198., 212.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1008.6497,  464.3902, 1014.6424,  469.3280]])), gt_classes: tensor([57])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000129129.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [502, 1035, 964, 75, 967], 'neg_category_ids': [300, 1123, 73, 1050, 437, 858, 957, 1086, 337], 'image_id': 129129, 'annotations': [{'bbox': [135.03, 112.76, 8.32, 7.43], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 57}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000129129.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [502, 1035, 964, 75, 967], 'neg_category_ids': [300, 1123, 73, 1050, 437, 858, 957, 1086, 337], 'image_id': 129129, 'image': tensor([[[168., 168., 168.,  ..., 191., 191., 191.],
         [173., 173., 168.,  ..., 191., 191., 191.],
         [173., 173., 173.,  ..., 184., 191., 191.],
         ...,
         [236., 236., 232.,  ...,  96.,  96.,  97.],
         [236., 232., 229.,  ...,  96.,  97.,  98.],
         [229., 229., 220.,  ...,  98.,  98.,  98.]],

        [[144., 144., 146.,  ..., 156., 156., 156.],
         [144., 144., 146.,  ..., 156., 156., 156.],
         [142., 144., 146.,  ..., 156., 156., 156.],
         ...,
         [252., 249., 245.,  ...,  84.,  84.,  85.],
         [251., 247., 243.,  ...,  85.,  85.,  85.],
         [240., 236., 231.,  ...,  85.,  85.,  85.]],

        [[131., 131., 132.,  ..., 142., 142., 142.],
         [130., 131., 132.,  ..., 142., 142., 142.],
         [130., 130., 131.,  ..., 142., 142., 142.],
         ...,
         [250., 244., 238.,  ...,  74.,  74.,  75.],
         [248., 243., 236.,  ...,  74.,  74.,  76.],
         [238., 234., 229.,  ...,  76.,  76.,  76.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000185906.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [496], 'neg_category_ids': [736, 436, 153, 1077, 613, 59, 1083, 37], 'image_id': 185906, 'annotations': [{'bbox': [151.01, 229.9, 79.09, 66.27], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 57}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000185906.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [496], 'neg_category_ids': [736, 436, 153, 1077, 613, 59, 1083, 37], 'image_id': 185906, 'image': tensor([[[133., 132., 132.,  ..., 146., 144., 141.],
         [134., 133., 133.,  ..., 144., 140., 139.],
         [134., 133., 133.,  ..., 142., 137., 136.],
         ...,
         [156., 157., 159.,  ..., 118., 116., 115.],
         [157., 160., 160.,  ..., 119., 115., 114.],
         [163., 166., 164.,  ..., 118., 112., 112.]],

        [[153., 153., 153.,  ..., 130., 136., 135.],
         [155., 154., 154.,  ..., 131., 133., 132.],
         [156., 155., 155.,  ..., 132., 130., 129.],
         ...,
         [103., 106., 111.,  ...,  95.,  86.,  90.],
         [105., 109., 112.,  ...,  95.,  83.,  87.],
         [107., 113., 115.,  ...,  96.,  86.,  89.]],

        [[185., 185., 184.,  ..., 126., 130., 128.],
         [184., 184., 183.,  ..., 124., 127., 129.],
         [184., 183., 183.,  ..., 121., 124., 129.],
         ...,
         [ 71.,  74.,  77.,  ...,  84.,  91.,  90.],
         [ 75.,  78.,  79.,  ...,  85.,  93.,  90.],
         [ 90.,  91.,  88.,  ...,  83.,  91.,  86.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 75.8283, 483.0185, 275.2834, 650.2122]])), gt_classes: tensor([57])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000320089.jpg', 'height': 478, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [898, 712, 108, 378, 597, 1061, 512, 213, 341, 167], 'image_id': 320089, 'image': tensor([[[139., 150., 152.,  ..., 128., 128., 128.],
         [137., 144., 155.,  ..., 128., 128., 128.],
         [135., 144., 154.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[157., 168., 171.,  ..., 128., 128., 128.],
         [155., 162., 173.,  ..., 128., 128., 128.],
         [151., 162., 171.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[218., 227., 229.,  ..., 128., 128., 128.],
         [216., 222., 231.,  ..., 128., 128., 128.],
         [211., 220., 228.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[359.7876, 335.8566, 750.5952, 428.1980]])), gt_classes: tensor([216])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000526801.jpg', 'height': 483, 'width': 640, 'not_exhaustive_category_ids': [670, 781], 'neg_category_ids': [582, 1145, 1047, 926, 1103, 1127, 29, 1195, 889, 332, 186, 144], 'image_id': 526801, 'image': tensor([[[177., 174., 175.,  ..., 223., 206., 189.],
         [178., 175., 173.,  ..., 217., 208., 189.],
         [177., 176., 173.,  ..., 212., 209., 197.],
         ...,
         [ 74.,  79.,  88.,  ...,   7.,   9.,  11.],
         [ 80.,  81.,  86.,  ...,   8.,  10.,  12.],
         [ 86.,  84.,  84.,  ...,   9.,  11.,  13.]],

        [[151., 148., 148.,  ..., 202., 204., 205.],
         [150., 148., 148.,  ..., 196., 204., 207.],
         [146., 145., 145.,  ..., 198., 206., 207.],
         ...,
         [ 65.,  72.,  75.,  ...,   3.,   4.,   4.],
         [ 64.,  68.,  71.,  ...,   4.,   5.,   6.],
         [ 63.,  66.,  66.,  ...,   5.,   6.,   8.]],

        [[124., 118., 117.,  ..., 217., 207., 195.],
         [120., 113., 110.,  ..., 211., 205., 192.],
         [118., 113., 112.,  ..., 210., 206., 195.],
         ...,
         [ 62.,  72.,  76.,  ...,   2.,   2.,   2.],
         [ 63.,  71.,  72.,  ...,   2.,   2.,   3.],
         [ 64.,  72.,  70.,  ...,   2.,   3.,   4.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 59.7262, 723.8040, 318.8984, 851.0605]])), gt_classes: tensor([216])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000186442.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1044, 1049, 437, 509, 548, 992, 526, 749, 446], 'image_id': 186442, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [ 38.,  27.,  14.,  ...,   1.,   5.,  12.],
         [ 53.,  34.,  18.,  ...,  12.,  12.,  12.],
         [ 73.,  47.,  22.,  ...,  31.,  27.,  16.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [163., 150., 139.,  ...,  69.,  73.,  84.],
         [172., 152., 132.,  ...,  88.,  86.,  88.],
         [185., 156., 125.,  ..., 112., 104.,  91.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [ 80.,  53.,  23.,  ...,  45.,  49.,  60.],
         [ 86.,  51.,  18.,  ...,  64.,  62.,  62.],
         [ 93.,  55.,  16.,  ...,  86.,  79.,  64.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  973.8962, 1024.0000, 1024.0000]])), gt_classes: tensor([216])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000321495.jpg', 'height': 335, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1043, 150, 391, 970, 110, 135, 797, 641, 749, 144, 184, 1161, 297, 363], 'image_id': 321495, 'image': tensor([[[188., 188., 188.,  ..., 177., 177., 177.],
         [188., 188., 188.,  ..., 177., 177., 177.],
         [188., 188., 188.,  ..., 177., 177., 178.],
         ...,
         [168., 168., 169.,  ..., 189., 189., 189.],
         [168., 169., 169.,  ..., 188., 188., 189.],
         [168., 169., 169.,  ..., 187., 188., 189.]],

        [[189., 189., 189.,  ..., 176., 176., 176.],
         [189., 189., 189.,  ..., 176., 176., 176.],
         [189., 189., 189.,  ..., 176., 176., 176.],
         ...,
         [165., 166., 166.,  ..., 189., 190., 190.],
         [166., 166., 166.,  ..., 188., 189., 190.],
         [166., 166., 166.,  ..., 188., 189., 189.]],

        [[189., 189., 189.,  ..., 180., 180., 180.],
         [189., 189., 189.,  ..., 180., 180., 180.],
         [189., 189., 189.,  ..., 180., 180., 180.],
         ...,
         [164., 164., 164.,  ..., 189., 190., 190.],
         [164., 164., 165.,  ..., 188., 189., 190.],
         [164., 165., 165.,  ..., 188., 189., 189.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[264.7760, 782.0720, 481.8920, 848.2401]])), gt_classes: tensor([216])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000263434.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [127], 'neg_category_ids': [540, 436, 646, 865, 751, 622, 871, 978, 342], 'image_id': 263434, 'image': tensor([[[ 96.,  96.,  97.,  ..., 106., 108., 107.],
         [ 97.,  98.,  98.,  ..., 107., 108., 107.],
         [ 99., 100.,  99.,  ..., 107., 108., 107.],
         ...,
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.]],

        [[ 96.,  96.,  97.,  ..., 109., 110., 110.],
         [ 97.,  98.,  98.,  ..., 110., 110., 110.],
         [ 99., 100.,  99.,  ..., 110., 110., 110.],
         ...,
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.]],

        [[101., 101., 100.,  ..., 110., 109., 111.],
         [102., 102., 101.,  ..., 110., 110., 111.],
         [103., 104., 103.,  ..., 111., 110., 111.],
         ...,
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.],
         [109., 109., 109.,  ..., 109., 109., 109.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 74.2482, 555.9493, 291.8992, 666.0599]])), gt_classes: tensor([216])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000388066.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [72, 24, 739, 639, 83, 907, 16, 266, 205, 771, 820, 401, 931, 12, 275, 533, 731], 'image_id': 388066, 'annotations_cat_set': {615, 296, 818, 469, 415}, 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'instances': Instances(num_instances=6, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  851.9612,  412.9132, 1024.0000],
        [   0.0000,    0.0000,  992.4441,  743.4910],
        [ 139.1665,  555.0742,  513.7416,  865.7138],
        [ 558.7757,  387.4524,  964.3920,  757.9301],
        [ 204.6806,  132.9082, 1024.0000,  397.5509],
        [   0.0000,  214.4270, 1024.0000, 1024.0000]])), gt_classes: tensor([335, 216, 295, 295, 435, 577])])}], 'support_set_target': tensor(216)}
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000311240.jpg', 'height': 500, 'width': 335, 'not_exhaustive_category_ids': [], 'neg_category_ids': [691, 1073, 653, 134, 228, 550, 444, 1179, 576], 'image_id': 311240, 'image': tensor([[[ 67.,  67.,  71.,  ..., 211., 212., 212.],
         [ 66.,  66.,  71.,  ..., 211., 212., 212.],
         [ 66.,  66.,  71.,  ..., 211., 212., 212.],
         ...,
         [125., 125., 125.,  ..., 109., 109., 108.],
         [129., 129., 129.,  ..., 108., 108., 108.],
         [131., 131., 131.,  ..., 106., 108., 109.]],

        [[ 41.,  42.,  45.,  ..., 185., 186., 187.],
         [ 40.,  41.,  45.,  ..., 185., 186., 187.],
         [ 40.,  41.,  45.,  ..., 185., 186., 187.],
         ...,
         [161., 161., 161.,  ..., 155., 155., 154.],
         [161., 162., 162.,  ..., 154., 155., 156.],
         [162., 162., 162.,  ..., 153., 156., 158.]],

        [[ 32.,  32.,  35.,  ..., 169., 170., 171.],
         [ 31.,  31.,  35.,  ..., 169., 170., 171.],
         [ 31.,  31.,  35.,  ..., 169., 170., 171.],
         ...,
         [173., 174., 174.,  ..., 176., 174., 174.],
         [172., 172., 172.,  ..., 175., 176., 176.],
         [171., 171., 171.,  ..., 175., 177., 178.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[867.1894, 184.7694, 901.0733, 212.1501]])), gt_classes: tensor([57])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000525360.jpg', 'height': 603, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1166, 1028, 545, 595, 958, 1118], 'image_id': 525360, 'image': tensor([[[151., 150., 150.,  ..., 132., 132., 132.],
         [151., 150., 150.,  ..., 132., 132., 132.],
         [150., 149., 150.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]],

        [[149., 147., 145.,  ..., 132., 132., 132.],
         [148., 147., 146.,  ..., 132., 132., 132.],
         [147., 146., 147.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]],

        [[149., 148., 146.,  ..., 132., 132., 132.],
         [148., 147., 146.,  ..., 132., 132., 132.],
         [147., 146., 147.,  ..., 132., 132., 132.],
         ...,
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.],
         [132., 132., 132.,  ..., 132., 132., 132.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[251.2345, 103.9442, 290.5895, 138.4164]])), gt_classes: tensor([57])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000044600.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [75, 556, 967], 'neg_category_ids': [124, 737, 612, 930, 33, 723, 512, 97, 497], 'image_id': 44600, 'image': tensor([[[180., 179., 178.,  ..., 144., 144., 143.],
         [181., 180., 180.,  ..., 145., 145., 144.],
         [181., 180., 180.,  ..., 145., 145., 144.],
         ...,
         [232., 234., 235.,  ..., 226., 226., 225.],
         [229., 231., 233.,  ..., 214., 214., 220.],
         [225., 228., 231.,  ..., 203., 202., 216.]],

        [[134., 133., 132.,  ...,  83.,  83.,  82.],
         [134., 133., 133.,  ...,  83.,  83.,  82.],
         [133., 133., 133.,  ...,  83.,  83.,  82.],
         ...,
         [227., 229., 230.,  ..., 221., 221., 220.],
         [224., 226., 228.,  ..., 209., 209., 215.],
         [220., 223., 226.,  ..., 198., 197., 211.]],

        [[107., 106., 105.,  ...,  43.,  43.,  42.],
         [107., 106., 106.,  ...,  43.,  43.,  42.],
         [107., 106., 106.,  ...,  43.,  43.,  42.],
         ...,
         [228., 230., 231.,  ..., 222., 222., 221.],
         [225., 227., 229.,  ..., 210., 210., 216.],
         [221., 224., 227.,  ..., 199., 198., 212.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1008.6497,  464.3902, 1014.6424,  469.3280]])), gt_classes: tensor([57])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000185906.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [496], 'neg_category_ids': [736, 436, 153, 1077, 613, 59, 1083, 37], 'image_id': 185906, 'image': tensor([[[133., 132., 132.,  ..., 146., 144., 141.],
         [134., 133., 133.,  ..., 144., 140., 139.],
         [134., 133., 133.,  ..., 142., 137., 136.],
         ...,
         [156., 157., 159.,  ..., 118., 116., 115.],
         [157., 160., 160.,  ..., 119., 115., 114.],
         [163., 166., 164.,  ..., 118., 112., 112.]],

        [[153., 153., 153.,  ..., 130., 136., 135.],
         [155., 154., 154.,  ..., 131., 133., 132.],
         [156., 155., 155.,  ..., 132., 130., 129.],
         ...,
         [103., 106., 111.,  ...,  95.,  86.,  90.],
         [105., 109., 112.,  ...,  95.,  83.,  87.],
         [107., 113., 115.,  ...,  96.,  86.,  89.]],

        [[185., 185., 184.,  ..., 126., 130., 128.],
         [184., 184., 183.,  ..., 124., 127., 129.],
         [184., 183., 183.,  ..., 121., 124., 129.],
         ...,
         [ 71.,  74.,  77.,  ...,  84.,  91.,  90.],
         [ 75.,  78.,  79.,  ...,  85.,  93.,  90.],
         [ 90.,  91.,  88.,  ...,  83.,  91.,  86.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 75.8283, 483.0185, 275.2834, 650.2122]])), gt_classes: tensor([57])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000185906.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [496], 'neg_category_ids': [736, 436, 153, 1077, 613, 59, 1083, 37], 'image_id': 185906, 'image': tensor([[[133., 132., 132.,  ..., 146., 144., 141.],
         [134., 133., 133.,  ..., 144., 140., 139.],
         [134., 133., 133.,  ..., 142., 137., 136.],
         ...,
         [156., 157., 159.,  ..., 118., 116., 115.],
         [157., 160., 160.,  ..., 119., 115., 114.],
         [163., 166., 164.,  ..., 118., 112., 112.]],

        [[153., 153., 153.,  ..., 130., 136., 135.],
         [155., 154., 154.,  ..., 131., 133., 132.],
         [156., 155., 155.,  ..., 132., 130., 129.],
         ...,
         [103., 106., 111.,  ...,  95.,  86.,  90.],
         [105., 109., 112.,  ...,  95.,  83.,  87.],
         [107., 113., 115.,  ...,  96.,  86.,  89.]],

        [[185., 185., 184.,  ..., 126., 130., 128.],
         [184., 184., 183.,  ..., 124., 127., 129.],
         [184., 183., 183.,  ..., 121., 124., 129.],
         ...,
         [ 71.,  74.,  77.,  ...,  84.,  91.,  90.],
         [ 75.,  78.,  79.,  ...,  85.,  93.,  90.],
         [ 90.,  91.,  88.,  ...,  83.,  91.,  86.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 75.8283, 483.0185, 275.2834, 650.2122]])), gt_classes: tensor([57])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000530216.jpg', 'height': 335, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [454, 150, 1168, 54, 717, 59, 891, 1063, 662], 'image_id': 530216, 'annotations_cat_set': {75, 592, 1043, 500, 981, 951, 793, 474}, 'image': tensor([[[ 0.,  1.,  2.,  ...,  8.,  8.,  7.],
         [ 0.,  1.,  2.,  ...,  8.,  8.,  7.],
         [ 1.,  1.,  1.,  ...,  7.,  8.,  7.],
         ...,
         [18., 18., 18.,  ..., 19., 20., 20.],
         [18., 17., 17.,  ..., 17., 17., 17.],
         [17., 17., 16.,  ..., 15., 15., 15.]],

        [[ 2.,  3.,  4.,  ...,  9.,  9.,  9.],
         [ 2.,  3.,  4.,  ...,  9.,  9.,  9.],
         [ 3.,  3.,  3.,  ...,  9.,  9.,  9.],
         ...,
         [30., 29., 29.,  ..., 29., 30., 30.],
         [30., 29., 29.,  ..., 28., 28., 28.],
         [30., 29., 29.,  ..., 26., 26., 26.]],

        [[ 1.,  1.,  2.,  ...,  8.,  8.,  8.],
         [ 1.,  1.,  2.,  ...,  8.,  8.,  8.],
         [ 1.,  2.,  2.,  ...,  8.,  8.,  8.],
         ...,
         [27., 27., 27.,  ..., 26., 27., 27.],
         [27., 27., 27.,  ..., 25., 24., 25.],
         [27., 27., 26.,  ..., 23., 22., 23.]]]), 'instances': Instances(num_instances=17, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 255.4708,  824.7910,  288.2398,  856.9023],
        [ 186.0269,  572.8659,  334.8115,  740.5070],
        [ 527.0894,  412.9382,  680.9051,  619.3115],
        [   0.0000,  394.7307,  113.8690,  587.2332],
        [ 190.3631,  391.8175,  334.5136,  623.8467],
        [ 976.2895,  402.6427, 1024.0000,  602.7261],
        [ 262.0908,  375.5301,  322.3990,  428.7290],
        [ 590.2773,  367.8830,  640.0597,  419.9894],
        [  33.1381,  243.8074,  113.9021,  275.3560],
        [   0.0000,  569.9196,   79.8753,  766.3285],
        [ 525.0372,  593.9866,  664.5537,  800.1944],
        [ 974.2373,  577.0371, 1024.0000,  741.6326],
        [ 136.4763,  359.8055,  335.1425,  893.6483],
        [   0.0000,  340.4725,  112.9422,  781.4572],
        [ 525.2027,  368.4127,  680.1107,  801.5186],
        [ 947.5587,  403.8014, 1024.0000,  816.7135],
        [ 137.6017,  361.2621,  193.1435,  405.6221]])), gt_classes: tensor([690, 667, 733, 733, 733, 733,  57,  57, 340, 419, 419, 419, 560, 560,
        560, 560, 357])])}], 'support_set_target': tensor(57)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000008045.jpg', 'height': 495, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [120, 1165, 1045, 347, 393, 30, 1120, 465, 892, 494, 361, 513, 1000], 'image_id': 8045, 'annotations': [{'bbox': [161.96, 83.71, 33.21, 24.57], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 670}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000008045.jpg', 'height': 495, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [120, 1165, 1045, 347, 393, 30, 1120, 465, 892, 494, 361, 513, 1000], 'image_id': 8045, 'image': tensor([[[148., 146., 146.,  ..., 116., 116., 116.],
         [146., 145., 145.,  ..., 116., 116., 116.],
         [146., 145., 145.,  ..., 116., 116., 116.],
         ...,
         [  0.,   0.,   0.,  ..., 113., 113., 114.],
         [  0.,   0.,   0.,  ..., 113., 113., 113.],
         [  0.,   0.,   0.,  ..., 113., 113., 113.]],

        [[152., 150., 150.,  ..., 122., 122., 120.],
         [150., 150., 150.,  ..., 122., 122., 120.],
         [150., 150., 150.,  ..., 122., 122., 120.],
         ...,
         [  0.,   0.,   0.,  ...,  94.,  94.,  96.],
         [  0.,   0.,   0.,  ...,  94.,  94.,  94.],
         [  0.,   0.,   0.,  ...,  94.,  94.,  94.]],

        [[175., 173., 173.,  ..., 137., 137., 139.],
         [175., 173., 173.,  ..., 137., 137., 139.],
         [175., 173., 173.,  ..., 137., 137., 139.],
         ...,
         [ 21.,  19.,  17.,  ...,  94.,  94.,  96.],
         [ 24.,  23.,  21.,  ...,  94.,  94.,  94.],
         [ 26.,  24.,  21.,  ...,  94.,  94.,  94.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000118256.jpg', 'height': 334, 'width': 500, 'not_exhaustive_category_ids': [1071], 'neg_category_ids': [21, 1002, 586, 696, 740, 1065, 909, 996, 937], 'image_id': 118256, 'annotations': [{'bbox': [61.34, 141.0, 37.49, 67.82], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 670}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000118256.jpg', 'height': 334, 'width': 500, 'not_exhaustive_category_ids': [1071], 'neg_category_ids': [21, 1002, 586, 696, 740, 1065, 909, 996, 937], 'image_id': 118256, 'image': tensor([[[ 57.,  57.,  57.,  ...,  52.,  53.,  53.],
         [ 57.,  57.,  57.,  ...,  52.,  53.,  53.],
         [ 57.,  57.,  57.,  ...,  52.,  53.,  53.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[153., 153., 153.,  ..., 154., 154., 153.],
         [153., 153., 153.,  ..., 154., 154., 153.],
         [153., 153., 153.,  ..., 155., 154., 154.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[223., 223., 223.,  ..., 247., 247., 247.],
         [223., 223., 223.,  ..., 247., 247., 247.],
         [223., 223., 223.,  ..., 247., 247., 247.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000539755.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [279, 876, 369, 1187, 793, 1080, 1173, 952], 'image_id': 539755, 'annotations': [{'bbox': [33.21, 33.03, 50.06, 21.45], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 670}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000539755.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [279, 876, 369, 1187, 793, 1080, 1173, 952], 'image_id': 539755, 'image': tensor([[[ 8.,  8.,  8.,  ..., 43., 43., 43.],
         [ 9.,  9.,  9.,  ..., 43., 43., 43.],
         [ 9.,  9.,  9.,  ..., 43., 43., 43.],
         ...,
         [43., 43., 43.,  ..., 43., 43., 43.],
         [43., 43., 43.,  ..., 43., 43., 43.],
         [43., 43., 43.,  ..., 43., 43., 43.]],

        [[ 7.,  7.,  7.,  ..., 36., 36., 36.],
         [ 7.,  7.,  8.,  ..., 36., 36., 36.],
         [ 8.,  8.,  8.,  ..., 36., 36., 36.],
         ...,
         [36., 36., 36.,  ..., 36., 36., 36.],
         [36., 36., 36.,  ..., 36., 36., 36.],
         [36., 36., 36.,  ..., 36., 36., 36.]],

        [[ 8.,  8.,  8.,  ..., 30., 30., 30.],
         [ 8.,  8.,  8.,  ..., 30., 30., 30.],
         [ 8.,  8.,  9.,  ..., 30., 30., 30.],
         ...,
         [30., 30., 30.,  ..., 30., 30., 30.],
         [30., 30., 30.,  ..., 30., 30., 30.],
         [30., 30., 30.,  ..., 30., 30., 30.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[494.0979,  29.3141, 538.5261,  48.3510]])), gt_classes: tensor([670])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000178785.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [957], 'neg_category_ids': [174, 404, 796, 194], 'image_id': 178785, 'annotations': [{'bbox': [440.0, 91.56, 38.47, 30.27], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 670}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000178785.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [957], 'neg_category_ids': [174, 404, 796, 194], 'image_id': 178785, 'image': tensor([[[103., 103., 104.,  ..., 186., 187., 189.],
         [102., 102., 103.,  ..., 187., 188., 190.],
         [101., 101., 102.,  ..., 187., 189., 191.],
         ...,
         [157., 157., 157.,  ..., 116., 115., 114.],
         [157., 157., 157.,  ..., 115., 115., 114.],
         [158., 157., 156.,  ..., 115., 114., 115.]],

        [[101.,  99.,  97.,  ..., 174., 172., 171.],
         [100.,  99.,  98.,  ..., 177., 177., 176.],
         [100.,  99.,  99.,  ..., 180., 181., 182.],
         ...,
         [144., 145., 146.,  ..., 124., 124., 124.],
         [145., 145., 146.,  ..., 123., 123., 124.],
         [145., 146., 146.,  ..., 123., 123., 123.]],

        [[ 91.,  90.,  89.,  ..., 169., 168., 166.],
         [ 90.,  90.,  89.,  ..., 170., 170., 169.],
         [ 90.,  89.,  90.,  ..., 171., 172., 172.],
         ...,
         [130., 130., 130.,  ..., 113., 113., 112.],
         [131., 131., 131.,  ..., 112., 112., 112.],
         [132., 132., 132.,  ..., 112., 112., 112.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 966.6250,  146.1772, 1024.0000,  230.8702]])), gt_classes: tensor([670])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000442428.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [409, 520, 1007, 591, 274, 204, 819, 796, 821, 68, 894, 916, 533, 1117], 'image_id': 442428, 'annotations': [{'bbox': [399.33, 69.46, 17.17, 10.58], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 670}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000442428.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [409, 520, 1007, 591, 274, 204, 819, 796, 821, 68, 894, 916, 533, 1117], 'image_id': 442428, 'image': tensor([[[176., 175., 174.,  ..., 182., 183., 183.],
         [176., 175., 174.,  ..., 182., 183., 183.],
         [178., 177., 175.,  ..., 182., 183., 183.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[176., 175., 174.,  ..., 183., 184., 184.],
         [176., 175., 174.,  ..., 183., 184., 184.],
         [178., 177., 175.,  ..., 183., 184., 184.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[176., 175., 174.,  ..., 187., 188., 188.],
         [176., 175., 174.,  ..., 187., 188., 188.],
         [178., 177., 175.,  ..., 187., 188., 188.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1017.8821,  178.1880, 1024.0000,  205.3293]])), gt_classes: tensor([670])])}, len instances: 1
not 0
entering support set: 2
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000539755.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [279, 876, 369, 1187, 793, 1080, 1173, 952], 'image_id': 539755, 'image': tensor([[[ 8.,  8.,  8.,  ..., 43., 43., 43.],
         [ 9.,  9.,  9.,  ..., 43., 43., 43.],
         [ 9.,  9.,  9.,  ..., 43., 43., 43.],
         ...,
         [43., 43., 43.,  ..., 43., 43., 43.],
         [43., 43., 43.,  ..., 43., 43., 43.],
         [43., 43., 43.,  ..., 43., 43., 43.]],

        [[ 7.,  7.,  7.,  ..., 36., 36., 36.],
         [ 7.,  7.,  8.,  ..., 36., 36., 36.],
         [ 8.,  8.,  8.,  ..., 36., 36., 36.],
         ...,
         [36., 36., 36.,  ..., 36., 36., 36.],
         [36., 36., 36.,  ..., 36., 36., 36.],
         [36., 36., 36.,  ..., 36., 36., 36.]],

        [[ 8.,  8.,  8.,  ..., 30., 30., 30.],
         [ 8.,  8.,  8.,  ..., 30., 30., 30.],
         [ 8.,  8.,  9.,  ..., 30., 30., 30.],
         ...,
         [30., 30., 30.,  ..., 30., 30., 30.],
         [30., 30., 30.,  ..., 30., 30., 30.],
         [30., 30., 30.,  ..., 30., 30., 30.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[494.0979,  29.3141, 538.5261,  48.3510]])), gt_classes: tensor([670])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000178785.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [957], 'neg_category_ids': [174, 404, 796, 194], 'image_id': 178785, 'image': tensor([[[103., 103., 104.,  ..., 186., 187., 189.],
         [102., 102., 103.,  ..., 187., 188., 190.],
         [101., 101., 102.,  ..., 187., 189., 191.],
         ...,
         [157., 157., 157.,  ..., 116., 115., 114.],
         [157., 157., 157.,  ..., 115., 115., 114.],
         [158., 157., 156.,  ..., 115., 114., 115.]],

        [[101.,  99.,  97.,  ..., 174., 172., 171.],
         [100.,  99.,  98.,  ..., 177., 177., 176.],
         [100.,  99.,  99.,  ..., 180., 181., 182.],
         ...,
         [144., 145., 146.,  ..., 124., 124., 124.],
         [145., 145., 146.,  ..., 123., 123., 124.],
         [145., 146., 146.,  ..., 123., 123., 123.]],

        [[ 91.,  90.,  89.,  ..., 169., 168., 166.],
         [ 90.,  90.,  89.,  ..., 170., 170., 169.],
         [ 90.,  89.,  90.,  ..., 171., 172., 172.],
         ...,
         [130., 130., 130.,  ..., 113., 113., 112.],
         [131., 131., 131.,  ..., 112., 112., 112.],
         [132., 132., 132.,  ..., 112., 112., 112.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 966.6250,  146.1772, 1024.0000,  230.8702]])), gt_classes: tensor([670])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000442428.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [409, 520, 1007, 591, 274, 204, 819, 796, 821, 68, 894, 916, 533, 1117], 'image_id': 442428, 'image': tensor([[[176., 175., 174.,  ..., 182., 183., 183.],
         [176., 175., 174.,  ..., 182., 183., 183.],
         [178., 177., 175.,  ..., 182., 183., 183.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[176., 175., 174.,  ..., 183., 184., 184.],
         [176., 175., 174.,  ..., 183., 184., 184.],
         [178., 177., 175.,  ..., 183., 184., 184.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[176., 175., 174.,  ..., 187., 188., 188.],
         [176., 175., 174.,  ..., 187., 188., 188.],
         [178., 177., 175.,  ..., 187., 188., 188.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1017.8821,  178.1880, 1024.0000,  205.3293]])), gt_classes: tensor([670])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000442428.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [409, 520, 1007, 591, 274, 204, 819, 796, 821, 68, 894, 916, 533, 1117], 'image_id': 442428, 'image': tensor([[[176., 175., 174.,  ..., 182., 183., 183.],
         [176., 175., 174.,  ..., 182., 183., 183.],
         [178., 177., 175.,  ..., 182., 183., 183.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[176., 175., 174.,  ..., 183., 184., 184.],
         [176., 175., 174.,  ..., 183., 184., 184.],
         [178., 177., 175.,  ..., 183., 184., 184.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[176., 175., 174.,  ..., 187., 188., 188.],
         [176., 175., 174.,  ..., 187., 188., 188.],
         [178., 177., 175.,  ..., 187., 188., 188.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[1017.8821,  178.1880, 1024.0000,  205.3293]])), gt_classes: tensor([670])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000539755.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [279, 876, 369, 1187, 793, 1080, 1173, 952], 'image_id': 539755, 'image': tensor([[[ 8.,  8.,  8.,  ..., 43., 43., 43.],
         [ 9.,  9.,  9.,  ..., 43., 43., 43.],
         [ 9.,  9.,  9.,  ..., 43., 43., 43.],
         ...,
         [43., 43., 43.,  ..., 43., 43., 43.],
         [43., 43., 43.,  ..., 43., 43., 43.],
         [43., 43., 43.,  ..., 43., 43., 43.]],

        [[ 7.,  7.,  7.,  ..., 36., 36., 36.],
         [ 7.,  7.,  8.,  ..., 36., 36., 36.],
         [ 8.,  8.,  8.,  ..., 36., 36., 36.],
         ...,
         [36., 36., 36.,  ..., 36., 36., 36.],
         [36., 36., 36.,  ..., 36., 36., 36.],
         [36., 36., 36.,  ..., 36., 36., 36.]],

        [[ 8.,  8.,  8.,  ..., 30., 30., 30.],
         [ 8.,  8.,  8.,  ..., 30., 30., 30.],
         [ 8.,  8.,  9.,  ..., 30., 30., 30.],
         ...,
         [30., 30., 30.,  ..., 30., 30., 30.],
         [30., 30., 30.,  ..., 30., 30., 30.],
         [30., 30., 30.,  ..., 30., 30., 30.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[494.0979,  29.3141, 538.5261,  48.3510]])), gt_classes: tensor([670])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000195790.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [323, 631, 257, 75, 605, 76, 484, 701, 746, 90, 359, 823, 43, 513, 601], 'image_id': 195790, 'annotations_cat_set': {65, 68, 261, 1097, 1098, 955, 1055}, 'image': tensor([[[255., 255., 255.,  ...,  95.,  95.,  95.],
         [255., 255., 255.,  ...,  95.,  95.,  95.],
         [255., 255., 255.,  ...,  95.,  95.,  95.],
         ...,
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.],
         [ 95.,  95.,  95.,  ...,  95.,  95.,  95.]],

        [[255., 255., 255.,  ...,  93.,  93.,  93.],
         [255., 255., 255.,  ...,  93.,  93.,  93.],
         [255., 255., 255.,  ...,  93.,  93.,  93.],
         ...,
         [ 93.,  93.,  93.,  ...,  93.,  93.,  93.],
         [ 93.,  93.,  93.,  ...,  93.,  93.,  93.],
         [ 93.,  93.,  93.,  ...,  93.,  93.,  93.]],

        [[255., 255., 255.,  ...,  76.,  76.,  76.],
         [255., 255., 255.,  ...,  76.,  76.,  76.],
         [255., 255., 255.,  ...,  76.,  76.,  76.],
         ...,
         [ 76.,  76.,  76.,  ...,  76.,  76.,  76.],
         [ 76.,  76.,  76.,  ...,  76.,  76.,  76.],
         [ 76.,  76.,  76.,  ...,  76.,  76.,  76.]]]), 'instances': Instances(num_instances=9, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  2.2623, 389.7693,  43.6270, 444.8176],
        [  0.0000, 726.0700, 259.6028, 822.0000],
        [ 86.7528, 271.8380, 308.7957, 437.0985],
        [391.8336, 303.0611, 615.7146, 801.7454],
        [ 89.3493, 249.9008, 310.1582, 667.9521],
        [178.0559,  89.0200, 185.3314, 113.7314],
        [317.6650,  34.3185, 329.5423,  54.9070],
        [327.8455, 243.4147, 348.2194, 256.2713],
        [559.2848, 237.4809, 600.1996, 304.7051]])), gt_classes: tensor([778,  49, 194,  52, 777, 740, 740, 740, 670])])}], 'support_set_target': tensor(670)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000271829.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1020, 459, 817, 331, 678, 444, 1200, 1164], 'image_id': 271829, 'annotations': [{'bbox': [325.67, 85.5, 15.1, 15.56], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 826}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000271829.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1020, 459, 817, 331, 678, 444, 1200, 1164], 'image_id': 271829, 'image': tensor([[[ 87.,  71.,  74.,  ..., 128., 128., 128.],
         [ 76.,  71.,  63.,  ..., 128., 128., 128.],
         [ 65.,  61.,  49.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 74.,  59.,  67.,  ..., 128., 128., 128.],
         [ 60.,  60.,  59.,  ..., 128., 128., 128.],
         [ 59.,  57.,  45.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 88.,  85.,  86.,  ..., 128., 128., 128.],
         [ 69.,  72.,  72.,  ..., 128., 128., 128.],
         [ 70.,  76.,  78.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[349.1183,  91.6560, 365.3055, 108.3363]])), gt_classes: tensor([826])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000158105.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [922, 1124, 594, 134, 891, 1020], 'image_id': 158105, 'annotations': [{'bbox': [274.39, 315.36, 16.5, 12.89], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 826}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000158105.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [922, 1124, 594, 134, 891, 1020], 'image_id': 158105, 'image': tensor([[[  5.,   4.,   3.,  ..., 128., 128., 128.],
         [  6.,   6.,   5.,  ..., 128., 128., 128.],
         [  3.,   3.,   1.,  ..., 128., 128., 128.],
         ...,
         [  2.,   2.,   2.,  ..., 128., 128., 128.],
         [  3.,   3.,   4.,  ..., 128., 128., 128.],
         [  4.,   4.,   5.,  ..., 128., 128., 128.]],

        [[154., 154., 153.,  ..., 128., 128., 128.],
         [154., 154., 153.,  ..., 128., 128., 128.],
         [154., 154., 154.,  ..., 128., 128., 128.],
         ...,
         [  0.,   1.,   2.,  ..., 128., 128., 128.],
         [  1.,   1.,   2.,  ..., 128., 128., 128.],
         [  2.,   2.,   2.,  ..., 128., 128., 128.]],

        [[232., 232., 231.,  ..., 128., 128., 128.],
         [232., 232., 231.,  ..., 128., 128., 128.],
         [231., 231., 231.,  ..., 128., 128., 128.],
         ...,
         [189., 191., 195.,  ..., 128., 128., 128.],
         [184., 185., 191.,  ..., 128., 128., 128.],
         [178., 181., 186.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[372.3103, 513.3577, 404.7946, 538.7551]])), gt_classes: tensor([826])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000155131.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1161, 1133, 29, 461], 'neg_category_ids': [99, 603, 368, 628, 830, 899, 77, 239, 589, 904, 1129, 293, 919], 'image_id': 155131, 'annotations': [{'bbox': [169.97, 216.36, 3.6, 5.48], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 826}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000155131.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1161, 1133, 29, 461], 'neg_category_ids': [99, 603, 368, 628, 830, 899, 77, 239, 589, 904, 1129, 293, 919], 'image_id': 155131, 'image': tensor([[[ 84., 110., 126.,  ..., 116., 115., 115.],
         [ 63.,  78.,  99.,  ..., 118., 117., 116.],
         [ 35.,  34.,  59.,  ..., 120., 118., 117.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 95., 124., 147.,  ..., 111., 112., 112.],
         [ 82.,  99., 126.,  ..., 112., 112., 112.],
         [ 64.,  63.,  94.,  ..., 114., 113., 113.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 88., 123., 148.,  ..., 110., 109., 108.],
         [ 87., 107., 137.,  ..., 108., 107., 106.],
         [ 84.,  83., 118.,  ..., 105., 104., 104.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[749.9487, 351.5850, 755.7988, 360.4900]])), gt_classes: tensor([826])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000016308.jpg', 'height': 640, 'width': 460, 'not_exhaustive_category_ids': [1023, 1161, 177], 'neg_category_ids': [939, 247, 415, 183, 613, 58, 656, 400, 406, 270, 1014, 892, 68, 67, 297, 869, 145, 271], 'image_id': 16308, 'annotations': [{'bbox': [323.55, 190.08, 4.69, 6.8], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 826}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000016308.jpg', 'height': 640, 'width': 460, 'not_exhaustive_category_ids': [1023, 1161, 177], 'neg_category_ids': [939, 247, 415, 183, 613, 58, 656, 400, 406, 270, 1014, 892, 68, 67, 297, 869, 145, 271], 'image_id': 16308, 'image': tensor([[[156., 149., 150.,  ..., 128., 128., 128.],
         [117., 117., 150.,  ..., 128., 128., 128.],
         [149., 110., 123.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[134., 127., 128.,  ..., 128., 128., 128.],
         [ 95.,  95., 128.,  ..., 128., 128., 128.],
         [127.,  88., 101.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[115., 108., 106.,  ..., 128., 128., 128.],
         [ 77.,  73., 106.,  ..., 128., 128., 128.],
         [104.,  66.,  79.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[142.0717, 205.2270, 147.1287, 212.5689]])), gt_classes: tensor([826])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000382731.jpg', 'height': 521, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1123, 784, 1168, 945, 283, 200, 745, 191], 'image_id': 382731, 'annotations': [{'bbox': [498.2, 13.18, 6.6, 13.55], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 826}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000382731.jpg', 'height': 521, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1123, 784, 1168, 945, 283, 200, 745, 191], 'image_id': 382731, 'image': tensor([[[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128.,   0.,   0.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[796.9153,  25.0951, 809.4863,  50.8947]])), gt_classes: tensor([826])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000271829.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1020, 459, 817, 331, 678, 444, 1200, 1164], 'image_id': 271829, 'image': tensor([[[ 87.,  71.,  74.,  ..., 128., 128., 128.],
         [ 76.,  71.,  63.,  ..., 128., 128., 128.],
         [ 65.,  61.,  49.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 74.,  59.,  67.,  ..., 128., 128., 128.],
         [ 60.,  60.,  59.,  ..., 128., 128., 128.],
         [ 59.,  57.,  45.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 88.,  85.,  86.,  ..., 128., 128., 128.],
         [ 69.,  72.,  72.,  ..., 128., 128., 128.],
         [ 70.,  76.,  78.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[349.1183,  91.6560, 365.3055, 108.3363]])), gt_classes: tensor([826])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000158105.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [922, 1124, 594, 134, 891, 1020], 'image_id': 158105, 'image': tensor([[[  5.,   4.,   3.,  ..., 128., 128., 128.],
         [  6.,   6.,   5.,  ..., 128., 128., 128.],
         [  3.,   3.,   1.,  ..., 128., 128., 128.],
         ...,
         [  2.,   2.,   2.,  ..., 128., 128., 128.],
         [  3.,   3.,   4.,  ..., 128., 128., 128.],
         [  4.,   4.,   5.,  ..., 128., 128., 128.]],

        [[154., 154., 153.,  ..., 128., 128., 128.],
         [154., 154., 153.,  ..., 128., 128., 128.],
         [154., 154., 154.,  ..., 128., 128., 128.],
         ...,
         [  0.,   1.,   2.,  ..., 128., 128., 128.],
         [  1.,   1.,   2.,  ..., 128., 128., 128.],
         [  2.,   2.,   2.,  ..., 128., 128., 128.]],

        [[232., 232., 231.,  ..., 128., 128., 128.],
         [232., 232., 231.,  ..., 128., 128., 128.],
         [231., 231., 231.,  ..., 128., 128., 128.],
         ...,
         [189., 191., 195.,  ..., 128., 128., 128.],
         [184., 185., 191.,  ..., 128., 128., 128.],
         [178., 181., 186.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[372.3103, 513.3577, 404.7946, 538.7551]])), gt_classes: tensor([826])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000155131.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [1161, 1133, 29, 461], 'neg_category_ids': [99, 603, 368, 628, 830, 899, 77, 239, 589, 904, 1129, 293, 919], 'image_id': 155131, 'image': tensor([[[ 84., 110., 126.,  ..., 116., 115., 115.],
         [ 63.,  78.,  99.,  ..., 118., 117., 116.],
         [ 35.,  34.,  59.,  ..., 120., 118., 117.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 95., 124., 147.,  ..., 111., 112., 112.],
         [ 82.,  99., 126.,  ..., 112., 112., 112.],
         [ 64.,  63.,  94.,  ..., 114., 113., 113.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 88., 123., 148.,  ..., 110., 109., 108.],
         [ 87., 107., 137.,  ..., 108., 107., 106.],
         [ 84.,  83., 118.,  ..., 105., 104., 104.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[749.9487, 351.5850, 755.7988, 360.4900]])), gt_classes: tensor([826])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000016308.jpg', 'height': 640, 'width': 460, 'not_exhaustive_category_ids': [1023, 1161, 177], 'neg_category_ids': [939, 247, 415, 183, 613, 58, 656, 400, 406, 270, 1014, 892, 68, 67, 297, 869, 145, 271], 'image_id': 16308, 'image': tensor([[[156., 149., 150.,  ..., 128., 128., 128.],
         [117., 117., 150.,  ..., 128., 128., 128.],
         [149., 110., 123.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[134., 127., 128.,  ..., 128., 128., 128.],
         [ 95.,  95., 128.,  ..., 128., 128., 128.],
         [127.,  88., 101.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[115., 108., 106.,  ..., 128., 128., 128.],
         [ 77.,  73., 106.,  ..., 128., 128., 128.],
         [104.,  66.,  79.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[142.0717, 205.2270, 147.1287, 212.5689]])), gt_classes: tensor([826])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000382731.jpg', 'height': 521, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1123, 784, 1168, 945, 283, 200, 745, 191], 'image_id': 382731, 'image': tensor([[[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128.,   0.,   0.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[796.9153,  25.0951, 809.4863,  50.8947]])), gt_classes: tensor([826])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000569046.jpg', 'height': 405, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1044, 261, 57, 287, 778, 12, 1065], 'image_id': 569046, 'annotations_cat_set': {451, 452, 132, 232, 1161, 1046, 183}, 'image': tensor([[[ 50.,  52.,  53.,  ...,  93.,  93.,  93.],
         [ 51.,  53.,  54.,  ...,  93.,  93.,  93.],
         [ 52.,  54.,  55.,  ...,  94.,  94.,  92.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 96.,  97., 100.,  ..., 151., 152., 153.],
         [ 96.,  98., 101.,  ..., 152., 153., 153.],
         [ 97.,  99., 103.,  ..., 154., 155., 154.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[119., 120., 123.,  ..., 177., 178., 178.],
         [119., 121., 124.,  ..., 177., 179., 178.],
         [120., 122., 125.,  ..., 178., 180., 178.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=9, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  566.3710,  556.7761,  715.8881],
        [ 963.3666,  313.0615, 1024.0000,  597.2053],
        [ 745.0959,  378.0370,  945.0001,  601.5441],
        [ 933.0366,  260.9969, 1024.0000,  478.0170],
        [   0.0000,  206.6787,  152.5235,  469.5923],
        [  97.0660,  511.1892,  141.1919,  554.5975],
        [ 863.1512,  558.4096,  975.1405,  652.5345],
        [ 898.5151,  615.2763, 1004.1857,  695.5847],
        [   8.0979,  547.1416,  354.7445,  790.3624]])), gt_classes: tensor([736, 178, 178, 178, 178, 826, 101, 101, 138])])}], 'support_set_target': tensor(826)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000341052.jpg', 'height': 500, 'width': 333, 'not_exhaustive_category_ids': [], 'neg_category_ids': [344, 484, 421, 155, 266, 678, 866, 1137, 363, 364], 'image_id': 341052, 'annotations': [{'bbox': [72.78, 346.44, 138.71, 21.54], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 67}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000341052.jpg', 'height': 500, 'width': 333, 'not_exhaustive_category_ids': [], 'neg_category_ids': [344, 484, 421, 155, 266, 678, 866, 1137, 363, 364], 'image_id': 341052, 'image': tensor([[[ 84.,  85.,  87.,  ...,  74.,  74.,  74.],
         [ 84.,  84.,  86.,  ...,  73.,  73.,  73.],
         [ 83.,  84.,  84.,  ...,  73.,  73.,  73.],
         ...,
         [231., 230., 230.,  ...,  72.,  73.,  75.],
         [231., 230., 230.,  ...,  71.,  73.,  75.],
         [231., 230., 230.,  ...,  72.,  74.,  76.]],

        [[143., 143., 144.,  ..., 130., 130., 130.],
         [143., 142., 143.,  ..., 130., 130., 130.],
         [142., 142., 141.,  ..., 130., 129., 129.],
         ...,
         [245., 243., 243.,  ..., 129., 130., 131.],
         [246., 244., 243.,  ..., 127., 128., 129.],
         [246., 244., 243.,  ..., 127., 128., 129.]],

        [[121., 121., 121.,  ..., 109., 109., 109.],
         [121., 121., 120.,  ..., 108., 108., 109.],
         [121., 120., 119.,  ..., 107., 108., 108.],
         ...,
         [242., 241., 244.,  ..., 111., 114., 116.],
         [242., 242., 244.,  ..., 109., 112., 114.],
         [242., 242., 244.,  ..., 109., 112., 114.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[168.4351, 745.4539, 649.5464, 820.1547]])), gt_classes: tensor([67])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000158420.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [666, 829, 237, 153, 833, 442], 'image_id': 158420, 'annotations': [{'bbox': [574.0, 26.22, 65.15, 32.89], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 67}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000158420.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [666, 829, 237, 153, 833, 442], 'image_id': 158420, 'image': tensor([[[ 83.,  83.,  84.,  ...,  17.,  15.,  13.],
         [ 83.,  83.,  84.,  ...,  18.,  17.,  15.],
         [ 84.,  84.,  84.,  ...,  19.,  21.,  19.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[114., 114., 115.,  ...,  17.,  15.,  13.],
         [114., 114., 115.,  ...,  19.,  18.,  16.],
         [115., 115., 115.,  ...,  23.,  24.,  22.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[165., 165., 168.,  ...,  23.,  21.,  19.],
         [165., 165., 168.,  ...,  24.,  23.,  22.],
         [166., 166., 167.,  ...,  27.,  28.,  27.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 900.0219,   50.8360, 1024.0000,  114.6039]])), gt_classes: tensor([67])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000066524.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [215, 301, 433, 104, 394, 901, 647, 112, 380, 271, 163, 363, 601], 'image_id': 66524, 'annotations': [{'bbox': [206.28, 244.83, 7.77, 1.46], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 67}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000066524.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [215, 301, 433, 104, 394, 901, 647, 112, 380, 271, 163, 363, 601], 'image_id': 66524, 'image': tensor([[[253., 253., 253.,  ..., 128., 128., 128.],
         [254., 254., 254.,  ..., 128., 128., 128.],
         [254., 254., 254.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[247., 247., 247.,  ..., 128., 128., 128.],
         [248., 248., 248.,  ..., 128., 128., 128.],
         [248., 248., 248.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[240., 240., 240.,  ..., 128., 128., 128.],
         [241., 241., 241.,  ..., 128., 128., 128.],
         [243., 243., 243.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[183.7181, 217.8815, 190.6383, 219.1808]])), gt_classes: tensor([67])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000552561.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [941, 322, 508, 133, 423, 576, 1062, 826], 'image_id': 552561, 'annotations': [{'bbox': [311.99, 237.3, 20.66, 7.68], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 67}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000552561.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [941, 322, 508, 133, 423, 576, 1062, 826], 'image_id': 552561, 'image': tensor([[[ 23.,  28.,  28.,  ...,  37.,  36.,  34.],
         [ 24.,  30.,  30.,  ...,  35.,  32.,  30.],
         [ 25.,  31.,  33.,  ...,  32.,  28.,  25.],
         ...,
         [ 80.,  86.,  88.,  ...,  83.,  78.,  74.],
         [ 85.,  93.,  94.,  ...,  83.,  78.,  73.],
         [ 82.,  91.,  94.,  ...,  85.,  80.,  76.]],

        [[ 20.,  23.,  28.,  ...,  24.,  24.,  22.],
         [ 23.,  28.,  34.,  ...,  25.,  23.,  21.],
         [ 27.,  33.,  39.,  ...,  25.,  22.,  19.],
         ...,
         [151., 158., 159.,  ..., 147., 140., 133.],
         [156., 164., 165.,  ..., 147., 139., 131.],
         [152., 162., 164.,  ..., 149., 141., 133.]],

        [[ 32.,  41.,  42.,  ...,  17.,  19.,  20.],
         [ 28.,  37.,  46.,  ...,  14.,  14.,  14.],
         [ 23.,  32.,  50.,  ...,  10.,   9.,   8.],
         ...,
         [125., 132., 133.,  ..., 121., 115., 108.],
         [130., 138., 139.,  ..., 121., 114., 107.],
         [128., 137., 139.,  ..., 123., 116., 110.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[513.7760, 568.4091, 563.3600, 586.8375]])), gt_classes: tensor([67])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000246412.jpg', 'height': 400, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [896, 194, 692, 76, 857, 833, 1115, 1181], 'image_id': 246412, 'annotations': [{'bbox': [219.34, 176.05, 51.99, 19.69], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 67}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000246412.jpg', 'height': 400, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [896, 194, 692, 76, 857, 833, 1115, 1181], 'image_id': 246412, 'image': tensor([[[ 13.,  13.,  13.,  ...,  17.,  20.,  19.],
         [ 13.,  13.,  13.,  ...,  18.,  21.,  21.],
         [ 12.,  13.,  13.,  ...,  26.,  28.,  31.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 14.,  14.,  14.,  ...,  15.,  16.,  19.],
         [ 14.,  14.,  14.,  ...,  16.,  17.,  21.],
         [ 13.,  14.,  14.,  ...,  18.,  24.,  29.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  7.,   7.,   7.,  ...,  73.,  78.,  80.],
         [  7.,   7.,   7.,  ...,  72.,  77.,  81.],
         [  6.,   7.,   7.,  ...,  67.,  74.,  79.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[453.8405, 437.0441, 582.9837, 485.9246]])), gt_classes: tensor([67])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000210804.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 1061, 1074, 564, 608, 654, 35, 113, 230, 384, 846, 318, 365], 'image_id': 210804, 'image': tensor([[[223., 223., 223.,  ..., 220., 219., 219.],
         [223., 223., 223.,  ..., 220., 219., 219.],
         [223., 223., 223.,  ..., 219., 219., 219.],
         ...,
         [ 78.,  72.,  75.,  ..., 133., 135., 139.],
         [ 83.,  73.,  74.,  ..., 129., 131., 138.],
         [ 89.,  82.,  82.,  ..., 137., 142., 148.]],

        [[235., 235., 235.,  ..., 225., 224., 224.],
         [235., 235., 235.,  ..., 225., 224., 224.],
         [235., 235., 235.,  ..., 224., 224., 224.],
         ...,
         [100.,  95.,  96.,  ..., 153., 154., 157.],
         [106.,  96.,  96.,  ..., 148., 150., 155.],
         [112., 105., 104.,  ..., 155., 160., 165.]],

        [[237., 237., 237.,  ..., 226., 225., 225.],
         [237., 237., 237.,  ..., 226., 225., 225.],
         [237., 237., 237.,  ..., 225., 225., 225.],
         ...,
         [118., 112., 114.,  ..., 170., 171., 174.],
         [122., 112., 112.,  ..., 165., 167., 172.],
         [128., 121., 119.,  ..., 172., 176., 181.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  877.2360,  234.1798, 1022.2791]])), gt_classes: tensor([307])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000175469.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [666, 74, 1029, 107, 487, 37, 621], 'image_id': 175469, 'image': tensor([[[ 60.,  66.,  67.,  ..., 127., 127., 127.],
         [ 65.,  67.,  66.,  ..., 127., 127., 127.],
         [ 62.,  60.,  59.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[105., 107., 109.,  ..., 127., 127., 127.],
         [110., 112., 112.,  ..., 127., 127., 127.],
         [115., 117., 118.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[ 78.,  85.,  89.,  ..., 127., 127., 127.],
         [ 83.,  84.,  85.,  ..., 127., 127., 127.],
         [ 89.,  86.,  85.,  ..., 127., 127., 127.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[249.4359, 156.8133, 425.9136, 319.5067]])), gt_classes: tensor([307])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000527163.jpg', 'height': 640, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [602, 709, 807, 736, 1172, 521, 653, 1105, 860, 569, 158, 1156, 956, 46], 'image_id': 527163, 'image': tensor([[[166., 167., 168.,  ..., 239., 239., 239.],
         [166., 167., 168.,  ..., 239., 239., 239.],
         [167., 168., 169.,  ..., 238., 238., 238.],
         ...,
         [ 66.,  37.,   7.,  ..., 136., 140., 144.],
         [ 76.,  53.,  28.,  ..., 142., 134., 125.],
         [ 86.,  69.,  51.,  ..., 148., 127., 105.]],

        [[154., 154., 154.,  ..., 249., 249., 249.],
         [154., 154., 154.,  ..., 248., 248., 248.],
         [155., 155., 154.,  ..., 247., 247., 247.],
         ...,
         [ 75.,  41.,   7.,  ..., 178., 182., 186.],
         [100.,  73.,  44.,  ..., 183., 175., 166.],
         [125., 106.,  83.,  ..., 187., 166., 145.]],

        [[144., 146., 148.,  ..., 249., 249., 249.],
         [144., 147., 149.,  ..., 249., 249., 249.],
         [145., 148., 151.,  ..., 250., 250., 250.],
         ...,
         [ 83.,  53.,  23.,  ..., 213., 217., 221.],
         [111.,  83.,  53.,  ..., 219., 210., 201.],
         [140., 115.,  86.,  ..., 225., 203., 180.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[131.3975, 522.3856, 422.5606, 644.7950]])), gt_classes: tensor([307])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000040325.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [330], 'neg_category_ids': [518, 968, 396, 441, 400, 576, 577, 514], 'image_id': 40325, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 168., 173., 177.],
         [253., 255., 255.,  ..., 164., 171., 177.],
         [254., 255., 255.,  ..., 175., 176., 179.]],

        [[187., 188., 189.,  ..., 184., 185., 184.],
         [188., 188., 188.,  ..., 187., 188., 188.],
         [188., 186., 186.,  ..., 190., 190., 190.],
         ...,
         [240., 241., 241.,  ..., 104., 112., 120.],
         [238., 239., 241.,  ..., 100., 110., 122.],
         [241., 243., 243.,  ..., 108., 114., 119.]],

        [[ 99., 100.,  99.,  ..., 117., 119., 120.],
         [102., 102., 103.,  ..., 114., 115., 115.],
         [103., 103., 107.,  ..., 109., 109., 111.],
         ...,
         [207., 209., 211.,  ...,  46.,  48.,  51.],
         [205., 209., 215.,  ...,  42.,  43.,  46.],
         [209., 213., 215.,  ...,  54.,  50.,  48.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  123.9918, 1024.0000,  936.6167]])), gt_classes: tensor([307])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000210804.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [], 'neg_category_ids': [147, 1061, 1074, 564, 608, 654, 35, 113, 230, 384, 846, 318, 365], 'image_id': 210804, 'image': tensor([[[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [  0.,   0.,   0.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]],

        [[255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         ...,
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.],
         [255., 255., 255.,  ..., 255., 255., 255.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 44.8843, 816.6127, 755.0594, 979.6130]])), gt_classes: tensor([307])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000175193.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [366, 1045, 635, 284, 316, 513, 1120], 'image_id': 175193, 'annotations_cat_set': {434}, 'image': tensor([[[  0.,   0.,   0.,  ...,   1.,   1.,   1.],
         [  0.,   0.,   0.,  ...,   1.,   1.,   1.],
         [  0.,   0.,   0.,  ...,   1.,   1.,   1.],
         ...,
         [108., 107., 106.,  ..., 182., 182., 183.],
         [104., 104., 104.,  ..., 182., 182., 183.],
         [100., 101., 102.,  ..., 182., 182., 183.]],

        [[  0.,   0.,   0.,  ...,   1.,   1.,   1.],
         [  0.,   0.,   0.,  ...,   1.,   1.,   1.],
         [  0.,   0.,   0.,  ...,   1.,   1.,   1.],
         ...,
         [162., 161., 160.,  ..., 206., 206., 207.],
         [160., 160., 160.,  ..., 206., 206., 207.],
         [158., 160., 161.,  ..., 206., 206., 207.]],

        [[  0.,   0.,   0.,  ...,   1.,   1.,   1.],
         [  0.,   0.,   0.,  ...,   1.,   1.,   1.],
         [  0.,   0.,   0.,  ...,   1.,   1.,   1.],
         ...,
         [  0.,   1.,   1.,  ...,   4.,   3.,   2.],
         [  1.,   1.,   1.,  ...,   4.,   3.,   2.],
         [  2.,   2.,   0.,  ...,   4.,   3.,   2.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[360.3615, 789.5032, 558.3110, 920.2228]])), gt_classes: tensor([307])])}], 'support_set_target': tensor(307)}
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000341052.jpg', 'height': 500, 'width': 333, 'not_exhaustive_category_ids': [], 'neg_category_ids': [344, 484, 421, 155, 266, 678, 866, 1137, 363, 364], 'image_id': 341052, 'image': tensor([[[ 84.,  85.,  87.,  ...,  74.,  74.,  74.],
         [ 84.,  84.,  86.,  ...,  73.,  73.,  73.],
         [ 83.,  84.,  84.,  ...,  73.,  73.,  73.],
         ...,
         [231., 230., 230.,  ...,  72.,  73.,  75.],
         [231., 230., 230.,  ...,  71.,  73.,  75.],
         [231., 230., 230.,  ...,  72.,  74.,  76.]],

        [[143., 143., 144.,  ..., 130., 130., 130.],
         [143., 142., 143.,  ..., 130., 130., 130.],
         [142., 142., 141.,  ..., 130., 129., 129.],
         ...,
         [245., 243., 243.,  ..., 129., 130., 131.],
         [246., 244., 243.,  ..., 127., 128., 129.],
         [246., 244., 243.,  ..., 127., 128., 129.]],

        [[121., 121., 121.,  ..., 109., 109., 109.],
         [121., 121., 120.,  ..., 108., 108., 109.],
         [121., 120., 119.,  ..., 107., 108., 108.],
         ...,
         [242., 241., 244.,  ..., 111., 114., 116.],
         [242., 242., 244.,  ..., 109., 112., 114.],
         [242., 242., 244.,  ..., 109., 112., 114.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[168.4351, 745.4539, 649.5464, 820.1547]])), gt_classes: tensor([67])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000158420.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [666, 829, 237, 153, 833, 442], 'image_id': 158420, 'image': tensor([[[ 83.,  83.,  84.,  ...,  17.,  15.,  13.],
         [ 83.,  83.,  84.,  ...,  18.,  17.,  15.],
         [ 84.,  84.,  84.,  ...,  19.,  21.,  19.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[114., 114., 115.,  ...,  17.,  15.,  13.],
         [114., 114., 115.,  ...,  19.,  18.,  16.],
         [115., 115., 115.,  ...,  23.,  24.,  22.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[165., 165., 168.,  ...,  23.,  21.,  19.],
         [165., 165., 168.,  ...,  24.,  23.,  22.],
         [166., 166., 167.,  ...,  27.,  28.,  27.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 900.0219,   50.8360, 1024.0000,  114.6039]])), gt_classes: tensor([67])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000066524.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [215, 301, 433, 104, 394, 901, 647, 112, 380, 271, 163, 363, 601], 'image_id': 66524, 'image': tensor([[[253., 253., 253.,  ..., 128., 128., 128.],
         [254., 254., 254.,  ..., 128., 128., 128.],
         [254., 254., 254.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[247., 247., 247.,  ..., 128., 128., 128.],
         [248., 248., 248.,  ..., 128., 128., 128.],
         [248., 248., 248.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[240., 240., 240.,  ..., 128., 128., 128.],
         [241., 241., 241.,  ..., 128., 128., 128.],
         [243., 243., 243.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[183.7181, 217.8815, 190.6383, 219.1808]])), gt_classes: tensor([67])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000552561.jpg', 'height': 428, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [941, 322, 508, 133, 423, 576, 1062, 826], 'image_id': 552561, 'image': tensor([[[ 23.,  28.,  28.,  ...,  37.,  36.,  34.],
         [ 24.,  30.,  30.,  ...,  35.,  32.,  30.],
         [ 25.,  31.,  33.,  ...,  32.,  28.,  25.],
         ...,
         [ 80.,  86.,  88.,  ...,  83.,  78.,  74.],
         [ 85.,  93.,  94.,  ...,  83.,  78.,  73.],
         [ 82.,  91.,  94.,  ...,  85.,  80.,  76.]],

        [[ 20.,  23.,  28.,  ...,  24.,  24.,  22.],
         [ 23.,  28.,  34.,  ...,  25.,  23.,  21.],
         [ 27.,  33.,  39.,  ...,  25.,  22.,  19.],
         ...,
         [151., 158., 159.,  ..., 147., 140., 133.],
         [156., 164., 165.,  ..., 147., 139., 131.],
         [152., 162., 164.,  ..., 149., 141., 133.]],

        [[ 32.,  41.,  42.,  ...,  17.,  19.,  20.],
         [ 28.,  37.,  46.,  ...,  14.,  14.,  14.],
         [ 23.,  32.,  50.,  ...,  10.,   9.,   8.],
         ...,
         [125., 132., 133.,  ..., 121., 115., 108.],
         [130., 138., 139.,  ..., 121., 114., 107.],
         [128., 137., 139.,  ..., 123., 116., 110.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[513.7760, 568.4091, 563.3600, 586.8375]])), gt_classes: tensor([67])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000246412.jpg', 'height': 400, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [896, 194, 692, 76, 857, 833, 1115, 1181], 'image_id': 246412, 'image': tensor([[[ 13.,  13.,  13.,  ...,  17.,  20.,  19.],
         [ 13.,  13.,  13.,  ...,  18.,  21.,  21.],
         [ 12.,  13.,  13.,  ...,  26.,  28.,  31.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 14.,  14.,  14.,  ...,  15.,  16.,  19.],
         [ 14.,  14.,  14.,  ...,  16.,  17.,  21.],
         [ 13.,  14.,  14.,  ...,  18.,  24.,  29.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  7.,   7.,   7.,  ...,  73.,  78.,  80.],
         [  7.,   7.,   7.,  ...,  72.,  77.,  81.],
         [  6.,   7.,   7.,  ...,  67.,  74.,  79.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[453.8405, 437.0441, 582.9837, 485.9246]])), gt_classes: tensor([67])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000415370.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1044, 518, 1050, 396, 612, 225, 656, 677, 821], 'image_id': 415370, 'annotations_cat_set': {88, 1161, 995}, 'image': tensor([[[201., 204., 210.,  ..., 128., 128., 128.],
         [204., 207., 211.,  ..., 128., 128., 128.],
         [210., 211., 214.,  ..., 128., 128., 128.],
         ...,
         [205., 206., 208.,  ..., 128., 128., 128.],
         [204., 207., 212.,  ..., 128., 128., 128.],
         [197., 208., 221.,  ..., 128., 128., 128.]],

        [[212., 217., 223.,  ..., 128., 128., 128.],
         [217., 220., 225.,  ..., 128., 128., 128.],
         [223., 225., 228.,  ..., 128., 128., 128.],
         ...,
         [228., 227., 225.,  ..., 128., 128., 128.],
         [223., 226., 129.,  ..., 128., 128., 128.],
         [208., 222., 139.,  ..., 128., 128., 128.]],

        [[200., 206., 212.,  ..., 128., 128., 128.],
         [205., 209., 214.,  ..., 128., 128., 128.],
         [211., 213., 216.,  ..., 128., 128., 128.],
         ...,
         [134., 137., 141.,  ..., 128., 128., 128.],
         [131., 137., 145.,  ..., 128., 128., 128.],
         [218., 133., 154.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=3, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[461.4894, 389.3113, 489.3481, 405.2398],
        [282.4071, 209.9538, 340.8440, 247.1527],
        [339.6138, 420.0190, 451.7608, 452.3292]])), gt_classes: tensor([826, 697,  67])])}], 'support_set_target': tensor(67)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000316795.jpg', 'height': 578, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [412, 341, 457, 1169, 1030, 481, 310, 35, 1084, 208, 92, 1160, 1119, 41], 'image_id': 316795, 'annotations': [{'bbox': [328.53, 312.68, 130.26, 155.31], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 736}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000316795.jpg', 'height': 578, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [412, 341, 457, 1169, 1030, 481, 310, 35, 1084, 208, 92, 1160, 1119, 41], 'image_id': 316795, 'image': tensor([[[ 82.,  82.,  81.,  ..., 128., 128., 128.],
         [ 81.,  82.,  82.,  ..., 128., 128., 128.],
         [ 82.,  83.,  83.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 49.,  49.,  48.,  ..., 128., 128., 128.],
         [ 48.,  49.,  49.,  ..., 128., 128., 128.],
         [ 49.,  50.,  50.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[146.1006, 252.0915, 251.1227, 377.3068]])), gt_classes: tensor([736])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000405222.jpg', 'height': 494, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [759, 150, 1072, 391, 196, 310, 648], 'image_id': 405222, 'annotations': [{'bbox': [177.61, 252.62, 3.56, 8.64], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 736}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000405222.jpg', 'height': 494, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [759, 150, 1072, 391, 196, 310, 648], 'image_id': 405222, 'image': tensor([[[ 89.,  87.,  60.,  ...,  63.,  66.,  68.],
         [ 75.,  81.,  65.,  ...,  62.,  63.,  64.],
         [ 73.,  81.,  73.,  ...,  61.,  60.,  60.],
         ...,
         [158., 151., 165.,  ..., 112., 153., 193.],
         [171., 157., 166.,  ..., 119., 163., 206.],
         [184., 168., 170.,  ..., 157., 180., 202.]],

        [[ 89.,  87.,  60.,  ...,  63.,  66.,  68.],
         [ 75.,  81.,  65.,  ...,  62.,  63.,  64.],
         [ 73.,  81.,  73.,  ...,  61.,  60.,  60.],
         ...,
         [158., 151., 165.,  ..., 112., 153., 193.],
         [171., 157., 166.,  ..., 119., 163., 206.],
         [184., 168., 170.,  ..., 157., 180., 202.]],

        [[ 89.,  87.,  60.,  ...,  63.,  66.,  68.],
         [ 75.,  81.,  65.,  ...,  62.,  63.,  64.],
         [ 73.,  81.,  73.,  ...,  61.,  60.,  60.],
         ...,
         [158., 151., 165.,  ..., 112., 153., 193.],
         [171., 157., 166.,  ..., 119., 163., 206.],
         [184., 168., 170.,  ..., 157., 180., 202.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[346.5360, 530.3202, 354.0232, 548.4922]])), gt_classes: tensor([736])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000097683.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [366, 981, 860, 380, 731, 145, 962], 'image_id': 97683, 'annotations': [{'bbox': [189.21, 131.71, 76.06, 14.64], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 736}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000097683.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [366, 981, 860, 380, 731, 145, 962], 'image_id': 97683, 'image': tensor([[[181., 182., 185.,  ...,  17.,  18.,  19.],
         [182., 184., 186.,  ...,  16.,  17.,  19.],
         [183., 184., 187.,  ...,  18.,  19.,  21.],
         ...,
         [ 85.,  85.,  85.,  ...,  22.,  22.,  22.],
         [ 85.,  85.,  85.,  ...,  22.,  22.,  22.],
         [ 85.,  85.,  85.,  ...,  22.,  22.,  22.]],

        [[171., 172., 172.,  ...,  26.,  26.,  26.],
         [172., 173., 174.,  ...,  24.,  24.,  25.],
         [173., 174., 174.,  ...,  25.,  25.,  27.],
         ...,
         [ 89.,  90.,  90.,  ...,  15.,  15.,  15.],
         [ 89.,  90.,  90.,  ...,  15.,  15.,  15.],
         [ 89.,  90.,  90.,  ...,  15.,  15.,  15.]],

        [[168., 168., 169.,  ...,  53.,  52.,  52.],
         [168., 169., 170.,  ...,  52.,  52.,  52.],
         [168., 168., 169.,  ...,  51.,  51.,  52.],
         ...,
         [ 94.,  93.,  93.,  ...,  12.,  12.,  12.],
         [ 94.,  93.,  93.,  ...,  12.,  12.,  12.],
         [ 94.,  93.,  93.,  ...,  12.,  12.,  12.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[126.8778, 272.9306, 371.6389, 320.0519]])), gt_classes: tensor([736])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000574221.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [1008], 'neg_category_ids': [99, 661, 992, 292, 993, 165, 512, 825, 873, 1019], 'image_id': 574221, 'annotations': [{'bbox': [144.15, 419.88, 10.17, 48.41], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 736}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000574221.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [1008], 'neg_category_ids': [99, 661, 992, 292, 993, 165, 512, 825, 873, 1019], 'image_id': 574221, 'image': tensor([[[165., 168., 167.,  ..., 113., 111., 110.],
         [157., 161., 161.,  ..., 109., 109., 109.],
         [142., 147., 150.,  ..., 105., 109., 113.],
         ...,
         [  7.,   7.,   7.,  ...,  26.,  27.,  29.],
         [  6.,   7.,   7.,  ...,  28.,  29.,  31.],
         [  7.,   6.,   5.,  ...,  29.,  30.,  31.]],

        [[201., 203., 203.,  ..., 189., 186., 183.],
         [199., 204., 206.,  ..., 181., 180., 180.],
         [193., 201., 205.,  ..., 171., 174., 178.],
         ...,
         [ 11.,  12.,  12.,  ...,  52.,  50.,  48.],
         [ 10.,  11.,  11.,  ...,  52.,  50.,  48.],
         [ 10.,  10.,   9.,  ...,  51.,  49.,  48.]],

        [[224., 225., 225.,  ..., 213., 214., 215.],
         [222., 226., 227.,  ..., 204., 207., 210.],
         [216., 222., 226.,  ..., 193., 199., 204.],
         ...,
         [ 15.,  13.,  12.,  ...,  83.,  87.,  93.],
         [ 15.,  13.,  12.,  ...,  86.,  91.,  97.],
         [ 16.,  13.,  11.,  ...,  85.,  90.,  95.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 99.5615, 574.4431, 130.8555, 723.4552]])), gt_classes: tensor([736])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000074428.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [29], 'neg_category_ids': [99, 1002, 920, 696, 792, 82, 226, 1059, 843, 120], 'image_id': 74428, 'annotations': [{'bbox': [145.97, 326.47, 70.04, 47.15], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 736}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000074428.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [29], 'neg_category_ids': [99, 1002, 920, 696, 792, 82, 226, 1059, 843, 120], 'image_id': 74428, 'image': tensor([[[ 93.,  94.,  94.,  ...,  58.,  63.,  67.],
         [ 98., 100., 101.,  ...,  59.,  66.,  69.],
         [101., 103., 104.,  ...,  63.,  69.,  71.],
         ...,
         [ 83.,  84.,  85.,  ...,  21.,  20.,  20.],
         [ 76.,  81.,  85.,  ...,  21.,  19.,  20.],
         [ 67.,  74.,  82.,  ...,  20.,  20.,  20.]],

        [[109., 109., 109.,  ...,  91.,  99., 103.],
         [106., 106., 106.,  ...,  94., 102., 104.],
         [107., 107., 107.,  ...,  97., 104., 106.],
         ...,
         [103., 117., 131.,  ...,  18.,  18.,  19.],
         [ 98., 115., 132.,  ...,  18.,  19.,  20.],
         [ 92., 110., 129.,  ...,  19.,  20.,  20.]],

        [[128., 129., 130.,  ...,  72.,  78.,  80.],
         [132., 132., 133.,  ...,  77.,  83.,  83.],
         [135., 136., 137.,  ...,  79.,  85.,  85.],
         ...,
         [ 94., 100., 108.,  ...,  18.,  14.,  17.],
         [ 89.,  98., 108.,  ...,  17.,  13.,  16.],
         [ 84.,  95., 107.,  ...,  15.,  13.,  16.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[247.1881, 776.0537, 420.9748, 893.0446]])), gt_classes: tensor([736])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000316795.jpg', 'height': 578, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [412, 341, 457, 1169, 1030, 481, 310, 35, 1084, 208, 92, 1160, 1119, 41], 'image_id': 316795, 'image': tensor([[[ 82.,  82.,  81.,  ..., 128., 128., 128.],
         [ 81.,  82.,  82.,  ..., 128., 128., 128.],
         [ 82.,  83.,  83.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 49.,  49.,  48.,  ..., 128., 128., 128.],
         [ 48.,  49.,  49.,  ..., 128., 128., 128.],
         [ 49.,  50.,  50.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   1.,   1.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[146.1006, 252.0915, 251.1227, 377.3068]])), gt_classes: tensor([736])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000405222.jpg', 'height': 494, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [759, 150, 1072, 391, 196, 310, 648], 'image_id': 405222, 'image': tensor([[[ 89.,  87.,  60.,  ...,  63.,  66.,  68.],
         [ 75.,  81.,  65.,  ...,  62.,  63.,  64.],
         [ 73.,  81.,  73.,  ...,  61.,  60.,  60.],
         ...,
         [158., 151., 165.,  ..., 112., 153., 193.],
         [171., 157., 166.,  ..., 119., 163., 206.],
         [184., 168., 170.,  ..., 157., 180., 202.]],

        [[ 89.,  87.,  60.,  ...,  63.,  66.,  68.],
         [ 75.,  81.,  65.,  ...,  62.,  63.,  64.],
         [ 73.,  81.,  73.,  ...,  61.,  60.,  60.],
         ...,
         [158., 151., 165.,  ..., 112., 153., 193.],
         [171., 157., 166.,  ..., 119., 163., 206.],
         [184., 168., 170.,  ..., 157., 180., 202.]],

        [[ 89.,  87.,  60.,  ...,  63.,  66.,  68.],
         [ 75.,  81.,  65.,  ...,  62.,  63.,  64.],
         [ 73.,  81.,  73.,  ...,  61.,  60.,  60.],
         ...,
         [158., 151., 165.,  ..., 112., 153., 193.],
         [171., 157., 166.,  ..., 119., 163., 206.],
         [184., 168., 170.,  ..., 157., 180., 202.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[346.5360, 530.3202, 354.0232, 548.4922]])), gt_classes: tensor([736])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000097683.jpg', 'height': 375, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [366, 981, 860, 380, 731, 145, 962], 'image_id': 97683, 'image': tensor([[[181., 182., 185.,  ...,  17.,  18.,  19.],
         [182., 184., 186.,  ...,  16.,  17.,  19.],
         [183., 184., 187.,  ...,  18.,  19.,  21.],
         ...,
         [ 85.,  85.,  85.,  ...,  22.,  22.,  22.],
         [ 85.,  85.,  85.,  ...,  22.,  22.,  22.],
         [ 85.,  85.,  85.,  ...,  22.,  22.,  22.]],

        [[171., 172., 172.,  ...,  26.,  26.,  26.],
         [172., 173., 174.,  ...,  24.,  24.,  25.],
         [173., 174., 174.,  ...,  25.,  25.,  27.],
         ...,
         [ 89.,  90.,  90.,  ...,  15.,  15.,  15.],
         [ 89.,  90.,  90.,  ...,  15.,  15.,  15.],
         [ 89.,  90.,  90.,  ...,  15.,  15.,  15.]],

        [[168., 168., 169.,  ...,  53.,  52.,  52.],
         [168., 169., 170.,  ...,  52.,  52.,  52.],
         [168., 168., 169.,  ...,  51.,  51.,  52.],
         ...,
         [ 94.,  93.,  93.,  ...,  12.,  12.,  12.],
         [ 94.,  93.,  93.,  ...,  12.,  12.,  12.],
         [ 94.,  93.,  93.,  ...,  12.,  12.,  12.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[126.8778, 272.9306, 371.6389, 320.0519]])), gt_classes: tensor([736])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000574221.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [1008], 'neg_category_ids': [99, 661, 992, 292, 993, 165, 512, 825, 873, 1019], 'image_id': 574221, 'image': tensor([[[165., 168., 167.,  ..., 113., 111., 110.],
         [157., 161., 161.,  ..., 109., 109., 109.],
         [142., 147., 150.,  ..., 105., 109., 113.],
         ...,
         [  7.,   7.,   7.,  ...,  26.,  27.,  29.],
         [  6.,   7.,   7.,  ...,  28.,  29.,  31.],
         [  7.,   6.,   5.,  ...,  29.,  30.,  31.]],

        [[201., 203., 203.,  ..., 189., 186., 183.],
         [199., 204., 206.,  ..., 181., 180., 180.],
         [193., 201., 205.,  ..., 171., 174., 178.],
         ...,
         [ 11.,  12.,  12.,  ...,  52.,  50.,  48.],
         [ 10.,  11.,  11.,  ...,  52.,  50.,  48.],
         [ 10.,  10.,   9.,  ...,  51.,  49.,  48.]],

        [[224., 225., 225.,  ..., 213., 214., 215.],
         [222., 226., 227.,  ..., 204., 207., 210.],
         [216., 222., 226.,  ..., 193., 199., 204.],
         ...,
         [ 15.,  13.,  12.,  ...,  83.,  87.,  93.],
         [ 15.,  13.,  12.,  ...,  86.,  91.,  97.],
         [ 16.,  13.,  11.,  ...,  85.,  90.,  95.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 99.5615, 574.4431, 130.8555, 723.4552]])), gt_classes: tensor([736])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000074428.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [29], 'neg_category_ids': [99, 1002, 920, 696, 792, 82, 226, 1059, 843, 120], 'image_id': 74428, 'image': tensor([[[ 93.,  94.,  94.,  ...,  58.,  63.,  67.],
         [ 98., 100., 101.,  ...,  59.,  66.,  69.],
         [101., 103., 104.,  ...,  63.,  69.,  71.],
         ...,
         [ 83.,  84.,  85.,  ...,  21.,  20.,  20.],
         [ 76.,  81.,  85.,  ...,  21.,  19.,  20.],
         [ 67.,  74.,  82.,  ...,  20.,  20.,  20.]],

        [[109., 109., 109.,  ...,  91.,  99., 103.],
         [106., 106., 106.,  ...,  94., 102., 104.],
         [107., 107., 107.,  ...,  97., 104., 106.],
         ...,
         [103., 117., 131.,  ...,  18.,  18.,  19.],
         [ 98., 115., 132.,  ...,  18.,  19.,  20.],
         [ 92., 110., 129.,  ...,  19.,  20.,  20.]],

        [[128., 129., 130.,  ...,  72.,  78.,  80.],
         [132., 132., 133.,  ...,  77.,  83.,  83.],
         [135., 136., 137.,  ...,  79.,  85.,  85.],
         ...,
         [ 94., 100., 108.,  ...,  18.,  14.,  17.],
         [ 89.,  98., 108.,  ...,  17.,  13.,  16.],
         [ 84.,  95., 107.,  ...,  15.,  13.,  16.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[247.1881, 776.0537, 420.9748, 893.0446]])), gt_classes: tensor([736])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000253915.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [23, 1126, 856, 1128, 34, 95, 334, 164, 895], 'image_id': 253915, 'annotations_cat_set': {1056, 132, 1142, 694, 1046}, 'image': tensor([[[255., 255., 255.,  ...,  10.,  13.,  15.],
         [255., 255., 255.,  ...,  14.,  18.,  22.],
         [255., 255., 255.,  ...,  20.,  26.,  32.],
         ...,
         [166., 176., 186.,  ..., 138., 140., 143.],
         [151., 160., 170.,  ..., 140., 141., 142.],
         [142., 147., 151.,  ..., 149., 146., 143.]],

        [[255., 255., 255.,  ...,  65.,  67.,  69.],
         [255., 255., 255.,  ...,  70.,  74.,  78.],
         [255., 255., 255.,  ...,  76.,  83.,  90.],
         ...,
         [206., 210., 215.,  ..., 121., 125., 129.],
         [204., 208., 212.,  ..., 122., 125., 128.],
         [210., 210., 210.,  ..., 123., 120., 117.]],

        [[255., 255., 255.,  ...,  38.,  39.,  40.],
         [255., 255., 255.,  ...,  41.,  45.,  48.],
         [255., 255., 255.,  ...,  47.,  53.,  60.],
         ...,
         [239., 241., 241.,  ..., 116., 120., 123.],
         [242., 243., 244.,  ..., 116., 120., 122.],
         [247., 248., 248.,  ..., 118., 117., 114.]]]), 'instances': Instances(num_instances=6, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  403.9734,   28.8152,  558.2934],
        [ 612.5558,  327.7867,  625.0383,  336.6400],
        [ 147.5584,  342.9333,  350.1313,  660.9067],
        [  35.8299,  874.5867,  157.9071, 1024.0000],
        [ 305.2692,  914.5600,  383.7645, 1024.0000],
        [ 800.0858,  334.0533,  809.5810,  349.7334]])), gt_classes: tensor([736, 487, 815, 101, 101, 741])])}], 'support_set_target': tensor(736)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000368373.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [282, 1029, 306, 461, 1131, 423, 205, 1134, 772, 912, 1197, 487, 745], 'image_id': 368373, 'annotations': [{'bbox': [470.62, 119.93, 9.38, 38.83], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 467}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000368373.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [282, 1029, 306, 461, 1131, 423, 205, 1134, 772, 912, 1197, 487, 745], 'image_id': 368373, 'image': tensor([[[122., 126., 129.,  ..., 128., 128., 128.],
         [130., 146., 158.,  ..., 128., 128., 128.],
         [138., 167., 188.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[113., 117., 119.,  ..., 128., 128., 128.],
         [121., 137., 148.,  ..., 128., 128., 128.],
         [129., 158., 179.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[103., 107., 110.,  ..., 128., 128., 128.],
         [109., 125., 138.,  ..., 128., 128., 128.],
         [116., 145., 167.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[706.9105, 180.0824, 721.0000, 238.3881]])), gt_classes: tensor([467])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000563233.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1126, 719, 659, 425, 68, 682, 298], 'image_id': 563233, 'annotations': [{'bbox': [350.15, 349.61, 4.96, 6.51], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 467}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000563233.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1126, 719, 659, 425, 68, 682, 298], 'image_id': 563233, 'image': tensor([[[212., 212., 212.,  ..., 128., 128., 128.],
         [211., 211., 211.,  ..., 128., 128., 128.],
         [212., 212., 212.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[138., 138., 138.,  ..., 128., 128., 128.],
         [137., 137., 137.,  ..., 128., 128., 128.],
         [138., 138., 138.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[163., 163., 163.,  ..., 128., 128., 128.],
         [162., 162., 162.,  ..., 128., 128., 128.],
         [163., 163., 163.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[255.0656, 313.1923, 259.5063, 319.0242]])), gt_classes: tensor([467])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000556969.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [661, 125], 'neg_category_ids': [584, 898, 789, 5, 636, 130, 1131, 249], 'image_id': 556969, 'annotations': [{'bbox': [111.03, 172.55, 63.79, 37.99], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 467}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000556969.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [661, 125], 'neg_category_ids': [584, 898, 789, 5, 636, 130, 1131, 249], 'image_id': 556969, 'image': tensor([[[253., 253., 253.,  ..., 128., 128., 128.],
         [253., 254., 254.,  ..., 128., 128., 128.],
         [252., 253., 253.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[200., 200., 200.,  ..., 128., 128., 128.],
         [202., 202., 202.,  ..., 128., 128., 128.],
         [200., 201., 201.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[158., 157., 157.,  ..., 128., 128., 128.],
         [157., 155., 155.,  ..., 128., 128., 128.],
         [159., 158., 157.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[374.3245, 138.6057, 425.6555, 169.1223]])), gt_classes: tensor([467])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000006810.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [757, 965, 220, 153, 107, 858, 905, 1128, 593, 290, 615, 421, 334, 490, 359, 70, 496], 'image_id': 6810, 'annotations': [{'bbox': [73.12, 308.48, 20.35, 25.66], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 467}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000006810.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [757, 965, 220, 153, 107, 858, 905, 1128, 593, 290, 615, 421, 334, 490, 359, 70, 496], 'image_id': 6810, 'image': tensor([[[161., 161., 161.,  ..., 153., 151., 150.],
         [161., 161., 161.,  ..., 156., 152., 150.],
         [161., 161., 161.,  ..., 160., 155., 152.],
         ...,
         [147., 148., 148.,  ..., 165., 166., 164.],
         [147., 147., 148.,  ..., 165., 166., 165.],
         [147., 147., 147.,  ..., 166., 166., 166.]],

        [[161., 161., 161.,  ..., 153., 151., 150.],
         [161., 161., 161.,  ..., 156., 152., 150.],
         [161., 161., 161.,  ..., 160., 155., 152.],
         ...,
         [147., 148., 148.,  ..., 165., 166., 164.],
         [147., 147., 148.,  ..., 165., 166., 165.],
         [147., 147., 147.,  ..., 166., 166., 166.]],

        [[161., 161., 161.,  ..., 153., 151., 150.],
         [161., 161., 161.,  ..., 156., 152., 150.],
         [161., 161., 161.,  ..., 160., 155., 152.],
         ...,
         [147., 148., 148.,  ..., 165., 166., 164.],
         [147., 147., 148.,  ..., 165., 166., 165.],
         [147., 147., 147.,  ..., 166., 166., 166.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000528198.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [385], 'neg_category_ids': [690, 762, 812, 283, 565, 988, 133, 598, 89], 'image_id': 528198, 'annotations': [{'bbox': [574.11, 241.81, 31.26, 45.29], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 467}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000528198.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [385], 'neg_category_ids': [690, 762, 812, 283, 565, 988, 133, 598, 89], 'image_id': 528198, 'image': tensor([[[240., 240., 239.,  ..., 245., 245., 245.],
         [240., 240., 239.,  ..., 245., 245., 245.],
         [240., 240., 240.,  ..., 244., 244., 244.],
         ...,
         [ 93.,  95.,  97.,  ..., 102., 103., 100.],
         [ 94.,  94.,  94.,  ..., 102., 103., 102.],
         [ 96.,  95.,  94.,  ..., 100., 100.,  99.]],

        [[232., 232., 231.,  ..., 242., 242., 242.],
         [232., 232., 231.,  ..., 242., 242., 242.],
         [232., 232., 232.,  ..., 241., 241., 241.],
         ...,
         [ 88.,  90.,  92.,  ..., 102., 103., 100.],
         [ 89.,  89.,  89.,  ..., 102., 103., 102.],
         [ 91.,  90.,  89.,  ...,  99., 100.,  99.]],

        [[225., 225., 224.,  ..., 234., 234., 234.],
         [225., 225., 224.,  ..., 234., 234., 234.],
         [225., 225., 225.,  ..., 233., 233., 233.],
         ...,
         [ 89.,  91.,  93.,  ..., 103., 104., 101.],
         [ 90.,  90.,  90.,  ..., 103., 103., 102.],
         [ 92.,  91.,  90.,  ..., 100., 100.,  99.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
entering support set: 2
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000368373.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [282, 1029, 306, 461, 1131, 423, 205, 1134, 772, 912, 1197, 487, 745], 'image_id': 368373, 'image': tensor([[[122., 126., 129.,  ..., 128., 128., 128.],
         [130., 146., 158.,  ..., 128., 128., 128.],
         [138., 167., 188.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[113., 117., 119.,  ..., 128., 128., 128.],
         [121., 137., 148.,  ..., 128., 128., 128.],
         [129., 158., 179.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[103., 107., 110.,  ..., 128., 128., 128.],
         [109., 125., 138.,  ..., 128., 128., 128.],
         [116., 145., 167.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[706.9105, 180.0824, 721.0000, 238.3881]])), gt_classes: tensor([467])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000563233.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1126, 719, 659, 425, 68, 682, 298], 'image_id': 563233, 'image': tensor([[[212., 212., 212.,  ..., 128., 128., 128.],
         [211., 211., 211.,  ..., 128., 128., 128.],
         [212., 212., 212.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[138., 138., 138.,  ..., 128., 128., 128.],
         [137., 137., 137.,  ..., 128., 128., 128.],
         [138., 138., 138.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[163., 163., 163.,  ..., 128., 128., 128.],
         [162., 162., 162.,  ..., 128., 128., 128.],
         [163., 163., 163.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[255.0656, 313.1923, 259.5063, 319.0242]])), gt_classes: tensor([467])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000556969.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [661, 125], 'neg_category_ids': [584, 898, 789, 5, 636, 130, 1131, 249], 'image_id': 556969, 'image': tensor([[[253., 253., 253.,  ..., 128., 128., 128.],
         [253., 254., 254.,  ..., 128., 128., 128.],
         [252., 253., 253.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[200., 200., 200.,  ..., 128., 128., 128.],
         [202., 202., 202.,  ..., 128., 128., 128.],
         [200., 201., 201.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[158., 157., 157.,  ..., 128., 128., 128.],
         [157., 155., 155.,  ..., 128., 128., 128.],
         [159., 158., 157.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[374.3245, 138.6057, 425.6555, 169.1223]])), gt_classes: tensor([467])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000368373.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [282, 1029, 306, 461, 1131, 423, 205, 1134, 772, 912, 1197, 487, 745], 'image_id': 368373, 'image': tensor([[[122., 126., 129.,  ..., 128., 128., 128.],
         [130., 146., 158.,  ..., 128., 128., 128.],
         [138., 167., 188.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[113., 117., 119.,  ..., 128., 128., 128.],
         [121., 137., 148.,  ..., 128., 128., 128.],
         [129., 158., 179.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[103., 107., 110.,  ..., 128., 128., 128.],
         [109., 125., 138.,  ..., 128., 128., 128.],
         [116., 145., 167.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[706.9105, 180.0824, 721.0000, 238.3881]])), gt_classes: tensor([467])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000368373.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [282, 1029, 306, 461, 1131, 423, 205, 1134, 772, 912, 1197, 487, 745], 'image_id': 368373, 'image': tensor([[[122., 126., 129.,  ..., 128., 128., 128.],
         [130., 146., 158.,  ..., 128., 128., 128.],
         [138., 167., 188.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[113., 117., 119.,  ..., 128., 128., 128.],
         [121., 137., 148.,  ..., 128., 128., 128.],
         [129., 158., 179.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[103., 107., 110.,  ..., 128., 128., 128.],
         [109., 125., 138.,  ..., 128., 128., 128.],
         [116., 145., 167.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[706.9105, 180.0824, 721.0000, 238.3881]])), gt_classes: tensor([467])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000429485.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [876, 1056, 661, 1178], 'neg_category_ids': [1121, 1142, 560, 651, 810, 989, 594, 182, 776, 190], 'image_id': 429485, 'annotations_cat_set': {1056, 33, 800, 876, 661, 1178}, 'image': tensor([[[129., 128., 128.,  ..., 158., 159., 159.],
         [128., 128., 226.,  ..., 157., 158., 158.],
         [128., 128., 226.,  ..., 156., 157., 158.],
         ...,
         [192., 192., 193.,  ..., 148., 147., 147.],
         [193., 193., 193.,  ..., 149., 148., 148.],
         [193., 193., 194.,  ..., 151., 150., 149.]],

        [[130., 129., 129.,  ..., 158., 159., 159.],
         [129., 129., 128.,  ..., 157., 158., 158.],
         [129., 129., 128.,  ..., 156., 157., 158.],
         ...,
         [193., 193., 194.,  ..., 150., 149., 149.],
         [193., 193., 194.,  ..., 150., 149., 149.],
         [193., 193., 193.,  ..., 149., 150., 150.]],

        [[134., 133., 133.,  ..., 158., 159., 159.],
         [133., 133., 132.,  ..., 157., 158., 158.],
         [133., 133., 132.,  ..., 156., 157., 158.],
         ...,
         [197., 197., 198.,  ..., 151., 150., 150.],
         [198., 199., 199.,  ..., 152., 152., 152.],
         [200., 200., 201.,  ..., 154., 154., 154.]]]), 'instances': Instances(num_instances=18, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 545.1130,  334.3918,  549.7113,  345.0448],
        [ 775.4312,  275.4240,  786.4295,  283.6020],
        [ 818.7789,  412.5135,  852.5535,  445.1987],
        [ 529.6778,  600.2047,  575.4188,  699.3632],
        [ 645.7109,  341.9511,  657.5159,  349.8332],
        [  76.1674,  506.5877, 1024.0000,  971.1750],
        [ 651.1428,  358.3341, 1024.0000,  573.5453],
        [ 768.0094,  241.5013,  844.8628,  319.1387],
        [ 267.1446,  250.9167,  368.0920,  295.6807],
        [ 713.8785,  377.5686,  744.5070,  394.9469],
        [ 924.3516,  310.2344,  954.5497,  354.6217],
        [ 964.5799,  284.8932,  982.1932,  322.3400],
        [ 555.6273,  352.9269,  588.2187,  364.8173],
        [ 519.1636,  471.1317,  570.6860,  508.0673],
        [ 176.4963,  749.0502,  372.7172,  922.7526],
        [ 717.9391,  486.8152,  789.4681,  511.8604],
        [ 164.7989,  473.6066,  231.9717,  535.7758],
        [ 246.1162,  477.0769,  318.1024,  539.7572]])), gt_classes: tensor([741, 741, 616, 616, 616, 566, 566, 566, 566, 467, 467, 467, 467, 841,
        841, 841, 841, 841])])}], 'support_set_target': tensor(467)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000392915.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [430, 181], 'neg_category_ids': [365, 1151, 396, 742, 462, 575, 379, 266, 846, 573, 294, 247, 868, 15, 364, 19], 'image_id': 392915, 'annotations': [{'bbox': [0.0, 266.94, 96.84, 70.03], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 237}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000392915.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [430, 181], 'neg_category_ids': [365, 1151, 396, 742, 462, 575, 379, 266, 846, 573, 294, 247, 868, 15, 364, 19], 'image_id': 392915, 'image': tensor([[[190., 189., 188.,  ..., 205., 205., 204.],
         [190., 189., 188.,  ..., 205., 205., 205.],
         [190., 189., 189.,  ..., 206., 206., 206.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[185., 184., 183.,  ..., 200., 200., 199.],
         [185., 184., 183.,  ..., 200., 200., 200.],
         [185., 184., 184.,  ..., 201., 201., 201.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[186., 185., 184.,  ..., 199., 199., 198.],
         [186., 185., 184.,  ..., 199., 199., 199.],
         [186., 185., 185.,  ..., 200., 200., 200.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 961.3467,  588.8934, 1024.0000,  743.3858]])), gt_classes: tensor([237])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000222043.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [390, 1139, 143, 160, 329], 'neg_category_ids': [1095, 539, 1125, 1074, 240, 637, 1128, 83, 398, 973, 524, 992, 679, 867, 140, 643, 600], 'image_id': 222043, 'annotations': [{'bbox': [169.04, 397.04, 70.67, 170.8], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 237}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000222043.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [390, 1139, 143, 160, 329], 'neg_category_ids': [1095, 539, 1125, 1074, 240, 637, 1128, 83, 398, 973, 524, 992, 679, 867, 140, 643, 600], 'image_id': 222043, 'image': tensor([[[163., 163., 164.,  ..., 128., 128., 128.],
         [164., 164., 165.,  ..., 128., 128., 128.],
         [165., 165., 165.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[169., 169., 170.,  ..., 128., 128., 128.],
         [170., 170., 171.,  ..., 128., 128., 128.],
         [171., 171., 171.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[174., 174., 175.,  ..., 128., 128., 128.],
         [175., 175., 176.,  ..., 128., 128., 128.],
         [176., 176., 176.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[175.3928, 411.9615, 248.7187, 589.1804]])), gt_classes: tensor([237])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000302026.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [204], 'neg_category_ids': [1002, 301, 123, 303, 55, 420, 268, 993, 424, 445, 976, 15, 386], 'image_id': 302026, 'annotations': [{'bbox': [439.69, 367.97, 40.31, 80.52], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 237}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000302026.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [204], 'neg_category_ids': [1002, 301, 123, 303, 55, 420, 268, 993, 424, 445, 976, 15, 386], 'image_id': 302026, 'image': tensor([[[105., 105., 105.,  ..., 162., 162., 162.],
         [105., 105., 105.,  ..., 162., 162., 162.],
         [105., 105., 105.,  ..., 162., 162., 162.],
         ...,
         [123., 123., 123.,  ..., 119., 119., 119.],
         [122., 122., 123.,  ..., 119., 119., 119.],
         [122., 122., 122.,  ..., 118., 119., 118.]],

        [[109., 109., 109.,  ..., 162., 162., 162.],
         [109., 109., 109.,  ..., 162., 162., 162.],
         [109., 109., 109.,  ..., 162., 162., 162.],
         ...,
         [126., 126., 126.,  ..., 116., 116., 116.],
         [126., 126., 126.,  ..., 116., 116., 116.],
         [126., 126., 127.,  ..., 116., 115., 116.]],

        [[118., 118., 118.,  ..., 162., 162., 162.],
         [118., 118., 118.,  ..., 162., 162., 162.],
         [118., 118., 118.,  ..., 162., 162., 162.],
         ...,
         [135., 135., 136.,  ..., 136., 136., 136.],
         [135., 135., 136.,  ..., 136., 136., 136.],
         [135., 135., 135.,  ..., 135., 136., 136.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000259137.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [61, 329], 'neg_category_ids': [340, 981, 1070, 1100, 459, 440, 143, 918], 'image_id': 259137, 'annotations': [{'bbox': [228.14, 175.76, 97.16, 88.98], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 237}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000259137.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [61, 329], 'neg_category_ids': [340, 981, 1070, 1100, 459, 440, 143, 918], 'image_id': 259137, 'image': tensor([[[15., 15., 16.,  ..., 29., 29., 29.],
         [15., 15., 16.,  ..., 29., 29., 29.],
         [15., 15., 16.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]],

        [[28., 28., 28.,  ..., 29., 29., 29.],
         [28., 28., 28.,  ..., 29., 29., 29.],
         [29., 28., 28.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]],

        [[42., 42., 42.,  ..., 29., 29., 29.],
         [42., 42., 42.,  ..., 29., 29., 29.],
         [42., 41., 42.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[325.8124, 251.1903, 464.5690, 378.3576]])), gt_classes: tensor([237])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000259137.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [61, 329], 'neg_category_ids': [340, 981, 1070, 1100, 459, 440, 143, 918], 'image_id': 259137, 'annotations': [{'bbox': [270.63, 220.33, 144.49, 127.63], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 237}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000259137.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [61, 329], 'neg_category_ids': [340, 981, 1070, 1100, 459, 440, 143, 918], 'image_id': 259137, 'image': tensor([[[117., 116., 113.,  ..., 237., 216., 195.],
         [117., 116., 114.,  ..., 241., 215., 190.],
         [118., 116., 113.,  ..., 232., 213., 193.],
         ...,
         [164., 167., 172.,  ...,  84.,  85.,  87.],
         [162., 164., 167.,  ...,  85.,  86.,  87.],
         [160., 161., 162.,  ...,  87.,  87.,  88.]],

        [[ 96.,  93.,  88.,  ..., 179., 164., 149.],
         [ 96.,  93.,  88.,  ..., 177., 161., 144.],
         [ 95.,  93.,  89.,  ..., 175., 159., 145.],
         ...,
         [109., 110., 112.,  ...,  79.,  80.,  81.],
         [110., 110., 111.,  ...,  80.,  81.,  82.],
         [111., 111., 110.,  ...,  82.,  82.,  83.]],

        [[ 91.,  87.,  81.,  ..., 123., 110.,  96.],
         [ 92.,  87.,  81.,  ..., 123., 107.,  92.],
         [ 90.,  87.,  83.,  ..., 121., 108.,  94.],
         ...,
         [102., 104., 107.,  ...,  80.,  81.,  82.],
         [104., 105., 107.,  ...,  81.,  82.,  83.],
         [106., 107., 107.,  ...,  83.,  83.,  84.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[177.4113, 463.2997, 491.2255, 740.3632]])), gt_classes: tensor([237])])}, len instances: 1
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000025799.jpg', 'height': 640, 'width': 424, 'not_exhaustive_category_ids': [617], 'neg_category_ids': [876, 877, 8, 675, 795, 61, 641, 67, 447], 'image_id': 25799, 'annotations': [{'bbox': [159.32, 358.29, 85.45, 227.64], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 371}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000025799.jpg', 'height': 640, 'width': 424, 'not_exhaustive_category_ids': [617], 'neg_category_ids': [876, 877, 8, 675, 795, 61, 641, 67, 447], 'image_id': 25799, 'image': tensor([[[  3.,   3.,   3.,  ...,  95.,  95.,  95.],
         [  3.,   3.,   3.,  ...,  95.,  95.,  95.],
         [  3.,   3.,   3.,  ...,  95.,  95.,  95.],
         ...,
         [190., 187., 183.,  ...,  95.,  95.,  95.],
         [184., 183., 181.,  ...,  95.,  95.,  95.],
         [187., 185., 183.,  ...,  95.,  95.,  95.]],

        [[  6.,   6.,   6.,  ..., 103., 103., 103.],
         [  6.,   6.,   6.,  ..., 103., 103., 103.],
         [ 11.,  11.,   6.,  ..., 103., 103., 103.],
         ...,
         [245., 242., 237.,  ..., 103., 103., 103.],
         [ 64., 252., 245.,  ..., 103., 103., 103.],
         [ 60.,  64., 248.,  ..., 103., 103., 103.]],

        [[  6.,   6.,   6.,  ..., 132., 132., 132.],
         [  6.,   6.,   6.,  ..., 132., 132., 132.],
         [ 16.,  11.,  11.,  ..., 132., 132., 132.],
         ...,
         [  0.,   1.,   3.,  ..., 132., 132., 132.],
         [  0.,   0.,   1.,  ..., 132., 132., 132.],
         [  0.,   1.,   3.,  ..., 132., 132., 132.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 300.6038,  573.2724,  461.8302, 1002.9429]])), gt_classes: tensor([371])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000317035.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [585, 232, 1102, 328, 308, 462, 487, 575, 553, 1063, 234], 'image_id': 317035, 'annotations': [{'bbox': [0.0, 0.0, 142.11, 427.0], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 371}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000317035.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [585, 232, 1102, 328, 308, 462, 487, 575, 553, 1063, 234], 'image_id': 317035, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [ 78.,  75.,  71.,  ...,   0.,   0.,   0.],
         [ 78.,  76.,  73.,  ...,   0.,   0.,   0.],
         [ 80.,  78.,  76.,  ...,   0.,   0.,   0.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   2.],
         [  0.,   0.,   0.,  ...,   0.,   2.,   2.],
         ...,
         [134., 131., 129.,  ...,  67.,  67.,  67.],
         [134., 132., 131.,  ...,  65.,  65.,  65.],
         [136., 134., 132.,  ...,  64.,  64.,  64.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 774.6684,    0.0000, 1024.0000, 1024.0000]])), gt_classes: tensor([371])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000046385.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [194], 'neg_category_ids': [259, 979, 884, 1183, 1016, 647, 756], 'image_id': 46385, 'annotations': [{'bbox': [556.49, 103.88, 52.82, 139.23], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 371}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000046385.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [194], 'neg_category_ids': [259, 979, 884, 1183, 1016, 647, 756], 'image_id': 46385, 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]]), 'instances': Instances(num_instances=0, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([], size=(0, 4))), gt_classes: tensor([], dtype=torch.int64)])}, len instances: 0
0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000332176.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [899, 717, 419, 132, 399, 841], 'image_id': 332176, 'annotations': [{'bbox': [246.53, 319.66, 17.32, 25.64], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 371}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000332176.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [899, 717, 419, 132, 399, 841], 'image_id': 332176, 'image': tensor([[[238., 233., 227.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [227., 233., 236.,  ..., 233., 233., 233.],
         ...,
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.]],

        [[233., 227., 222.,  ..., 233., 233., 233.],
         [227., 227., 227.,  ..., 233., 233., 233.],
         [222., 227., 231.,  ..., 233., 233., 233.],
         ...,
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.]],

        [[225., 220., 215.,  ..., 233., 233., 233.],
         [220., 220., 220.,  ..., 233., 233., 233.],
         [215., 220., 224.,  ..., 233., 233., 233.],
         ...,
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[364.7874, 473.0968, 390.4156, 511.0440]])), gt_classes: tensor([371])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000406555.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [149, 1145, 634, 988, 1084, 331, 730], 'image_id': 406555, 'annotations': [{'bbox': [95.25, 62.97, 311.2, 91.1], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 371}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000406555.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [149, 1145, 634, 988, 1084, 331, 730], 'image_id': 406555, 'image': tensor([[[ 24.,  24.,  24.,  ...,  69.,  69.,  68.],
         [ 24.,  24.,  25.,  ...,  69.,  69.,  68.],
         [ 25.,  25.,  26.,  ...,  69.,  69.,  68.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 24.,  24.,  24.,  ...,  69.,  69.,  68.],
         [ 24.,  24.,  25.,  ...,  69.,  69.,  68.],
         [ 25.,  25.,  26.,  ...,  69.,  69.,  68.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 24.,  24.,  24.,  ...,  69.,  69.,  68.],
         [ 24.,  24.,  25.,  ...,  69.,  69.,  68.],
         [ 25.,  25.,  26.,  ...,  69.,  69.,  68.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[360.8455, 106.3931, 886.9680, 260.3141]])), gt_classes: tensor([371])])}, len instances: 1
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000392915.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [430, 181], 'neg_category_ids': [365, 1151, 396, 742, 462, 575, 379, 266, 846, 573, 294, 247, 868, 15, 364, 19], 'image_id': 392915, 'image': tensor([[[190., 189., 188.,  ..., 205., 205., 204.],
         [190., 189., 188.,  ..., 205., 205., 205.],
         [190., 189., 189.,  ..., 206., 206., 206.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[185., 184., 183.,  ..., 200., 200., 199.],
         [185., 184., 183.,  ..., 200., 200., 200.],
         [185., 184., 184.,  ..., 201., 201., 201.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[186., 185., 184.,  ..., 199., 199., 198.],
         [186., 185., 184.,  ..., 199., 199., 199.],
         [186., 185., 185.,  ..., 200., 200., 200.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 961.3467,  588.8934, 1024.0000,  743.3858]])), gt_classes: tensor([237])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000222043.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [390, 1139, 143, 160, 329], 'neg_category_ids': [1095, 539, 1125, 1074, 240, 637, 1128, 83, 398, 973, 524, 992, 679, 867, 140, 643, 600], 'image_id': 222043, 'image': tensor([[[163., 163., 164.,  ..., 128., 128., 128.],
         [164., 164., 165.,  ..., 128., 128., 128.],
         [165., 165., 165.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[169., 169., 170.,  ..., 128., 128., 128.],
         [170., 170., 171.,  ..., 128., 128., 128.],
         [171., 171., 171.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[174., 174., 175.,  ..., 128., 128., 128.],
         [175., 175., 176.,  ..., 128., 128., 128.],
         [176., 176., 176.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[175.3928, 411.9615, 248.7187, 589.1804]])), gt_classes: tensor([237])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000259137.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [61, 329], 'neg_category_ids': [340, 981, 1070, 1100, 459, 440, 143, 918], 'image_id': 259137, 'image': tensor([[[15., 15., 16.,  ..., 29., 29., 29.],
         [15., 15., 16.,  ..., 29., 29., 29.],
         [15., 15., 16.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]],

        [[28., 28., 28.,  ..., 29., 29., 29.],
         [28., 28., 28.,  ..., 29., 29., 29.],
         [29., 28., 28.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]],

        [[42., 42., 42.,  ..., 29., 29., 29.],
         [42., 42., 42.,  ..., 29., 29., 29.],
         [42., 41., 42.,  ..., 29., 29., 29.],
         ...,
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.],
         [29., 29., 29.,  ..., 29., 29., 29.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[325.8124, 251.1903, 464.5690, 378.3576]])), gt_classes: tensor([237])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000259137.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [61, 329], 'neg_category_ids': [340, 981, 1070, 1100, 459, 440, 143, 918], 'image_id': 259137, 'image': tensor([[[117., 116., 113.,  ..., 237., 216., 195.],
         [117., 116., 114.,  ..., 241., 215., 190.],
         [118., 116., 113.,  ..., 232., 213., 193.],
         ...,
         [164., 167., 172.,  ...,  84.,  85.,  87.],
         [162., 164., 167.,  ...,  85.,  86.,  87.],
         [160., 161., 162.,  ...,  87.,  87.,  88.]],

        [[ 96.,  93.,  88.,  ..., 179., 164., 149.],
         [ 96.,  93.,  88.,  ..., 177., 161., 144.],
         [ 95.,  93.,  89.,  ..., 175., 159., 145.],
         ...,
         [109., 110., 112.,  ...,  79.,  80.,  81.],
         [110., 110., 111.,  ...,  80.,  81.,  82.],
         [111., 111., 110.,  ...,  82.,  82.,  83.]],

        [[ 91.,  87.,  81.,  ..., 123., 110.,  96.],
         [ 92.,  87.,  81.,  ..., 123., 107.,  92.],
         [ 90.,  87.,  83.,  ..., 121., 108.,  94.],
         ...,
         [102., 104., 107.,  ...,  80.,  81.,  82.],
         [104., 105., 107.,  ...,  81.,  82.,  83.],
         [106., 107., 107.,  ...,  83.,  83.,  84.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[177.4113, 463.2997, 491.2255, 740.3632]])), gt_classes: tensor([237])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000259137.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [61, 329], 'neg_category_ids': [340, 981, 1070, 1100, 459, 440, 143, 918], 'image_id': 259137, 'image': tensor([[[117., 116., 113.,  ..., 237., 216., 195.],
         [117., 116., 114.,  ..., 241., 215., 190.],
         [118., 116., 113.,  ..., 232., 213., 193.],
         ...,
         [164., 167., 172.,  ...,  84.,  85.,  87.],
         [162., 164., 167.,  ...,  85.,  86.,  87.],
         [160., 161., 162.,  ...,  87.,  87.,  88.]],

        [[ 96.,  93.,  88.,  ..., 179., 164., 149.],
         [ 96.,  93.,  88.,  ..., 177., 161., 144.],
         [ 95.,  93.,  89.,  ..., 175., 159., 145.],
         ...,
         [109., 110., 112.,  ...,  79.,  80.,  81.],
         [110., 110., 111.,  ...,  80.,  81.,  82.],
         [111., 111., 110.,  ...,  82.,  82.,  83.]],

        [[ 91.,  87.,  81.,  ..., 123., 110.,  96.],
         [ 92.,  87.,  81.,  ..., 123., 107.,  92.],
         [ 90.,  87.,  83.,  ..., 121., 108.,  94.],
         ...,
         [102., 104., 107.,  ...,  80.,  81.,  82.],
         [104., 105., 107.,  ...,  81.,  82.,  83.],
         [106., 107., 107.,  ...,  83.,  83.,  84.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[177.4113, 463.2997, 491.2255, 740.3632]])), gt_classes: tensor([237])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000222043.jpg', 'height': 612, 'width': 612, 'not_exhaustive_category_ids': [390, 1139, 143, 160, 329], 'neg_category_ids': [1095, 539, 1125, 1074, 240, 637, 1128, 83, 398, 973, 524, 992, 679, 867, 140, 643, 600], 'image_id': 222043, 'annotations_cat_set': {160, 898, 390, 329, 143, 1139}, 'image': tensor([[[188., 191., 194.,  ..., 126., 120., 114.],
         [182., 189., 196.,  ..., 122., 117., 112.],
         [180., 188., 197.,  ..., 119., 115., 110.],
         ...,
         [172., 174., 177.,  ...,  89.,  88.,  88.],
         [171., 173., 176.,  ...,  89.,  89.,  89.],
         [170., 172., 175.,  ...,  89.,  90.,  90.]],

        [[167., 170., 173.,  ...,  69.,  65.,  60.],
         [160., 167., 174.,  ...,  68.,  64.,  59.],
         [157., 166., 175.,  ...,  67.,  64.,  61.],
         ...,
         [158., 159., 161.,  ...,  76.,  75.,  75.],
         [157., 158., 160.,  ...,  76.,  76.,  76.],
         [156., 157., 159.,  ...,  76.,  77.,  77.]],

        [[137., 140., 143.,  ...,  27.,  24.,  20.],
         [131., 138., 145.,  ...,  26.,  23.,  19.],
         [128., 137., 146.,  ...,  26.,  24.,  21.],
         ...,
         [144., 146., 147.,  ...,  62.,  61.,  61.],
         [143., 145., 146.,  ...,  62.,  62.,  62.],
         [142., 144., 145.,  ...,  62.,  63.,  63.]]]), 'instances': Instances(num_instances=60, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 176.4883,   97.5616,  329.4070,  291.1299],
        [   0.0000,  284.2338,  159.2162,  518.3885],
        [  42.7398,  464.4525,  146.3411,  609.3995],
        [ 853.1710,  373.5365, 1024.0000,  785.6641],
        [ 160.3234,  454.7409,  385.9370, 1020.3250],
        [ 702.0870,  491.4680,  944.8146,  968.4769],
        [ 236.2766,  282.7470,  388.7208,  470.1467],
        [ 720.8144,  243.7422,  897.2055,  513.7067],
        [ 545.8784,  377.2377,  704.9974,  576.7532],
        [ 369.2975,  189.8695,  466.6036,  360.4399],
        [   0.0000,  404.5378,    2.6280,  752.6066],
        [   0.0000,  230.3294,   37.1723,  409.9789],
        [  95.6635,  405.0439,  307.6745,  868.4186],
        [   0.0000,  609.8107,  175.7608, 1014.2197],
        [ 327.1611,  211.2541,  376.3203,  296.8557],
        [ 515.0037,  221.9780,  618.6050,  393.1179],
        [ 433.6410,  741.1550,  671.6235, 1024.0000],
        [ 431.0787,  162.0949,  547.2387,  301.6325],
        [ 443.0680,  291.3514,  588.2363,  465.7813],
        [ 142.4818,  284.1704,  236.1184,  420.3547],
        [ 307.8010,    0.0000,  471.6651,   41.4429],
        [   0.0000,  509.4677,   99.0167,  857.4415],
        [   2.3433,   66.5919,  118.4716,  294.8944],
        [ 371.7017,  449.9958,  595.2591,  990.3044],
        [ 203.0293,  202.7763,  348.7987,  402.2918],
        [ 557.6146,  556.0646,  808.8834, 1024.0000],
        [ 344.9393,  353.1642,  548.5673,  488.6841],
        [ 216.1890,  653.6238,  414.5025, 1024.0000],
        [ 588.6476,  215.7778,  767.5694,  561.8853],
        [  50.6800,  105.0272,  165.6379,  304.8274],
        [ 442.4669,  290.4340,  586.6230,  404.7276],
        [ 591.4630,  212.1715,  767.1265,  560.5249],
        [ 143.2411,  284.3602,  235.9919,  421.8099],
        [ 430.1613,  161.4306,  546.0366,  302.2651],
        [ 213.5318,  653.4340,  419.1210, 1024.0000],
        [   0.0000,  284.7398,  159.2795,  518.4201],
        [ 722.4594,  245.6086,  897.2687,  511.2392],
        [ 304.6693,    0.0000,  468.5017,   39.0704],
        [ 551.7308,  558.0259,  809.8641, 1024.0000],
        [   0.0000,  230.3610,   37.0458,  407.1001],
        [ 161.7153,  452.0520,  383.3430, 1019.1860],
        [ 228.0835,  279.5202,  390.3025,  466.9516],
        [ 542.4303,  380.0847,  700.9482,  581.1820],
        [   0.0000,  406.7205,    4.3362,  740.4590],
        [ 370.5945,  191.4829,  467.9323,  361.1043],
        [   0.0000,  504.3113,  103.8251,  863.8949],
        [ 343.5475,  354.2397,  548.2826,  490.3291],
        [ 523.2601,  224.6037,  616.5171,  389.0372],
        [ 703.7953,  489.4750,  945.2575,  975.3098],
        [ 101.2627,  403.6521,  308.8766,  869.4308],
        [ 330.7673,  210.2735,  374.6121,  295.4955],
        [ 175.8874,   96.2962,  328.2999,  290.1810],
        [ 203.2507,  200.7516,  350.1273,  385.7788],
        [   1.9637,   65.3898,  118.5349,  293.9137],
        [   0.0000,  609.9689,  175.8240, 1014.0297],
        [ 408.4920,  741.2183,  675.7043, 1024.0000],
        [ 854.8160,  373.5998, 1024.0000,  784.1457],
        [ 370.8792,  451.5775,  595.0377,  986.4449],
        [  53.5270,  107.2732,  167.2513,  307.5480],
        [  42.6450,  463.9464,  145.8034,  534.2372]])), gt_classes: tensor([237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237,
        237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237, 237,
        237, 237, 812, 812, 812, 812, 812, 812, 812, 812, 812, 812, 812, 812,
        812, 812, 812, 812, 812, 812, 812, 812, 812, 812, 812, 812, 812, 812,
        812, 812, 812, 812])])}], 'support_set_target': tensor(237)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000000913.jpg', 'height': 512, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1142, 1097, 714, 1152, 515, 597, 916, 98, 408], 'image_id': 913, 'annotations': [{'bbox': [0.0, 161.16, 209.07, 79.18], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 308}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000000913.jpg', 'height': 512, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1142, 1097, 714, 1152, 515, 597, 916, 98, 408], 'image_id': 913, 'image': tensor([[[ 61.,  61.,  61.,  ...,  42.,  42.,  42.],
         [ 60.,  61.,  61.,  ...,  42.,  42.,  42.],
         [ 61.,  62.,  62.,  ...,  42.,  42.,  42.],
         ...,
         [166., 165., 165.,  ..., 129., 125., 119.],
         [165., 164., 164.,  ..., 131., 129., 124.],
         [163., 162., 164.,  ..., 133., 133., 129.]],

        [[112., 113., 114.,  ...,  86.,  86.,  86.],
         [111., 112., 113.,  ...,  86.,  86.,  86.],
         [111., 112., 113.,  ...,  86.,  86.,  86.],
         ...,
         [164., 163., 163.,  ..., 115., 110., 103.],
         [163., 162., 162.,  ..., 117., 114., 107.],
         [161., 160., 162.,  ..., 120., 118., 111.]],

        [[128., 129., 130.,  ..., 103., 103., 103.],
         [127., 128., 129.,  ..., 103., 103., 103.],
         [127., 128., 129.,  ..., 103., 103., 103.],
         ...,
         [156., 155., 155.,  ...,  97.,  93.,  86.],
         [155., 154., 154.,  ...,  99.,  96.,  90.],
         [153., 152., 154.,  ..., 102., 100.,  94.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 920.3181,  325.1759, 1024.0000,  529.1572]])), gt_classes: tensor([308])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000170451.jpg', 'height': 328, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [538, 1168, 483, 701, 774, 1064, 623], 'image_id': 170451, 'annotations': [{'bbox': [209.72, 98.47, 238.49, 177.2], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 308}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000170451.jpg', 'height': 328, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [538, 1168, 483, 701, 774, 1064, 623], 'image_id': 170451, 'image': tensor([[[ 90.,  90.,  91.,  ...,  89.,  89.,  89.],
         [ 90.,  90.,  91.,  ...,  89.,  89.,  89.],
         [ 90.,  90.,  91.,  ...,  89.,  89.,  89.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[120., 120., 120.,  ..., 119., 119., 119.],
         [120., 120., 120.,  ..., 119., 119., 119.],
         [120., 120., 120.,  ..., 119., 119., 119.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[149., 150., 150.,  ..., 146., 146., 146.],
         [149., 150., 150.,  ..., 146., 146., 146.],
         [149., 150., 150.,  ..., 146., 146., 146.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 299.3128, 659.1382, 837.9359]])), gt_classes: tensor([308])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000466623.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [807, 391, 1125, 240, 287, 110, 888, 780], 'image_id': 466623, 'annotations': [{'bbox': [441.54, 266.2, 88.32, 111.01], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 308}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000466623.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [807, 391, 1125, 240, 287, 110, 888, 780], 'image_id': 466623, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 752.8749,  633.0432, 1024.0000,  975.4323]])), gt_classes: tensor([308])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000173596.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [981, 899, 479, 696, 988, 329, 319], 'image_id': 173596, 'annotations': [{'bbox': [13.89, 109.9, 601.19, 191.47], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 308}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000173596.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [981, 899, 479, 696, 988, 329, 319], 'image_id': 173596, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  215.9312, 1024.0000,  761.1263]])), gt_classes: tensor([308])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000426939.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [853, 711, 985, 158, 136, 800, 318], 'image_id': 426939, 'annotations': [{'bbox': [22.36, 122.17, 595.34, 165.55], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 308}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000426939.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [853, 711, 985, 158, 136, 800, 318], 'image_id': 426939, 'image': tensor([[[210., 210., 210.,  ..., 215., 215., 215.],
         [210., 210., 210.,  ..., 215., 215., 214.],
         [210., 210., 210.,  ..., 215., 214., 214.],
         ...,
         [107., 107., 107.,  ..., 108., 107., 106.],
         [109., 108., 108.,  ..., 107., 106., 105.],
         [111., 110., 110.,  ..., 107., 106., 105.]],

        [[197., 197., 197.,  ..., 201., 201., 201.],
         [197., 197., 197.,  ..., 201., 201., 201.],
         [197., 197., 197.,  ..., 201., 201., 201.],
         ...,
         [133., 133., 133.,  ..., 126., 125., 124.],
         [133., 133., 134.,  ..., 127., 126., 125.],
         [134., 134., 134.,  ..., 127., 126., 125.]],

        [[183., 183., 183.,  ..., 189., 189., 189.],
         [183., 183., 183.,  ..., 189., 189., 189.],
         [183., 183., 183.,  ..., 189., 189., 189.],
         ...,
         [147., 147., 148.,  ..., 142., 141., 141.],
         [148., 148., 149.,  ..., 143., 142., 142.],
         [150., 150., 150.,  ..., 143., 142., 142.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  231.8097, 1024.0000,  731.5759]])), gt_classes: tensor([308])])}, len instances: 1
not 0
entering support set: 1
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000025799.jpg', 'height': 640, 'width': 424, 'not_exhaustive_category_ids': [617], 'neg_category_ids': [876, 877, 8, 675, 795, 61, 641, 67, 447], 'image_id': 25799, 'image': tensor([[[  3.,   3.,   3.,  ...,  95.,  95.,  95.],
         [  3.,   3.,   3.,  ...,  95.,  95.,  95.],
         [  3.,   3.,   3.,  ...,  95.,  95.,  95.],
         ...,
         [190., 187., 183.,  ...,  95.,  95.,  95.],
         [184., 183., 181.,  ...,  95.,  95.,  95.],
         [187., 185., 183.,  ...,  95.,  95.,  95.]],

        [[  6.,   6.,   6.,  ..., 103., 103., 103.],
         [  6.,   6.,   6.,  ..., 103., 103., 103.],
         [ 11.,  11.,   6.,  ..., 103., 103., 103.],
         ...,
         [245., 242., 237.,  ..., 103., 103., 103.],
         [ 64., 252., 245.,  ..., 103., 103., 103.],
         [ 60.,  64., 248.,  ..., 103., 103., 103.]],

        [[  6.,   6.,   6.,  ..., 132., 132., 132.],
         [  6.,   6.,   6.,  ..., 132., 132., 132.],
         [ 16.,  11.,  11.,  ..., 132., 132., 132.],
         ...,
         [  0.,   1.,   3.,  ..., 132., 132., 132.],
         [  0.,   0.,   1.,  ..., 132., 132., 132.],
         [  0.,   1.,   3.,  ..., 132., 132., 132.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 300.6038,  573.2724,  461.8302, 1002.9429]])), gt_classes: tensor([371])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000317035.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [585, 232, 1102, 328, 308, 462, 487, 575, 553, 1063, 234], 'image_id': 317035, 'image': tensor([[[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         ...,
         [ 78.,  75.,  71.,  ...,   0.,   0.,   0.],
         [ 78.,  76.,  73.,  ...,   0.,   0.,   0.],
         [ 80.,  78.,  76.,  ...,   0.,   0.,   0.]],

        [[  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   2.],
         [  0.,   0.,   0.,  ...,   0.,   2.,   2.],
         ...,
         [134., 131., 129.,  ...,  67.,  67.,  67.],
         [134., 132., 131.,  ...,  65.,  65.,  65.],
         [136., 134., 132.,  ...,  64.,  64.,  64.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 774.6684,    0.0000, 1024.0000, 1024.0000]])), gt_classes: tensor([371])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000332176.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [899, 717, 419, 132, 399, 841], 'image_id': 332176, 'image': tensor([[[238., 233., 227.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [227., 233., 236.,  ..., 233., 233., 233.],
         ...,
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.]],

        [[233., 227., 222.,  ..., 233., 233., 233.],
         [227., 227., 227.,  ..., 233., 233., 233.],
         [222., 227., 231.,  ..., 233., 233., 233.],
         ...,
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.]],

        [[225., 220., 215.,  ..., 233., 233., 233.],
         [220., 220., 220.,  ..., 233., 233., 233.],
         [215., 220., 224.,  ..., 233., 233., 233.],
         ...,
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.],
         [233., 233., 233.,  ..., 233., 233., 233.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[364.7874, 473.0968, 390.4156, 511.0440]])), gt_classes: tensor([371])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000406555.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [149, 1145, 634, 988, 1084, 331, 730], 'image_id': 406555, 'image': tensor([[[ 24.,  24.,  24.,  ...,  69.,  69.,  68.],
         [ 24.,  24.,  25.,  ...,  69.,  69.,  68.],
         [ 25.,  25.,  26.,  ...,  69.,  69.,  68.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 24.,  24.,  24.,  ...,  69.,  69.,  68.],
         [ 24.,  24.,  25.,  ...,  69.,  69.,  68.],
         [ 25.,  25.,  26.,  ...,  69.,  69.,  68.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 24.,  24.,  24.,  ...,  69.,  69.,  68.],
         [ 24.,  24.,  25.,  ...,  69.,  69.,  68.],
         [ 25.,  25.,  26.,  ...,  69.,  69.,  68.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[360.8455, 106.3931, 886.9680, 260.3141]])), gt_classes: tensor([371])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000406555.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [149, 1145, 634, 988, 1084, 331, 730], 'image_id': 406555, 'image': tensor([[[ 24.,  24.,  24.,  ...,  69.,  69.,  68.],
         [ 24.,  24.,  25.,  ...,  69.,  69.,  68.],
         [ 25.,  25.,  26.,  ...,  69.,  69.,  68.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 24.,  24.,  24.,  ...,  69.,  69.,  68.],
         [ 24.,  24.,  25.,  ...,  69.,  69.,  68.],
         [ 25.,  25.,  26.,  ...,  69.,  69.,  68.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 24.,  24.,  24.,  ...,  69.,  69.,  68.],
         [ 24.,  24.,  25.,  ...,  69.,  69.,  68.],
         [ 25.,  25.,  26.,  ...,  69.,  69.,  68.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[360.8455, 106.3931, 886.9680, 260.3141]])), gt_classes: tensor([371])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000342831.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [603, 391, 879, 1151, 928, 399, 509, 227, 381, 12, 824, 406], 'image_id': 342831, 'annotations_cat_set': {1122, 548, 968, 521, 77, 885}, 'image': tensor([[[132., 131., 132.,  ..., 138., 138., 139.],
         [134., 133., 134.,  ..., 138., 138., 138.],
         [138., 137., 136.,  ..., 138., 138., 138.],
         ...,
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.]],

        [[132., 131., 132.,  ..., 138., 138., 139.],
         [134., 133., 134.,  ..., 138., 138., 138.],
         [138., 137., 136.,  ..., 138., 138., 138.],
         ...,
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.]],

        [[132., 131., 132.,  ..., 138., 138., 139.],
         [134., 133., 134.,  ..., 138., 138., 138.],
         [138., 137., 136.,  ..., 138., 138., 138.],
         ...,
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.],
         [136., 136., 136.,  ..., 136., 136., 136.]]]), 'instances': Instances(num_instances=7, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 99.1357, 208.6161, 759.0190, 455.0821],
        [ 82.0309, 521.7825, 339.2081, 682.9433],
        [  0.0000, 211.5409, 758.6727, 736.2482],
        [376.0491, 404.8751, 946.3748, 657.8657],
        [611.0836, 539.7123, 898.4538, 739.0000],
        [559.7001, 488.8995, 569.4644, 500.6681],
        [797.1411, 482.3576, 811.5451, 489.4534]])), gt_classes: tensor([390, 799,  59, 371, 681, 624, 624])])}], 'support_set_target': tensor(371)}
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000000913.jpg', 'height': 512, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1142, 1097, 714, 1152, 515, 597, 916, 98, 408], 'image_id': 913, 'image': tensor([[[ 61.,  61.,  61.,  ...,  42.,  42.,  42.],
         [ 60.,  61.,  61.,  ...,  42.,  42.,  42.],
         [ 61.,  62.,  62.,  ...,  42.,  42.,  42.],
         ...,
         [166., 165., 165.,  ..., 129., 125., 119.],
         [165., 164., 164.,  ..., 131., 129., 124.],
         [163., 162., 164.,  ..., 133., 133., 129.]],

        [[112., 113., 114.,  ...,  86.,  86.,  86.],
         [111., 112., 113.,  ...,  86.,  86.,  86.],
         [111., 112., 113.,  ...,  86.,  86.,  86.],
         ...,
         [164., 163., 163.,  ..., 115., 110., 103.],
         [163., 162., 162.,  ..., 117., 114., 107.],
         [161., 160., 162.,  ..., 120., 118., 111.]],

        [[128., 129., 130.,  ..., 103., 103., 103.],
         [127., 128., 129.,  ..., 103., 103., 103.],
         [127., 128., 129.,  ..., 103., 103., 103.],
         ...,
         [156., 155., 155.,  ...,  97.,  93.,  86.],
         [155., 154., 154.,  ...,  99.,  96.,  90.],
         [153., 152., 154.,  ..., 102., 100.,  94.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 920.3181,  325.1759, 1024.0000,  529.1572]])), gt_classes: tensor([308])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000170451.jpg', 'height': 328, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [538, 1168, 483, 701, 774, 1064, 623], 'image_id': 170451, 'image': tensor([[[ 90.,  90.,  91.,  ...,  89.,  89.,  89.],
         [ 90.,  90.,  91.,  ...,  89.,  89.,  89.],
         [ 90.,  90.,  91.,  ...,  89.,  89.,  89.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[120., 120., 120.,  ..., 119., 119., 119.],
         [120., 120., 120.,  ..., 119., 119., 119.],
         [120., 120., 120.,  ..., 119., 119., 119.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]],

        [[149., 150., 150.,  ..., 146., 146., 146.],
         [149., 150., 150.,  ..., 146., 146., 146.],
         [149., 150., 150.,  ..., 146., 146., 146.],
         ...,
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.],
         [127., 127., 127.,  ..., 127., 127., 127.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 299.3128, 659.1382, 837.9359]])), gt_classes: tensor([308])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000466623.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [807, 391, 1125, 240, 287, 110, 888, 780], 'image_id': 466623, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 752.8749,  633.0432, 1024.0000,  975.4323]])), gt_classes: tensor([308])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000173596.jpg', 'height': 426, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [981, 899, 479, 696, 988, 329, 319], 'image_id': 173596, 'image': tensor([[[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  215.9312, 1024.0000,  761.1263]])), gt_classes: tensor([308])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000426939.jpg', 'height': 425, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [853, 711, 985, 158, 136, 800, 318], 'image_id': 426939, 'image': tensor([[[210., 210., 210.,  ..., 215., 215., 215.],
         [210., 210., 210.,  ..., 215., 215., 214.],
         [210., 210., 210.,  ..., 215., 214., 214.],
         ...,
         [107., 107., 107.,  ..., 108., 107., 106.],
         [109., 108., 108.,  ..., 107., 106., 105.],
         [111., 110., 110.,  ..., 107., 106., 105.]],

        [[197., 197., 197.,  ..., 201., 201., 201.],
         [197., 197., 197.,  ..., 201., 201., 201.],
         [197., 197., 197.,  ..., 201., 201., 201.],
         ...,
         [133., 133., 133.,  ..., 126., 125., 124.],
         [133., 133., 134.,  ..., 127., 126., 125.],
         [134., 134., 134.,  ..., 127., 126., 125.]],

        [[183., 183., 183.,  ..., 189., 189., 189.],
         [183., 183., 183.,  ..., 189., 189., 189.],
         [183., 183., 183.,  ..., 189., 189., 189.],
         ...,
         [147., 147., 148.,  ..., 142., 141., 141.],
         [148., 148., 149.,  ..., 143., 142., 142.],
         [150., 150., 150.,  ..., 143., 142., 142.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[   0.0000,  231.8097, 1024.0000,  731.5759]])), gt_classes: tensor([308])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000579341.jpg', 'height': 394, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [102, 739, 1131, 487, 157, 838, 38], 'image_id': 579341, 'annotations_cat_set': {436}, 'image': tensor([[[191., 192., 192.,  ..., 197., 197., 197.],
         [191., 192., 192.,  ..., 197., 197., 197.],
         [191., 192., 192.,  ..., 197., 197., 197.],
         ...,
         [182., 181., 181.,  ..., 186., 186., 188.],
         [183., 181., 181.,  ..., 184., 186., 186.],
         [183., 181., 181.,  ..., 184., 186., 186.]],

        [[166., 167., 167.,  ..., 165., 165., 165.],
         [166., 167., 167.,  ..., 165., 165., 165.],
         [166., 167., 167.,  ..., 167., 167., 167.],
         ...,
         [172., 173., 173.,  ..., 176., 176., 176.],
         [173., 174., 174.,  ..., 176., 176., 176.],
         [173., 174., 174.,  ..., 176., 176., 176.]],

        [[134., 135., 135.,  ..., 135., 135., 135.],
         [134., 135., 135.,  ..., 135., 135., 135.],
         [134., 135., 135.,  ..., 133., 133., 133.],
         ...,
         [156., 157., 157.,  ..., 156., 156., 154.],
         [153., 155., 155.,  ..., 156., 156., 156.],
         [153., 155., 155.,  ..., 156., 156., 156.]]]), 'instances': Instances(num_instances=2, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[347.8355, 408.0907, 776.1519, 647.6808],
        [172.8710, 286.6168, 603.4883, 591.0013]])), gt_classes: tensor([308, 308])])}], 'support_set_target': tensor(308)}
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000159929.jpg', 'height': 406, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [605, 634, 1101, 813, 524, 355, 1157, 429, 756], 'image_id': 159929, 'annotations': [{'bbox': [1.89, 93.08, 298.03, 64.13], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 747}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000159929.jpg', 'height': 406, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [605, 634, 1101, 813, 524, 355, 1157, 429, 756], 'image_id': 159929, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[290.6621,  79.5536, 545.3846, 134.3642]])), gt_classes: tensor([747])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000274949.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [368, 966, 25, 76, 173, 976, 1118], 'image_id': 274949, 'annotations': [{'bbox': [63.8, 0.37, 242.37, 228.42], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 747}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000274949.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [368, 966, 25, 76, 173, 976, 1118], 'image_id': 274949, 'image': tensor([[[ 91.,  87.,  89.,  ...,  37.,  40.,  42.],
         [ 91.,  88.,  88.,  ...,  40.,  42.,  43.],
         [ 93.,  91.,  91.,  ...,  43.,  45.,  47.],
         ...,
         [225., 232., 222.,  ..., 145., 141., 143.],
         [221., 227., 216.,  ..., 146., 134., 134.],
         [216., 221., 211.,  ..., 142., 122., 119.]],

        [[ 66.,  65.,  64.,  ...,  18.,  21.,  21.],
         [ 66.,  65.,  64.,  ...,  21.,  21.,  21.],
         [ 66.,  65.,  63.,  ...,  23.,  23.,  23.],
         ...,
         [195., 208., 194.,  ..., 117., 118., 121.],
         [201., 212., 202.,  ..., 119., 113., 116.],
         [201., 209., 195.,  ..., 118., 111., 110.]],

        [[ 41.,  37.,  47.,  ...,   7.,   9.,   9.],
         [ 41.,  34.,  47.,  ...,   9.,   9.,   9.],
         [ 41.,  34.,  47.,  ...,  10.,   9.,   9.],
         ...,
         [173., 160., 168.,  ..., 117., 115., 119.],
         [173., 168., 175.,  ..., 118., 113., 114.],
         [168., 163., 168.,  ..., 117., 109., 109.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[124.2967,   0.0000, 653.4711, 267.4057]])), gt_classes: tensor([747])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000420500.jpg', 'height': 399, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [48, 784, 248, 1078, 7, 224, 1089, 682, 1091], 'image_id': 420500, 'annotations': [{'bbox': [0.0, 160.19, 111.95, 44.45], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 747}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000420500.jpg', 'height': 399, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [48, 784, 248, 1078, 7, 224, 1089, 682, 1091], 'image_id': 420500, 'image': tensor([[[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[540.4261, 163.8033, 655.0000, 209.2559]])), gt_classes: tensor([747])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349960.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [782, 1077, 287, 1033, 266, 1179, 165], 'image_id': 349960, 'annotations': [{'bbox': [438.59, 116.67, 201.41, 62.78], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 747}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349960.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [782, 1077, 287, 1033, 266, 1179, 165], 'image_id': 349960, 'image': tensor([[[  4.,  14.,  24.,  ..., 128., 128., 128.],
         [  5.,  11.,  17.,  ..., 128., 128., 128.],
         [ 10.,   9.,  10.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 13.,  24.,  36.,  ..., 128., 128., 128.],
         [ 14.,  21.,  28.,  ..., 128., 128., 128.],
         [ 19.,  19.,  21.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 10.,  21.,  33.,  ..., 128., 128., 128.],
         [ 11.,  18.,  25.,  ..., 128., 128., 128.],
         [ 16.,  16.,  18.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 178.4204, 308.0944, 274.4282]])), gt_classes: tensor([747])])}, len instances: 1
not 0
{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000082346.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1064, 125], 'neg_category_ids': [946, 589, 817, 463, 795, 645, 191], 'image_id': 82346, 'annotations': [{'bbox': [201.84, 85.51, 131.6, 94.14], 'bbox_mode': <BoxMode.XYWH_ABS: 1>, 'category_id': 747}]}
mapped data: {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000082346.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1064, 125], 'neg_category_ids': [946, 589, 817, 463, 795, 645, 191], 'image_id': 82346, 'image': tensor([[[255., 255., 255.,  ..., 130., 130., 142.],
         [255., 255., 255.,  ..., 126., 123., 138.],
         [255., 255., 255.,  ..., 130., 130., 143.],
         ...,
         [255., 255., 255.,  ...,  62.,  49.,  39.],
         [255., 255., 255.,  ...,  64.,  56.,  49.],
         [255., 255., 255.,  ...,  68.,  64.,  56.]],

        [[255., 255., 255.,  ..., 221., 225., 231.],
         [255., 255., 255.,  ..., 217., 223., 234.],
         [255., 255., 255.,  ..., 215., 225., 238.],
         ...,
         [255., 255., 255.,  ...,  79.,  66.,  54.],
         [255., 255., 255.,  ...,  79.,  68.,  56.],
         [255., 255., 255.,  ...,  79.,  70.,  60.]],

        [[255., 255., 255.,  ..., 187., 193., 202.],
         [255., 255., 255.,  ..., 185., 191., 204.],
         [255., 255., 255.,  ..., 183., 193., 208.],
         ...,
         [255., 255., 255.,  ...,  96.,  79.,  60.],
         [255., 255., 255.,  ...,  96.,  85.,  68.],
         [255., 255., 255.,  ...,  96.,  90.,  75.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[477.4371, 219.2988, 835.0190, 475.0421]])), gt_classes: tensor([747])])}, len instances: 1
not 0
entering support set: 0
mapped_data_list: 5
change with data aug: {'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000159929.jpg', 'height': 406, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [605, 634, 1101, 813, 524, 355, 1157, 429, 756], 'image_id': 159929, 'image': tensor([[[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[290.6621,  79.5536, 545.3846, 134.3642]])), gt_classes: tensor([747])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000274949.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [368, 966, 25, 76, 173, 976, 1118], 'image_id': 274949, 'image': tensor([[[ 91.,  87.,  89.,  ...,  37.,  40.,  42.],
         [ 91.,  88.,  88.,  ...,  40.,  42.,  43.],
         [ 93.,  91.,  91.,  ...,  43.,  45.,  47.],
         ...,
         [225., 232., 222.,  ..., 145., 141., 143.],
         [221., 227., 216.,  ..., 146., 134., 134.],
         [216., 221., 211.,  ..., 142., 122., 119.]],

        [[ 66.,  65.,  64.,  ...,  18.,  21.,  21.],
         [ 66.,  65.,  64.,  ...,  21.,  21.,  21.],
         [ 66.,  65.,  63.,  ...,  23.,  23.,  23.],
         ...,
         [195., 208., 194.,  ..., 117., 118., 121.],
         [201., 212., 202.,  ..., 119., 113., 116.],
         [201., 209., 195.,  ..., 118., 111., 110.]],

        [[ 41.,  37.,  47.,  ...,   7.,   9.,   9.],
         [ 41.,  34.,  47.,  ...,   9.,   9.,   9.],
         [ 41.,  34.,  47.,  ...,  10.,   9.,   9.],
         ...,
         [173., 160., 168.,  ..., 117., 115., 119.],
         [173., 168., 175.,  ..., 118., 113., 114.],
         [168., 163., 168.,  ..., 117., 109., 109.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[124.2967,   0.0000, 653.4711, 267.4057]])), gt_classes: tensor([747])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000420500.jpg', 'height': 399, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [48, 784, 248, 1078, 7, 224, 1089, 682, 1091], 'image_id': 420500, 'image': tensor([[[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]],

        [[128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         [128., 128., 128.,  ...,   0.,   0.,   0.],
         ...,
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.],
         [  0.,   0.,   0.,  ...,   0.,   0.,   0.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[540.4261, 163.8033, 655.0000, 209.2559]])), gt_classes: tensor([747])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000349960.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [782, 1077, 287, 1033, 266, 1179, 165], 'image_id': 349960, 'image': tensor([[[  4.,  14.,  24.,  ..., 128., 128., 128.],
         [  5.,  11.,  17.,  ..., 128., 128., 128.],
         [ 10.,   9.,  10.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 13.,  24.,  36.,  ..., 128., 128., 128.],
         [ 14.,  21.,  28.,  ..., 128., 128., 128.],
         [ 19.,  19.,  21.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]],

        [[ 10.,  21.,  33.,  ..., 128., 128., 128.],
         [ 11.,  18.,  25.,  ..., 128., 128., 128.],
         [ 16.,  16.,  18.,  ..., 128., 128., 128.],
         ...,
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.],
         [128., 128., 128.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[  0.0000, 178.4204, 308.0944, 274.4282]])), gt_classes: tensor([747])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000082346.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [1064, 125], 'neg_category_ids': [946, 589, 817, 463, 795, 645, 191], 'image_id': 82346, 'image': tensor([[[255., 255., 255.,  ..., 130., 130., 142.],
         [255., 255., 255.,  ..., 126., 123., 138.],
         [255., 255., 255.,  ..., 130., 130., 143.],
         ...,
         [255., 255., 255.,  ...,  62.,  49.,  39.],
         [255., 255., 255.,  ...,  64.,  56.,  49.],
         [255., 255., 255.,  ...,  68.,  64.,  56.]],

        [[255., 255., 255.,  ..., 221., 225., 231.],
         [255., 255., 255.,  ..., 217., 223., 234.],
         [255., 255., 255.,  ..., 215., 225., 238.],
         ...,
         [255., 255., 255.,  ...,  79.,  66.,  54.],
         [255., 255., 255.,  ...,  79.,  68.,  56.],
         [255., 255., 255.,  ...,  79.,  70.,  60.]],

        [[255., 255., 255.,  ..., 187., 193., 202.],
         [255., 255., 255.,  ..., 185., 191., 204.],
         [255., 255., 255.,  ..., 183., 193., 208.],
         ...,
         [255., 255., 255.,  ...,  96.,  79.,  60.],
         [255., 255., 255.,  ...,  96.,  85.,  68.],
         [255., 255., 255.,  ...,  96.,  90.,  75.]]]), 'instances': Instances(num_instances=1, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[477.4371, 219.2988, 835.0190, 475.0421]])), gt_classes: tensor([747])])}], 'query_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000144273.jpg', 'height': 640, 'width': 430, 'not_exhaustive_category_ids': [735], 'neg_category_ids': [476, 2, 51, 248, 108, 306, 1129, 420, 35, 441, 68, 316, 406, 624, 278], 'image_id': 144273, 'annotations_cat_set': {1122, 1064, 746, 177, 735, 277, 919, 1055, 959}, 'image': tensor([[[  2.,   1.,   0.,  ..., 128., 128., 128.],
         [  3.,   2.,   0.,  ..., 128., 128., 128.],
         [  1.,   1.,   0.,  ..., 128., 128., 128.],
         ...,
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  0.,   0.,   1.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   1.,  ..., 128., 128., 128.],
         [  1.,   1.,   2.,  ..., 128., 128., 128.],
         [  1.,   1.,   2.,  ..., 128., 128., 128.],
         ...,
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  0.,   0.,   1.,  ..., 128., 128., 128.]],

        [[  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         [  0.,   0.,   0.,  ..., 128., 128., 128.],
         ...,
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  1.,   1.,   1.,  ..., 128., 128., 128.],
         [  0.,   0.,   1.,  ..., 128., 128., 128.]]]), 'instances': Instances(num_instances=66, image_height=1024, image_width=1024, fields=[gt_boxes: Boxes(tensor([[ 72.8339, 505.4782,  79.0134, 512.7039],
        [ 88.8160, 319.4729, 101.3275, 334.1950],
        [ 31.0331, 503.6168,  37.5174, 509.1841],
        [562.6763, 580.5775, 598.2297, 613.9813],
        [607.8123, 518.0173, 640.8940, 544.3985],
        [376.5284, 581.3389, 414.0796, 608.0247],
        [598.0605, 579.8329, 636.7799, 613.6767],
        [583.1957, 555.2285, 615.8372, 591.8136],
        [631.5485, 494.7498, 664.0884, 513.9899],
        [559.2056, 502.1954, 589.9678, 525.1076],
        [438.6623, 554.5009, 472.4043, 586.2294],
        [546.6942, 552.9440, 579.7927, 588.3785],
        [636.5259, 578.6992, 674.7375, 614.2858],
        [398.4699, 534.0762, 427.9116, 560.3728],
        [652.5419, 502.8045, 683.5920, 530.5903],
        [400.9756, 557.7160, 434.9546, 592.1013],
        [363.5260, 555.2793, 396.2013, 586.8217],
        [693.5808, 560.1528, 719.5857, 592.4059],
        [673.1461, 516.6805, 707.6160, 544.5508],
        [541.7505, 529.2365, 576.6776, 557.0223],
        [619.7311, 535.6499, 654.6752, 563.8079],
        [619.2740, 554.8732, 653.0837, 589.1738],
        [711.5438, 585.9925, 719.2979, 617.4841],
        [339.4173, 556.2946, 367.6061, 578.6484],
        [286.8659, 572.9965, 320.7433, 591.3568],
        [526.3948, 579.5622, 562.3885, 612.3229],
        [690.1102, 535.8022, 719.5857, 566.0078],
        [255.1725, 574.2994, 283.6660, 592.0167],
        [294.4337, 578.7330, 330.8506, 607.4833],
        [622.0337, 506.7981, 652.9652, 528.8643],
        [471.4562, 531.6902, 505.4352, 559.2390],
        [521.0956, 502.5846, 547.0158, 528.1027],
        [654.7767, 536.4960, 690.8381, 564.5524],
        [585.7183, 532.7901, 620.7978, 560.7281],
        [640.9448, 521.4355, 671.8932, 548.3413],
        [420.0729, 583.0143, 456.3713, 608.0586],
        [454.8984, 576.6178, 491.6031, 608.3801],
        [459.1310, 553.1133, 483.0703, 577.0408],
        [531.8971, 508.8456, 565.4190, 536.2760],
        [674.3142, 582.8619, 712.1364, 616.0964],
        [656.9269, 557.0392, 693.1406, 593.4550],
        [299.8344, 554.8901, 333.1700, 581.3559],
        [601.6666, 496.0527, 629.8724, 514.2945],
        [510.5312, 556.0577, 544.0023, 588.2769],
        [428.1317, 527.4089, 465.5645, 561.6588],
        [505.3844, 527.0705, 543.4266, 558.7652],
        [225.7139, 580.1206, 261.0473, 604.2681],
        [259.7097, 582.2189, 294.8908, 605.6050],
        [588.9012, 502.1277, 623.8113, 532.7055],
        [474.4867, 554.1455, 509.7016, 589.5291],
        [568.1786, 518.9142, 600.3630, 550.6427],
        [489.4699, 507.5596, 522.4331, 541.5726],
        [490.8582, 580.2391, 526.5302, 612.0860],
        [597.5864,   0.0000, 689.7208, 450.1606],
        [599.5334, 419.5320, 695.8495, 487.2195],
        [665.2735, 392.4062, 719.6026, 456.4894],
        [461.2980, 404.6407, 539.7697, 534.5330],
        [  8.7022, 235.0667, 231.8596, 660.4318],
        [181.6614, 600.0038, 718.2144, 828.8044],
        [427.6238,  20.3111, 444.8080,  51.9720],
        [112.9924,  44.1033, 125.2329,  68.7077],
        [596.9769,   0.0000, 689.3314, 455.3049],
        [665.7814, 392.6939, 719.6534, 445.7778],
        [599.7874, 419.4474, 694.8337, 487.3041],
        [  8.1434, 548.8998, 154.0313, 942.3503],
        [262.2493, 379.2410, 494.6845, 531.1826]])), gt_classes: tensor([134, 134, 134, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519,
        519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 519, 740, 740, 740,
        204, 204, 747, 529, 529, 672, 672, 672, 799, 645])])}], 'support_set_target': tensor(747)}
[32m[11/14 23:18:32 d2.engine.hooks]: [0mOverall training speed: 4 iterations in 0:07:24 (111.1496 s / it)
[32m[11/14 23:18:32 d2.engine.hooks]: [0mTotal training time: 0:07:24 (0:00:00 on hooks)
[32m[11/14 23:18:32 d2.utils.events]: [0m eta: 131 days, 22:09:06  iter: 6  total_loss: 1.334  time: 94.3047  data_time: 8.2448  lr: 2.8109e-07  
Executing: /usr/local/bin/flow-cli test-locally vision.few_shot_detection.meta_fcos_workflow.e2e_workflow@few_shot_detection   --name "lvis_meta_learn_[all]_[sylph_fp]_[lsj]_min_0_5" --run-as-secure-group "oncall_fai4ar" --parameters-json '{"config_file": "sylph://LVISv1-Detection/Meta-FCOS/Meta-FCOS-finetune.yaml", "output_dir": "manifold://fai4ar/tree/liyin/few-shot/meta-fcos/test/20211114230156", "runner_name": "sylph.runner.MetaFCOSRunner", "e2e_train": {"dist_config": {"num_machines": 1, "num_processes_per_machine": 4, "gang_schedule": false, "gang_affinity": false}, "resources": {"memory": "225g", "capabilities": ["GPU_A100_HOST"]}, "overwrite_opts": []}}'  --mode dev-nosan


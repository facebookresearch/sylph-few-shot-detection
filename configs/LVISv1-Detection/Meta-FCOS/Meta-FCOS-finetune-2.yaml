# This tests the continual object detection
_BASE_: "Base-Meta-FCOS.yaml" # ensure the pretraining is the same as previous training
# Overwrites
MODEL:
  META_ARCHITECTURE: "MetaOneStageDetector"
  # WEIGHTS: # pretrained weights on base classes
  DDP_FIND_UNUSED_PARAMETERS: True
  BACKBONE:
    NAME: "build_fcos_resnet_fpn_backbone"
    FREEZE: True
  PROPOSAL_GENERATOR:
    NAME: "MetaFCOS"
    # freeze by components
    FREEZE_CLS_TOWER: True
    # bbox tower and branch
    FREEZE_BBOX_BRANCH: True
  FCOS:
    NUM_CLASSES: 100 #Train with all novel categories
  META_LEARN:
    EPISODIC_LEARNING: True
    USE_ALL_GTS_IN_BASE_CLASSES: False # used in evaluation for base classes
    CLASS: 3 # define episodics, CLASS is computed from gpu setup
    SHOT: 5 # training shot
    BASE_EVAL_SHOT: 10 # -1 means using all
    EVAL_SHOT: 10 # for novel classes
    QUERY_SHOT: 1
    CODE_GENERATOR:
      NAME: "CodeGenerator"
      USE_MASK: True
      ALL_MASK: False
      MASK_NORM: "GN"
      # USE_BKG: True
      CONV_L2_NORM: True
      USE_BIAS: True # when it is on, we use prior bias and potentially predicted bias
      TOWER_LAYERS: [["GN", "ReLU"], ["GN", "ReLU"]] # Layers before the conditional conv, eg, [["GN", "ReLU"],["", ""]]
      CLS_LAYER: ["", "", 1] # (norm_type, activation type, 1*1*256)
      BIAS_LAYER: ["", "", 1]
      # WEIGHT_LAYER: ["", "", 1]
      OUT_CHANNEL: 256 #256 X 1 X 1
      CONTRASTIVE_LOSS: ""
      CLS_REWEIGHT: False
      COMPRESS_CODE_W_MAX: False
      POST_NORM: "GN" # add norm after the mean, so no "GN" in CLS_LAYER
      FREEZE: False
      DISTILLATION_LOSS_WEIGHT: 0.0 # when distillation is on, keep all setup same with pretraining
  # PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
DATASETS:
  TRAIN: ("lvis_meta_train_novelv1",) #finetune on novel categories with all the data
  TEST: ("lvis_meta_val_novelv1",) # TODO: test on all categories. If training stage is meta-finetuning, then, it loads previous class_codes, and predict for all
SOLVER:
  IMS_PER_BATCH: 48 # we use 2 machines, each with 4 gpus, each gpu get 24/8 = 3 classes, 3*4
  BASE_LR: 0.0005
  STEPS: (20000, 26000) # (12000, 20000), (10000, 20000, 25000) # (60000, 80000)
  MAX_ITER: 30000 #45000 #90000
  REFERENCE_WORLD_SIZE: 16 # do not rescale
  CHECKPOINT_PERIOD: 5000

  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "norm"
    CLIP_VALUE: 1.0

TEST:
  REPEAT_TEST: 5

DATALOADER:
  ASPECT_RATIO_GROUPING: False # Does not support grouping now
  NUM_WORKERS: 8
  # SAMPLER_TRAIN: "SupportSetRepeatFactorTrainingSampler"  # RepeatFactorTrainingSampler
  # REPEAT_THRESHOLD: 0.001
# set up data loader
D2GO_DATA:
  AUG_OPS:
    TRAIN:
      [
        "ResizeShortestEdgeOp",
        "RandomFlipOp",
        'RandAugmentOp::{"magnitude":9.0, "magnitude_std":0.5, "increasing":1}',
      ]
    #   [
    #   ["ResizeShortestEdgeOp", "RandomFlipOp"]
    #   'ResizeScaleOp::{"min_scale": 0.1, "max_scale": 2.0, "target_height": 1024, "target_width": 1024}',
    #   "RandomFlipOp",
    #   'FixedSizeCropOp::{"crop_size": [1024, 1024]}',
    #   # 'RandAugmentOp::{"magnitude":9.0, "magnitude_std":0.5, "increasing":1}',
    # ]
    TEST: ["ResizeShortestEdgeOp"]
  MAPPER:
    BACKFILL_SIZE: False
    CATCH_EXCEPTION: True
    NAME: MetalearnDatasetMapper
    RETRY: 3

#!/usr/bin/env python3
"""define logics that takes in
query_images
query_features
query_gt_instances
proposals (faster rcnn)
class_codes
support_set_gt_instances

Two steps:
* use class codes to get class logits
* use clas logits and support set gt instances to adapt the loss
"""

from .fcos import MetaFCOS  # noqa
# from .fast_rcnn_predictor_head import BiStandardROIHeads # noqa

# a = [{'support_set': [{'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000110442.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [498, 27, 1077, 242, 156, 449, 556], 'image_id': 110442, 'image': tensor([[[172., 175., 179.,  ..., 255., 255., 255.],
#          [175., 175., 176.,  ..., 255., 255., 255.],
#          [179., 176., 171.,  ..., 255., 255., 255.],
#          ...,
#          [ 41.,  30.,  13.,  ..., 107., 105., 103.],
#          [ 36.,  26.,  11.,  ..., 112., 108., 105.],
#          [ 32.,  23.,  10.,  ..., 116., 110., 106.]],

#         [[153., 154., 155.,  ..., 255., 255., 255.],
#          [153., 154., 156.,  ..., 255., 255., 255.],
#          [153., 155., 157.,  ..., 255., 255., 255.],
#          ...,
#          [ 46.,  47.,  48.,  ..., 126., 127., 128.],
#          [ 44.,  45.,  45.,  ..., 127., 128., 128.],
#          [ 43.,  43.,  43.,  ..., 127., 128., 128.]],

#         [[138., 137., 135.,  ..., 255., 255., 255.],
#          [138., 138., 136.,  ..., 255., 255., 255.],
#          [139., 139., 138.,  ..., 255., 255., 255.],
#          ...,
#          [ 71.,  72.,  74.,  ..., 159., 160., 160.],
#          [ 67.,  67.,  65.,  ..., 158., 158., 158.],
#          [ 65.,  63.,  59.,  ..., 157., 156., 156.]]]), 'instances': Instances(num_instances=1, image_height=1067, image_width=800, fields=[gt_boxes: Boxes(tensor([[320.4167,   0.0000, 415.4167, 224.8203]])), gt_classes: tensor([0])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000554860.jpg', 'height': 640, 'width': 428, 'not_exhaustive_category_ids': [133], 'neg_category_ids': [475, 1072, 259, 635, 587, 157, 572, 1115], 'image_id': 554860, 'image': tensor([[[ 41.,  43.,  45.,  ...,  52.,  53.,  53.],
#          [ 41.,  43.,  45.,  ...,  53.,  54.,  53.],
#          [ 41.,  43.,  46.,  ...,  55.,  55.,  54.],
#          ...,
#          [ 41.,  38.,  35.,  ...,  36.,  29.,  24.],
#          [ 43.,  39.,  33.,  ...,  34.,  29.,  26.],
#          [ 44.,  39.,  31.,  ...,  33.,  29.,  27.]],

#         [[ 47.,  46.,  44.,  ...,  73.,  74.,  74.],
#          [ 48.,  46.,  43.,  ...,  72.,  73.,  73.],
#          [ 49.,  46.,  41.,  ...,  71.,  71.,  71.],
#          ...,
#          [ 11.,  10.,   8.,  ...,  26.,  23.,  21.],
#          [  9.,   9.,   8.,  ...,  25.,  22.,  21.],
#          [  8.,   8.,   8.,  ...,  24.,  22.,  21.]],

#         [[ 54.,  53.,  52.,  ..., 124., 125., 125.],
#          [ 52.,  52.,  51.,  ..., 125., 126., 126.],
#          [ 49.,  50.,  50.,  ..., 127., 127., 127.],
#          ...,
#          [  0.,   0.,   0.,  ...,  54.,  49.,  47.],
#          [  0.,   1.,   2.,  ...,  52.,  48.,  46.],
#          [  0.,   1.,   3.,  ...,  51.,  48.,  46.]]]), 'instances': Instances(num_instances=5, image_height=1196, image_width=800, fields=[gt_boxes: Boxes(tensor([[465.1776, 211.7668, 491.9065, 310.3246],
#         [522.0560, 364.3876, 536.9532, 405.5187],
#         [624.4860, 305.9331, 668.5607, 317.2951],
#         [545.9813, 354.5766, 570.6168, 449.4344],
#         [514.5421, 378.6274, 533.9626, 455.1154]])), gt_classes: tensor([0, 0, 0, 0, 0])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000292118.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [452, 522, 266, 526, 1159, 600, 646, 780], 'image_id': 292118, 'image': tensor([[[ 31.,  32.,  33.,  ...,  96.,  87.,  81.],
#          [ 33.,  34.,  34.,  ..., 102.,  89.,  81.],
#          [ 36.,  36.,  35.,  ..., 111.,  92.,  80.],
#          ...,
#          [160., 160., 160.,  ..., 136., 131., 127.],
#          [164., 162., 161.,  ..., 146., 141., 137.],
#          [166., 164., 162.,  ..., 152., 147., 144.]],

#         [[ 28.,  29.,  30.,  ..., 151., 110.,  83.],
#          [ 30.,  31.,  31.,  ..., 154., 111.,  83.],
#          [ 33.,  33.,  32.,  ..., 158., 113.,  83.],
#          ...,
#          [163., 163., 163.,  ..., 131., 127., 125.],
#          [167., 165., 164.,  ..., 141., 137., 135.],
#          [169., 167., 165.,  ..., 147., 144., 142.]],

#         [[ 30.,  31.,  32.,  ..., 212., 159., 124.],
#          [ 32.,  33.,  33.,  ..., 215., 159., 123.],
#          [ 35.,  35.,  34.,  ..., 219., 160., 121.],
#          ...,
#          [168., 168., 167.,  ..., 132., 128., 125.],
#          [172., 170., 169.,  ..., 142., 138., 135.],
#          [174., 172., 170.,  ..., 148., 144., 142.]]]), 'instances': Instances(num_instances=1, image_height=800, image_width=1067, fields=[gt_boxes: Boxes(tensor([[111.6682, 514.5667, 167.3523, 586.7333]])), gt_classes: tensor([0])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000150032.jpg', 'height': 640, 'width': 480, 'not_exhaustive_category_ids': [], 'neg_category_ids': [650, 884, 82, 312, 62, 1196, 1013], 'image_id': 150032, 'image': tensor([[[124., 123., 122.,  ..., 133., 133., 133.],
#          [124., 123., 122.,  ..., 133., 133., 133.],
#          [123., 123., 123.,  ..., 133., 132., 132.],
#          ...,
#          [129., 129., 130.,  ..., 118., 117., 117.],
#          [129., 128., 128.,  ..., 117., 117., 117.],
#          [129., 128., 127.,  ..., 117., 117., 117.]],

#         [[119., 119., 120.,  ..., 128., 126., 124.],
#          [120., 120., 120.,  ..., 128., 126., 124.],
#          [121., 121., 121.,  ..., 127., 125., 124.],
#          ...,
#          [132., 132., 133.,  ..., 120., 119., 119.],
#          [131., 131., 131.,  ..., 119., 119., 119.],
#          [131., 130., 129.,  ..., 119., 119., 119.]],

#         [[120., 120., 120.,  ..., 130., 128., 127.],
#          [120., 120., 120.,  ..., 129., 127., 126.],
#          [120., 120., 120.,  ..., 128., 126., 125.],
#          ...,
#          [130., 130., 131.,  ..., 120., 119., 119.],
#          [131., 130., 130.,  ..., 119., 119., 119.],
#          [131., 130., 129.,  ..., 119., 119., 119.]]]), 'instances': Instances(num_instances=1, image_height=1067, image_width=800, fields=[gt_boxes: Boxes(tensor([[734.8833, 601.1544, 769.4333, 727.3772]])), gt_classes: tensor([0])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000449098.jpg', 'height': 640, 'width': 427, 'not_exhaustive_category_ids': [1178], 'neg_category_ids': [254, 219, 607, 720, 511, 208, 443, 914], 'image_id': 449098, 'image': tensor([[[ 83.,  85.,  87.,  ...,  35.,  38.,  40.],
#          [ 81.,  84.,  87.,  ...,  35.,  38.,  41.],
#          [ 79.,  82.,  86.,  ...,  34.,  39.,  42.],
#          ...,
#          [178., 177., 175.,  ..., 163., 157., 154.],
#          [176., 174., 170.,  ..., 153., 166., 174.],
#          [175., 172., 167.,  ..., 147., 171., 185.]],

#         [[ 68.,  72.,  78.,  ...,  30.,  31.,  31.],
#          [ 67.,  71.,  76.,  ...,  29.,  30.,  31.],
#          [ 66.,  69.,  74.,  ...,  27.,  29.,  30.],
#          ...,
#          [159., 160., 160.,  ..., 138., 133., 130.],
#          [160., 159., 155.,  ..., 127., 140., 148.],
#          [161., 158., 153.,  ..., 120., 144., 158.]],

#         [[ 76.,  77.,  79.,  ...,  25.,  27.,  28.],
#          [ 75.,  76.,  78.,  ...,  25.,  27.,  28.],
#          [ 73.,  74.,  76.,  ...,  25.,  27.,  28.],
#          ...,
#          [138., 140., 143.,  ..., 108., 103.,  99.],
#          [139., 139., 138.,  ...,  98., 112., 120.],
#          [139., 138., 136.,  ...,  93., 117., 131.]]]), 'instances': Instances(num_instances=1, image_height=1199, image_width=800, fields=[gt_boxes: Boxes(tensor([[320.7869, 395.4827, 341.5644, 474.4668]])), gt_classes: tensor([0])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000270096.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [581, 807, 1047, 304, 176, 81, 672, 1062, 1130, 202, 1084, 243, 357, 116, 801, 781], 'image_id': 270096, 'image': tensor([[[ 89.,  86.,  82.,  ...,  93.,  95.,  96.],
#          [ 97.,  90.,  80.,  ..., 107.,  99.,  94.],
#          [108.,  95.,  76.,  ..., 127., 105.,  91.],
#          ...,
#          [ 46.,  45.,  43.,  ...,   4.,   2.,   0.],
#          [ 36.,  37.,  36.,  ...,   6.,   4.,   2.],
#          [ 30.,  31.,  32.,  ...,   7.,   5.,   3.]],

#         [[122., 124., 127.,  ...,  87.,  85.,  84.],
#          [116., 114., 111.,  ...,  99.,  97.,  95.],
#          [108., 100.,  87.,  ..., 118., 114., 111.],
#          ...,
#          [ 78.,  74.,  69.,  ...,  17.,  14.,  12.],
#          [ 76.,  75.,  73.,  ...,  21.,  19.,  17.],
#          [ 75.,  75.,  76.,  ...,  23.,  22.,  21.]],

#         [[161., 162., 164.,  ..., 134.,  97.,  72.],
#          [156., 151., 144.,  ..., 145., 112.,  90.],
#          [148., 134., 114.,  ..., 161., 134., 116.],
#          ...,
#          [ 97.,  95.,  93.,  ...,  31.,  28.,  26.],
#          [ 86.,  88.,  91.,  ...,  36.,  35.,  33.],
#          [ 79.,  83.,  89.,  ...,  40.,  39.,  38.]]]), 'instances': Instances(num_instances=1, image_height=800, image_width=1067, fields=[gt_boxes: Boxes(tensor([[234.9734,   0.0000, 268.4005,  44.3167]])), gt_classes: tensor([0])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000188702.jpg', 'height': 427, 'width': 640, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1003, 259, 1148, 910, 954, 527, 360, 845, 43], 'image_id': 188702, 'image': tensor([[[ 78.,  68.,  50.,  ...,  41.,  39.,  37.],
#          [ 79.,  70.,  52.,  ...,  37.,  34.,  32.],
#          [ 81.,  72.,  57.,  ...,  31.,  26.,  22.],
#          ...,
#          [181., 182., 183.,  ..., 169., 170., 170.],
#          [180., 181., 182.,  ..., 168., 169., 169.],
#          [180., 181., 182.,  ..., 168., 169., 169.]],

#         [[ 90.,  79.,  59.,  ...,  41.,  40.,  40.],
#          [ 92.,  81.,  61.,  ...,  37.,  35.,  34.],
#          [ 94.,  84.,  66.,  ...,  30.,  26.,  23.],
#          ...,
#          [176., 178., 180.,  ..., 181., 180., 180.],
#          [175., 177., 179.,  ..., 180., 179., 179.],
#          [175., 177., 179.,  ..., 180., 179., 179.]],

#         [[ 96.,  85.,  66.,  ...,  43.,  44.,  44.],
#          [ 98.,  87.,  68.,  ...,  39.,  39.,  38.],
#          [100.,  90.,  72.,  ...,  33.,  29.,  27.],
#          ...,
#          [177., 178., 180.,  ..., 187., 187., 187.],
#          [176., 177., 179.,  ..., 186., 186., 186.],
#          [176., 177., 179.,  ..., 186., 186., 186.]]]), 'instances': Instances(num_instances=1, image_height=800, image_width=1199, fields=[gt_boxes: Boxes(tensor([[642.6078, 195.1476, 706.6606, 377.4801]])), gt_classes: tensor([0])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000305781.jpg', 'height': 400, 'width': 500, 'not_exhaustive_category_ids': [], 'neg_category_ids': [236, 559, 324, 584, 350, 1007, 970, 176, 308, 32, 746, 182, 1112, 575, 95, 1141], 'image_id': 305781, 'image': tensor([[[  1.,   8.,  21.,  ..., 252., 253., 253.],
#          [ 15.,  21.,  31.,  ..., 253., 254., 254.],
#          [ 43.,  46.,  50.,  ..., 254., 255., 255.],
#          ...,
#          [ 92.,  93.,  94.,  ..., 227., 235., 239.],
#          [ 93.,  94.,  95.,  ..., 228., 236., 240.],
#          [ 94.,  95.,  96.,  ..., 229., 236., 240.]],

#         [[ 76.,  73.,  68.,  ..., 254., 255., 255.],
#          [ 68.,  66.,  62.,  ..., 254., 255., 255.],
#          [ 51.,  51.,  50.,  ..., 255., 255., 255.],
#          ...,
#          [ 88.,  89.,  90.,  ..., 182., 189., 192.],
#          [ 89.,  90.,  91.,  ..., 178., 185., 188.],
#          [ 90.,  91.,  92.,  ..., 176., 183., 186.]],

#         [[  2.,   9.,  24.,  ..., 254., 255., 255.],
#          [ 22.,  26.,  35.,  ..., 254., 255., 255.],
#          [ 61.,  59.,  56.,  ..., 255., 255., 255.],
#          ...,
#          [100., 101., 102.,  ..., 159., 165., 168.],
#          [101., 102., 103.,  ..., 156., 162., 165.],
#          [102., 103., 104.,  ..., 154., 160., 163.]]]), 'instances': Instances(num_instances=1, image_height=800, image_width=1000, fields=[gt_boxes: Boxes(tensor([[810.5600, 424.5800, 867.9200, 544.7600]])), gt_classes: tensor([0])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000341397.jpg', 'height': 640, 'width': 613, 'not_exhaustive_category_ids': [], 'neg_category_ids': [1170, 745, 681, 293, 66, 1088, 977, 940], 'image_id': 341397, 'image': tensor([[[132., 131., 131.,  ..., 134., 135., 136.],
#          [138., 136., 136.,  ..., 135., 136., 137.],
#          [143., 141., 140.,  ..., 136., 136., 137.],
#          ...,
#          [226., 228., 227.,  ..., 126., 128., 128.],
#          [225., 224., 223.,  ..., 126., 128., 130.],
#          [224., 219., 218.,  ..., 125., 128., 133.]],

#         [[135., 135., 136.,  ..., 143., 143., 143.],
#          [141., 140., 141.,  ..., 144., 144., 144.],
#          [146., 146., 146.,  ..., 144., 144., 144.],
#          ...,
#          [225., 228., 228.,  ..., 134., 136., 136.],
#          [224., 225., 224.,  ..., 134., 136., 138.],
#          [223., 221., 221.,  ..., 133., 135., 139.]],

#         [[133., 133., 134.,  ..., 140., 140., 140.],
#          [139., 138., 139.,  ..., 141., 141., 141.],
#          [143., 143., 143.,  ..., 141., 141., 141.],
#          ...,
#          [215., 219., 218.,  ..., 133., 135., 135.],
#          [214., 216., 215.,  ..., 133., 135., 137.],
#          [213., 212., 212.,  ..., 133., 134., 138.]]]), 'instances': Instances(num_instances=1, image_height=835, image_width=800, fields=[gt_boxes: Boxes(tensor([[669.2855, 479.9554, 690.5579, 539.6579]])), gt_classes: tensor([0])])}, {'file_name': 'memcache_manifold://fair_vision_data/tree/coco_train2017/000000321242.jpg', 'height': 480, 'width': 640, 'not_exhaustive_category_ids': [818], 'neg_category_ids': [759, 345, 50, 1074, 462, 205, 530, 577], 'image_id': 321242, 'image': tensor([[[ 21.,  20.,  19.,  ...,  76.,  79.,  81.],
#          [ 21.,  19.,  18.,  ...,  76.,  75.,  75.],
#          [ 20.,  18.,  16.,  ...,  77.,  70.,  66.],
#          ...,
#          [ 30.,  29.,  27.,  ...,  51.,  47.,  44.],
#          [ 32.,  31.,  28.,  ...,  41.,  42.,  42.],
#          [ 34.,  32.,  28.,  ...,  34.,  38.,  41.]],

#         [[ 26.,  25.,  23.,  ..., 100.,  97.,  95.],
#          [ 28.,  27.,  25.,  ..., 100.,  97.,  96.],
#          [ 31.,  29.,  27.,  ..., 100.,  98.,  97.],
#          ...,
#          [ 38.,  37.,  35.,  ...,  53.,  47.,  43.],
#          [ 42.,  41.,  37.,  ...,  44.,  44.,  44.],
#          [ 45.,  43.,  39.,  ...,  38.,  42.,  45.]],

#         [[ 29.,  29.,  28.,  ..., 120., 118., 117.],
#          [ 33.,  32.,  31.,  ..., 121., 119., 117.],
#          [ 39.,  37.,  35.,  ..., 122., 120., 118.],
#          ...,
#          [ 37.,  36.,  34.,  ...,  77.,  76.,  75.],
#          [ 41.,  39.,  36.,  ...,  64.,  67.,  68.],
#          [ 43.,  41.,  37.,  ...,  56.,  61.,  64.]]]), 'instances': Instances(num_instances=1, image_height=800, image_width=1067, fields=[gt_boxes: Boxes(tensor([[ 74.8734, 700.7833, 118.4370, 800.0000]])), gt_classes: tensor([0])])}], 'support_set_target': tensor(0), 'class_name': 'aerosol_can'}]
